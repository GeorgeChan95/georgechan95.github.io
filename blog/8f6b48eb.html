<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>025-K8S-二进制高可用部署 | George&#39;s Blog</title>
  <meta name="google-site-verification" content="RobLWkyyFziZxPJ4I887QROdX8XrYthcJwWTcuH0wwQ" />
  <meta name="msvalidate.01" content="626D541C48E5D151F52CECC2C6714BD4" />
  <meta name="360-site-verification" content="c838adf8357ca2f614d08ad5235a1717" />
  <meta name="keywords" content=" linux , Docker , Rocky , Etcd ">
  <meta name="description" content="025-K8S-二进制高可用部署 | George&#39;s Blog">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="一、系统环境 操作系统：Rocky Linux 9.3 内核版本：5.14.0-284.11.1.el9_2.x86_64 容器运行时：Docker + CRI-Docker Kubernetes 版本：1.29.2 网络插件：Calico  二、集群规划基于二进制安装包，部署三主两从的高可用集群。    主机名称 IPV4地址 CPU&#x2F;内存&#x2F;磁盘 说明 软件     10.2">
<meta property="og:type" content="article">
<meta property="og:title" content="025-K8S-二进制高可用部署">
<meta property="og:url" content="https://georgechan95.github.io/blog/8f6b48eb.html">
<meta property="og:site_name" content="George&#39;s Blog">
<meta property="og:description" content="一、系统环境 操作系统：Rocky Linux 9.3 内核版本：5.14.0-284.11.1.el9_2.x86_64 容器运行时：Docker + CRI-Docker Kubernetes 版本：1.29.2 网络插件：Calico  二、集群规划基于二进制安装包，部署三主两从的高可用集群。    主机名称 IPV4地址 CPU&#x2F;内存&#x2F;磁盘 说明 软件     10.2">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/04/20250104-112243.png">
<meta property="og:image" content="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/11/20251011-124215.png">
<meta property="og:image" content="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/18/20251018-150523.png">
<meta property="og:image" content="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/18/20251018-151718.png">
<meta property="og:image" content="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/28/20251028-204641.png">
<meta property="og:image" content="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/28/20251028-204754.png">
<meta property="article:published_time" content="2025-09-30T22:33:00.000Z">
<meta property="article:modified_time" content="2025-10-30T07:13:01.979Z">
<meta property="article:author" content="George">
<meta property="article:tag" content="linux">
<meta property="article:tag" content="Docker">
<meta property="article:tag" content="Rocky">
<meta property="article:tag" content="Etcd">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/04/20250104-112243.png">


<link rel="icon" href="/img/favicon.png">

<link href="/css/style.css?v=1.1.0" rel="stylesheet">

<link href="/css/hl_theme/sublime.css?v=1.1.0" rel="stylesheet">

<link href="//cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" rel="stylesheet">

<script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="/js/titleTip.js?v=1.1.0" ></script>

<script src="//cdn.jsdelivr.net/npm/highlightjs@9.16.2/highlight.pack.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script>



<script src="//cdn.jsdelivr.net/npm/jquery.cookie@1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.1.0" ></script>

<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="George's Blog" type="application/atom+xml">
</head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="">
  <input class="theme_blog_path" value="">
  <input id="theme_shortcut" value="true" />
  <input id="theme_highlight_on" value="true" />
  <input id="theme_code_copy" value="true" />
</div>



<script src="/js/image-loader.js"></script>
<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/"
   class="avatar_target">
    <img class="avatar"
         src="/img/avatar.jpg"/>
</a>
<div class="author">
    <span>George</span>
</div>

<div class="icon">
    
        
            <a title="rss"
               href="/atom.xml"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-rss"></use>
                    </svg>
                
            </a>
        
    
        
            <a title="github"
               href="https://github.com/GeorgeChan95"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-github"></use>
                    </svg>
                
            </a>
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
            <a title="email"
               href="mailto:george_95@126.com"
               target="_blank">
                
                    <svg class="iconfont-svg" aria-hidden="true">
                        <use xlink:href="#icon-email"></use>
                    </svg>
                
            </a>
        
    
        
    
        
    
        
    
</div>





<ul>
    <li>
        <div class="all active" data-rel="全部文章">全部文章
            
                <small>(122)</small>
            
        </div>
    </li>
    
        
            
                
    <li>
        <div data-rel="设计模式">
            
            设计模式
            <small>(24)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="算法">
            
            算法
            <small>(5)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="Docker">
            
            Docker
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="Hexo">
            <i class="fold iconfont icon-right"></i>
            Hexo
            <small>(5)</small>
        </div>
        
            <ul class="sub hide">
                
                    
    <li>
        <div data-rel="Hexo&lt;---&gt;Typora">
            
            Typora
            <small>(1)</small>
        </div>
        
    </li>

                
            </ul>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="JUC">
            
            JUC
            <small>(24)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="JVM">
            
            JVM
            <small>(27)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="k8s">
            
            k8s
            <small>(25)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="linux">
            
            linux
            <small>(4)</small>
        </div>
        
    </li>

            
        
    
        
            
                
    <li>
        <div data-rel="neo4j">
            
            neo4j
            <small>(3)</small>
        </div>
        
    </li>

            
        
    
        
            
        
    
        
            
                
    <li>
        <div data-rel="Python">
            <i class="fold iconfont icon-right"></i>
            Python
            <small>(3)</small>
        </div>
        
            <ul class="sub hide">
                
                    
    <li>
        <div data-rel="Python&lt;---&gt;PyCharm">
            
            PyCharm
            <small>(1)</small>
        </div>
        
    </li>

                
            </ul>
        
    </li>

            
        
    
        
            
        
    
        
            
                
    <li>
        <div data-rel="UML">
            
            UML
            <small>(1)</small>
        </div>
        
    </li>

            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
        
            
            
            
    </div>
    <div>
        
            <a class="about  site_url"
               
               href="/about">关于</a>
        
        
    </div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="122">
<input type="hidden" id="yelog_site_word_count" value="627.9k">
<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="iconfont icon-left"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://yelog.org/">叶落阁</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <div class="right-top">
        <div id="default-panel">
            <i class="iconfont icon-search" data-title="搜索 快捷键 i"></i>
            <div class="right-title">全部文章</div>
            <i class="iconfont icon-file-tree" data-title="切换到大纲视图 快捷键 w"></i>
        </div>
        <div id="search-panel">
            <i class="iconfont icon-left" data-title="返回"></i>
            <input id="local-search-input" autocomplete="off"/>
            <label class="border-line" for="input"></label>
            <i class="iconfont icon-case-sensitive" data-title="大小写敏感"></i>
            <i class="iconfont icon-tag" data-title="标签"></i>
        </div>
        <div id="outline-panel" style="display: none">
            <div class="right-title">大纲</div>
            <i class="iconfont icon-list" data-title="切换到文章列表"></i>
        </div>
    </div>

    <div class="tags-list">
    <input id="tag-search" />
    <div class="tag-wrapper">
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>插入排序</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>二分法</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>二进制</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>合并有序链表</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>科学上网</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>链表</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>冒泡排序</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>设计模式</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>双亲委派机制</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>算法</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>位运算</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>选择排序</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Docker</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Etcd</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>github</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>github pages</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Harbor</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>hexo</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>java</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>jenkins</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>juc</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>jvm</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>linux</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Loki</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>neo4j</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Pod</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Prometheus</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Python</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Rocky</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>sitemap</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>SpringBoot</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>typora</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>ubuntu18</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>UML</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Velero</a>
            </li>
        
    </div>

</div>

    
    <nav id="title-list-nav">
        
        
        <a  class="全部文章 k8s "
           href="/blog/8f6b48eb.html"
           data-tag="linux,Docker,Rocky,Etcd"
           data-author="" >
            <span class="post-title" title="025-K8S-二进制高可用部署">025-K8S-二进制高可用部署</span>
            <span class="post-date" title="2025-10-01 06:33:00">2025/10/01</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/7a3c8be2.html"
           data-tag="linux,Docker,Rocky,Etcd,Velero"
           data-author="" >
            <span class="post-title" title="024-K8S-Etcd的备份与恢复">024-K8S-Etcd的备份与恢复</span>
            <span class="post-date" title="2025-09-14 17:30:00">2025/09/14</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/847bacfd.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="023-K8S-Cordon和Drain的使用">023-K8S-Cordon和Drain的使用</span>
            <span class="post-date" title="2025-09-12 20:11:00">2025/09/12</span>
        </a>
        
        
        <a  class="全部文章 Python PyCharm "
           href="/blog/2cd8097a.html"
           data-tag="Python"
           data-author="" >
            <span class="post-title" title="003-PyCharm下载和安装">003-PyCharm下载和安装</span>
            <span class="post-date" title="2025-09-10 12:17:00">2025/09/10</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/6617f273.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="022-K8S-资源限制">022-K8S-资源限制</span>
            <span class="post-date" title="2025-09-09 21:03:00">2025/09/09</span>
        </a>
        
        
        <a  class="全部文章 Python "
           href="/blog/7591dd09.html"
           data-tag="Python"
           data-author="" >
            <span class="post-title" title="002-安装Python开发环境">002-安装Python开发环境</span>
            <span class="post-date" title="2025-09-08 20:22:00">2025/09/08</span>
        </a>
        
        
        <a  class="全部文章 Python "
           href="/blog/95026633.html"
           data-tag="Python"
           data-author="" >
            <span class="post-title" title="001-Python语言概述">001-Python语言概述</span>
            <span class="post-date" title="2025-09-07 10:44:00">2025/09/07</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/e2c03adc.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="021-K8S-安全参数">021-K8S-安全参数</span>
            <span class="post-date" title="2025-08-23 14:43:00">2025/08/23</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/88f4f580.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="020-K8S-审计">020-K8S-审计</span>
            <span class="post-date" title="2025-08-10 14:43:00">2025/08/10</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/9bea6e2e.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="019-K8S-kubectl端口转发">019-K8S-kubectl端口转发</span>
            <span class="post-date" title="2025-08-04 23:02:00">2025/08/04</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/af9812e0.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="018-K8S-临时容器">018-K8S-临时容器</span>
            <span class="post-date" title="2025-08-03 22:01:00">2025/08/03</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/99657768.html"
           data-tag="linux,Docker,Rocky,Pod"
           data-author="" >
            <span class="post-title" title="017-K8S-网络策略NetworkPolicy">017-K8S-网络策略NetworkPolicy</span>
            <span class="post-date" title="2025-07-28 21:33:00">2025/07/28</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/c9536d9e.html"
           data-tag="linux,Docker,Rocky,Pod"
           data-author="" >
            <span class="post-title" title="016-K8S-固定Pod IP地址，基于Calico插件">016-K8S-固定Pod IP地址，基于Calico插件</span>
            <span class="post-date" title="2025-07-26 13:35:00">2025/07/26</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/e62b8338.html"
           data-tag="linux,Docker,Rocky,Prometheus"
           data-author="" >
            <span class="post-title" title="015-K8S-Prometheus部署及监控告警">015-K8S-Prometheus部署及监控告警</span>
            <span class="post-date" title="2025-07-19 16:39:00">2025/07/19</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/f8cf646f.html"
           data-tag="linux,Docker,Rocky,Loki"
           data-author="" >
            <span class="post-title" title="014-K8S-部署Loki+Promtail+Grafana实现日志监控">014-K8S-部署Loki+Promtail+Grafana实现日志监控</span>
            <span class="post-date" title="2025-07-10 21:00:00">2025/07/10</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/3fee6d19.html"
           data-tag="linux,Docker,Rocky,Harbor"
           data-author="" >
            <span class="post-title" title="013-K8S-使用Helm安装Harbor">013-K8S-使用Helm安装Harbor</span>
            <span class="post-date" title="2025-07-07 22:37:00">2025/07/07</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/b42f2c7b.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="012-新建Node节点添加到K8S集群中">012-新建Node节点添加到K8S集群中</span>
            <span class="post-date" title="2025-07-07 20:32:00">2025/07/07</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/6436eaf1.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="011-Kubernetes Ingress-Nginx">011-Kubernetes Ingress-Nginx</span>
            <span class="post-date" title="2025-06-25 19:42:00">2025/06/25</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/d8e3c7b3.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="010-Kubernetes Helm">010-Kubernetes Helm</span>
            <span class="post-date" title="2025-06-21 14:12:00">2025/06/21</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/424f1119.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="009-Kubernetes 集群安全机制">009-Kubernetes 集群安全机制</span>
            <span class="post-date" title="2025-06-14 09:18:00">2025/06/14</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/f2285a2d.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="008-Kubernetes 调度器">008-Kubernetes 调度器</span>
            <span class="post-date" title="2025-06-02 14:40:00">2025/06/02</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/ef156b88.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="007-Kubernetes 存储">007-Kubernetes 存储</span>
            <span class="post-date" title="2025-05-02 10:26:00">2025/05/02</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/970719d6.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="006-Kubernetes Service">006-Kubernetes Service</span>
            <span class="post-date" title="2025-04-28 22:10:00">2025/04/28</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/c790096a.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="005-Kubernetes控制器">005-Kubernetes控制器</span>
            <span class="post-date" title="2025-04-02 20:12:00">2025/04/02</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/79e06aab.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="004-Pod的生命周期">004-Pod的生命周期</span>
            <span class="post-date" title="2025-03-22 09:05:00">2025/03/22</span>
        </a>
        
        
        <a  class="全部文章 Docker "
           href="/blog/b01d5c62.html"
           data-tag="linux,Docker,科学上网"
           data-author="" >
            <span class="post-title" title="Docker配置网络代理实现外网镜像下载">Docker配置网络代理实现外网镜像下载</span>
            <span class="post-date" title="2025-01-08 23:00:00">2025/01/08</span>
        </a>
        
        
        <a  class="全部文章 linux "
           href="/blog/7f174b3e.html"
           data-tag="linux,科学上网,Rocky"
           data-author="" >
            <span class="post-title" title="Rocky9安装Shadowsocks实现科学上网">Rocky9安装Shadowsocks实现科学上网</span>
            <span class="post-date" title="2025-01-08 21:09:00">2025/01/08</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/b00f53e9.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="003-基于Rocky9.3系统使用kubeadm安装k8s1.29集群">003-基于Rocky9.3系统使用kubeadm安装k8s1.29集群</span>
            <span class="post-date" title="2025-01-03 22:05:00">2025/01/03</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/3c79d8d9.html"
           data-tag="linux,Docker,Rocky"
           data-author="" >
            <span class="post-title" title="002-Rocky9.3系统初始化设置和Docker安装">002-Rocky9.3系统初始化设置和Docker安装</span>
            <span class="post-date" title="2025-01-02 13:25:00">2025/01/02</span>
        </a>
        
        
        <a  class="全部文章 k8s "
           href="/blog/7e3a5200.html"
           data-tag="linux,Rocky"
           data-author="" >
            <span class="post-title" title="001-ESXi8安装Rocky9.3虚拟机">001-ESXi8安装Rocky9.3虚拟机</span>
            <span class="post-date" title="2025-01-02 09:34:00">2025/01/02</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/77d85f50.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="25-责任链模式">25-责任链模式</span>
            <span class="post-date" title="2024-12-03 21:08:00">2024/12/03</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/fcec839d.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="24-策略模式">24-策略模式</span>
            <span class="post-date" title="2024-12-02 18:16:00">2024/12/02</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/6109865a.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="23-状态模式">23-状态模式</span>
            <span class="post-date" title="2024-11-29 19:30:00">2024/11/29</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/58d4db7.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="22-解释器模式">22-解释器模式</span>
            <span class="post-date" title="2024-11-28 22:00:00">2024/11/28</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/a5cf7eb4.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="21-备忘录模式">21-备忘录模式</span>
            <span class="post-date" title="2024-11-27 21:40:00">2024/11/27</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/3148d6be.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="20-中介者模式">20-中介者模式</span>
            <span class="post-date" title="2024-11-26 20:35:00">2024/11/26</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/f06aea0b.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="19-观察者模式">19-观察者模式</span>
            <span class="post-date" title="2024-11-25 21:07:00">2024/11/25</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/7dbd9149.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="18-迭代器模式">18-迭代器模式</span>
            <span class="post-date" title="2024-11-24 00:02:00">2024/11/24</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/4fdf6e52.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="17-访问者模式">17-访问者模式</span>
            <span class="post-date" title="2024-11-23 21:55:00">2024/11/23</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/60fd53f.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="16-命令模式">16-命令模式</span>
            <span class="post-date" title="2024-11-23 20:30:00">2024/11/23</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/4930323d.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="15-模板方法模式">15-模板方法模式</span>
            <span class="post-date" title="2024-11-23 19:40:00">2024/11/23</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/e4235185.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="14-代理模式">14-代理模式</span>
            <span class="post-date" title="2024-11-21 23:16:00">2024/11/21</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/1b225c1f.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="13-享元模式">13-享元模式</span>
            <span class="post-date" title="2024-11-20 23:10:00">2024/11/20</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/906e9e8b.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="12-外观模式">12-外观模式</span>
            <span class="post-date" title="2024-11-20 22:09:00">2024/11/20</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/c456a66a.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="11-组合模式">11-组合模式</span>
            <span class="post-date" title="2024-11-16 17:00:00">2024/11/16</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/90213fc6.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="10-装饰器模式">10-装饰器模式</span>
            <span class="post-date" title="2024-11-16 14:06:00">2024/11/16</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/c7419cfa.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="09-桥接模式">09-桥接模式</span>
            <span class="post-date" title="2024-11-14 20:51:00">2024/11/14</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/f77fc055.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="08-适配器模式">08-适配器模式</span>
            <span class="post-date" title="2024-11-12 22:55:00">2024/11/12</span>
        </a>
        
        
        <a  class="全部文章 neo4j "
           href="/blog/a3b0b090.html"
           data-tag="neo4j,SpringBoot"
           data-author="" >
            <span class="post-title" title="Spring Boot对Neo4j节点关系的增删改查">Spring Boot对Neo4j节点关系的增删改查</span>
            <span class="post-date" title="2024-11-12 21:00:30">2024/11/12</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/3ab9aa56.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="07-建造者模式">07-建造者模式</span>
            <span class="post-date" title="2024-11-11 21:55:00">2024/11/11</span>
        </a>
        
        
        <a  class="全部文章 neo4j "
           href="/blog/7dc0fcde.html"
           data-tag="neo4j,SpringBoot"
           data-author="" >
            <span class="post-title" title="Spring Boot整合Neo4j实现增删改查">Spring Boot整合Neo4j实现增删改查</span>
            <span class="post-date" title="2024-11-07 19:04:30">2024/11/07</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/564adc33.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="06-原型模式">06-原型模式</span>
            <span class="post-date" title="2024-11-06 19:00:00">2024/11/06</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/effeea78.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="05-工厂模式">05-工厂模式</span>
            <span class="post-date" title="2024-11-04 21:00:00">2024/11/04</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/d7e99843.html"
           data-tag="设计模式"
           data-author="" >
            <span class="post-title" title="04-单例模式">04-单例模式</span>
            <span class="post-date" title="2024-11-04 19:00:00">2024/11/04</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/90f1850a.html"
           data-tag="设计模式,UML"
           data-author="" >
            <span class="post-title" title="03-UML类图">03-UML类图</span>
            <span class="post-date" title="2024-11-02 14:57:00">2024/11/02</span>
        </a>
        
        
        <a  class="全部文章 UML "
           href="/blog/c13304c1.html"
           data-tag="设计模式,UML"
           data-author="" >
            <span class="post-title" title="02-UML图绘制工具">02-UML图绘制工具</span>
            <span class="post-date" title="2024-11-02 09:57:00">2024/11/02</span>
        </a>
        
        
        <a  class="全部文章 linux "
           href="/blog/2e826df1.html"
           data-tag="linux,ubuntu18"
           data-author="" >
            <span class="post-title" title="Docker环境下RTSP流转RTMP和HLS">Docker环境下RTSP流转RTMP和HLS</span>
            <span class="post-date" title="2024-11-01 15:17:33">2024/11/01</span>
        </a>
        
        
        <a  class="全部文章 设计模式 "
           href="/blog/cd625bba.html"
           data-tag="设计模式,java"
           data-author="" >
            <span class="post-title" title="01-设计模式六大原则">01-设计模式六大原则</span>
            <span class="post-date" title="2024-10-31 17:00:00">2024/10/31</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/1a649f4c.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="13-JUC进阶-ReentrantReadWriteLock与StampedLock">13-JUC进阶-ReentrantReadWriteLock与StampedLock</span>
            <span class="post-date" title="2024-10-19 09:26:00">2024/10/19</span>
        </a>
        
        
        <a  class="全部文章 neo4j "
           href="/blog/5c93903a.html"
           data-tag="linux,neo4j"
           data-author="" >
            <span class="post-title" title="Docker部署Neo4j并导入CSV数据">Docker部署Neo4j并导入CSV数据</span>
            <span class="post-date" title="2024-10-17 15:00:30">2024/10/17</span>
        </a>
        
        
        <a  class="全部文章 linux "
           href="/blog/ad38e6b1.html"
           data-tag="linux,ubuntu18"
           data-author="" >
            <span class="post-title" title="Ubuntu18.04离线源环境搭建">Ubuntu18.04离线源环境搭建</span>
            <span class="post-date" title="2024-10-17 09:47:33">2024/10/17</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/3fdbf0f6.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="12-JUC进阶-从ReentrantLock到AQS源码详解">12-JUC进阶-从ReentrantLock到AQS源码详解</span>
            <span class="post-date" title="2024-10-15 19:42:07">2024/10/15</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/3e0d7592.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="11-JUC进阶-Synchronized与锁升级">11-JUC进阶-Synchronized与锁升级</span>
            <span class="post-date" title="2024-10-06 09:28:00">2024/10/06</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/4502cffa.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="10-JUC进阶-Java对象内存布局和对象头">10-JUC进阶-Java对象内存布局和对象头</span>
            <span class="post-date" title="2024-10-04 09:54:40">2024/10/04</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/4de6a39b.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="09-JUC进阶-ThreadLocal">09-JUC进阶-ThreadLocal</span>
            <span class="post-date" title="2024-10-01 20:39:10">2024/10/01</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/72329cf5.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="08-JUC进阶-常用的原子操作类(18个)">08-JUC进阶-常用的原子操作类(18个)</span>
            <span class="post-date" title="2024-09-28 13:37:09">2024/09/28</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/5e3757c1.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="07-JUC进阶-CAS">07-JUC进阶-CAS</span>
            <span class="post-date" title="2024-09-26 19:37:00">2024/09/26</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/546d628d.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="06-JUC进阶-Volatile与Java内存模型">06-JUC进阶-Volatile与Java内存模型</span>
            <span class="post-date" title="2024-09-25 19:01:01">2024/09/25</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/1f2e0014.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="05-JUC进阶-Java内存模型-JMM">05-JUC进阶-Java内存模型-JMM</span>
            <span class="post-date" title="2024-09-23 23:01:07">2024/09/23</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/19653fb9.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="04-JUC进阶-LockSupport与线程中断">04-JUC进阶-LockSupport与线程中断</span>
            <span class="post-date" title="2024-09-23 20:51:50">2024/09/23</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/219e52ea.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="03-JUC进阶-Java中的锁的解析">03-JUC进阶-Java中的锁的解析</span>
            <span class="post-date" title="2024-09-21 14:15:20">2024/09/21</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/7e2d78eb.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="02-JUC进阶-CompletableFuture">02-JUC进阶-CompletableFuture</span>
            <span class="post-date" title="2024-09-18 22:50:00">2024/09/18</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/3d102971.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="01-JUC进阶-线程基础">01-JUC进阶-线程基础</span>
            <span class="post-date" title="2024-09-18 22:32:00">2024/09/18</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/37d56d14.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="11-CompletableFuture">11-CompletableFuture</span>
            <span class="post-date" title="2024-09-16 16:12:00">2024/09/16</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/31919959.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="10-Fork/Join">10-Fork/Join</span>
            <span class="post-date" title="2024-09-16 13:10:00">2024/09/16</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/a0197c15.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="09-ThreadPool-线程池">09-ThreadPool-线程池</span>
            <span class="post-date" title="2024-09-13 20:10:08">2024/09/13</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/a6760d1f.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="08-阻塞队列BlockingQueue">08-阻塞队列BlockingQueue</span>
            <span class="post-date" title="2024-09-07 17:30:00">2024/09/07</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/838e7581.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="07-JUC辅助类CountDownLatch、CyclicBarrier、Semaphore">07-JUC辅助类CountDownLatch、CyclicBarrier、Semaphore</span>
            <span class="post-date" title="2024-09-07 13:00:00">2024/09/07</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/f60e37c5.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="06-Callable &amp; Future 接口">06-Callable &amp; Future 接口</span>
            <span class="post-date" title="2024-09-06 22:10:00">2024/09/06</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/f184587f.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="05-公平锁和非公平锁，死锁，可重入锁">05-公平锁和非公平锁，死锁，可重入锁</span>
            <span class="post-date" title="2024-09-05 20:12:00">2024/09/05</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/9a09d992.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="04-集合的线程安全">04-集合的线程安全</span>
            <span class="post-date" title="2024-09-04 21:09:05">2024/09/04</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/bd2134da.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="03-线程间通信">03-线程间通信</span>
            <span class="post-date" title="2024-09-04 20:06:00">2024/09/04</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/850dac3c.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="02-Lock接口">02-Lock接口</span>
            <span class="post-date" title="2024-08-30 19:27:00">2024/08/30</span>
        </a>
        
        
        <a  class="全部文章 JUC "
           href="/blog/4e6bd685.html"
           data-tag="java,juc"
           data-author="" >
            <span class="post-title" title="01-多线程的基本概念">01-多线程的基本概念</span>
            <span class="post-date" title="2024-08-30 19:03:01">2024/08/30</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/1b0522f4.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第二十五章-分析GC日志">第二十五章-分析GC日志</span>
            <span class="post-date" title="2024-08-28 21:36:08">2024/08/28</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/944806143.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第二十四章-JVM运行时参数">第二十四章-JVM运行时参数</span>
            <span class="post-date" title="2024-08-27 18:30:10">2024/08/27</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/490498600.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第二十三章-使用OQL语言查询对象信息">第二十三章-使用OQL语言查询对象信息</span>
            <span class="post-date" title="2024-08-24 15:02:10">2024/08/24</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/1471620196.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第二十三章-浅堆-深堆-内存泄漏">第二十三章-浅堆-深堆-内存泄漏</span>
            <span class="post-date" title="2024-08-24 13:04:37">2024/08/24</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/971417975.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第二十三章-JVM监控及诊断工具-GUI篇">第二十三章-JVM监控及诊断工具-GUI篇</span>
            <span class="post-date" title="2024-08-16 21:00:00">2024/08/16</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/2165702380.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第二十二章-JVM监控及诊断工具-命令行篇">第二十二章-JVM监控及诊断工具-命令行篇</span>
            <span class="post-date" title="2024-08-12 19:36:32">2024/08/12</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/2681163762.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第二十一章-性能监控与调优概述">第二十一章-性能监控与调优概述</span>
            <span class="post-date" title="2024-08-12 19:13:06">2024/08/12</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/3537043756.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第二十章-再谈类的加载器">第二十章-再谈类的加载器</span>
            <span class="post-date" title="2024-08-10 13:43:10">2024/08/10</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/3387211378.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第十九章-类的加载过程详解">第十九章-类的加载过程详解</span>
            <span class="post-date" title="2024-08-02 19:33:27">2024/08/02</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/1107503247.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第十八章-字节码指令集与解析指令">第十八章-字节码指令集与解析指令</span>
            <span class="post-date" title="2024-08-01 01:40:02">2024/08/01</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/2772873157.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第十七章-使用javap指令解析class文件">第十七章-使用javap指令解析class文件</span>
            <span class="post-date" title="2024-07-22 23:54:00">2024/07/22</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/143162370.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第十六章-Class文件结构">第十六章-Class文件结构</span>
            <span class="post-date" title="2024-07-15 19:54:50">2024/07/15</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/309245330.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第十五章-GC日志分析">第十五章-GC日志分析</span>
            <span class="post-date" title="2024-07-13 08:34:00">2024/07/13</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/1750792302.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第十四章-垃圾收集器">第十四章-垃圾收集器</span>
            <span class="post-date" title="2024-07-10 19:27:00">2024/07/10</span>
        </a>
        
        
        <a  class="全部文章 算法 "
           href="/blog/484946532.html"
           data-tag="算法,合并有序链表"
           data-author="" >
            <span class="post-title" title="合并两个有序链表">合并两个有序链表</span>
            <span class="post-date" title="2024-07-06 09:11:00">2024/07/06</span>
        </a>
        
        
        <a  class="全部文章 算法 "
           href="/blog/2929260443.html"
           data-tag="算法,链表"
           data-author="" >
            <span class="post-title" title="链表反转">链表反转</span>
            <span class="post-date" title="2024-07-05 19:45:45">2024/07/05</span>
        </a>
        
        
        <a  class="全部文章 算法 "
           href="/blog/1403776474.html"
           data-tag="算法,选择排序,冒泡排序,插入排序"
           data-author="" >
            <span class="post-title" title="选择-冒泡-插入排序">选择-冒泡-插入排序</span>
            <span class="post-date" title="2024-07-03 11:02:16">2024/07/03</span>
        </a>
        
        
        <a  class="全部文章 算法 "
           href="/blog/2561891005.html"
           data-tag="算法,二分法"
           data-author="" >
            <span class="post-title" title="二分搜索">二分搜索</span>
            <span class="post-date" title="2024-06-29 10:04:10">2024/06/29</span>
        </a>
        
        
        <a  class="全部文章 算法 "
           href="/blog/2224151177.html"
           data-tag="算法,二进制,位运算"
           data-author="" >
            <span class="post-title" title="二进制和位运算">二进制和位运算</span>
            <span class="post-date" title="2024-06-20 08:04:00">2024/06/20</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/2105268063.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第十三章-垃圾回收相关概念">第十三章-垃圾回收相关概念</span>
            <span class="post-date" title="2024-01-14 14:27:00">2024/01/14</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/364508352.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第十二章-垃圾回收概述和相关算法">第十二章-垃圾回收概述和相关算法</span>
            <span class="post-date" title="2024-01-06 16:28:00">2024/01/06</span>
        </a>
        
        
        <a  class="全部文章 linux "
           href="/blog/2050535563.html"
           data-tag="linux,jenkins"
           data-author="" >
            <span class="post-title" title="Jenkins的安装和搭建自动化部署平台">Jenkins的安装和搭建自动化部署平台</span>
            <span class="post-date" title="2024-01-05 16:00:00">2024/01/05</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/2388209687.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第十一章-StringTable(字符串常量池)">第十一章-StringTable(字符串常量池)</span>
            <span class="post-date" title="2023-12-25 17:27:06">2023/12/25</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/3385856233.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第十章-执行引擎">第十章-执行引擎</span>
            <span class="post-date" title="2023-12-23 20:03:00">2023/12/23</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/4075763684.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第九章-对象的实例化内存布局与访问定位">第九章-对象的实例化内存布局与访问定位</span>
            <span class="post-date" title="2023-12-21 11:50:00">2023/12/21</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/3720767522.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第八章-直接内存">第八章-直接内存</span>
            <span class="post-date" title="2023-12-20 17:03:00">2023/12/20</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/105864584.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第七章-方法区">第七章-方法区</span>
            <span class="post-date" title="2023-12-14 18:24:00">2023/12/14</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/543408063.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第六章-JVM堆">第六章-JVM堆</span>
            <span class="post-date" title="2023-12-02 08:01:00">2023/12/02</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/554039338.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第五章-本地方法接口">第五章-本地方法接口</span>
            <span class="post-date" title="2023-11-30 17:55:00">2023/11/30</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/1123461525.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第四章-虚拟机栈">第四章-虚拟机栈</span>
            <span class="post-date" title="2023-11-28 20:55:00">2023/11/28</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/1626061462.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第三章-运行时数据区">第三章-运行时数据区</span>
            <span class="post-date" title="2023-11-28 19:31:00">2023/11/28</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/222077543.html"
           data-tag="java,jvm,双亲委派机制"
           data-author="" >
            <span class="post-title" title="第二章-JVM类加载子系统">第二章-JVM类加载子系统</span>
            <span class="post-date" title="2023-11-25 14:35:00">2023/11/25</span>
        </a>
        
        
        <a  class="全部文章 JVM "
           href="/blog/1897413233.html"
           data-tag="java,jvm"
           data-author="" >
            <span class="post-title" title="第一章-JVM和Java体系结构">第一章-JVM和Java体系结构</span>
            <span class="post-date" title="2023-11-25 10:00:00">2023/11/25</span>
        </a>
        
        
        <a  class="全部文章 Hexo "
           href="/blog/4179015178.html"
           data-tag="hexo,github pages,sitemap"
           data-author="" >
            <span class="post-title" title="给博客网站添加站点地图-sitemap">给博客网站添加站点地图-sitemap</span>
            <span class="post-date" title="2023-11-21 20:00:00">2023/11/21</span>
        </a>
        
        
        <a  class="全部文章 Hexo Typora "
           href="/blog/877664098.html"
           data-tag="hexo,typora,github"
           data-author="" >
            <span class="post-title" title="Typora设置图片自动上传Github">Typora设置图片自动上传Github</span>
            <span class="post-date" title="2023-11-20 20:30:00">2023/11/20</span>
        </a>
        
        
        <a  class="全部文章 Hexo "
           href="/blog/2016918085.html"
           data-tag="hexo,github pages"
           data-author="" >
            <span class="post-title" title="Hexo博客安装主题">Hexo博客安装主题</span>
            <span class="post-date" title="2023-11-20 00:00:01">2023/11/20</span>
        </a>
        
        
        <a  class="全部文章 Hexo "
           href="/blog/3069199997.html"
           data-tag="hexo,github pages"
           data-author="" >
            <span class="post-title" title="Hexo主题常用配置">Hexo主题常用配置</span>
            <span class="post-date" title="2023-11-20 00:00:01">2023/11/20</span>
        </a>
        
        
        <a  class="全部文章 Hexo "
           href="/blog/3070587776.html"
           data-tag="hexo,github pages"
           data-author="" >
            <span class="post-title" title="基于Hexo和Github Pages搭建个人博客">基于Hexo和Github Pages搭建个人博客</span>
            <span class="post-date" title="2023-11-18 15:40:20">2023/11/18</span>
        </a>
        
        <div id="no-item-tips">

        </div>
    </nav>
    <div id="outline-list">
    </div>
</div>

    </div>
    <div class="hide-list">
        <div class="semicircle" data-title="切换全屏 快捷键 s">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div id="post">
    <div class="pjax">
        <article id="post-k8s/025-K8S-二进制高可用部署" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">025-K8S-二进制高可用部署</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            <i class="iconfont icon-category"></i>
            
            
            <a  data-rel="k8s">k8s</a>
            
        </span>
        
        
        <span class="tag">
            <i class="iconfont icon-tag"></i>
            
            <a class="color1">linux</a>
            
            <a class="color2">Docker</a>
            
            <a class="color1">Rocky</a>
            
            <a class="color5">Etcd</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
            发布时间 : <time class="date" title='最后更新: 2025-10-30 15:13:01'>2025-10-01 06:33</time>
        
    </div>
    <div class="article-meta">
        
        <span>字数:33.9k</span>
        
        
        <span id="busuanzi_container_page_pv">
            阅读 :<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
        <span class="top-comment" title="跳转至评论区">
            <a href="#comments">
                评论:<span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </a>
        </span>
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83"><span class="toc-text">一、系统环境</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92"><span class="toc-text">二、集群规划</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-%E6%89%80%E6%9C%89%E8%8A%82%E7%82%B9"><span class="toc-text">三、基础环境配置(所有节点)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%B8%BB%E6%9C%BA%E5%90%8D%E8%AE%BE%E7%BD%AE"><span class="toc-text">1. 主机名设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81IP"><span class="toc-text">2. 配置静态IP</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E4%BF%AE%E6%94%B9hosts%E6%96%87%E4%BB%B6"><span class="toc-text">3. 修改hosts文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E4%BF%AE%E6%94%B9%E7%BB%88%E7%AB%AF%E9%A2%9C%E8%89%B2"><span class="toc-text">4. 修改终端颜色</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%9B%B4%E6%8D%A2%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E6%BA%90"><span class="toc-text">5. 更换系统软件源</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E4%BF%AE%E6%94%B9%E9%98%B2%E7%81%AB%E5%A2%99"><span class="toc-text">6. 修改防火墙</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E7%A6%81%E7%94%A8-Selinux"><span class="toc-text">7. 禁用 Selinux</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E8%AE%BE%E7%BD%AE%E6%97%B6%E5%8C%BA"><span class="toc-text">8. 设置时区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E5%85%B3%E9%97%AD-swap-%E5%88%86%E5%8C%BA"><span class="toc-text">9. 关闭 swap 分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E5%AE%89%E8%A3%85%E5%9F%BA%E6%9C%AC%E5%B7%A5%E5%85%B7"><span class="toc-text">10. 安装基本工具</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E4%BF%AE%E6%94%B9%E7%B3%BB%E7%BB%9F%E6%9C%80%E5%A4%A7%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6%E6%95%B0"><span class="toc-text">11. 修改系统最大打开文件数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-%E5%AE%89%E8%A3%85-ipvs"><span class="toc-text">12. 安装 ipvs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-%E5%BC%80%E5%90%AF%E8%B7%AF%E7%94%B1%E8%BD%AC%E5%8F%91"><span class="toc-text">13. 开启路由转发</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-%E6%8E%92%E9%99%A4-calico-%E7%BD%91%E5%8D%A1%E8%A2%AB-NetworkManager-%E6%89%80%E7%AE%A1%E7%90%86"><span class="toc-text">14. 排除 calico 网卡被 NetworkManager 所管理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-%E4%BF%AE%E6%94%B9%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0"><span class="toc-text">15. 修改内核参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#16-%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%E8%AE%BE%E7%BD%AE"><span class="toc-text">16. 集群时间同步设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-%E9%85%8D%E7%BD%AE%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95"><span class="toc-text">17. 配置免密登录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#18-%E5%AE%89%E8%A3%85-Docker"><span class="toc-text">18. 安装 Docker</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#18-1-%E5%AE%89%E8%A3%85-Docker-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85"><span class="toc-text">18.1 安装 Docker 二进制包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#18-2-%E9%85%8D%E7%BD%AE-containerd-service"><span class="toc-text">18.2 配置 containerd.service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#18-3-%E9%85%8D%E7%BD%AE-docker-service"><span class="toc-text">18.3 配置 docker.service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#18-4-%E5%87%86%E5%A4%87-docker-%E7%9A%84-socket-%E6%96%87%E4%BB%B6"><span class="toc-text">18.4 准备 docker 的 socket 文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#18-5-%E9%85%8D%E7%BD%AE-Docker-%E5%8A%A0%E9%80%9F%E5%99%A8"><span class="toc-text">18.5 配置 Docker 加速器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#18-6-%E5%90%AF%E5%8A%A8-Docker"><span class="toc-text">18.6 启动 Docker</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#19-%E5%AE%89%E8%A3%85-cri-docker"><span class="toc-text">19. 安装 cri-docker</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#19-1-%E5%AE%89%E8%A3%85-cri-docker-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85"><span class="toc-text">19.1 安装 cri-docker 二进制包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#19-2-%E9%85%8D%E7%BD%AE-cri-docker-service"><span class="toc-text">19.2 配置 cri-docker.service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#19-3-%E9%85%8D%E7%BD%AE-cri-docker-socket"><span class="toc-text">19.3 配置 cri-docker.socket</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#19-4-%E5%90%AF%E5%8A%A8-cri-docker"><span class="toc-text">19.4 启动 cri-docker</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81K8S-%E4%B8%8E-ETCD-%E4%B8%8B%E8%BD%BD%E5%8F%8A%E5%AE%89%E8%A3%85%EF%BC%88%E5%9C%A8-master01-%E8%8A%82%E7%82%B9%E4%B8%8A%E6%93%8D%E4%BD%9C%EF%BC%89"><span class="toc-text">四、K8S 与 ETCD 下载及安装（在 master01 节点上操作）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%AE%89%E8%A3%85-K8S-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85"><span class="toc-text">1. 安装 K8S 二进制包</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%89%E8%A3%85-ETCD-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85"><span class="toc-text">2. 安装 ETCD 二进制包</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E7%94%9F%E6%88%90%E7%9B%B8%E5%85%B3%E8%AF%81%E4%B9%A6"><span class="toc-text">3. 生成相关证书</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%AE%89%E8%A3%85%E8%AF%81%E4%B9%A6%E5%B7%A5%E5%85%B7"><span class="toc-text">3.1 安装证书工具</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E7%94%9F%E6%88%90-ETCD-%E8%AF%81%E4%B9%A6"><span class="toc-text">3.2 生成 ETCD 证书</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-ca-config-json"><span class="toc-text">3.2.1 ca-config.json</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-2-etcd-ca-csr-json"><span class="toc-text">3.2.2 etcd-ca-csr.json</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-3-%E7%94%9F%E6%88%90-ETCD-%E7%9A%84%E6%A0%B9-CA-%E8%AF%81%E4%B9%A6"><span class="toc-text">3.2.3 生成 ETCD 的根 CA 证书</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-4-etcd-csr-json"><span class="toc-text">3.2.4 etcd-csr.json</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-5-%E7%94%9F%E6%88%90-ETCD-%E8%8A%82%E7%82%B9%E8%AF%81%E4%B9%A6"><span class="toc-text">3.2.5 生成 ETCD 节点证书</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-6-%E5%B0%86%E8%AF%81%E4%B9%A6%E5%A4%8D%E5%88%B6%E5%88%B0%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9"><span class="toc-text">3.2.6 将证书复制到其他节点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E7%94%9F%E6%88%90-K8S-%E7%9B%B8%E5%85%B3%E8%AF%81%E4%B9%A6"><span class="toc-text">3.3 生成 K8S 相关证书</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-1-ca-config-json"><span class="toc-text">3.3.1 ca-config.json</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-2-ca-csr-json"><span class="toc-text">3.3.2 ca-csr.json</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-3-%E7%94%9F%E6%88%90-Kubernetes-%E9%9B%86%E7%BE%A4%E7%9A%84%E6%A0%B9-CA-%E8%AF%81%E4%B9%A6"><span class="toc-text">3.3.3 生成 Kubernetes 集群的根 CA 证书</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-4-apiserver-csr-json"><span class="toc-text">3.3.4 apiserver-csr.json</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-5-%E7%94%9F%E6%88%90-apiserver-%E8%AF%81%E4%B9%A6"><span class="toc-text">3.3.5 生成 apiserver 证书</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-6-apiserver-%E8%81%9A%E5%90%88%E8%AF%81%E4%B9%A6"><span class="toc-text">3.3.6 apiserver 聚合证书</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#3-3-6-1-front-proxy-ca-csr-json"><span class="toc-text">3.3.6.1 front-proxy-ca-csr.json</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-3-6-2-%E7%94%9F%E6%88%90-Kubernetes-Front-Proxy-%E6%A0%B9-CA-%E8%AF%81%E4%B9%A6"><span class="toc-text">3.3.6.2 生成 Kubernetes Front Proxy 根 CA 证书</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-7-%E7%94%9F%E6%88%90-controller-manage-%E7%9A%84%E8%AF%81%E4%B9%A6"><span class="toc-text">3.3.7 生成 controller-manage 的证书</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-8-%E7%94%9F%E6%88%90-kube-scheduler-%E7%9A%84%E8%AF%81%E4%B9%A6"><span class="toc-text">3.3.8 生成 kube-scheduler 的证书</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-9-%E7%94%9F%E6%88%90-admin-%E7%9A%84%E8%AF%81%E4%B9%A6%E9%85%8D%E7%BD%AE"><span class="toc-text">3.3.9 生成 admin 的证书配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-10-%E5%88%9B%E5%BB%BA-kube-proxy-%E8%AF%81%E4%B9%A6"><span class="toc-text">3.3.10 创建 kube-proxy 证书</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-11-%E7%94%9F%E6%88%90-ServiceAccount%EF%BC%88%E7%AE%80%E7%A7%B0-SA%EF%BC%89%E7%AD%BE%E5%90%8D%E5%AF%86%E9%92%A5%E5%AF%B9"><span class="toc-text">3.3.11 生成 ServiceAccount（简称 SA）签名密钥对</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E5%88%86%E5%8F%91%E8%AF%81%E4%B9%A6%E5%88%B0%E5%85%B6%E5%AE%83%E8%8A%82%E7%82%B9"><span class="toc-text">4. 分发证书到其它节点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%88%86%E5%8F%91%E5%88%B0-master-%E8%8A%82%E7%82%B9"><span class="toc-text">4.1 分发到 master 节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E5%88%86%E5%8F%91%E5%88%B0-node-%E8%8A%82%E7%82%B9"><span class="toc-text">4.2 分发到 node 节点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%9F%A5%E7%9C%8B%E8%AF%81%E4%B9%A6"><span class="toc-text">5. 查看证书</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-master-%E8%8A%82%E7%82%B9"><span class="toc-text">5.1 master 节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-node-%E8%8A%82%E7%82%B9"><span class="toc-text">5.2 node 节点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81K8S-%E7%B3%BB%E7%BB%9F%E7%BB%84%E4%BB%B6%E9%85%8D%E7%BD%AE"><span class="toc-text">五、K8S 系统组件配置</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-ETCD-%E9%85%8D%E7%BD%AE"><span class="toc-text">1. ETCD 配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-Master01-%E8%8A%82%E7%82%B9"><span class="toc-text">1.1 Master01 节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-Master02-%E8%8A%82%E7%82%B9"><span class="toc-text">1.2 Master02 节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-Master03-%E8%8A%82%E7%82%B9"><span class="toc-text">1.3 Master03 节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-%E5%88%9B%E5%BB%BA-ETCD-Service"><span class="toc-text">1.4 创建 ETCD Service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-%E5%90%AF%E5%8A%A8-ETCD-Service"><span class="toc-text">1.5 启动 ETCD Service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-%E6%A3%80%E6%9F%A5-ETCD-%E9%9B%86%E7%BE%A4%E7%9A%84%E5%81%A5%E5%BA%B7%E7%8A%B6%E6%80%81"><span class="toc-text">1.6 检查 ETCD 集群的健康状态</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Nginx-%E9%85%8D%E7%BD%AE"><span class="toc-text">2. Nginx 配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85"><span class="toc-text">2.1 编译安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-nginx-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-text">2.2 nginx 配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E9%85%8D%E7%BD%AE-Nginx-Service"><span class="toc-text">2.3 配置 Nginx Service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E8%AE%BE%E7%BD%AE-Nginx-%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF"><span class="toc-text">2.4 设置 Nginx 开机自启</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-kube-apiserver-%E9%85%8D%E7%BD%AE"><span class="toc-text">3. kube-apiserver 配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%88%9B%E5%BB%BA%E5%BF%85%E8%A6%81%E7%9A%84%E7%9B%AE%E5%BD%95"><span class="toc-text">3.1 创建必要的目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E9%85%8D%E7%BD%AE-kube-apiserver-service"><span class="toc-text">3.2 配置 kube-apiserver.service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E5%90%AF%E5%8A%A8-kube-apiserver"><span class="toc-text">3.3 启动 kube-apiserver</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-kube-controller-manager-%E9%85%8D%E7%BD%AE"><span class="toc-text">4. kube-controller-manager 配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E9%85%8D%E7%BD%AE-kube-controller-manager-service"><span class="toc-text">4.1 配置 kube-controller-manager.service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E5%90%AF%E5%8A%A8-kube-controller-manager"><span class="toc-text">4.2 启动 kube-controller-manager</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-kube-scheduler-%E9%85%8D%E7%BD%AE"><span class="toc-text">5. kube-scheduler 配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-kube-scheduler-service"><span class="toc-text">5.1 kube-scheduler.service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%90%AF%E5%8A%A8-kube-scheduler"><span class="toc-text">5.2 启动 kube-scheduler</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AD%E3%80%81TLS-Bootstrapping-%E9%85%8D%E7%BD%AE"><span class="toc-text">六、TLS Bootstrapping 配置</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%94%9F%E6%88%90-bootstrap-%E7%9A%84-token"><span class="toc-text">1. 生成 bootstrap 的 token</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E9%85%8D%E7%BD%AE-bootstrap-kubelet-kubeconfig"><span class="toc-text">2. 配置 bootstrap-kubelet.kubeconfig</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%88%9B%E5%BB%BA-bootstrap-secret-yaml"><span class="toc-text">3. 创建 bootstrap-secret.yaml</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E5%88%9B%E5%BB%BA-kubelet-bootstrap-rbac-yaml"><span class="toc-text">4. 创建 kubelet-bootstrap-rbac.yaml</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%88%86%E5%8F%91%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-text">5. 分发配置文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E6%9F%A5%E7%9C%8B%E9%9B%86%E7%BE%A4%E7%8A%B6%E6%80%81"><span class="toc-text">6. 查看集群状态</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%83%E3%80%81Node-%E9%85%8D%E7%BD%AE"><span class="toc-text">七、Node 配置</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%A4%8D%E5%88%B6%E7%9B%B8%E5%85%B3%E8%AF%81%E4%B9%A6%E8%87%B3-node-%E8%8A%82%E7%82%B9"><span class="toc-text">1. 复制相关证书至 node 节点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E9%85%8D%E7%BD%AE-kubelet%EF%BC%88%E6%89%80%E6%9C%89%E8%8A%82%E7%82%B9%EF%BC%89"><span class="toc-text">2. 配置 kubelet（所有节点）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E7%BC%96%E8%BE%91-kubelet-service"><span class="toc-text">2.1 编辑 kubelet.service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E7%BC%96%E8%BE%91-kubelet-conf-yml"><span class="toc-text">2.2 编辑 kubelet-conf.yml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E5%90%8C%E6%AD%A5%E6%96%87%E4%BB%B6%E5%88%B0%E5%85%B6%E5%AE%83%E8%8A%82%E7%82%B9"><span class="toc-text">2.3 同步文件到其它节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E6%89%80%E6%9C%89%E8%8A%82%E7%82%B9%E5%90%AF%E5%8A%A8-kubelet"><span class="toc-text">2.4 所有节点启动 kubelet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E6%B5%8B%E8%AF%95"><span class="toc-text">2.5 测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-kube-proxy-%E9%85%8D%E7%BD%AE%EF%BC%88%E6%89%80%E6%9C%89%E8%8A%82%E7%82%B9%EF%BC%89"><span class="toc-text">3. kube-proxy 配置（所有节点）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%90%8C%E6%AD%A5-kube-proxy-kubeconfig"><span class="toc-text">3.1 同步 kube-proxy.kubeconfig</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E7%BC%96%E8%BE%91-kube-proxy-service"><span class="toc-text">3.2 编辑 kube-proxy.service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E7%BC%96%E8%BE%91-kube-proxy-yaml"><span class="toc-text">3.3 编辑 kube-proxy.yaml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E5%90%AF%E5%8A%A8-kube-proxy"><span class="toc-text">3.4 启动 kube-proxy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E5%90%8C%E6%AD%A5-kube-proxy-%E5%88%B0%E5%85%B6%E5%AE%83%E8%8A%82%E7%82%B9"><span class="toc-text">3.5 同步 kube-proxy 到其它节点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AB%E3%80%81%E5%AE%89%E8%A3%85-calico-%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6"><span class="toc-text">八、安装 calico 网络插件</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%B8%8B%E8%BD%BD-calico-%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95"><span class="toc-text">1. 下载 calico 资源清单</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%BC%96%E8%BE%91-calico-%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95-IPV4"><span class="toc-text">2. 编辑 calico 资源清单-IPV4</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E7%BC%96%E8%BE%91-calico-%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95-IPV6"><span class="toc-text">3. 编辑 calico 资源清单-IPV6</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%89%A7%E8%A1%8C-calico-%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95"><span class="toc-text">4. 执行 calico 资源清单</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E5%AE%89%E8%A3%85-Core-DNS"><span class="toc-text">九、安装 Core DNS</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%AE%89%E8%A3%85Helm%EF%BC%88%E4%BB%85master01%EF%BC%89"><span class="toc-text">1. 安装Helm（仅master01）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%89%E8%A3%85-CoreDns"><span class="toc-text">2. 安装 CoreDns</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E4%B8%8B%E8%BD%BD-CoreDns-%E5%AE%89%E8%A3%85%E5%8C%85"><span class="toc-text">2.1 下载 CoreDns 安装包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E7%BC%96%E8%BE%91%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-text">2.2 编辑配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E5%AE%89%E8%A3%85-CoreDns"><span class="toc-text">2.3 安装 CoreDns</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E3%80%81%E5%AE%89%E8%A3%85-Metrics-Server"><span class="toc-text">十、安装 Metrics Server</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%B8%8B%E8%BD%BD-metrics-server-%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95"><span class="toc-text">1. 下载 metrics-server 资源清单</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%BC%96%E8%BE%91-components-yaml"><span class="toc-text">2. 编辑 components.yaml</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E9%83%A8%E7%BD%B2-metrics-server"><span class="toc-text">3. 部署 metrics-server</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%B8%80%E3%80%81%E5%AE%89%E8%A3%85Dashboard"><span class="toc-text">十一、安装Dashboard</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%B8%8B%E8%BD%BD%E5%B9%B6%E6%89%A7%E8%A1%8C-dashboard-%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95"><span class="toc-text">1. 下载并执行 dashboard 资源清单</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%88%9B%E5%BB%BA-ServiceAccount"><span class="toc-text">2. 创建 ServiceAccount</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%9B%B4%E6%94%B9-dashboard-%E7%9A%84-svc-%E4%B8%BA-NodePort"><span class="toc-text">3. 更改 dashboard 的 svc 为 NodePort</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E5%88%9B%E5%BB%BA-token-%E8%AE%BF%E9%97%AE"><span class="toc-text">4. 创建 token 访问</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%BA%8C%E3%80%81%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E8%A1%A5%E5%85%A8"><span class="toc-text">十二、安装命令补全</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%B8%89%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%E9%AA%8C%E8%AF%81"><span class="toc-text">十三、高可用验证</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%BB%84%E4%BB%B6%E7%8A%B6%E6%80%81%E9%AA%8C%E8%AF%81"><span class="toc-text">1. 组件状态验证</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E4%BD%BF%E7%94%A8-dnstools-%E6%B5%8B%E8%AF%95"><span class="toc-text">2. 使用 dnstools 测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Nginx-%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95"><span class="toc-text">3. Nginx 部署测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Ubuntu-%E9%95%9C%E5%83%8F%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95"><span class="toc-text">4. Ubuntu 镜像部署测试</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E9%83%A8%E7%BD%B2-NetworkPolicy"><span class="toc-text">3.1 部署 NetworkPolicy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E9%83%A8%E7%BD%B2-Ubuntu-Pod"><span class="toc-text">3.2 部署 Ubuntu Pod</span></a></li></ol></li></ol></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一、系统环境"><a href="#一、系统环境" class="headerlink" title="一、系统环境"></a>一、系统环境</h1><ul>
<li>操作系统：Rocky Linux 9.3</li>
<li>内核版本：5.14.0-284.11.1.el9_2.x86_64</li>
<li>容器运行时：Docker + CRI-Docker</li>
<li>Kubernetes 版本：1.29.2</li>
<li>网络插件：Calico</li>
</ul>
<h1 id="二、集群规划"><a href="#二、集群规划" class="headerlink" title="二、集群规划"></a>二、集群规划</h1><p>基于二进制安装包，部署三主两从的高可用集群。</p>
<table>
<thead>
<tr>
<th>主机名称</th>
<th>IPV4地址</th>
<th>CPU&#x2F;内存&#x2F;磁盘</th>
<th>说明</th>
<th>软件</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>10.20.1.203</td>
<td>2C&#x2F;4G&#x2F;200G</td>
<td>外网节点(可翻墙)</td>
<td>下载各种所需安装包</td>
</tr>
<tr>
<td>Master01</td>
<td>10.20.1.100</td>
<td>2C&#x2F;4G&#x2F;200G</td>
<td>master节点</td>
<td>apiserver、controller-manager、scheduler、etcd、 kubelet、kube-proxy、nginx</td>
</tr>
<tr>
<td>Master02</td>
<td>10.20.1.101</td>
<td>2C&#x2F;4G&#x2F;200G</td>
<td>master节点</td>
<td>apiserver、controller-manager、scheduler、etcd、 kubelet、kube-proxy、nginx</td>
</tr>
<tr>
<td>Master03</td>
<td>10.20.1.102</td>
<td>2C&#x2F;4G&#x2F;200G</td>
<td>master节点</td>
<td>apiserver、controller-manager、scheduler、etcd、 kubelet、kube-proxy、nginx</td>
</tr>
<tr>
<td>Node01</td>
<td>10.20.1.103</td>
<td>2C&#x2F;4G&#x2F;200G</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nginx</td>
</tr>
<tr>
<td>Node02</td>
<td>10.20.1.104</td>
<td>2C&#x2F;4G&#x2F;200G</td>
<td>node节点</td>
<td>kubelet、kube-proxy、nginx</td>
</tr>
</tbody></table>
<h1 id="三、基础环境配置-所有节点"><a href="#三、基础环境配置-所有节点" class="headerlink" title="三、基础环境配置(所有节点)"></a>三、基础环境配置(所有节点)</h1><h2 id="1-主机名设置"><a href="#1-主机名设置" class="headerlink" title="1. 主机名设置"></a>1. 主机名设置</h2><p>设置集群中各个节点的主机名</p>
<p><strong>Master01 节点</strong></p>
<pre><code class="highlight bash">hostnamectl set-hostname k8s-master01</code></pre>



<p><strong>Master02 节点</strong></p>
<pre><code class="highlight bash">hostnamectl set-hostname k8s-master02</code></pre>



<p><strong>Master03 节点</strong></p>
<pre><code class="highlight bash">hostnamectl set-hostname k8s-master03</code></pre>



<p><strong>Node01 节点</strong></p>
<pre><code class="highlight bash">hostnamectl set-hostname k8s-node01</code></pre>



<p><strong>Node02 节点</strong></p>
<pre><code class="highlight bash">hostnamectl set-hostname k8s-node02</code></pre>





<h2 id="2-配置静态IP"><a href="#2-配置静态IP" class="headerlink" title="2. 配置静态IP"></a>2. 配置静态IP</h2><p>集群内的每个几点都需要配置唯一的IP地址，这里同时配置了 IPV4地址 和 IPV6地址。</p>
<p><strong>Master01 节点</strong></p>
<pre><code class="highlight bash">[root@k8s-master01 ~]<span class="comment"># cat /etc/NetworkManager/system-connections/ens34.nmconnection</span>
[ipv4]
method=manual
address1=10.20.1.101/24;10.20.1.1
dns=61.132.163.68;114.114.114.114

[ipv6]
method=manual
addresses=2400:3200::101/64
gateway=2400:3200::1
dns=2400:3200::1;2400:3200:baba::1;2001:4860:4860::8888;2001:4860:4860::8844</code></pre>



<p><strong>Master02 节点</strong></p>
<pre><code class="highlight bash">[root@k8s-master02 ~]<span class="comment"># cat /etc/NetworkManager/system-connections/ens34.nmconnection</span>
[ipv4]
method=manual
address1=10.20.1.102/24;10.20.1.1
dns=61.132.163.68;114.114.114.114

[ipv6]
method=manual
addresses=2400:3200::102/64
gateway=2400:3200::1
dns=2400:3200::1;2400:3200:baba::1;2001:4860:4860::8888;2001:4860:4860::8844</code></pre>



<p><strong>Master03 节点</strong></p>
<pre><code class="highlight bash">[root@k8s-master03 ~]<span class="comment"># cat /etc/NetworkManager/system-connections/ens34.nmconnection</span>
[ipv4]
method=manual
address1=10.20.1.103/24;10.20.1.1
dns=61.132.163.68;114.114.114.114

[ipv6]
method=manual
addresses=2400:3200::103/64
gateway=2400:3200::1
dns=2400:3200::1;2400:3200:baba::1;2001:4860:4860::8888;2001:4860:4860::8844</code></pre>



<p><strong>Node01 节点</strong></p>
<pre><code class="highlight bash">[root@k8s-node01 ~]<span class="comment"># cat /etc/NetworkManager/system-connections/ens34.nmconnection</span>
[ipv4]
method=manual
address1=10.20.1.104/24;10.20.1.1
dns=61.132.163.68;114.114.114.114

[ipv6]
method=manual
addresses=2400:3200::104/64
gateway=2400:3200::1
dns=2400:3200::1;2400:3200:baba::1;2001:4860:4860::8888;2001:4860:4860::8844</code></pre>



<p><strong>Node02 节点</strong></p>
<pre><code class="highlight bash">[root@k8s-node02 ~]<span class="comment"># cat /etc/NetworkManager/system-connections/ens34.nmconnection</span>
[ipv4]
method=manual
address1=10.20.1.105/24;10.20.1.1
dns=61.132.163.68;114.114.114.114

[ipv6]
method=manual
addresses=2400:3200::105/64
gateway=2400:3200::1
dns=2400:3200::1;2400:3200:baba::1;2001:4860:4860::8888;2001:4860:4860::8844</code></pre>





<h2 id="3-修改hosts文件"><a href="#3-修改hosts文件" class="headerlink" title="3. 修改hosts文件"></a>3. 修改hosts文件</h2><p>配置集群各节点 hostname 和 ip 的映射</p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt; <span class="string">&quot;EOF&quot;</span>
10.20.1.101 k8s-master01 m1
10.20.1.102 k8s-master02 m2
10.20.1.103 k8s-master03 m3
10.20.1.104 k8s-node01 n1
10.20.1.105 k8s-node02 n2
2400:3200::101 k8s-master01 m1
2400:3200::102 k8s-master02 m2
2400:3200::103 k8s-master03 m3
2400:3200::104 k8s-node01 n1
2400:3200::105 k8s-node02 n2
EOF</code></pre>

<p><strong>验证 hosts 文件配置</strong></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> /etc/hosts
ping k8s-master01 -c 4  <span class="comment"># 默认使用 IPv4</span>
ping6 k8s-master01 -c 4  <span class="comment"># 使用 IPv6</span></code></pre>





<h2 id="4-修改终端颜色"><a href="#4-修改终端颜色" class="headerlink" title="4. 修改终端颜色"></a>4. 修改终端颜色</h2><p>这里只是修改shell终端显示文本的颜色，非必要步骤。</p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF &gt;&gt; ~/.bashrc</span>
<span class="string">PS1=&quot;\[\e[37;47m\][\[\e[32;47m\]\u\[\e[34;47m\]@\h \[\e[36;47m\]\w\[\e[0m\]]\\$ &quot;</span>
<span class="string">EOF</span>

<span class="comment"># 让修改立即见效</span>
<span class="built_in">source</span> ~/.bashrc</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>这段命令用于修改当前用户的 <strong>Bash Shell 提示符</strong>（<code>PS1</code>），并将其设置写入到 <code>~/.bashrc</code> 文件中，以便在每次登录或启动 Shell 时自动加载该配置。</p>
<pre><code class="highlight plaintext">PS1=&quot;...&quot;
定义 Shell 的主提示符格式（Prompt String 1），即你在终端中输入命令时显示的提示符。</code></pre>

<p>最终效果如下：</p>
<p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/04/20250104-112243.png" alt="终端颜色修改"></p>
</blockquote>
<h2 id="5-更换系统软件源"><a href="#5-更换系统软件源" class="headerlink" title="5. 更换系统软件源"></a>5. 更换系统软件源</h2><p>将 Rocky 默认源替换成阿里源，提升软件安装速度。</p>
<pre><code class="highlight bash"><span class="comment"># 更新源</span>
sed -e <span class="string">&#x27;s|^mirrorlist=|#mirrorlist=|g&#x27;</span> \
    -e <span class="string">&#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27;</span> \
    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo
    

<span class="comment"># 刷新dnf缓存</span>
dnf makecache

<span class="comment"># 验证源更新</span>
dnf repolist</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext"># 使用 sed 命令修改 Rocky Linux 的 YUM/DNF 源配置文件，切换到阿里云的镜像源。
sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \
    -e &#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27; \
    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo
    
# 将以 mirrorlist= 开头的行注释掉（在前面加 #）
-e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27;

# 将以 #baseurl= 开头并指向默认 Rocky Linux 源的行取消注释，并替换为阿里云镜像源 URL。
&#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27;

# -i.bak：直接修改文件，并为原文件创建备份（扩展名为 .bak）。
# 修改 /etc/yum.repos.d/ 目录下所有以 rocky 或 Rocky 开头的 .repo 文件。
# 修改完成后，原始文件会被备份为 .bak 文件。
-i.bak /etc/yum.repos.d/[Rr]ocky*.repo



# 更新本地缓存，确保系统可以快速查询软件包信息。
dnf makecache</code></pre>
</blockquote>
<h2 id="6-修改防火墙"><a href="#6-修改防火墙" class="headerlink" title="6. 修改防火墙"></a>6. 修改防火墙</h2><p>关闭默认防火墙firewalld，配置 iptables 防火墙</p>
<pre><code class="highlight bash">systemctl stop firewalld
systemctl <span class="built_in">disable</span> firewalld
yum -y install iptables-services
systemctl start iptables
iptables -F
systemctl <span class="built_in">enable</span> iptables
service iptables save</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext"># 停止运行 firewalld
systemctl stop firewalld

# 禁止 firewalld 开机自启
systemctl disable firewalld

# 安装 iptables 服务，用于管理 Linux 的防火墙规则
yum -y install iptables-services

# 使防火墙规则立即生效，并开始运行 iptables 防火墙服务。
systemctl start iptables

# 删除当前的防火墙规则，通常用于重置或清理防火墙规则。
iptables -F

# 设置 iptables 服务开机自启动，确保服务器重启后，iptables 服务会自动加载防火墙规则。
systemctl enable iptables

# 将当前 iptables 的规则配置保存到文件中（通常是 /etc/sysconfig/iptables），以便在系统重启或 iptables 服务重新启动后，能够自动加载保存的规则。
service iptables save</code></pre>
</blockquote>
<h2 id="7-禁用-Selinux"><a href="#7-禁用-Selinux" class="headerlink" title="7. 禁用 Selinux"></a>7. 禁用 Selinux</h2><pre><code class="highlight bash">setenforce 0
sed -i <span class="string">&quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot;</span> /etc/selinux/config
grubby --update-kernel ALL --args selinux=0</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext"># 将 SELinux 的模式设置为 Permissive（宽容模式）。
# 0：表示设置为 Permissive 模式，此模式下 SELinux 不会强制执行安全策略，而是记录违规日志。
# 1：表示 Enforcing 模式，此模式下 SELinux 会强制执行安全策略。
setenforce 0

# 修改 SELinux 配置文件 /etc/selinux/config，将 SELINUX 设置为 disabled。永久禁用 SELinux，即使系统重启也不会再启用。
sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config

# 通过 grubby 工具将 selinux=0 参数添加到所有内核启动配置中。
grubby --update-kernel ALL --args selinux=0
grubby --info DEFAULT

# 查看是否禁用，
grubby --info DEFAULT
# 回滚内核层禁用操作，、
grubby --update-kernel ALL --remove-args selinux</code></pre>
</blockquote>
<h2 id="8-设置时区"><a href="#8-设置时区" class="headerlink" title="8. 设置时区"></a>8. 设置时区</h2><pre><code class="highlight bash">timedatectl set-timezone Asia/Shanghai</code></pre>





<h2 id="9-关闭-swap-分区"><a href="#9-关闭-swap-分区" class="headerlink" title="9. 关闭 swap 分区"></a>9. 关闭 swap 分区</h2><pre><code class="highlight bash">swapoff -a
sed -i <span class="string">&#x27;s:/dev/mapper/rl-swap:#/dev/mapper/rl-swap:g&#x27;</span> /etc/fstab</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">#  立即关闭系统中所有的交换分区
swapoff -a

# 注释掉 /etc/fstab 文件中定义的交换分区挂载条目，防止系统在重启后重新启用交换分区。
sed -i &#x27;s:/dev/mapper/rl-swap:#/dev/mapper/rl-swap:g&#x27; /etc/fstab

# 验证交换分区是否关系
free -h
输出中 Swap 一栏的值会变为 0。</code></pre>
</blockquote>
<h2 id="10-安装基本工具"><a href="#10-安装基本工具" class="headerlink" title="10. 安装基本工具"></a>10. 安装基本工具</h2><pre><code class="highlight bash">dnf -y install openssh-server wget tree bash-completion psmisc vim net-tools lrzsz nfs-utils epel-release telnet rsync yum-utils device-mapper-persistent-data lvm2 git tar curl network-scripts</code></pre>





<h2 id="11-修改系统最大打开文件数"><a href="#11-修改系统最大打开文件数" class="headerlink" title="11. 修改系统最大打开文件数"></a>11. 修改系统最大打开文件数</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt;&gt; /etc/security/limits.conf &lt;&lt;<span class="string">EOF</span>
<span class="string">* soft nofile 655360</span>
<span class="string">* hard nofile 131072</span>
<span class="string">* soft nproc 655350</span>
<span class="string">* hard nproc 655350</span>
<span class="string">* soft memlock unlimited</span>
<span class="string">* hard memlock unlimited</span>
<span class="string">EOF</span>
 
<span class="built_in">echo</span> <span class="string">&quot;ulimit -SHn 65535&quot;</span> &gt;&gt; /etc/profile
<span class="built_in">source</span> /etc/profile</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>soft nofile 655360<br>soft表示软限制，nofile 表示一个进程可打开的最大文件数，默认值为1024。这里的软限制设置为655360，即一个进程可打开的最大文件数为655360。</p>
<p>hard nofile 131072<br>hard表示硬限制，即系统设置的最大值。nofile表示一个进程可打开的最大文件数，默认值为4096。这里的硬限制设置为131072，即系统设置的最大文件数为131072。</p>
<p>soft nproc 655350<br>soft表示软限制，nproc表示一个用户可创建的最大进程数，默认值为30720。这里的软限制设置为655350，即一个用户可创建的最大进程数为655350。</p>
<p>hard nproc 655350<br>hard表示硬限制，即系统设置的最大值。nproc表示一个用户可创建的最大进程数，默认值为4096。这里的硬限制设置为655350，即系统设置的最大进程数为655350。</p>
<p>soft memlock unlimited<br>seft表示软限制，memlock表示一个进程可锁定在RAM中的最大内存，默认值为64 KB。这里的软限制设置为unlimited，即一个进程可锁定的最大内存为无限制。</p>
<p>hard memlock unlimited<br>hard表示硬限制，即系统设置的最大值。memlock表示一个进程可锁定在RAM中的最大内存，默认值为64 KB。这里的硬限制设置为unlimited，即系统设置的最大内存锁定为无限制。</p>
</blockquote>
<h2 id="12-安装-ipvs"><a href="#12-安装-ipvs" class="headerlink" title="12. 安装 ipvs"></a>12. 安装 ipvs</h2><pre><code class="highlight bash"><span class="comment"># 安装 ipvs</span>
yum install ipvsadm ipset sysstat conntrack libseccomp -y

<span class="built_in">cat</span> &gt;&gt; /etc/modules-load.d/ipvs.conf &lt;&lt;<span class="string">EOF </span>
<span class="string">ip_vs</span>
<span class="string">ip_vs_rr</span>
<span class="string">ip_vs_wrr</span>
<span class="string">ip_vs_sh</span>
<span class="string">nf_conntrack</span>
<span class="string">ip_tables</span>
<span class="string">ip_set</span>
<span class="string">xt_set</span>
<span class="string">ipt_set</span>
<span class="string">ipt_rpfilter</span>
<span class="string">ipt_REJECT</span>
<span class="string">ipip</span>
<span class="string">EOF</span>

systemctl restart systemd-modules-load.service

lsmod | grep -e ip_vs -e nf_conntrack</code></pre>

<blockquote>
<p><strong>命名解析：</strong></p>
<ul>
<li><p>ipvsadm  命令行工具，用于管理IPVS（IP Virtual Server）</p>
</li>
<li><p>ipset  内核级工具，用于高效管理IP地址、端口或MAC地址的集合（sets）</p>
</li>
<li><p>sysstat  系统性能监控工具包，包括sar、iostat、mpstat等命令，用于收集和报告CPU、内存、磁盘I&#x2F;O、网络等系统统计数据</p>
</li>
<li><p>conntrack  命令行工具（conntrack-tools的一部分），用于管理Netfilter的连接跟踪表（connection tracking table）</p>
</li>
<li><p>libseccomp  这是一个库，用于支持seccomp（Secure Computing Mode），seccomp是Linux内核功能，用于限制进程的系统调用（syscall），从而增强安全性（如沙箱化）</p>
</li>
</ul>
<p>cat &gt;&gt; ….. 显示的加载内核模块</p>
<ul>
<li>ip_vs  核心IPVS模块，提供虚拟服务器功能，用于L4负载均衡</li>
<li>ip_vs_rr  IPVS的 round-robin 调度算法模块（轮询）</li>
<li>ip_vs_wrr  IPVS的 weighted round-robin 调度算法模块（加权轮询）</li>
<li>ip_vs_sh  IPVS的 source hashing 调度算法模块（源地址哈希）</li>
<li>nf_conntrack  Netfilter连接跟踪模块，跟踪网络连接状态（用于NAT和防火墙）</li>
<li>ip_tables  iptables的核心模块，用于IPv4包过滤和NAT</li>
<li>ip_set  IP集合管理模块，支持高效的IP列表处理</li>
<li>xt_set  iptables的扩展模块，用于与ip_set集成</li>
<li>ipt_set  iptables的set匹配模块（类似xt_set，但特定于IPv4）</li>
<li>ipt_rpfilter  iptables的反向路径过滤模块，防止IP欺骗攻击</li>
<li>ipt_REJECT  iptables的REJECT目标模块，用于拒绝包并发送拒绝消息</li>
<li>ipip  隧道模块，用于封装IP包（类似VPN隧道）</li>
</ul>
<p><code>systemctl restart systemd-modules-load.service</code>：立即加载这些模块（因为&#x2F;etc&#x2F;modules-load.d&#x2F;目录下的.conf文件会被systemd-modules-load服务读取）</p>
<p><code>lsmod | grep -e ip_vs -e nf_conntrack</code> ：检查模块是否加载成功。</p>
</blockquote>
<h2 id="13-开启路由转发"><a href="#13-开启路由转发" class="headerlink" title="13. 开启路由转发"></a>13. 开启路由转发</h2><pre><code class="highlight bash"><span class="built_in">echo</span> <span class="string">&#x27;net.ipv4.ip_forward=1&#x27;</span> &gt;&gt; /etc/sysctl.conf
sysctl -p</code></pre>





<h2 id="14-排除-calico-网卡被-NetworkManager-所管理"><a href="#14-排除-calico-网卡被-NetworkManager-所管理" class="headerlink" title="14. 排除 calico 网卡被 NetworkManager 所管理"></a>14. 排除 calico 网卡被 NetworkManager 所管理</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/NetworkManager/conf.d/calico.conf &lt;&lt; <span class="string">EOF</span>
<span class="string">[keyfile]</span>
<span class="string">unmanaged-devices=interface-name:cali*;interface-name:tunl*;interface-name:vxlan.calico;interface-name:vxlan-v6.calico;interface-name:wireguard.cali;interface-name:wg-v6.cali</span>
<span class="string">EOF</span>

systemctl restart NetworkManager</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">这个参数用于指定不由 NetworkManager 管理的设备。它由以下两个部分组成

interface-name:cali*
表示以 &quot;cali&quot; 开头的接口名称被排除在 NetworkManager 管理之外。例如，&quot;cali0&quot;, &quot;cali1&quot; 等接口不受 NetworkManager 管理

interface-name:tunl*
表示以 &quot;tunl&quot; 开头的接口名称被排除在 NetworkManager 管理之外。例如，&quot;tunl0&quot;, &quot;tunl1&quot; 等接口不受 NetworkManager 管理

interface-name:vxlan.calico
匹配名为vxlan.calico的接口，Calico在VXLAN模式下可能使用该接口名进行跨节点通信（VXLAN是一种覆盖网络技术）

interface-name:vxlan-v6.calico
匹配名为vxlan-v6.calico的接口，这是Calico在支持IPv6的VXLAN模式下使用的接口名

interface-name:wireguard.cali
匹配名为wireguard.cali的接口，Calico支持使用WireGuard（一种高性能VPN协议）进行加密通信，这个接口用于WireGuard隧道。

interface-name:wg-v6.cali
匹配名为wg-v6.cali的接口，这是Calico在IPv6网络中使用的WireGuard接口

通过使用这个参数，可以将特定的接口排除在 NetworkManager 的管理范围之外，以便其他工具或进程可以独立地管理和配置这些接口</code></pre>
</blockquote>
<h2 id="15-修改内核参数"><a href="#15-修改内核参数" class="headerlink" title="15. 修改内核参数"></a>15. 修改内核参数</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class="string">EOF</span>
<span class="string">net.ipv4.ip_forward = 1</span>
<span class="string">net.bridge.bridge-nf-call-iptables = 1</span>
<span class="string">fs.may_detach_mounts = 1</span>
<span class="string">vm.overcommit_memory=1</span>
<span class="string">vm.panic_on_oom=0</span>
<span class="string">fs.inotify.max_user_watches=89100</span>
<span class="string">fs.file-max=52706963</span>
<span class="string">fs.nr_open=52706963</span>
<span class="string">net.netfilter.nf_conntrack_max=2310720</span>
<span class="string">net.ipv4.tcp_keepalive_time = 600</span>
<span class="string">net.ipv4.tcp_keepalive_probes = 3</span>
<span class="string">net.ipv4.tcp_keepalive_intvl =15</span>
<span class="string">net.ipv4.tcp_max_tw_buckets = 36000</span>
<span class="string">net.ipv4.tcp_tw_reuse = 1</span>
<span class="string">net.ipv4.tcp_max_orphans = 327680</span>
<span class="string">net.ipv4.tcp_orphan_retries = 3</span>
<span class="string">net.ipv4.tcp_syncookies = 1</span>
<span class="string">net.ipv4.tcp_max_syn_backlog = 16384</span>
<span class="string">net.ipv4.ip_conntrack_max = 65536</span>
<span class="string">net.ipv4.tcp_max_syn_backlog = 16384</span>
<span class="string">net.ipv4.tcp_timestamps = 0</span>
<span class="string">net.core.somaxconn = 16384</span>
<span class="string">net.ipv6.conf.all.disable_ipv6 = 0</span>
<span class="string">net.ipv6.conf.default.disable_ipv6 = 0</span>
<span class="string">net.ipv6.conf.lo.disable_ipv6 = 0</span>
<span class="string">net.ipv6.conf.all.forwarding = 1</span>
<span class="string">EOF</span>

sysctl --system</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">这些是Linux系统的一些参数设置，用于配置和优化网络、文件系统和虚拟内存等方面的功能。以下是每个参数的详细解释：

net.ipv4.ip_forward = 1
这个参数启用了IPv4的IP转发功能，允许服务器作为网络路由器转发数据包。

net.bridge.bridge-nf-call-iptables = 1
当使用网络桥接技术时，将数据包传递到iptables进行处理。

fs.may_detach_mounts = 1
允许在挂载文件系统时，允许被其他进程使用。

vm.overcommit_memory=1
该设置允许原始的内存过量分配策略，当系统的内存已经被完全使用时，系统仍然会分配额外的内存。

vm.panic_on_oom=0
当系统内存不足（OOM）时，禁用系统崩溃和重启。

fs.inotify.max_user_watches=89100
设置系统允许一个用户的inotify实例可以监控的文件数目的上限。

fs.file-max=52706963
设置系统同时打开的文件数的上限。

fs.nr_open=52706963
设置系统同时打开的文件描述符数的上限。

net.netfilter.nf_conntrack_max=2310720
设置系统可以创建的网络连接跟踪表项的最大数量。

net.ipv4.tcp_keepalive_time = 600
设置TCP套接字的空闲超时时间（秒），超过该时间没有活动数据时，内核会发送心跳包。

net.ipv4.tcp_keepalive_probes = 3
设置未收到响应的TCP心跳探测次数。

net.ipv4.tcp_keepalive_intvl = 15
设置TCP心跳探测的时间间隔（秒）。

net.ipv4.tcp_max_tw_buckets = 36000
设置系统可以使用的TIME_WAIT套接字的最大数量。

net.ipv4.tcp_tw_reuse = 1
启用TIME_WAIT套接字的重新利用，允许新的套接字使用旧的TIME_WAIT套接字。

net.ipv4.tcp_max_orphans = 327680
设置系统可以同时存在的TCP套接字垃圾回收包裹数的最大数量。

net.ipv4.tcp_orphan_retries = 3
设置系统对于孤立的TCP套接字的重试次数。

net.ipv4.tcp_syncookies = 1
启用TCP SYN cookies保护，用于防止SYN洪泛攻击。

net.ipv4.tcp_max_syn_backlog = 16384
设置新的TCP连接的半连接数（半连接队列）的最大长度。

net.ipv4.ip_conntrack_max = 65536
设置系统可以创建的网络连接跟踪表项的最大数量。

net.ipv4.tcp_timestamps = 0
关闭TCP时间戳功能，用于提供更好的安全性。

net.core.somaxconn = 16384
设置系统核心层的连接队列的最大值。

net.ipv6.conf.all.disable_ipv6 = 0
启用IPv6协议。

net.ipv6.conf.default.disable_ipv6 = 0
启用IPv6协议。

net.ipv6.conf.lo.disable_ipv6 = 0
启用IPv6协议。

net.ipv6.conf.all.forwarding = 1
允许IPv6数据包转发。</code></pre>
</blockquote>
<h2 id="16-集群时间同步设置"><a href="#16-集群时间同步设置" class="headerlink" title="16. 集群时间同步设置"></a>16. 集群时间同步设置</h2><p>在3主2从的集群环境中，配置3台 master 节点向使用 chony 通过外部网络同步时间校正自身的时间，并作为时间主服务器给集群中的其它 node 节点校正时间。</p>
<p><em>主节点时间权重不同</em></p>
<p><strong>Master01 节点</strong></p>
<pre><code class="highlight bash">yum install chrony -y

<span class="built_in">cat</span> &gt; /etc/chrony.conf &lt;&lt; <span class="string">EOF </span>
<span class="string">pool ntp1.aliyun.com iburst</span>
<span class="string">pool ntp2.aliyun.com iburst</span>
<span class="string">pool ntp3.aliyun.com iburst</span>
<span class="string">pool ntp4.aliyun.com iburst</span>
<span class="string">driftfile /var/lib/chrony/drift</span>
<span class="string">makestep 1.0 3</span>
<span class="string">rtcsync</span>
<span class="string">allow 10.20.1.0/24</span>
<span class="string">local stratum 10</span>
<span class="string">keyfile /etc/chrony.keys</span>
<span class="string">leapsectz right/UTC</span>
<span class="string">logdir /var/log/chrony</span>
<span class="string">EOF</span>

systemctl restart chronyd ; systemctl <span class="built_in">enable</span> chronyd</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">pool ntp.aliyun.com iburst
指定使用ntp.aliyun.com作为时间服务器池，iburst选项表示在初始同步时会发送多个请求以加快同步速度。

driftfile /var/lib/chrony/drift
指定用于保存时钟漂移信息的文件路径。

makestep 1.0 3
设置当系统时间与服务器时间偏差大于1秒时，会以1秒的步长进行调整。如果偏差超过3秒，则立即进行时间调整。

rtcsync
启用硬件时钟同步功能，可以提高时钟的准确性。

allow 10.20.1.0/24
允许10.20.1.0/24网段范围内的主机与chrony进行时间同步。

local stratum 10
将本地时钟设为stratum 10，stratum值表示时钟的准确度，值越小表示准确度越高。

keyfile /etc/chrony.keys
指定使用的密钥文件路径，用于对时间同步进行身份验证。

leapsectz right/UTC
指定时区为UTC。

logdir /var/log/chrony
指定日志文件存放目录。</code></pre>
</blockquote>
<p><strong>Master02 节点</strong></p>
<pre><code class="highlight bash">yum install chrony -y

<span class="built_in">cat</span> &gt; /etc/chrony.conf &lt;&lt; <span class="string">EOF </span>
<span class="string">pool ntp1.aliyun.com iburst</span>
<span class="string">pool ntp2.aliyun.com iburst</span>
<span class="string">pool ntp3.aliyun.com iburst</span>
<span class="string">pool ntp4.aliyun.com iburst</span>
<span class="string">driftfile /var/lib/chrony/drift</span>
<span class="string">makestep 1.0 3</span>
<span class="string">rtcsync</span>
<span class="string">allow 10.20.1.0/24</span>
<span class="string">local stratum 12</span>
<span class="string">keyfile /etc/chrony.keys</span>
<span class="string">leapsectz right/UTC</span>
<span class="string">logdir /var/log/chrony</span>
<span class="string">EOF</span>

systemctl restart chronyd ; systemctl <span class="built_in">enable</span> chronyd</code></pre>



<p><strong>Master03 节点</strong></p>
<pre><code class="highlight bash">yum install chrony -y

<span class="built_in">cat</span> &gt; /etc/chrony.conf &lt;&lt; <span class="string">EOF </span>
<span class="string">pool ntp1.aliyun.com iburst</span>
<span class="string">pool ntp2.aliyun.com iburst</span>
<span class="string">pool ntp3.aliyun.com iburst</span>
<span class="string">pool ntp4.aliyun.com iburst</span>
<span class="string">driftfile /var/lib/chrony/drift</span>
<span class="string">makestep 1.0 3</span>
<span class="string">rtcsync</span>
<span class="string">allow 10.20.1.0/24</span>
<span class="string">local stratum 15</span>
<span class="string">keyfile /etc/chrony.keys</span>
<span class="string">leapsectz right/UTC</span>
<span class="string">logdir /var/log/chrony</span>
<span class="string">EOF</span>

systemctl restart chronyd ; systemctl <span class="built_in">enable</span> chronyd</code></pre>



<p><strong>Node01节点 和 Node02节点</strong></p>
<pre><code class="highlight bash">yum install chrony -y

<span class="built_in">cat</span> &gt; /etc/chrony.conf &lt;&lt; <span class="string">EOF </span>
<span class="string">pool 10.20.1.101 iburst</span>
<span class="string">pool 10.20.1.102 iburst</span>
<span class="string">pool 10.20.1.103 iburst</span>
<span class="string">driftfile /var/lib/chrony/drift</span>
<span class="string">makestep 1.0 3</span>
<span class="string">rtcsync</span>
<span class="string">keyfile /etc/chrony.keys</span>
<span class="string">leapsectz right/UTC</span>
<span class="string">logdir /var/log/chrony</span>
<span class="string">EOF</span>

systemctl restart chronyd ; systemctl <span class="built_in">enable</span> chronyd

<span class="comment">#使用客户端进行验证</span>
chronyc sources -v</code></pre>





<h2 id="17-配置免密登录"><a href="#17-配置免密登录" class="headerlink" title="17. 配置免密登录"></a>17. 配置免密登录</h2><p>配置 k8s-master01 节点免密登录到其它节点，方便后续从 master01 节点往其它节点发送文件。</p>
<p><strong>master-01</strong></p>
<pre><code class="highlight bash">yum install -y expect
ssh-keygen -t rsa -P <span class="string">&quot;&quot;</span> -f /root/.ssh/id_rsa
<span class="built_in">export</span> user=root
<span class="built_in">export</span> pass=123456
host=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02 m1 m2 m3 n1 n2)
 
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>;<span class="keyword">do</span> expect -c <span class="string">&quot;</span>
<span class="string">spawn ssh-copy-id -i /root/.ssh/id_rsa.pub <span class="variable">$user</span>@<span class="variable">$host</span></span>
<span class="string">    expect &#123;</span>
<span class="string">        \&quot;*yes/no*\&quot; &#123;send \&quot;yes\r\&quot;; exp_continue&#125;</span>
<span class="string">        \&quot;*password*\&quot; &#123;send \&quot;<span class="variable">$pass</span>\r\&quot;; exp_continue&#125;</span>
<span class="string">        \&quot;*Password*\&quot; &#123;send \&quot;<span class="variable">$pass</span>\r\&quot;;&#125;</span>
<span class="string">    &#125;&quot;</span>;
<span class="keyword">done</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext"># 一个自动化交互工具，用于处理需要用户输入的命令行交互
yum install -y expect

# 生成RSA类型的SSH密钥对（公钥和私钥），并存储在指定路径。-P &quot;&quot;：设置空密码（无口令保护），便于自动化使用
ssh-keygen -t rsa -P &quot;&quot; -f /root/.ssh/id_rsa
export user=root
export pass=123456

# 定义一个Bash数组host，包含集群中所有节点的主机名和别名
host=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)

# 遍历host数组，对每个节点执行expect脚本
for host in $&#123;host[@]&#125;;do expect -c &quot;

# 启动ssh-copy-id命令，将公钥文件/root/.ssh/id_rsa.pub分发到目标节点
spawn ssh-copy-id -i /root/.ssh/id_rsa.pub $user@$host
    expect &#123;
    	# 匹配：当ssh-copy-id提示是否信任目标主机
    	# 动作：发送yes并换行（\r），确认连接
    	# exp_continue：继续匹配后续模式（不退出expect）
        \&quot;*yes/no*\&quot; &#123;send \&quot;yes\r\&quot;; exp_continue&#125;
        
        # 匹配：当提示输入密码（大写Password）
        # 动作：发送变量$pass（即123456）并换行
        # exp_continue：继续匹配后续模式。
        \&quot;*password*\&quot; &#123;send \&quot;$pass\r\&quot;; exp_continue&#125;
        \&quot;*Password*\&quot; &#123;send \&quot;$pass\r\&quot;;&#125;
    &#125;&quot;;
done</code></pre>
</blockquote>
<h2 id="18-安装-Docker"><a href="#18-安装-Docker" class="headerlink" title="18. 安装 Docker"></a>18. 安装 Docker</h2><h3 id="18-1-安装-Docker-二进制包"><a href="#18-1-安装-Docker-二进制包" class="headerlink" title="18.1 安装 Docker 二进制包"></a>18.1 安装 Docker 二进制包</h3><p><strong>k8s-master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 二进制包下载地址：https://download.docker.com/linux/static/stable/x86_64/</span>

<span class="comment"># 创建目录，后续下载的文件都放在这里</span>
<span class="built_in">mkdir</span> -p /opt/software/ /opt/module/ &amp;&amp; <span class="built_in">chmod</span> 777 -R /opt/software/ /opt/module/

<span class="comment"># 更新 openssh-server</span>
dnf -y install  openssh-server

<span class="comment"># 下载 Docker</span>
wget https://download.docker.com/linux/static/stable/x86_64/docker-28.4.0.tgz

<span class="comment"># 解压二进制包</span>
tar xf docker-*.tgz

<span class="comment"># 拷贝解压后的二进制包到 /usr/bin 目录下</span>
<span class="built_in">cp</span> docker/* /usr/bin/

<span class="comment"># 将 Docker 复制到其它服务器中</span>
hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
 
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span> 
  <span class="built_in">echo</span> <span class="variable">$i</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> docker/* <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/bin/; 
<span class="keyword">done</span>

<span class="comment"># 验证</span>
$ docker --version
Docker version 28.4.0, build d8eb465

<span class="comment"># 查看 containerd 版本</span>
$ containerd --version
containerd github.com/containerd/containerd v1.7.28 b98a3aace656320842a23f4a392a33f46af97866</code></pre>





<h3 id="18-2-配置-containerd-service"><a href="#18-2-配置-containerd-service" class="headerlink" title="18.2 配置 containerd.service"></a>18.2 配置 containerd.service</h3><ul>
<li><p><strong>containerd 的作用</strong>：它是一个独立的守护进程（daemon），处理低级任务，如镜像拉取、容器启动&#x2F;停止、快照管理、网络&#x2F;存储挂载等。它基于 OCI（Open Container Initiative）标准，与 runC（Docker 的另一个组件，用于实际执行容器）协作。</p>
</li>
<li><p><strong>dockerd 的作用</strong>：Docker Daemon (dockerd) 不再直接管理容器，而是作为一个高层管理器，通过 gRPC 接口与 containerd 通信。dockerd 处理用户命令（如 docker run）、镜像构建、网络&#x2F;卷管理等，并将容器相关操作委托给 containerd。</p>
</li>
</ul>
<p>Docker底层依赖 containerd ，如果不安装 containerd ，Docker 会启动失败，因为 dockerd 需要连接到 containerd.sock（由 containerd 服务生成）。这会导致整个链条崩溃：cri-dockerd → dockerd → containerd。</p>
<p>即使 Kubernetes 通过 cri-dockerd 使用 Docker，Docker 本身还是依赖 containerd 来实际执行容器操作。没有 containerd，cri-dockerd 和 Docker 都无法工作。</p>
<pre><code class="highlight bash"><span class="comment"># 下载 containerd.service, 版本需要与 docker 二进制包中的 containerd 一致</span>
<span class="comment"># https://github.com/containerd/containerd/blob/main/containerd.service</span>
wget https://raw.githubusercontent.com/containerd/containerd/refs/tags/v1.7.28/containerd.service


<span class="comment"># containerd 路径修改后，内容如下：</span>
<span class="built_in">cat</span> &gt;/etc/systemd/system/containerd.service &lt;&lt;<span class="string">EOF</span>
<span class="string">[Unit]</span>
<span class="string">Description=containerd container runtime</span>
<span class="string">Documentation=https://containerd.io</span>
<span class="string">After=network.target local-fs.target dbus.service</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">ExecStartPre=-/sbin/modprobe overlay</span>
<span class="string">ExecStart=/usr/bin/containerd</span>
<span class="string"></span>
<span class="string">Type=notify</span>
<span class="string">Delegate=yes</span>
<span class="string">KillMode=process</span>
<span class="string">Restart=always</span>
<span class="string">RestartSec=5</span>
<span class="string">LimitNPROC=infinity</span>
<span class="string">LimitCORE=infinity</span>
<span class="string">LimitNOFILE=infinity</span>
<span class="string">TasksMax=infinity</span>
<span class="string">OOMScoreAdjust=-999</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string">EOF</span>


<span class="comment"># 设置 containerd 开机自启</span>
systemctl <span class="built_in">enable</span> --now containerd.service


<span class="comment"># 将 containerd.service 复制到其它服务器中</span>
hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span> 
  <span class="built_in">echo</span> <span class="variable">$i</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/systemd/system/containerd.service <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/systemd/system/; 
<span class="keyword">done</span>


<span class="comment"># 配置设置每一台服务器 containerd 开机自启</span>
hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now containerd.service&quot;</span>
<span class="keyword">done</span>

<span class="comment"># 验证</span>
systemctl is-enabled containerd.service</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">[Unit]

Description=containerd container runtime：指定服务的描述信息。
Documentation=https://containerd.io：指定服务的文档链接。
After=network.target local-fs.target：指定服务的启动顺序，在网络和本地文件系统启动之后再启动该服务。
[Service]

ExecStartPre=-/sbin/modprobe overlay：在启动服务之前执行的命令，使用-表示忽略错误。
ExecStart=/usr/bin/containerd：指定服务的启动命令。
Type=notify：指定服务的类型，notify表示服务会在启动完成后向systemd发送通知。
Delegate=yes：允许服务代理其他服务的应答，例如收到关机命令后终止其他服务。
KillMode=process：指定服务终止时的行为，process表示终止服务进程。
Restart=always：指定服务终止后是否自动重启，always表示总是自动重启。
RestartSec=5：指定服务重启的时间间隔，单位为秒。
LimitNPROC=infinity：限制服务的最大进程数，infinity表示没有限制。
LimitCORE=infinity：限制服务的最大核心数，infinity表示没有限制。
LimitNOFILE=1048576：限制服务的最大文件数，指定为1048576。
TasksMax=infinity：限制服务的最大任务数，infinity表示没有限制。
OOMScoreAdjust=-999：指定服务的OOM（Out of Memory）得分，负数表示降低被终止的概率。
[Install]

WantedBy=multi-user.target：指定服务的安装方式，multi-user.target表示该服务在多用户模式下安装。</code></pre>
</blockquote>
<h3 id="18-3-配置-docker-service"><a href="#18-3-配置-docker-service" class="headerlink" title="18.3 配置 docker.service"></a>18.3 配置 docker.service</h3><p>下载地址：<a target="_blank" rel="noopener" href="https://github.com/moby/moby/blob/master/contrib/init/systemd/docker.service">https://github.com/moby/moby/blob/master/contrib/init/systemd/docker.service</a></p>
<pre><code class="highlight bash"><span class="comment"># 下载 docker.service</span>
wget https://raw.githubusercontent.com/moby/moby/refs/tags/v28.4.0/contrib/init/systemd/docker.service


<span class="comment"># 修改后写入到指定目录中</span>
<span class="built_in">cat</span> &gt; /etc/systemd/system/docker.service &lt;&lt;<span class="string">EOF</span>
<span class="string">[Unit]</span>
<span class="string">Description=Docker Application Container Engine</span>
<span class="string">Documentation=https://docs.docker.com</span>
<span class="string">After=network-online.target nss-lookup.target docker.socket firewalld.service containerd.service time-set.target cri-docker.service</span>
<span class="string">Wants=network-online.target containerd.service</span>
<span class="string">Requires=docker.socket containerd.service</span>
<span class="string">StartLimitBurst=3</span>
<span class="string">StartLimitIntervalSec=60</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">Type=notify</span>
<span class="string">ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</span>
<span class="string">ExecReload=/bin/kill -s HUP $MAINPID</span>
<span class="string">TimeoutStartSec=0</span>
<span class="string">RestartSec=2</span>
<span class="string">Restart=always</span>
<span class="string">LimitNPROC=infinity</span>
<span class="string">LimitCORE=infinity</span>
<span class="string">TasksMax=infinity</span>
<span class="string">Delegate=yes</span>
<span class="string">KillMode=process</span>
<span class="string">OOMScoreAdjust=-500</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string">EOF</span>


<span class="comment"># 将 docker.service 复制到其它服务器中</span>
hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span> 
  <span class="built_in">echo</span> <span class="variable">$i</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/systemd/system/docker.service <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/systemd/system/; 
<span class="keyword">done</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">[Unit]

Description: 描述服务的作用，这里是Docker Application Container Engine，即Docker应用容器引擎。
Documentation: 提供关于此服务的文档链接，这里是Docker官方文档链接。
After: 说明该服务在哪些其他服务之后启动，这里是在网络在线、firewalld服务和containerd服务后启动。
Wants: 说明该服务想要的其他服务，这里是网络在线服务。
Requires: 说明该服务需要的其他服务，这里是docker.socket和containerd.service。
[Service]

Type: 服务类型，这里是notify，表示服务在启动完成时发送通知。
ExecStart: 命令，启动该服务时会执行的命令，这里是/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock，即启动dockerd并指定一些参数，其中-H指定dockerd的监听地址为fd://，--containerd指定containerd的sock文件位置。
ExecReload: 重载命令，当接收到HUP信号时执行的命令，这里是/bin/kill -s HUP $MAINPID，即发送HUP信号给主进程ID。
TimeoutSec: 服务超时时间，这里是0，表示没有超时限制。
RestartSec: 重启间隔时间，这里是2秒，表示重启失败后等待2秒再重启。
Restart: 重启策略，这里是always，表示总是重启。
StartLimitBurst: 启动限制次数，这里是3，表示在启动失败后最多重试3次。
StartLimitInterval: 启动限制时间间隔，这里是60秒，表示两次启动之间最少间隔60秒。
LimitNOFILE: 文件描述符限制，这里是infinity，表示没有限制。
LimitNPROC: 进程数限制，这里是infinity，表示没有限制。
LimitCORE: 核心转储限制，这里是infinity，表示没有限制。
TasksMax: 最大任务数，这里是infinity，表示没有限制。
Delegate: 修改权限，这里是yes，表示启用权限修改。
KillMode: 杀死模式，这里是process，表示杀死整个进程组。
OOMScoreAdjust: 用于调整进程在系统内存紧张时的优先级调整，这里是-500，表示将OOM分数降低500。
[Install]

WantedBy: 安装目标，这里是multi-user.target，表示在多用户模式下安装。
在WantedBy参数中，我们可以使用以下参数：
multi-user.target：指定该服务应该在多用户模式下启动。
graphical.target：指定该服务应该在图形化界面模式下启动。
default.target：指定该服务应该在系统的默认目标（runlevel）下启动。
rescue.target：指定该服务应该在系统救援模式下启动。
poweroff.target：指定该服务应该在关机时启动。
reboot.target：指定该服务应该在重启时启动。
halt.target：指定该服务应该在停止时启动。
shutdown.target：指定该服务应该在系统关闭时启动。
这些参数可以根据需要选择一个或多个，以告知系统在何时启动该服务。</code></pre>
</blockquote>
<h3 id="18-4-准备-docker-的-socket-文件"><a href="#18-4-准备-docker-的-socket-文件" class="headerlink" title="18.4 准备 docker 的 socket 文件"></a>18.4 准备 docker 的 socket 文件</h3><p>下载地址：<a target="_blank" rel="noopener" href="https://github.com/moby/moby/blob/v28.4.0/contrib/init/systemd/docker.socket">https://github.com/moby/moby/blob/v28.4.0/contrib/init/systemd/docker.socket</a></p>
<pre><code class="highlight bash"><span class="comment"># 下载 docker.socket</span>
wget https://raw.githubusercontent.com/moby/moby/refs/tags/v28.4.0/contrib/init/systemd/docker.socket


<span class="comment"># 修改后写入到指定路径</span>
<span class="built_in">cat</span> &gt; /etc/systemd/system/docker.socket &lt;&lt;<span class="string">EOF</span>
<span class="string">[Unit]</span>
<span class="string">Description=Docker Socket for the API</span>
<span class="string"></span>
<span class="string">[Socket]</span>
<span class="string"># If /var/run is not implemented as a symlink to /run, you may need to</span>
<span class="string"># specify ListenStream=/var/run/docker.sock instead.</span>
<span class="string">ListenStream=/var/run/docker.sock</span>
<span class="string">SocketMode=0660</span>
<span class="string">SocketUser=root</span>
<span class="string">SocketGroup=docker</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=sockets.target</span>
<span class="string">EOF</span>


<span class="comment"># 将 docker.socket 复制到其它服务器中</span>
hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span> 
  <span class="built_in">echo</span> <span class="variable">$i</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/systemd/system/docker.socket <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/systemd/system/; 
<span class="keyword">done</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">这是一个用于Docker API的socket配置文件，包含了以下参数：

[Unit]

Description：描述了该socket的作用，即为Docker API的socket。
[Socket]

ListenStream：指定了 socket 的监听地址，该 socket 会监听在 /var/run/docker.sock 上，即 Docker 守护程序使用的默认 sock 文件。
SocketMode：指定了socket文件的权限模式，此处为0660，即用户和用户组有读写权限，其他用户无权限。
SocketUser：指定了socket文件的所有者，此处为root用户。
SocketGroup：指定了socket文件的所属用户组，此处为docker用户组。
[Install]

WantedBy：指定了该socket被启用时的目标，此处为sockets.target，表示当sockets.target启动时启用该socket。
该配置文件的作用是为 Docker 提供 API 访问的通道，它监听在 /var/run/docker.sock 上，具有 root 用户权限，但只接受 docker 用户组的成员的连接，并且其他用户无法访问。这样，只有 docker 用户组的成员可以通过该 socket 与 Docker 守护进程进行通信。</code></pre>
</blockquote>
<h3 id="18-5-配置-Docker-加速器"><a href="#18-5-配置-Docker-加速器" class="headerlink" title="18.5 配置 Docker 加速器"></a>18.5 配置 Docker 加速器</h3><pre><code class="highlight bash"><span class="comment"># 创建 docker 配置目录 和 数据目录</span>
<span class="built_in">mkdir</span> /etc/docker/ /data/docker -pv

<span class="comment"># 写入docker配置，这里也修改了docker默认的数据目录</span>
<span class="built_in">cat</span> &gt; /etc/docker/daemon.json &lt;&lt;<span class="string">EOF</span>
<span class="string">&#123;</span>
<span class="string">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span>
<span class="string">  &quot;registry-mirrors&quot;: [</span>
<span class="string">    &quot;https://kfp63jaj.mirror.aliyuncs.com&quot;,</span>
<span class="string">    &quot;https://hub-mirror.c.163.com&quot;,</span>
<span class="string">    &quot;https://mirror.baidubce.com&quot;</span>
<span class="string">  ],</span>
<span class="string">  &quot;max-concurrent-downloads&quot;: 10,</span>
<span class="string">  &quot;log-driver&quot;: &quot;json-file&quot;,</span>
<span class="string">  &quot;log-level&quot;: &quot;warn&quot;,</span>
<span class="string">  &quot;log-opts&quot;: &#123;</span>
<span class="string">    &quot;max-size&quot;: &quot;10m&quot;,</span>
<span class="string">    &quot;max-file&quot;: &quot;3&quot;</span>
<span class="string">    &#125;,</span>
<span class="string">  &quot;data-root&quot;: &quot;/data/docker&quot;</span>
<span class="string">&#125;</span>
<span class="string">EOF</span>


<span class="comment"># 配置设置每一台服务器都创建docker的配置目录和数据目录</span>
hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir /etc/docker/ /data/docker -pv&quot;</span>
<span class="keyword">done</span>


<span class="comment"># 将 daemon.json 复制到其它服务器中</span>
hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span> 
  <span class="built_in">echo</span> <span class="variable">$i</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/docker/daemon.json <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/docker/; 
<span class="keyword">done</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">该参数文件中包含以下参数：

exec-opts: 用于设置Docker守护进程的选项，native.cgroupdriver=systemd表示使用systemd作为Cgroup驱动程序。
registry-mirrors: 用于指定Docker镜像的镜像注册服务器。在这里有三个镜像注册服务器：https://docker.m.daocloud.io、https://docker.mirrors.ustc.edu.cn和http://hub-mirror.c.163.com。
max-concurrent-downloads: 用于设置同时下载镜像的最大数量，默认值为3，这里设置为10。
log-driver: 用于设置Docker守护进程的日志驱动程序，这里设置为json-file。
log-level: 用于设置日志的级别，这里设置为warn。
log-opts: 用于设置日志驱动程序的选项，这里有两个选项：max-size和max-file。max-size表示每个日志文件的最大大小，这里设置为10m，max-file表示保存的最大日志文件数量，这里设置为3。
data-root: 用于设置Docker守护进程的数据存储根目录，默认为/var/lib/docker，这里设置为 /data/docker。</code></pre>
</blockquote>
<h3 id="18-6-启动-Docker"><a href="#18-6-启动-Docker" class="headerlink" title="18.6 启动 Docker"></a>18.6 启动 Docker</h3><pre><code class="highlight bash"><span class="comment"># 创建一个名为 docker 的组</span>
groupadd docker
<span class="comment"># 通知systemd重新加载所有单元配置文件（unit files），以识别新创建或修改的配置文件</span>
systemctl daemon-reload
<span class="comment"># 启用并立即启动Docker的socket单元（docker.socket），使其在系统启动时自动运行，并现在开始监听。</span>
systemctl <span class="built_in">enable</span> --now docker.socket
<span class="comment"># 启用并立即启动Docker守护进程服务（docker.service），使其在系统启动时自动运行，并现在开始运行。</span>
systemctl <span class="built_in">enable</span> --now docker.service
<span class="comment"># 验证：查看 docker 服务状态</span>
systemctl status docker.service
<span class="comment"># 验证：查看docker信息</span>
docker info


<span class="comment"># 集群中的其他服务器也启动 Docker </span>
hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;groupadd docker&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now docker.socket&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now docker.service&quot;</span>
<span class="keyword">done</span></code></pre>





<h2 id="19-安装-cri-docker"><a href="#19-安装-cri-docker" class="headerlink" title="19. 安装 cri-docker"></a>19. 安装 cri-docker</h2><h3 id="19-1-安装-cri-docker-二进制包"><a href="#19-1-安装-cri-docker-二进制包" class="headerlink" title="19.1 安装 cri-docker 二进制包"></a>19.1 安装 cri-docker 二进制包</h3><p>cri-docker 与 docker的版本匹配关系：<a target="_blank" rel="noopener" href="https://github.com/Mirantis/cri-dockerd/releases/tag/v0.4.0">https://github.com/Mirantis/cri-dockerd/releases/tag/v0.4.0</a></p>
<ul>
<li>Bump github.com&#x2F;docker&#x2F;docker to 27.0.2+incompatible by <a target="_blank" rel="noopener" href="https://github.com/cncal">@cncal</a> in <a target="_blank" rel="noopener" href="https://github.com/Mirantis/cri-dockerd/pull/381">#381</a></li>
</ul>
<pre><code class="highlight bash"><span class="comment"># 下载 cri-docker 二进制包</span>
wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.4.0/cri-dockerd-0.4.0.amd64.tgz
<span class="comment"># 解压</span>
tar xvf cri-dockerd-*.amd64.tgz 
<span class="comment"># 复制到 /usr/bin/</span>
<span class="built_in">cp</span> cri-dockerd/cri-dockerd /usr/bin/
<span class="comment"># 授权</span>
<span class="built_in">chmod</span> +x /usr/bin/cri-dockerd



<span class="comment"># 将 cri-dockerd 复制到其它服务器中</span>
hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span> 
  <span class="built_in">echo</span> <span class="variable">$i</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/bin/cri-dockerd <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/bin/; 
<span class="keyword">done</span>


<span class="comment"># 验证</span>
$ cri-dockerd --version
cri-dockerd 0.4.0 (b9b8893)</code></pre>





<h3 id="19-2-配置-cri-docker-service"><a href="#19-2-配置-cri-docker-service" class="headerlink" title="19.2 配置 cri-docker.service"></a>19.2 配置 cri-docker.service</h3><p>从 github 获取文件：<a target="_blank" rel="noopener" href="https://github.com/Mirantis/cri-dockerd/tree/master/packaging/systemd">https://github.com/Mirantis/cri-dockerd/tree/master/packaging/systemd</a></p>
<pre><code class="highlight bash"><span class="comment"># 下载 cri-docker.service 文件</span>
wget https://raw.githubusercontent.com/Mirantis/cri-dockerd/refs/tags/v0.4.0/packaging/systemd/cri-docker.service

<span class="comment"># 修改 ExecStart 启动命令后，写入到指定目录</span>
<span class="built_in">cat</span> &gt; /usr/lib/systemd/system/cri-docker.service &lt;&lt;<span class="string">EOF</span>
<span class="string">[Unit]</span>
<span class="string">Description=CRI Interface for Docker Application Container Engine</span>
<span class="string">Documentation=https://docs.mirantis.com</span>
<span class="string">After=network-online.target firewalld.service docker.service</span>
<span class="string">Wants=network-online.target</span>
<span class="string">Requires=cri-docker.socket</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">Type=notify</span>
<span class="string"># 修啊该启动命令</span>
<span class="string">ExecStart=/usr/bin/cri-dockerd --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9 --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --cri-dockerd-root-directory=/data/dockershim --cri-dockerd-root-directory=/data/docker</span>
<span class="string"></span>
<span class="string">ExecReload=/bin/kill -s HUP $MAINPID</span>
<span class="string">TimeoutSec=0</span>
<span class="string">RestartSec=2</span>
<span class="string">Restart=always</span>
<span class="string">StartLimitBurst=3</span>
<span class="string">StartLimitInterval=60s</span>
<span class="string">LimitNOFILE=infinity</span>
<span class="string">LimitNPROC=infinity</span>
<span class="string">LimitCORE=infinity</span>
<span class="string">TasksMax=infinity</span>
<span class="string">Delegate=yes</span>
<span class="string">KillMode=process</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string">EOF</span>


<span class="comment"># 将 cri-docker.service 复制到其它服务器中</span>
hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span> 
  <span class="built_in">echo</span> <span class="variable">$i</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/cri-docker.service <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/lib/systemd/system/; 
<span class="keyword">done</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">[Unit]

Description：该参数用于描述该单元的功能，这里描述的是CRI与Docker应用容器引擎的接口。
Documentation：该参数指定了相关文档的网址，供用户参考。
After：该参数指定了此单元应该在哪些其他单元之后启动，确保在网络在线、防火墙和Docker服务启动之后再启动此单元。
Wants：该参数指定了此单元希望也启动的所有单元，此处是希望在网络在线之后启动。
Requires：该参数指定了此单元需要依赖的单元，此处是cri-docker.socket单元。
[Service]

Type：该参数指定了服务的类型，这里是notify，表示当服务启动完成时向系统发送通知。
ExecStart：该参数指定了将要运行的命令和参数，此处是执行/usr/bin/cri-dockerd 命令，并指定了网络插件为cni和Pod基础设施容器的镜像为registry.aliyuncs.com/google_containers/pause:3.9。
  - --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock 
  	- 定义 CRI 的监听端点。
  - --cri-dockerd-root-directory=/data/dockershim
  	- 定义 cri-dockerd 的根目录，用于存储临时文件或配置数据。
  - --cri-dockerd-root-directory=/data/docker
  	- 定义 Docker 的根目录。
ExecReload：该参数指定在服务重载时运行的命令，此处是发送HUP信号给主进程。
TimeoutSec：该参数指定了服务启动的超时时间，此处为0，表示无限制。
RestartSec：该参数指定了自动重启服务的时间间隔，此处为2秒。
Restart：该参数指定了在服务发生错误时自动重启，此处是始终重启。
StartLimitBurst：该参数指定了在给定时间间隔内允许的启动失败次数，此处为3次。
StartLimitInterval：该参数指定启动失败的时间间隔，此处为60秒。
LimitNOFILE：该参数指定了允许打开文件的最大数量，此处为无限制。
LimitNPROC：该参数指定了允许同时运行的最大进程数，此处为无限制。
LimitCORE：该参数指定了允许生成的core文件的最大大小，此处为无限制。
TasksMax：该参数指定了此服务的最大任务数，此处为无限制。
Delegate：该参数指定了是否将控制权委托给指定服务，此处为是。
KillMode：该参数指定了在终止服务时如何处理进程，此处是通过终止进程来终止服务。
[Install]

WantedBy：该参数指定了希望这个单元启动的多用户目标。在这里，这个单元希望在multi-user.target启动。</code></pre>
</blockquote>
<h3 id="19-3-配置-cri-docker-socket"><a href="#19-3-配置-cri-docker-socket" class="headerlink" title="19.3 配置 cri-docker.socket"></a>19.3 配置 cri-docker.socket</h3><p>从 github 获取文件：<a target="_blank" rel="noopener" href="https://github.com/Mirantis/cri-dockerd/tree/master/packaging/systemd">https://github.com/Mirantis/cri-dockerd/tree/master/packaging/systemd</a></p>
<pre><code class="highlight bash"><span class="comment"># 下载</span>
wget https://raw.githubusercontent.com/Mirantis/cri-dockerd/refs/tags/v0.4.0/packaging/systemd/cri-docker.socket


<span class="comment"># 修改 ListenStream，并写入到指令目录</span>
<span class="built_in">cat</span> &gt; /usr/lib/systemd/system/cri-docker.socket &lt;&lt;<span class="string">EOF</span>
<span class="string">[Unit]</span>
<span class="string">Description=CRI Docker Socket for the API</span>
<span class="string">PartOf=cri-docker.service</span>
<span class="string"></span>
<span class="string">[Socket]</span>
<span class="string">ListenStream=/var/run/cri-dockerd.sock</span>
<span class="string">SocketMode=0660</span>
<span class="string">SocketUser=root</span>
<span class="string">SocketGroup=docker</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=sockets.target</span>
<span class="string">EOF</span>


<span class="comment"># 将 cri-docker.socket 复制到其它服务器中</span>
hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span> 
  <span class="built_in">echo</span> <span class="variable">$i</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/cri-docker.socket <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/lib/systemd/system/; 
<span class="keyword">done</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">该配置文件是用于systemd的单元配置文件(unit file)，用于定义一个socket单元。

[Unit]

Description：表示该单元的描述信息。
PartOf：表示该单元是cri-docker.service的一部分。
[Socket]

ListenStream：指定了该socket要监听的地址和端口，这里要与 cri-docker.service 配置的 ExecStart 指定的套接字一致，都为 /var/run/cri-dockerd.sock。Unix域套接字用于在同一台主机上的进程之间通信。
SocketMode：指定了socket文件的权限模式，此处为0660，即用户和用户组有读写权限，其他用户无权限。
SocketUser：指定了socket文件的所有者，此处为root用户。
SocketGroup：指定了socket文件的所属用户组，此处为docker用户组。
[Install]

WantedBy：部分定义了该单元的安装配置信息。WantedBy=sockets.target表示当sockets.target单元启动时，自动启动该socket单元。sockets.target是一个系统服务，用于管理所有的socket单元。</code></pre>
</blockquote>
<h3 id="19-4-启动-cri-docker"><a href="#19-4-启动-cri-docker" class="headerlink" title="19.4 启动 cri-docker"></a>19.4 启动 cri-docker</h3><pre><code class="highlight bash"><span class="comment"># 通知systemd重新加载所有单元配置文件（unit files），以识别新创建或修改的配置文件</span>
systemctl daemon-reload
<span class="comment"># 设置开机自启</span>
systemctl <span class="built_in">enable</span> --now cri-docker.service
<span class="comment"># 验证，查看状态</span>
systemctl status cri-docker.service


<span class="comment"># 集群中的其他服务器也启动 Docker </span>
hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now cri-docker.service&quot;</span>
<span class="keyword">done</span></code></pre>





<h1 id="四、K8S-与-ETCD-下载及安装（在-master01-节点上操作）"><a href="#四、K8S-与-ETCD-下载及安装（在-master01-节点上操作）" class="headerlink" title="四、K8S 与 ETCD 下载及安装（在 master01 节点上操作）"></a>四、K8S 与 ETCD 下载及安装（在 master01 节点上操作）</h1><p>当前选择安装 K8S 版本：1.29.2，ETCD 版本：3.5.16</p>
<p><strong>查看 K8S 与 ETCD 的版本匹配关系以及二进制包下载地址</strong></p>
<p><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/release-1.29/cluster/images/etcd/Makefile">https://github.com/kubernetes/kubernetes/blob/release-1.29/cluster/images/etcd/Makefile</a></p>
<p><strong>需要下载的镜像</strong> </p>
<p><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md#container-images-13">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md#container-images-13</a></p>
<p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/11/20251011-124215.png" alt="K8S 1.29.2 需要下载的镜像"></p>
<h2 id="1-安装-K8S-二进制包"><a href="#1-安装-K8S-二进制包" class="headerlink" title="1. 安装 K8S 二进制包"></a>1. 安装 K8S 二进制包</h2><p>下载地址：<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md#v1292">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md#v1292</a></p>
<pre><code class="highlight bash"><span class="comment"># 下载 K8S 二进制包</span>
wget https://dl.k8s.io/v1.29.2/kubernetes-server-linux-amd64.tar.gz

<span class="comment"># 解压文件到指定目录</span>
tar -xf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/local/bin kubernetes/server/bin/kube&#123;<span class="built_in">let</span>,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;

<span class="comment"># 查看解压的文件</span>
$ <span class="built_in">ls</span> /usr/local/bin/
kube-apiserver  kube-controller-manager  kube-proxy  kube-scheduler  kubectl  kubelet


<span class="comment"># 将解压后的 K8S 二进制包复制到其它服务器中</span>
<span class="comment"># 拷贝 master 组件</span>
hots=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span> 
  <span class="built_in">echo</span> <span class="variable">$i</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/local/bin/kube* <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/local/bin/; 
<span class="keyword">done</span>

<span class="comment"># 拷贝 worker 组件</span>
hots=<span class="string">&#x27;k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span> 
  <span class="built_in">echo</span> <span class="variable">$i</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/local/bin/kube&#123;<span class="built_in">let</span>,-proxy&#125; <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/local/bin/; 
<span class="keyword">done</span>

<span class="comment"># 验证</span>
$ kubelet --version
Kubernetes v1.29.2</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">这是一个 tar 命令，用于解压指定的 kubernetes-server-linux-amd64.tar.gz 文件，并将其中的特定文件提取到 /usr/local/bin 目录下。

命令的解释如下：

tar：用于处理 tar 压缩文件的命令。
-xf：表示解压操作。
kubernetes-server-linux-amd64.tar.gz：要解压的文件名。
--strip-components=3：表示解压时忽略压缩文件中的前3级目录结构，提取文件时直接放到目标目录中。
-C /usr/local/bin：指定提取文件的目标目录为 /usr/local/bin。
kubernetes/server/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;：要解压和提取的文件名模式，用花括号括起来表示模式中的多个可能的文件名。
总的来说，这个命令的作用是将 kubernetes-server-linux-amd64.tar.gz 文件中的 kubelet、kubectl、kube-apiserver、kube-controller-manager、kube-scheduler和kube-proxy 六个文件提取到 /usr/local/bin 目录下，同时忽略文件路径中的前三级目录结构。</code></pre>
</blockquote>
<h2 id="2-安装-ETCD-二进制包"><a href="#2-安装-ETCD-二进制包" class="headerlink" title="2. 安装 ETCD 二进制包"></a>2. 安装 ETCD 二进制包</h2><p>下载地址：<a target="_blank" rel="noopener" href="https://github.com/etcd-io/etcd/releases/tag/v3.5.16">https://github.com/etcd-io/etcd/releases/tag/v3.5.16</a></p>
<pre><code class="highlight bash"><span class="comment"># 下载 ETCD 二进制安装包</span>
wget https://github.com/etcd-io/etcd/releases/download/v3.5.16/etcd-v3.5.16-linux-amd64.tar.gz

<span class="comment"># 解压etcd安装文件</span>
tar -xf etcd*.tar.gz &amp;&amp; <span class="built_in">mv</span> etcd-*/etcd /usr/local/bin/ &amp;&amp; <span class="built_in">mv</span> etcd-*/etcdctl /usr/local/bin/


<span class="comment"># 将解压后的 K8S 二进制包复制到其它服务器中</span>
hots=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span> 
  <span class="built_in">echo</span> <span class="variable">$i</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/local/bin/etcd* <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/local/bin/; 
<span class="keyword">done</span>

<span class="comment"># 验证：查看/usr/local/bin下内容</span>
$ etcdctl version
etcdctl version: 3.5.16
API version: 3.5</code></pre>





<h2 id="3-生成相关证书"><a href="#3-生成相关证书" class="headerlink" title="3. 生成相关证书"></a>3. 生成相关证书</h2><h3 id="3-1-安装证书工具"><a href="#3-1-安装证书工具" class="headerlink" title="3.1 安装证书工具"></a>3.1 安装证书工具</h3><p><strong>k8s-master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># master01 节点下载证书生成工具</span>
wget https://github.com/cloudflare/cfssl/releases/download/v1.6.4/cfssl_1.6.4_linux_amd64 -O /usr/local/bin/cfssl
wget https://github.com/cloudflare/cfssl/releases/download/v1.6.4/cfssljson_1.6.4_linux_amd64 -O /usr/local/bin/cfssljson

<span class="built_in">chmod</span> +x /usr/local/bin/cfssl /usr/local/bin/cfssljson</code></pre>





<h3 id="3-2-生成-ETCD-证书"><a href="#3-2-生成-ETCD-证书" class="headerlink" title="3.2 生成 ETCD 证书"></a>3.2 生成 ETCD 证书</h3><h4 id="3-2-1-ca-config-json"><a href="#3-2-1-ca-config-json" class="headerlink" title="3.2.1 ca-config.json"></a>3.2.1 ca-config.json</h4><p><strong>k8s-master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 创建目录，存放生成的证书</span>
<span class="built_in">mkdir</span> /etc/etcd/ssl -p

<span class="comment"># 写入生成证书所需的配置文件,master01 节点生成 etcd 证书</span>
<span class="built_in">cat</span> &gt; /etc/etcd/ssl/ca-config.json &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;signing&quot;: &#123;</span>
<span class="string">    &quot;default&quot;: &#123;</span>
<span class="string">      &quot;expiry&quot;: &quot;876000h&quot;</span>
<span class="string">    &#125;,</span>
<span class="string">    &quot;profiles&quot;: &#123;</span>
<span class="string">      &quot;kubernetes&quot;: &#123;</span>
<span class="string">        &quot;usages&quot;: [</span>
<span class="string">            &quot;signing&quot;,</span>
<span class="string">            &quot;key encipherment&quot;,</span>
<span class="string">            &quot;server auth&quot;,</span>
<span class="string">            &quot;client auth&quot;</span>
<span class="string">        ],</span>
<span class="string">        &quot;expiry&quot;: &quot;876000h&quot;</span>
<span class="string">      &#125;</span>
<span class="string">    &#125;</span>
<span class="string">  &#125;</span>
<span class="string">&#125;</span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p><code>ca-config.json</code>文件是使用CFSSL（CloudFlare’s PKI&#x2F;TLS toolkit）工具生成证书的核心配置文件。它主要用于定义证书签名的全局策略和配置文件（profiles），确保生成的证书具有一致的安全属性、用途和有效期。</p>
<pre><code class="highlight plaintext">在这里，有两个部分：signing 和 profiles。

signing 包含了默认签名配置和配置文件。
默认签名配置 default 指定了证书的过期时间为 876000h 。876000h 表示证书有效期为 100 年。

profiles 部分定义了不同的证书配置文件。
在这里，只有一个配置文件 kubernetes 。它包含了以下 usages 和过期时间 expiry：

signing：用于对其他证书进行签名
key encipherment：用于加密和解密传输数据
server auth：用于服务器身份验证
client auth：用于客户端身份验证
对于 kubernetes 配置文件，证书的过期时间也是 876000h，即100年。</code></pre>
</blockquote>
<h4 id="3-2-2-etcd-ca-csr-json"><a href="#3-2-2-etcd-ca-csr-json" class="headerlink" title="3.2.2 etcd-ca-csr.json"></a>3.2.2 etcd-ca-csr.json</h4><p><strong>k8s-master01</strong></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/etcd/ssl/etcd-ca-csr.json  &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;CN&quot;: &quot;etcd&quot;,</span>
<span class="string">  &quot;key&quot;: &#123;</span>
<span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span>
<span class="string">    &quot;size&quot;: 2048</span>
<span class="string">  &#125;,</span>
<span class="string">  &quot;names&quot;: [</span>
<span class="string">    &#123;</span>
<span class="string">      &quot;C&quot;: &quot;CN&quot;,</span>
<span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;O&quot;: &quot;etcd&quot;,</span>
<span class="string">      &quot;OU&quot;: &quot;Etcd Security&quot;</span>
<span class="string">    &#125;</span>
<span class="string">  ],</span>
<span class="string">  &quot;ca&quot;: &#123;</span>
<span class="string">    &quot;expiry&quot;: &quot;876000h&quot;</span>
<span class="string">  &#125;</span>
<span class="string">&#125;</span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>etcd-ca-csr.json 是 Certificate Signing Request (CSR) 文件，用于生成 ETCD 的根 CA 证书（etcd-ca.pem 和 etcd-ca-key.pem）。根 CA 证书是 ETCD 集群的安全基石，用于签署 ETCD 节点证书（etcd.pem 和 etcd-key.pem）和其他相关证书，确保集群内部通信的加密和身份验证。</p>
<pre><code class="highlight plaintext">JSON 配置文件指定了生成证书签名请求所需的数据。

&quot;CN&quot;: &quot;etcd&quot; 指定了希望生成的证书的 CN 字段（Common Name），即证书的主题，通常是该证书标识的实体的名称。
&quot;key&quot;: &#123;&#125; 指定了生成证书所使用的密钥的配置信息。&quot;algo&quot;: &quot;rsa&quot; 指定了密钥的算法为 RSA，&quot;size&quot;: 2048 指定了密钥的长度为 2048 位。
&quot;names&quot;: [] 包含了生成证书时所需的实体信息。在这个例子中，只包含了一个实体，其相关信息如下：
&quot;C&quot;: &quot;CN&quot; 指定了实体的国家/地区代码，这里是中国。
&quot;ST&quot;: &quot;Beijing&quot; 指定了实体所在的省/州。
&quot;L&quot;: &quot;Beijing&quot; 指定了实体所在的城市。
&quot;O&quot;: &quot;etcd&quot; 指定了实体的组织名称。
&quot;OU&quot;: &quot;Etcd Security&quot; 指定了实体所属的组织单位。
&quot;ca&quot;: &#123;&#125; 指定了生成证书时所需的CA（Certificate Authority）配置信息。
&quot;expiry&quot;: &quot;876000h&quot; 指定了证书的有效期，这里是876000小时。
生成证书签名请求时，可以使用这个 JSON 配置文件作为输入，根据配置文件中的信息生成相应的 CSR 文件。然后，可以将 CSR 文件发送给 CA 进行签名，以获得有效的证书。

生成 etcd 证书和 etcd 证书的 key（如果你觉得以后可能会扩容，可以在 ip 那多写几个预留出来）
若没有IPv6 可删除可保留</code></pre>
</blockquote>
<h4 id="3-2-3-生成-ETCD-的根-CA-证书"><a href="#3-2-3-生成-ETCD-的根-CA-证书" class="headerlink" title="3.2.3 生成 ETCD 的根 CA 证书"></a>3.2.3 生成 ETCD 的根 CA 证书</h4><p><strong>k8s-master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 生成 ETCD 的根 CA 证书</span>
cfssl gencert -initca /etc/etcd/ssl/etcd-ca-csr.json | cfssljson -bare /etc/etcd/ssl/etcd-ca

<span class="comment"># 查看生成的 ETCD 的根 CA 证书</span>
$ ll /etc/etcd/ssl/
total 20
-rw-r--r--. 1 root root  294 Oct 11 19:03 ca-config.json
-rw-r--r--. 1 root root  249 Oct 11 19:20 etcd-ca-csr.json
-rw-------. 1 root root 1679 Oct 11 19:21 etcd-ca-key.pem
-rw-r--r--. 1 root root 1050 Oct 11 19:21 etcd-ca.csr
-rw-r--r--. 1 root root 1318 Oct 11 19:21 etcd-ca.pem</code></pre>

<blockquote>
<pre><code class="highlight plaintext">具体的解释如下：
cfssl 是一个用于生成 TLS/SSL 证书的工具，它支持 PKI、JSON 格式配置文件以及与许多其他集成工具的配合使用。

gencert 参数表示生成证书的操作。-initca 参数表示初始化一个CA（证书颁发机构）。CA 是用于签发其他证书的根证书。etcd-ca-csr.json 是一个 JSON 格式的配置文件，其中包含了CA的详细信息，如私钥、公钥、有效期等。这个文件提供了生成 CA 证书所需的信息。

| 符号表示将上一个命令的输出作为下一个命令的输入。

cfssljson 是 cfssl 工具的一个子命令，用于格式化 cfssl 生成的 JSON 数据。 -bare 参数表示直接输出裸证书，即只生成证书文件，不包含其他格式的文件。/etc/etcd/ssl/etcd-ca 是指定生成的证书文件的路径和名称。

所以，这条命令的含义是使用 cfssl 工具根据配置文件 etcd-ca-csr.json 生成一个 CA 证书，并将证书文件保存在 /etc/etcd/ssl/etcd-ca 路径下。</code></pre>
</blockquote>
<h4 id="3-2-4-etcd-csr-json"><a href="#3-2-4-etcd-csr-json" class="headerlink" title="3.2.4 etcd-csr.json"></a>3.2.4 etcd-csr.json</h4><p><strong>k8s-master01</strong></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/etcd/ssl/etcd-csr.json &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;CN&quot;: &quot;etcd&quot;,</span>
<span class="string">  &quot;key&quot;: &#123;</span>
<span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span>
<span class="string">    &quot;size&quot;: 2048</span>
<span class="string">  &#125;,</span>
<span class="string">  &quot;names&quot;: [</span>
<span class="string">    &#123;</span>
<span class="string">      &quot;C&quot;: &quot;CN&quot;,</span>
<span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;O&quot;: &quot;etcd&quot;,</span>
<span class="string">      &quot;OU&quot;: &quot;Etcd Security&quot;</span>
<span class="string">    &#125;</span>
<span class="string">  ]</span>
<span class="string">&#125;</span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p>命令解析：</p>
<p>etcd-csr.json 用于生成 ETCD 节点的 TLS 证书（etcd.pem 和 etcd-key.pem），这些证书由 ETCD 的根 CA（通过 etcd-ca-csr.json 生成的 etcd-ca.pem）签署。</p>
<pre><code class="highlight plaintext">这段代码是一个 JSON 格式的配置文件，用于生成一个证书签名请求（Certificate Signing Request，CSR）。

首先，&quot;CN&quot;字段指定了该证书的通用名称（Common Name），这里设为&quot;etcd&quot;。

接下来，&quot;key&quot;字段指定了密钥的算法（&quot;algo&quot;字段）和长度（&quot;size&quot;字段），此处使用的是RSA算法，密钥长度为2048位。

最后，&quot;names&quot;字段是一个数组，其中包含了一个名字对象，用于指定证书中的一些其他信息。这个名字对象包含了以下字段：

&quot;C&quot;字段指定了国家代码（Country），这里设置为&quot;CN&quot;。
&quot;ST&quot;字段指定了省份（State）或地区，这里设置为&quot;Beijing&quot;。
&quot;L&quot;字段指定了城市（Locality），这里设置为&quot;Beijing&quot;。
&quot;O&quot;字段指定了组织（Organization），这里设置为&quot;etcd&quot;。
&quot;OU&quot;字段指定了组织单元（Organizational Unit），这里设置为&quot;Etcd Security&quot;。
这些字段将作为证书的一部分，用于标识和验证证书的使用范围和颁发者等信息。</code></pre>
</blockquote>
<h4 id="3-2-5-生成-ETCD-节点证书"><a href="#3-2-5-生成-ETCD-节点证书" class="headerlink" title="3.2.5 生成 ETCD 节点证书"></a>3.2.5 生成 ETCD 节点证书</h4><p><strong>k8s-master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 生成 ETCD 节点证书</span>
cfssl gencert \
-ca=/etc/etcd/ssl/etcd-ca.pem \
-ca-key=/etc/etcd/ssl/etcd-ca-key.pem \
-config=/etc/etcd/ssl/ca-config.json \
-hostname=127.0.0.1,k8s-master01,k8s-master02,k8s-master03,10.20.1.101,10.20.1.102,10.20.1.103,2400:3200::101,2400:3200::102,2400:3200::103,::1 \
-profile=kubernetes \
/etc/etcd/ssl/etcd-csr.json | cfssljson -bare /etc/etcd/ssl/etcd</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">这是一条使用cfssl生成etcd节点证书的命令，下面是各个参数的解释：

-ca=/etc/etcd/ssl/etcd-ca.pem：指定用于签名etcd证书的CA文件的路径。
-ca-key=/etc/etcd/ssl/etcd-ca-key.pem：指定用于签名etcd证书的CA私钥文件的路径。
-config=ca-config.json：指定CA配置文件的路径，该文件定义了证书的有效期、加密算法等设置。
-hostname=xxxx：指定要为etcd生成证书的主机名和IP地址列表。
-profile=kubernetes：指定使用的证书配置文件，该文件定义了证书的用途和扩展属性。
etcd-csr.json：指定etcd证书请求的JSON文件的路径，该文件包含了证书请求的详细信息。
| cfssljson -bare /etc/etcd/ssl/etcd：通过管道将cfssl命令的输出传递给cfssljson命令，并使用-bare参数指定输出文件的前缀路径，这里将生成etcd证书的.pem和-key.pem文件。

这条命令的作用是使用指定的CA证书和私钥，根据证书请求的JSON文件和配置文件生成etcd的证书文件。</code></pre>
</blockquote>
<h4 id="3-2-6-将证书复制到其他节点"><a href="#3-2-6-将证书复制到其他节点" class="headerlink" title="3.2.6 将证书复制到其他节点"></a>3.2.6 将证书复制到其他节点</h4><p><strong>k8s-master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 将生成的 ETCD 证书复制到其他节点</span>
hosts=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir /etc/etcd/ssl -p&quot;</span>
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/etcd/ssl/* <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/etcd/ssl/; 
<span class="keyword">done</span></code></pre>





<h3 id="3-3-生成-K8S-相关证书"><a href="#3-3-生成-K8S-相关证书" class="headerlink" title="3.3 生成 K8S 相关证书"></a>3.3 生成 K8S 相关证书</h3><h4 id="3-3-1-ca-config-json"><a href="#3-3-1-ca-config-json" class="headerlink" title="3.3.1 ca-config.json"></a>3.3.1 ca-config.json</h4><p><strong>k8s-master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 创建目录，用于存放 K8S 相关证书</span>
<span class="built_in">mkdir</span> -p /etc/kubernetes/pki

<span class="built_in">cat</span> &gt; /etc/kubernetes/pki/ca-config.json &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;signing&quot;: &#123;</span>
<span class="string">    &quot;default&quot;: &#123;</span>
<span class="string">      &quot;expiry&quot;: &quot;876000h&quot;</span>
<span class="string">    &#125;,</span>
<span class="string">    &quot;profiles&quot;: &#123;</span>
<span class="string">      &quot;kubernetes&quot;: &#123;</span>
<span class="string">        &quot;usages&quot;: [</span>
<span class="string">            &quot;signing&quot;,</span>
<span class="string">            &quot;key encipherment&quot;,</span>
<span class="string">            &quot;server auth&quot;,</span>
<span class="string">            &quot;client auth&quot;</span>
<span class="string">        ],</span>
<span class="string">        &quot;expiry&quot;: &quot;876000h&quot;</span>
<span class="string">      &#125;</span>
<span class="string">    &#125;</span>
<span class="string">  &#125;</span>
<span class="string">&#125;</span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p><code>ca-config.json</code>文件是使用CFSSL（CloudFlare’s PKI&#x2F;TLS toolkit）工具生成证书的核心配置文件。它主要用于定义证书签名的全局策略和配置文件（profiles），确保生成的证书具有一致的安全属性、用途和有效期。</p>
<pre><code class="highlight plaintext">在这里，有两个部分：signing 和 profiles。

signing 包含了默认签名配置和配置文件。
默认签名配置 default 指定了证书的过期时间为 876000h 。876000h 表示证书有效期为 100 年。

profiles 部分定义了不同的证书配置文件。
在这里，只有一个配置文件 kubernetes 。它包含了以下 usages 和过期时间 expiry：

signing：用于对其他证书进行签名
key encipherment：用于加密和解密传输数据
server auth：用于服务器身份验证
client auth：用于客户端身份验证
对于 kubernetes 配置文件，证书的过期时间也是 876000h，即100年。</code></pre>
</blockquote>
<h4 id="3-3-2-ca-csr-json"><a href="#3-3-2-ca-csr-json" class="headerlink" title="3.3.2 ca-csr.json"></a>3.3.2 ca-csr.json</h4><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/pki/ca-csr.json &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;CN&quot;: &quot;kubernetes&quot;,</span>
<span class="string">  &quot;key&quot;: &#123;</span>
<span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span>
<span class="string">    &quot;size&quot;: 2048</span>
<span class="string">  &#125;,</span>
<span class="string">  &quot;names&quot;: [</span>
<span class="string">    &#123;</span>
<span class="string">      &quot;C&quot;: &quot;CN&quot;,</span>
<span class="string">      &quot;ST&quot;: &quot;Guangdong&quot;,</span>
<span class="string">      &quot;L&quot;: &quot;Guangzhou&quot;,</span>
<span class="string">      &quot;O&quot;: &quot;Kubernetes&quot;,</span>
<span class="string">      &quot;OU&quot;: &quot;System&quot;</span>
<span class="string">    &#125;</span>
<span class="string">  ],</span>
<span class="string">  &quot;ca&quot;: &#123;</span>
<span class="string">    &quot;expiry&quot;: &quot;876000h&quot;</span>
<span class="string">  &#125;</span>
<span class="string">&#125;</span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>ca-csr.json 用于生成 Kubernetes 集群的根 CA 证书（ca.pem 和 ca-key.pem）。根 CA 证书是 Kubernetes 安全体系的核心，用于签署集群内所有组件的证书（如 API Server、kubelet、admin 用户等），支持 TLS 加密和 Mutual TLS 认证。</p>
<pre><code class="highlight plaintext">这是一个用于生成 Kubernetes 相关证书的配置文件。该配置文件中包含以下信息：

CN：CommonName，即用于标识证书的通用名称。在此配置中，CN 设置为 &quot;kubernetes&quot;，表示该证书是用于 Kubernetes。
key：用于生成证书的算法和大小。在此配置中，使用的算法是 RSA，大小是 2048 位。
names：用于证书中的名称字段的详细信息。在此配置中，有以下字段信息：
	C：Country，即国家。在此配置中，设置为 &quot;CN&quot;。
	ST：State，即省/州。在此配置中，设置为 &quot;Beijing&quot;。
	L：Locality，即城市。在此配置中，设置为 &quot;Beijing&quot;。
	O：Organization，即组织。在此配置中，设置为 &quot;Kubernetes&quot;。
	OU：Organization Unit，即组织单位。在此配置中，设置为 &quot;Kubernetes-manual&quot;。
ca：用于证书签名的证书颁发机构（CA）的配置信息。在此配置中，设置了证书的有效期为 876000 小时。
这个配置文件可以用于生成 Kubernetes 相关的证书，以确保集群中的通信安全性。</code></pre>
</blockquote>
<h4 id="3-3-3-生成-Kubernetes-集群的根-CA-证书"><a href="#3-3-3-生成-Kubernetes-集群的根-CA-证书" class="headerlink" title="3.3.3 生成 Kubernetes 集群的根 CA 证书"></a>3.3.3 生成 Kubernetes 集群的根 CA 证书</h4><pre><code class="highlight bash">cfssl gencert -initca /etc/kubernetes/pki/ca-csr.json | cfssljson -bare /etc/kubernetes/pki/ca</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<pre><code class="highlight plaintext">具体的解释如下：

cfssl是一个用于生成TLS/SSL证书的工具，它支持PKI、JSON格式配置文件以及与许多其他集成工具的配合使用。

gencert参数表示生成证书的操作。-initca参数表示初始化一个CA（证书颁发机构）。CA是用于签发其他证书的根证书。ca-csr.json是一个JSON格式的配置文件，其中包含了CA的详细信息，如私钥、公钥、有效期等。这个文件提供了生成CA证书所需的信息。

| 符号表示将上一个命令的输出作为下一个命令的输入。

cfssljson是cfssl工具的一个子命令，用于格式化cfssl生成的JSON数据。 -bare参数表示直接输出裸证书，即只生成证书文件，不包含其他格式的文件。/etc/kubernetes/pki/ca是指定生成的证书文件的路径和名称。

所以，这条命令的含义是使用cfssl工具根据配置文件ca-csr.json生成一个CA证书，并将证书文件保存在/etc/kubernetes/pki/ca路径下。</code></pre>
</blockquote>
<h4 id="3-3-4-apiserver-csr-json"><a href="#3-3-4-apiserver-csr-json" class="headerlink" title="3.3.4 apiserver-csr.json"></a>3.3.4 apiserver-csr.json</h4><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/pki/apiserver-csr.json &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;CN&quot;: &quot;kube-apiserver&quot;,</span>
<span class="string">  &quot;key&quot;: &#123;</span>
<span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span>
<span class="string">    &quot;size&quot;: 2048</span>
<span class="string">  &#125;,</span>
<span class="string">  &quot;names&quot;: [</span>
<span class="string">    &#123;</span>
<span class="string">      &quot;C&quot;: &quot;CN&quot;,</span>
<span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;O&quot;: &quot;Kubernetes&quot;,</span>
<span class="string">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span>
<span class="string">    &#125;</span>
<span class="string">  ]</span>
<span class="string">&#125;</span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p>命令解析：</p>
<p>apiserver-csr.json 用于生成 Kubernetes API Server 的 TLS 证书（apiserver.pem 和 apiserver-key.pem），这些证书由 Kubernetes 的根 CA（通过 ca-csr.json 生成的 ca.pem）签署。</p>
<p>证书用于：</p>
<ul>
<li>服务器端认证：确保 API Server 的身份可信，客户端（如 kubectl、kubelet）可以通过 CA 证书（ca.pem）验证 API Server。</li>
<li>客户端认证：支持 Mutual TLS，API Server 验证客户端证书（如 admin、kubelet）的合法性。</li>
<li>加密通信：通过 TLS 加密 API Server 与客户端之间的通信，防止数据泄露或篡改。</li>
</ul>
</blockquote>
<h4 id="3-3-5-生成-apiserver-证书"><a href="#3-3-5-生成-apiserver-证书" class="headerlink" title="3.3.5 生成 apiserver 证书"></a>3.3.5 生成 apiserver 证书</h4><pre><code class="highlight bash">cfssl gencert \
-ca=/etc/kubernetes/pki/ca.pem \
-ca-key=/etc/kubernetes/pki/ca-key.pem \
-config=/etc/kubernetes/pki/ca-config.json \
-hostname=10.96.0.1,127.0.0.1,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,10.20.1.101,10.20.1.102,10.20.1.103,10.20.1.104,10.20.1.105,10.20.1.106,10.20.1.107,10.20.1.108,10.20.1.109,2400:3200::101,2400:3200::102,2400:3200::103,2400:3200::104,2400:3200::105,2400:3200::106,2400:3200::107,2400:3200::108,2400:3200::109 \
-profile=kubernetes \
/etc/kubernetes/pki/apiserver-csr.json | cfssljson -bare /etc/kubernetes/pki/apiserver</code></pre>



<h4 id="3-3-6-apiserver-聚合证书"><a href="#3-3-6-apiserver-聚合证书" class="headerlink" title="3.3.6 apiserver 聚合证书"></a>3.3.6 apiserver 聚合证书</h4><p>访问 kube-apiserver 的另一种方式就是使用 kube-proxy 来代理访问, 而该证书就是用来支持 SSL 代理访问的。在该种访问模式下，我们是以http的方式发起请求到代理服务的, 此时, 代理服务会将该请求发送给 kube-apiserver , 在此之前, 代理会将发送给 kube-apiserver 的请求头里加入证书信息。</p>
<pre><code class="highlight plaintext">客户端 -- 发起请求 ---&gt; 代理 -- Add Header信息:发起请求 --&gt; kube-apiserve</code></pre>

<p>如果apiserver所在的主机上没有运行kube-proxy，既无法通过服务的ClusterIP进行访问，需要 <code>--enable-aggregator-routing=true</code></p>
<h5 id="3-3-6-1-front-proxy-ca-csr-json"><a href="#3-3-6-1-front-proxy-ca-csr-json" class="headerlink" title="3.3.6.1 front-proxy-ca-csr.json"></a>3.3.6.1 front-proxy-ca-csr.json</h5><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/pki/front-proxy-ca-csr.json  &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;CN&quot;: &quot;kubernetes&quot;,</span>
<span class="string">  &quot;key&quot;: &#123;</span>
<span class="string">     &quot;algo&quot;: &quot;rsa&quot;,</span>
<span class="string">     &quot;size&quot;: 2048</span>
<span class="string">  &#125;,</span>
<span class="string">  &quot;ca&quot;: &#123;</span>
<span class="string">    &quot;expiry&quot;: &quot;876000h&quot;</span>
<span class="string">  &#125;</span>
<span class="string">&#125;</span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>front-proxy-ca-csr.json 用于生成 Kubernetes 的 Front Proxy CA 证书（front-proxy-ca.pem 和 front-proxy-ca-key.pem）。Front Proxy CA 是 Kubernetes 集群中用于 前端代理认证 的独立 CA，专门用于签署前端代理客户端证书（如 front-proxy-client.pem），以支持 API Server 的请求头认证机制。</p>
</blockquote>
<h5 id="3-3-6-2-生成-Kubernetes-Front-Proxy-根-CA-证书"><a href="#3-3-6-2-生成-Kubernetes-Front-Proxy-根-CA-证书" class="headerlink" title="3.3.6.2 生成 Kubernetes Front Proxy 根 CA 证书"></a>3.3.6.2 生成 Kubernetes Front Proxy 根 CA 证书</h5><p>包括证书文件（front-proxy-ca.pem）、私钥文件（front-proxy-ca-key.pem）和 CSR 文件（front-proxy-ca.csr）</p>
<pre><code class="highlight bash"><span class="comment"># 指示 CFSSL 生成根 CA 证书（而非普通证书）</span>
cfssl gencert -initca /etc/kubernetes/pki/front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca

<span class="comment"># 生成 前端代理客户端证书 的 CSR 配置文件</span>
<span class="built_in">cat</span> &gt; /etc/kubernetes/pki/front-proxy-client-csr.json &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;CN&quot;: &quot;front-proxy-client&quot;,</span>
<span class="string">  &quot;key&quot;: &#123;</span>
<span class="string">     &quot;algo&quot;: &quot;rsa&quot;,</span>
<span class="string">     &quot;size&quot;: 2048</span>
<span class="string">  &#125;</span>
<span class="string">&#125;</span>
<span class="string">EOF</span>

<span class="comment"># 生成前端代理客户端证书</span>
cfssl gencert  \
-ca=/etc/kubernetes/pki/front-proxy-ca.pem   \
-ca-key=/etc/kubernetes/pki/front-proxy-ca-key.pem   \
-config=/etc/kubernetes/pki/ca-config.json   \
-profile=kubernetes /etc/kubernetes/pki/front-proxy-client-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-client</code></pre>

<blockquote>
<p><strong>命令解析1：</strong></p>
<pre><code class="highlight bash">cfssl gencert -initca front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca</code></pre>

<ul>
<li><p>这个命令使用 CFSSL 工具生成 Kubernetes Front Proxy CA 证书（根 CA 证书），包括证书文件（front-proxy-ca.pem）、私钥文件（front-proxy-ca-key.pem）和 CSR 文件（front-proxy-ca.csr）。</p>
</li>
<li><p>Front Proxy CA 的背景：在 Kubernetes 高可用集群中，Front Proxy CA 是用于 请求头认证（RequestHeader Authentication） 的独立 CA。它专门用于签署前端代理客户端证书（如 front-proxy-client.pem），以支持 API Server 的聚合层（Aggregation Layer）。这对于扩展组件（如 Metrics Server）至关重要，确保客户端（如 Metrics Server）可以通过 HTTP 请求头提供身份信息，并由 API Server 验证。</p>
</li>
<li><p>上下文：博客中，此证书用于 Metrics Server 的部署（components.yaml 中引用 –requestheader-client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.pem），确保高可用集群（3 Master 节点 + 2 Node 节点）的扩展 API 安全。</p>
</li>
</ul>
<p><strong>命令解析2：</strong></p>
<p>cat &gt; front-proxy-client-csr.json &lt;&lt; EOF … EOF</p>
<p>生成 前端代理客户端证书 的 CSR 配置文件</p>
<ul>
<li><p>前端代理客户端证书的作用：用于 Metrics Server 或其他聚合 API 客户端的身份认证。客户端证书（front-proxy-client.pem 和 front-proxy-client-key.pem）由 Front Proxy CA 签署，API Server 使用它验证请求头中的客户端身份，确保只有可信客户端可以访问聚合 API</p>
</li>
<li><p>为什么需要？Kubernetes 的聚合层要求客户端提供证书以通过 RequestHeader 认证。Metrics Server 配置中引用了这些证书，确保安全访问 API Server。</p>
</li>
<li><p>上下文：博客中，此证书用于 Metrics Server 的 TLS 通信，支持高可用集群的扩展功能。</p>
</li>
</ul>
<p><strong>命令解析3：</strong></p>
<p>cfssl gencert  <br>-ca&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.pem   <br>-ca-key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca-key.pem   <br>-config&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca-config.json   <br>-profile&#x3D;kubernetes &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-client-csr.json | cfssljson -bare &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-client</p>
<ul>
<li>使用 CFSSL 生成 前端代理客户端证书（front-proxy-client.pem 和 front-proxy-client-key.pem），由 Front Proxy CA 签署。</li>
<li>客户端证书的作用：Metrics Server 等聚合客户端使用此证书在请求头中证明身份，API Server 通过 Front Proxy CA 验证，确保安全访问聚合 API（如 &#x2F;apis&#x2F;metrics.k8s.io&#x2F;）</li>
<li>Metrics Server 的配置（–requestheader-username-headers 等）依赖此证书，支持 RequestHeader 认证。</li>
<li>在高可用集群中，此证书分发到所有 Master 节点，供 kube-apiserver 使用</li>
</ul>
</blockquote>
<h4 id="3-3-7-生成-controller-manage-的证书"><a href="#3-3-7-生成-controller-manage-的证书" class="headerlink" title="3.3.7 生成 controller-manage 的证书"></a>3.3.7 生成 controller-manage 的证书</h4><pre><code class="highlight bash"><span class="comment"># 生成 Kubernetes Controller Manager 客户端证书 的 Certificate Signing Request (CSR) 配置文件</span>
<span class="built_in">cat</span> &gt; /etc/kubernetes/pki/manager-csr.json &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,</span>
<span class="string">  &quot;key&quot;: &#123;</span>
<span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span>
<span class="string">    &quot;size&quot;: 2048</span>
<span class="string">  &#125;,</span>
<span class="string">  &quot;names&quot;: [</span>
<span class="string">    &#123;</span>
<span class="string">      &quot;C&quot;: &quot;CN&quot;,</span>
<span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;O&quot;: &quot;system:kube-controller-manager&quot;,</span>
<span class="string">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span>
<span class="string">    &#125;</span>
<span class="string">  ]</span>
<span class="string">&#125;</span>
<span class="string">EOF</span>


<span class="comment"># 使用 CFSSL 生成 Controller Manager 客户端证书（controller-manager.pem 和 controller-manager-key.pem），由 Kubernetes 根 CA（ca.pem）签署</span>
cfssl gencert \
   -ca=/etc/kubernetes/pki/ca.pem \
   -ca-key=/etc/kubernetes/pki/ca-key.pem \
   -config=/etc/kubernetes/pki/ca-config.json \
   -profile=kubernetes \
   /etc/kubernetes/pki/manager-csr.json | cfssljson -bare /etc/kubernetes/pki/controller-manager
   

<span class="comment"># 配置 Controller Manager 的 kubeconfig 文件（/etc/kubernetes/controller-manager.kubeconfig），定义集群信息，指定 API Server 的地址和 CA 证书。</span>
kubectl config set-cluster kubernetes \
     --certificate-authority=/etc/kubernetes/pki/ca.pem \
     --embed-certs=<span class="literal">true</span> \
     --server=https://127.0.0.1:8443 \
     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig

<span class="comment"># 设置 kubeconfig 的上下文，将集群、用户和命名空间绑定，定义 Controller Manager 的访问环境</span>
kubectl config set-context system:kube-controller-manager@kubernetes \
    --cluster=kubernetes \
    --user=system:kube-controller-manager \
    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig

<span class="comment"># 设置 Controller Manager 的用户凭据，指定其客户端证书和私钥，用于与 API Server 的身份认证</span>
kubectl config set-credentials system:kube-controller-manager \
    --client-certificate=/etc/kubernetes/pki/controller-manager.pem \
    --client-key=/etc/kubernetes/pki/controller-manager-key.pem \
    --embed-certs=<span class="literal">true</span> \
    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig

<span class="comment"># 设置 kubeconfig 文件的默认上下文，确保 Controller Manager 使用 system:kube-controller-manager@kubernetes 上下文访问 API Server</span>
kubectl config use-context system:kube-controller-manager@kubernetes \
     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</code></pre>





<h4 id="3-3-8-生成-kube-scheduler-的证书"><a href="#3-3-8-生成-kube-scheduler-的证书" class="headerlink" title="3.3.8 生成 kube-scheduler 的证书"></a>3.3.8 生成 kube-scheduler 的证书</h4><pre><code class="highlight bash"><span class="comment"># 生成 Kubernetes Scheduler 客户端证书 的 Certificate Signing Request (CSR) 配置文件</span>
<span class="built_in">cat</span> &gt; /etc/kubernetes/pki/scheduler-csr.json &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;CN&quot;: &quot;system:kube-scheduler&quot;,</span>
<span class="string">  &quot;key&quot;: &#123;</span>
<span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span>
<span class="string">    &quot;size&quot;: 2048</span>
<span class="string">  &#125;,</span>
<span class="string">  &quot;names&quot;: [</span>
<span class="string">    &#123;</span>
<span class="string">      &quot;C&quot;: &quot;CN&quot;,</span>
<span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;O&quot;: &quot;system:kube-scheduler&quot;,</span>
<span class="string">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span>
<span class="string">    &#125;</span>
<span class="string">  ]</span>
<span class="string">&#125;</span>
<span class="string">EOF</span>


<span class="comment"># 使用 CFSSL 生成 Scheduler 客户端证书（scheduler.pem 和 scheduler-key.pem），由 Kubernetes 根 CA（ca.pem）签署</span>
cfssl gencert \
   -ca=/etc/kubernetes/pki/ca.pem \
   -ca-key=/etc/kubernetes/pki/ca-key.pem \
   -config=/etc/kubernetes/pki/ca-config.json \
   -profile=kubernetes \
   /etc/kubernetes/pki/scheduler-csr.json | cfssljson -bare /etc/kubernetes/pki/scheduler


<span class="comment"># 配置 Scheduler 的 kubeconfig 文件（/etc/kubernetes/scheduler.kubeconfig），定义集群信息，指定 API Server 的地址和 CA 证书。</span>
kubectl config set-cluster kubernetes \
     --certificate-authority=/etc/kubernetes/pki/ca.pem \
     --embed-certs=<span class="literal">true</span> \
     --server=https://127.0.0.1:8443 \
     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig


<span class="comment"># 设置 Scheduler 的用户凭据，指定其客户端证书和私钥，用于与 API Server 的身份认证。</span>
kubectl config set-credentials system:kube-scheduler \
     --client-certificate=/etc/kubernetes/pki/scheduler.pem \
     --client-key=/etc/kubernetes/pki/scheduler-key.pem \
     --embed-certs=<span class="literal">true</span> \
     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig


<span class="comment"># 设置 kubeconfig 的上下文，将集群、用户和命名空间绑定，定义 Scheduler 的访问环境。</span>
kubectl config set-context system:kube-scheduler@kubernetes \
     --cluster=kubernetes \
     --user=system:kube-scheduler \
     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig


<span class="comment"># 设置 kubeconfig 文件的默认上下文，确保 Scheduler 使用 system:kube-scheduler@kubernetes 上下文访问 API Server</span>
kubectl config use-context system:kube-scheduler@kubernetes \
     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</code></pre>





<h4 id="3-3-9-生成-admin-的证书配置"><a href="#3-3-9-生成-admin-的证书配置" class="headerlink" title="3.3.9 生成 admin 的证书配置"></a>3.3.9 生成 admin 的证书配置</h4><pre><code class="highlight bash"><span class="comment"># 生成一个 证书签名请求（Certificate Signing Request） 的配置文件，供 cfssl 工具使用</span>
<span class="built_in">cat</span> &gt; /etc/kubernetes/pki/admin-csr.json &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;CN&quot;: &quot;admin&quot;,</span>
<span class="string">  &quot;key&quot;: &#123;</span>
<span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span>
<span class="string">    &quot;size&quot;: 2048</span>
<span class="string">  &#125;,</span>
<span class="string">  &quot;names&quot;: [</span>
<span class="string">    &#123;</span>
<span class="string">      &quot;C&quot;: &quot;CN&quot;,</span>
<span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;O&quot;: &quot;system:masters&quot;,</span>
<span class="string">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span>
<span class="string">    &#125;</span>
<span class="string">  ]</span>
<span class="string">&#125;</span>
<span class="string">EOF</span>


<span class="comment"># 生成了管理员证书和密钥，用于 kubectl 访问 API Server 时进行身份认证</span>
cfssl gencert \
   -ca=/etc/kubernetes/pki/ca.pem \
   -ca-key=/etc/kubernetes/pki/ca-key.pem \
   -config=/etc/kubernetes/pki/ca-config.json \
   -profile=kubernetes \
   /etc/kubernetes/pki/admin-csr.json | cfssljson -bare /etc/kubernetes/pki/admin


<span class="comment"># 设置集群信息</span>
kubectl config set-cluster kubernetes     \
  --certificate-authority=/etc/kubernetes/pki/ca.pem     \
  --embed-certs=<span class="literal">true</span>     \
  --server=https://127.0.0.1:8443     \
  --kubeconfig=/etc/kubernetes/admin.kubeconfig


<span class="comment"># 设置用户凭证</span>
kubectl config set-credentials kubernetes-admin  \
  --client-certificate=/etc/kubernetes/pki/admin.pem     \
  --client-key=/etc/kubernetes/pki/admin-key.pem     \
  --embed-certs=<span class="literal">true</span>     \
  --kubeconfig=/etc/kubernetes/admin.kubeconfig


<span class="comment"># 绑定上下文</span>
kubectl config set-context kubernetes-admin@kubernetes    \
  --cluster=kubernetes     \
  --user=kubernetes-admin     \
  --kubeconfig=/etc/kubernetes/admin.kubeconfig


<span class="comment"># 启用当前上下文</span>
kubectl config use-context kubernetes-admin@kubernetes  --kubeconfig=/etc/kubernetes/admin.kubeconfig</code></pre>





<h4 id="3-3-10-创建-kube-proxy-证书"><a href="#3-3-10-创建-kube-proxy-证书" class="headerlink" title="3.3.10 创建 kube-proxy 证书"></a>3.3.10 创建 kube-proxy 证书</h4><pre><code class="highlight bash"><span class="comment"># 生成 kube-proxy 证书签名请求文件 (CSR),这个文件会被用来生成证书请求</span>
<span class="built_in">cat</span> &gt; /etc/kubernetes/pki/kube-proxy-csr.json  &lt;&lt; <span class="string">EOF </span>
<span class="string">&#123;</span>
<span class="string">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span>
<span class="string">  &quot;key&quot;: &#123;</span>
<span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span>
<span class="string">    &quot;size&quot;: 2048</span>
<span class="string">  &#125;,</span>
<span class="string">  &quot;names&quot;: [</span>
<span class="string">    &#123;</span>
<span class="string">      &quot;C&quot;: &quot;CN&quot;,</span>
<span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span>
<span class="string">      &quot;O&quot;: &quot;system:kube-proxy&quot;,</span>
<span class="string">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span>
<span class="string">    &#125;</span>
<span class="string">  ]</span>
<span class="string">&#125;</span>
<span class="string">EOF</span>


<span class="comment"># 使用前面创建好的集群 CA 根证书来签发 kube-proxy 的客户端证书</span>
cfssl gencert \
   -ca=/etc/kubernetes/pki/ca.pem \
   -ca-key=/etc/kubernetes/pki/ca-key.pem \
   -config=/etc/kubernetes/pki/ca-config.json \
   -profile=kubernetes \
   /etc/kubernetes/pki/kube-proxy-csr.json | cfssljson -bare /etc/kubernetes/pki/kube-proxy


<span class="comment"># 生成 kube-proxy 的 kubeconfig 文件, kube-proxy 在启动时需要使用一个 kubeconfig 文件来连接 API Server</span>
<span class="comment"># 设置集群信息</span>
kubectl config set-cluster kubernetes     \
  --certificate-authority=/etc/kubernetes/pki/ca.pem     \
  --embed-certs=<span class="literal">true</span>     \
  --server=https://127.0.0.1:8443     \
  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig


<span class="comment"># 设置用户凭证</span>
kubectl config set-credentials kube-proxy  \
  --client-certificate=/etc/kubernetes/pki/kube-proxy.pem     \
  --client-key=/etc/kubernetes/pki/kube-proxy-key.pem     \
  --embed-certs=<span class="literal">true</span>     \
  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig


<span class="comment"># 绑定上下文（Context）</span>
kubectl config set-context kube-proxy@kubernetes    \
  --cluster=kubernetes     \
  --user=kube-proxy     \
  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig


<span class="comment"># 启用当前上下文</span>
kubectl config use-context kube-proxy@kubernetes  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</code></pre>





<h4 id="3-3-11-生成-ServiceAccount（简称-SA）签名密钥对"><a href="#3-3-11-生成-ServiceAccount（简称-SA）签名密钥对" class="headerlink" title="3.3.11 生成 ServiceAccount（简称 SA）签名密钥对"></a>3.3.11 生成 ServiceAccount（简称 SA）签名密钥对</h4><pre><code class="highlight bash"><span class="comment"># 生成文件 /etc/kubernetes/pki/sa.key —— ServiceAccount 私钥文件</span>
openssl genrsa -out /etc/kubernetes/pki/sa.key 2048

<span class="comment"># 生成文件 /etc/kubernetes/pki/sa.pub —— ServiceAccount 公钥文件</span>
openssl rsa -<span class="keyword">in</span> /etc/kubernetes/pki/sa.key -pubout -out /etc/kubernetes/pki/sa.pub</code></pre>





<h2 id="4-分发证书到其它节点"><a href="#4-分发证书到其它节点" class="headerlink" title="4. 分发证书到其它节点"></a>4. 分发证书到其它节点</h2><h3 id="4-1-分发到-master-节点"><a href="#4-1-分发到-master-节点" class="headerlink" title="4.1 分发到 master 节点"></a>4.1 分发到 master 节点</h3><p><strong>k8s-master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 将生成的 ETCD 证书复制到其他节点</span>
hosts=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir -p /etc/kubernetes/pki/&quot;</span>
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/pki/* <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/pki/;
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/admin.kubeconfig <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/controller-manager.kubeconfig <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/scheduler.kubeconfig <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/kube-proxy.kubeconfig <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/
<span class="keyword">done</span></code></pre>



<h3 id="4-2-分发到-node-节点"><a href="#4-2-分发到-node-节点" class="headerlink" title="4.2 分发到 node 节点"></a>4.2 分发到 node 节点</h3><p><strong>k8s-master01</strong></p>
<pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir -p /etc/kubernetes/pki/&quot;</span>
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/pki/kube-proxy* <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/pki/;
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/kube-proxy.kubeconfig <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/
<span class="keyword">done</span></code></pre>





<h2 id="5-查看证书"><a href="#5-查看证书" class="headerlink" title="5. 查看证书"></a>5. 查看证书</h2><h3 id="5-1-master-节点"><a href="#5-1-master-节点" class="headerlink" title="5.1 master 节点"></a>5.1 master 节点</h3><pre><code class="highlight bash">$ ll /etc/kubernetes/pki/
total 140
-rw-r--r--. 1 root root  225 Oct 16 23:22 admin-csr.json
-rw-------. 1 root root 1679 Oct 16 23:25 admin-key.pem
-rw-r--r--. 1 root root 1025 Oct 16 23:25 admin.csr
-rw-r--r--. 1 root root 1432 Oct 16 23:25 admin.pem
-rw-r--r--. 1 root root  230 Oct 11 20:11 apiserver-csr.json
-rw-------. 1 root root 1675 Oct 11 20:17 apiserver-key.pem
-rw-r--r--. 1 root root 1565 Oct 11 20:17 apiserver.csr
-rw-r--r--. 1 root root 1948 Oct 11 20:17 apiserver.pem
-rw-r--r--. 1 root root  294 Oct 11 19:58 ca-config.json
-rw-r--r--. 1 root root  258 Oct 11 20:04 ca-csr.json
-rw-------. 1 root root 1679 Oct 11 20:04 ca-key.pem
-rw-r--r--. 1 root root 1062 Oct 11 20:04 ca.csr
-rw-r--r--. 1 root root 1342 Oct 11 20:04 ca.pem
-rw-------. 1 root root 1675 Oct 16 22:19 controller-manager-key.pem
-rw-r--r--. 1 root root 1082 Oct 16 22:19 controller-manager.csr
-rw-r--r--. 1 root root 1489 Oct 16 22:19 controller-manager.pem
-rw-r--r--. 1 root root  118 Oct 11 20:23 front-proxy-ca-csr.json
-rw-------. 1 root root 1679 Oct 16 21:19 front-proxy-ca-key.pem
-rw-r--r--. 1 root root  940 Oct 16 21:19 front-proxy-ca.csr
-rw-r--r--. 1 root root 1094 Oct 16 21:19 front-proxy-ca.pem
-rw-r--r--. 1 root root   87 Oct 16 21:22 front-proxy-client-csr.json
-rw-------. 1 root root 1679 Oct 16 21:25 front-proxy-client-key.pem
-rw-r--r--. 1 root root  903 Oct 16 21:25 front-proxy-client.csr
-rw-r--r--. 1 root root 1188 Oct 16 21:25 front-proxy-client.pem
-rw-r--r--. 1 root root  240 Oct 16 23:31 kube-proxy-csr.json
-rw-------. 1 root root 1675 Oct 16 23:31 kube-proxy-key.pem
-rw-r--r--. 1 root root 1045 Oct 16 23:31 kube-proxy.csr
-rw-r--r--. 1 root root 1456 Oct 16 23:31 kube-proxy.pem
-rw-r--r--. 1 root root  266 Oct 16 22:11 manager-csr.json
-rw-------. 1 root root 1704 Oct 16 23:34 sa.key
-rw-r--r--. 1 root root  451 Oct 16 23:34 sa.pub
-rw-r--r--. 1 root root  248 Oct 16 23:07 scheduler-csr.json
-rw-------. 1 root root 1679 Oct 16 23:08 scheduler-key.pem
-rw-r--r--. 1 root root 1058 Oct 16 23:08 scheduler.csr
-rw-r--r--. 1 root root 1464 Oct 16 23:08 scheduler.pem


$ ll /etc/kubernetes/
total 36
-rw-------. 1 root root 6341 Oct 16 23:26 admin.kubeconfig
-rw-------. 1 root root 6469 Oct 16 22:30 controller-manager.kubeconfig
-rw-------. 1 root root 6345 Oct 16 23:32 kube-proxy.kubeconfig
drwxr-xr-x. 2 root root 4096 Oct 16 23:34 pki
-rw-------. 1 root root 6401 Oct 16 23:14 scheduler.kubeconfig</code></pre>



<h3 id="5-2-node-节点"><a href="#5-2-node-节点" class="headerlink" title="5.2 node 节点"></a>5.2 node 节点</h3><pre><code class="highlight bash">$ ll /etc/kubernetes/pki/
total 16
-rw-r--r--. 1 root root  240 Oct 16 23:52 kube-proxy-csr.json
-rw-------. 1 root root 1675 Oct 16 23:52 kube-proxy-key.pem
-rw-r--r--. 1 root root 1045 Oct 16 23:52 kube-proxy.csr
-rw-r--r--. 1 root root 1456 Oct 16 23:52 kube-proxy.pem


$ ll /etc/kubernetes/
total 8
-rw-------. 1 root root 6345 Oct 16 23:52 kube-proxy.kubeconfig
drwxr-xr-x. 2 root root  103 Oct 16 23:52 pki</code></pre>





<h1 id="五、K8S-系统组件配置"><a href="#五、K8S-系统组件配置" class="headerlink" title="五、K8S 系统组件配置"></a>五、K8S 系统组件配置</h1><h2 id="1-ETCD-配置"><a href="#1-ETCD-配置" class="headerlink" title="1. ETCD 配置"></a>1. ETCD 配置</h2><p>etcd 配置大致相同，注意修改每个 Master 节点的 etcd 配置的主机名和IP地址</p>
<p>官方文档：<a target="_blank" rel="noopener" href="https://etcd.io/docs/v3.5/op-guide/configuration/">https://etcd.io/docs/v3.5/op-guide/configuration/</a></p>
<p>从 Github 获取配置文件示例 ：<a target="_blank" rel="noopener" href="https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample">https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample</a></p>
<p>配置项解读：</p>
<blockquote>
<ul>
<li>name：指定了当前节点的名称，用于集群中区分不同的节点。</li>
<li>data-dir：指定了 etcd 数据的存储目录。</li>
<li>wal-dir：指定了 etcd 数据写入磁盘的目录。</li>
<li>snapshot-count：指定了触发快照的事务数量。</li>
<li>heartbeat-interval：指定了 etcd 集群中节点之间的心跳间隔。</li>
<li>election-timeout：指定了选举超时时间。</li>
<li>quota-backend-bytes：指定了存储的限额，0 表示无限制。</li>
<li>listen-peer-urls：指定了节点之间通信的 URL，使用 HTTPS 协议。</li>
<li>listen-client-urls：指定了客户端访问 etcd 集群的 URL，同时提供了本地访问的 URL。</li>
<li>max-snapshots：指定了快照保留的数量。</li>
<li>max-wals：指定了日志保留的数量。</li>
<li>initial-advertise-peer-urls：指定了节点之间通信的初始 URL。</li>
<li>advertise-client-urls：指定了客户端访问 etcd 集群的初始 URL。</li>
<li>discovery：定义了 etcd 集群发现相关的选项。</li>
<li>initial-cluster：指定了 etcd 集群的初始成员。</li>
<li>initial-cluster-token：指定了集群的 token。</li>
<li>initial-cluster-state：指定了集群的初始状态。</li>
<li>strict-reconfig-check：指定了严格的重新配置检查选项。</li>
<li>enable-v2：启用了 v2 API。</li>
<li>enable-pprof：启用了性能分析。</li>
<li>proxy：设置了代理模式。</li>
<li>client-transport-security：客户端的传输安全配置。</li>
<li>peer-transport-security：节点之间的传输安全配置。</li>
<li>debug：是否启用调试模式。</li>
<li>log-package-levels：日志的输出级别。</li>
<li>log-outputs：指定了日志的输出类型。</li>
<li>force-new-cluster：是否强制创建一个新的集群。</li>
</ul>
</blockquote>
<h3 id="1-1-Master01-节点"><a href="#1-1-Master01-节点" class="headerlink" title="1.1 Master01 节点"></a>1.1 Master01 节点</h3><p>如果要用 IPv6 那么把 IPv4 地址修改为 IPv6 即可</p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/etcd/etcd.config.yml &lt;&lt; <span class="string">EOF </span>
<span class="string">name: &#x27;k8s-master01&#x27;</span>
<span class="string">data-dir: /data/etcd</span>
<span class="string">wal-dir: /data/etcd/wal</span>
<span class="string">snapshot-count: 5000</span>
<span class="string">heartbeat-interval: 100</span>
<span class="string">election-timeout: 1000</span>
<span class="string">quota-backend-bytes: 0</span>
<span class="string">listen-peer-urls: &#x27;https://10.20.1.101:2380&#x27;</span>
<span class="string">listen-client-urls: &#x27;https://10.20.1.101:2379,http://127.0.0.1:2379&#x27;</span>
<span class="string">max-snapshots: 3</span>
<span class="string">max-wals: 5</span>
<span class="string">cors:</span>
<span class="string">initial-advertise-peer-urls: &#x27;https://10.20.1.101:2380&#x27;</span>
<span class="string">advertise-client-urls: &#x27;https://10.20.1.101:2379&#x27;</span>
<span class="string">discovery:</span>
<span class="string">discovery-fallback: &#x27;proxy&#x27;</span>
<span class="string">discovery-proxy:</span>
<span class="string">discovery-srv:</span>
<span class="string">initial-cluster: &#x27;k8s-master01=https://10.20.1.101:2380,k8s-master02=https://10.20.1.102:2380,k8s-master03=https://10.20.1.103:2380&#x27;</span>
<span class="string">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span>
<span class="string">initial-cluster-state: &#x27;new&#x27;</span>
<span class="string">strict-reconfig-check: false</span>
<span class="string">enable-v2: true</span>
<span class="string">enable-pprof: true</span>
<span class="string">proxy: &#x27;off&#x27;</span>
<span class="string">proxy-failure-wait: 5000</span>
<span class="string">proxy-refresh-interval: 30000</span>
<span class="string">proxy-dial-timeout: 1000</span>
<span class="string">proxy-write-timeout: 5000</span>
<span class="string">proxy-read-timeout: 0</span>
<span class="string">client-transport-security:</span>
<span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span>
<span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span>
<span class="string">  client-cert-auth: true</span>
<span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span>
<span class="string">  auto-tls: true</span>
<span class="string">peer-transport-security:</span>
<span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span>
<span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span>
<span class="string">  peer-client-cert-auth: true</span>
<span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span>
<span class="string">  auto-tls: true</span>
<span class="string">debug: false</span>
<span class="string">log-package-levels:</span>
<span class="string">log-outputs: [default]</span>
<span class="string">force-new-cluster: false</span>
<span class="string">EOF</span></code></pre>



<h3 id="1-2-Master02-节点"><a href="#1-2-Master02-节点" class="headerlink" title="1.2 Master02 节点"></a>1.2 Master02 节点</h3><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/etcd/etcd.config.yml &lt;&lt; <span class="string">EOF </span>
<span class="string">name: &#x27;k8s-master02&#x27;</span>
<span class="string">data-dir: /data/etcd</span>
<span class="string">wal-dir: /data/etcd/wal</span>
<span class="string">snapshot-count: 5000</span>
<span class="string">heartbeat-interval: 100</span>
<span class="string">election-timeout: 1000</span>
<span class="string">quota-backend-bytes: 0</span>
<span class="string">listen-peer-urls: &#x27;https://10.20.1.102:2380&#x27;</span>
<span class="string">listen-client-urls: &#x27;https://10.20.1.102:2379,http://127.0.0.1:2379&#x27;</span>
<span class="string">max-snapshots: 3</span>
<span class="string">max-wals: 5</span>
<span class="string">cors:</span>
<span class="string">initial-advertise-peer-urls: &#x27;https://10.20.1.102:2380&#x27;</span>
<span class="string">advertise-client-urls: &#x27;https://10.20.1.102:2379&#x27;</span>
<span class="string">discovery:</span>
<span class="string">discovery-fallback: &#x27;proxy&#x27;</span>
<span class="string">discovery-proxy:</span>
<span class="string">discovery-srv:</span>
<span class="string">initial-cluster: &#x27;k8s-master01=https://10.20.1.101:2380,k8s-master02=https://10.20.1.102:2380,k8s-master03=https://10.20.1.103:2380&#x27;</span>
<span class="string">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span>
<span class="string">initial-cluster-state: &#x27;new&#x27;</span>
<span class="string">strict-reconfig-check: false</span>
<span class="string">enable-v2: true</span>
<span class="string">enable-pprof: true</span>
<span class="string">proxy: &#x27;off&#x27;</span>
<span class="string">proxy-failure-wait: 5000</span>
<span class="string">proxy-refresh-interval: 30000</span>
<span class="string">proxy-dial-timeout: 1000</span>
<span class="string">proxy-write-timeout: 5000</span>
<span class="string">proxy-read-timeout: 0</span>
<span class="string">client-transport-security:</span>
<span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span>
<span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span>
<span class="string">  client-cert-auth: true</span>
<span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span>
<span class="string">  auto-tls: true</span>
<span class="string">peer-transport-security:</span>
<span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span>
<span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span>
<span class="string">  peer-client-cert-auth: true</span>
<span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span>
<span class="string">  auto-tls: true</span>
<span class="string">debug: false</span>
<span class="string">log-package-levels:</span>
<span class="string">log-outputs: [default]</span>
<span class="string">force-new-cluster: false</span>
<span class="string">EOF</span></code></pre>



<h3 id="1-3-Master03-节点"><a href="#1-3-Master03-节点" class="headerlink" title="1.3 Master03 节点"></a>1.3 Master03 节点</h3><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/etcd/etcd.config.yml &lt;&lt; <span class="string">EOF </span>
<span class="string">name: &#x27;k8s-master03&#x27;</span>
<span class="string">data-dir: /data/etcd</span>
<span class="string">wal-dir: /data/etcd/wal</span>
<span class="string">snapshot-count: 5000</span>
<span class="string">heartbeat-interval: 100</span>
<span class="string">election-timeout: 1000</span>
<span class="string">quota-backend-bytes: 0</span>
<span class="string">listen-peer-urls: &#x27;https://10.20.1.103:2380&#x27;</span>
<span class="string">listen-client-urls: &#x27;https://10.20.1.103:2379,http://127.0.0.1:2379&#x27;</span>
<span class="string">max-snapshots: 3</span>
<span class="string">max-wals: 5</span>
<span class="string">cors:</span>
<span class="string">initial-advertise-peer-urls: &#x27;https://10.20.1.103:2380&#x27;</span>
<span class="string">advertise-client-urls: &#x27;https://10.20.1.103:2379&#x27;</span>
<span class="string">discovery:</span>
<span class="string">discovery-fallback: &#x27;proxy&#x27;</span>
<span class="string">discovery-proxy:</span>
<span class="string">discovery-srv:</span>
<span class="string">initial-cluster: &#x27;k8s-master01=https://10.20.1.101:2380,k8s-master02=https://10.20.1.102:2380,k8s-master03=https://10.20.1.103:2380&#x27;</span>
<span class="string">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span>
<span class="string">initial-cluster-state: &#x27;new&#x27;</span>
<span class="string">strict-reconfig-check: false</span>
<span class="string">enable-v2: true</span>
<span class="string">enable-pprof: true</span>
<span class="string">proxy: &#x27;off&#x27;</span>
<span class="string">proxy-failure-wait: 5000</span>
<span class="string">proxy-refresh-interval: 30000</span>
<span class="string">proxy-dial-timeout: 1000</span>
<span class="string">proxy-write-timeout: 5000</span>
<span class="string">proxy-read-timeout: 0</span>
<span class="string">client-transport-security:</span>
<span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span>
<span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span>
<span class="string">  client-cert-auth: true</span>
<span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span>
<span class="string">  auto-tls: true</span>
<span class="string">peer-transport-security:</span>
<span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span>
<span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span>
<span class="string">  peer-client-cert-auth: true</span>
<span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span>
<span class="string">  auto-tls: true</span>
<span class="string">debug: false</span>
<span class="string">log-package-levels:</span>
<span class="string">log-outputs: [default]</span>
<span class="string">force-new-cluster: false</span>
<span class="string">EOF</span></code></pre>





<h3 id="1-4-创建-ETCD-Service"><a href="#1-4-创建-ETCD-Service" class="headerlink" title="1.4 创建 ETCD Service"></a>1.4 创建 ETCD Service</h3><p><strong>master 01</strong></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; <span class="string">EOF</span>
<span class="string"></span>
<span class="string">[Unit]</span>
<span class="string">Description=Etcd Service</span>
<span class="string">Documentation=https://coreos.com/etcd/docs/latest/</span>
<span class="string">After=network.target</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">Type=notify</span>
<span class="string">ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yml</span>
<span class="string">Restart=on-failure</span>
<span class="string">RestartSec=10</span>
<span class="string">LimitNOFILE=65536</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string">Alias=etcd3.service</span>
<span class="string"></span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>该文件定义了 etcd 服务在 Linux 系统上的运行方式，使用 systemd 管理 etcd 进程的启动、停止、自动重启等行为。此配置是为 Kubernetes 高可用集群中的 etcd 节点（例如 k8s-master03）设计的，结合了 &#x2F;etc&#x2F;etcd&#x2F;etcd.config.yml 配置文件运行 etcd。</p>
<ul>
<li><p>After&#x3D;network.target：定义服务在哪些 systemd 目标或单元启动后启动。network.target 表示网络服务可用。 影响：确保 etcd 在网络初始化后启动，因为 etcd 需要监听网络端口（2379&#x2F;2380）进行客户端和节点间通信。如果网络不可用，etcd 可能启动失败</p>
</li>
<li><p>Type&#x3D;notify：默认值：simple 描述：定义服务进程的类型。notify 表示主进程通过 sd_notify(3) 向 systemd 发送启动完成信号（etcd 支持此机制）。 影响：notify 允许 systemd 等待 etcd 完成初始化（如绑定端口、加入集群）后再标记服务为“运行”。</p>
</li>
<li><p>ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;etcd –config-file&#x3D;&#x2F;etc&#x2F;etcd&#x2F;etcd.config.yml</p>
<p>服务启动时执行的命令及其参数。运行 etcd 二进制，指定配置文件路径</p>
</li>
<li><p>Restart&#x3D;on-failure：控制服务失败时的重启行为。on-failure 表示在进程异常退出（非零退出码）、超时或被信号终止时自动重启。</p>
</li>
<li><p>RestartSec&#x3D;10：重启前的等待时间（秒）</p>
</li>
<li><p>LimitNOFILE&#x3D;65536：设置进程的最大文件描述符数量（软限制和硬限制）。 影响：etcd 需处理大量网络连接（如 Kubernetes API 请求），默认值可能不足导致 “too many open files” 错误。65536 适合高负载集群，需确保系统级限制</p>
</li>
<li><p>WantedBy&#x3D;multi-user.target：指定服务在哪个 systemd 目标启用。multi-user.target 表示多用户模式（非图形界面，通常为服务器默认运行级别）</p>
</li>
<li><p>Alias&#x3D;etcd3.service：为服务创建别名，允许通过别名（如 systemctl start etcd3.service）操作服务</p>
</li>
</ul>
</blockquote>
<p><strong>同步到其它Master节点</strong></p>
<pre><code class="highlight bash"><span class="comment"># 将生成的 ETCD Service复制到其他节点</span>
hosts=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/etcd.service <span class="variable">$user</span>@<span class="variable">$host</span>:/usr/lib/systemd/system/;
<span class="keyword">done</span></code></pre>



<h3 id="1-5-启动-ETCD-Service"><a href="#1-5-启动-ETCD-Service" class="headerlink" title="1.5 启动 ETCD Service"></a>1.5 启动 ETCD Service</h3><pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master01 k8s-master02 k8s-master03&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  <span class="built_in">echo</span> <span class="string">&quot;创建 etcd 证书目录&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir -p /etc/kubernetes/pki/etcd&quot;</span>
  <span class="built_in">echo</span> <span class="string">&quot;创建软连接&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;ln -s /etc/etcd/ssl/* /etc/kubernetes/pki/etcd/&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now etcd.service&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl status etcd.service&quot;</span>
<span class="keyword">done</span></code></pre>

<p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/18/20251018-150523.png" alt="查看ETCD Service启动状态"></p>
<h3 id="1-6-检查-ETCD-集群的健康状态"><a href="#1-6-检查-ETCD-集群的健康状态" class="headerlink" title="1.6 检查 ETCD 集群的健康状态"></a>1.6 检查 ETCD 集群的健康状态</h3><p><strong>master01 、master02、master03</strong></p>
<pre><code class="highlight bash"><span class="built_in">export</span> ETCDCTL_API=3
etcdctl --endpoints=<span class="string">&quot;10.20.1.101:2379,10.20.1.102:2379,10.20.1.103:2379&quot;</span> \
  --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem \
  --cert=/etc/kubernetes/pki/etcd/etcd.pem \
  --key=/etc/kubernetes/pki/etcd/etcd-key.pem \
  endpoint status --write-out=table</code></pre>

<p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/18/20251018-151718.png" alt="检查 ETCD 集群的健康状态"></p>
<blockquote>
<p><strong>命令解析：</strong></p>
<p>该命令用于检查 etcd 集群的健康状态，是 Kubernetes 高可用部署中验证 etcd 集群运行情况的关键步骤</p>
<ul>
<li><p>export ETCDCTL_API&#x3D;3</p>
<p>明确设置 ETCDCTL_API&#x3D;3 确保 etcdctl 使用 v3 协议，避免与 v2 兼容性问题</p>
</li>
<li><p>etcdctl：是 etcd 提供的命令行工具，用于与 etcd 集群交互（如查询状态、管理成员、执行操作）</p>
</li>
<li><p>–endpoints：指定 etcd 集群的客户端访问端点，包含三个节点的 IP 和端口（2379）</p>
</li>
<li><p>–cacert：指定 CA 证书路径 &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;etcd-ca.pem</p>
</li>
<li><p>–cert：客户端证书路径 &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;etcd.pem</p>
</li>
<li><p>–key：客户端私钥路径 &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;etcd-key.pem</p>
</li>
</ul>
</blockquote>
<h2 id="2-Nginx-配置"><a href="#2-Nginx-配置" class="headerlink" title="2. Nginx 配置"></a>2. Nginx 配置</h2><h3 id="2-1-编译安装"><a href="#2-1-编译安装" class="headerlink" title="2.1 编译安装"></a>2.1 编译安装</h3><p><strong>master 01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 安装编译环境</span>
yum install -y openssl-devel pcre-devel gcc

<span class="comment"># 下载解压 nginx 二进制文件</span>
wget http://nginx.org/download/nginx-1.25.3.tar.gz
tar xvf nginx-*.tar.gz
<span class="built_in">cd</span> nginx-1.25.3

<span class="comment"># 进行编译</span>
./configure --prefix=/usr/local/nginx --sbin-path=/bin/ --user=nginx --group=nginx --with-stream --with-http_ssl_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --without-http --without-http_uwsgi_module --without-http_scgi_module --without-http_fastcgi_module
make &amp;&amp; make install

<span class="comment"># 将编译好的 nginx 二进制包，拷贝到其它节点</span>
hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  rsync -a --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/local/nginx <span class="variable">$user</span>@<span class="variable">$host</span>:/usr/local/;
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /bin/nginx* <span class="variable">$user</span>@<span class="variable">$host</span>:/bin/;
<span class="keyword">done</span>

<span class="comment"># 验证 </span>
$ nginx -v
nginx version: nginx/1.25.3</code></pre>



<h3 id="2-2-nginx-配置文件"><a href="#2-2-nginx-配置文件" class="headerlink" title="2.2 nginx 配置文件"></a>2.2 nginx 配置文件</h3><p><strong>Master 01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 写入配置文件（在所有主机上执行）</span>
<span class="built_in">cat</span> &gt; /usr/local/nginx/conf/kube-nginx.conf &lt;&lt;<span class="string">EOF</span>
<span class="string">worker_processes 1;</span>
<span class="string">user nobody;</span>
<span class="string">events &#123;</span>
<span class="string">    worker_connections  1024;</span>
<span class="string">&#125;</span>
<span class="string">stream &#123;</span>
<span class="string">    upstream backend &#123;</span>
<span class="string">    	least_conn;</span>
<span class="string">        hash $remote_addr consistent;</span>
<span class="string">        server 10.20.1.101:6443        max_fails=3 fail_timeout=30s;</span>
<span class="string">        server 10.20.1.102:6443        max_fails=3 fail_timeout=30s;</span>
<span class="string">        server 10.20.1.103:6443        max_fails=3 fail_timeout=30s;</span>
<span class="string">    &#125;</span>
<span class="string">    server &#123;</span>
<span class="string">        listen 127.0.0.1:8443;</span>
<span class="string">        proxy_connect_timeout 1s;</span>
<span class="string">        proxy_pass backend;</span>
<span class="string">    &#125;</span>
<span class="string">&#125;</span>
<span class="string">EOF</span>

<span class="comment"># 将kube-nginx.conf，拷贝到其它 Master 节点</span>
hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  rsync -a --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/local/nginx/conf/kube-nginx.conf <span class="variable">$user</span>@<span class="variable">$host</span>:/usr/local/nginx/conf/;
<span class="keyword">done</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>该命令用于创建 Nginx 配置文件 &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;kube-nginx.conf，配置 Nginx 作为 Kubernetes API 服务器的负载均衡器，处理 TCP 流量（端口 6443）</p>
<ul>
<li><p>upstream backend</p>
<p>将本地 8443 端口的请求分发到三个 master 节点的 API 服务器的 6443 端口</p>
</li>
<li><p>least_conn;</p>
<p>选择当前活跃连接数最少的后端服务器进行负载均衡</p>
</li>
<li><p>hash $remote_addr consistent;</p>
<p>基于客户端 IP（$remote_addr）进行一致性哈希，确保同一客户端始终连接到同一后端服务器</p>
</li>
<li><p>max_fails&#x3D;3 fail_timeout&#x3D;30s;</p>
<p>max_fails&#x3D;3（失败 3 次后标记为不可用），fail_timeout&#x3D;30s（标记不可用后 30 秒内不尝试）</p>
</li>
<li><p>6443 端口是 Kubernetes API 服务器（kube-apiserver）的默认端口，接受来自客户端（如 kubectl、kubelet、控制器等）的 HTTPS 请求。</p>
</li>
<li><p>8443 端口是 kube-apiserver 的代理端口，用于接收请求，并将请求转发到真正的 6443 端口</p>
</li>
</ul>
</blockquote>
<h3 id="2-3-配置-Nginx-Service"><a href="#2-3-配置-Nginx-Service" class="headerlink" title="2.3 配置 Nginx Service"></a>2.3 配置 Nginx Service</h3><p><strong>Master 01</strong></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/systemd/system/kube-nginx.service &lt;&lt;<span class="string">EOF</span>
<span class="string">[Unit]</span>
<span class="string">Description=kube-apiserver nginx proxy</span>
<span class="string">After=network.target</span>
<span class="string">After=network-online.target</span>
<span class="string">Wants=network-online.target</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">Type=forking</span>
<span class="string">ExecStartPre=/bin/nginx -c /usr/local/nginx/conf/kube-nginx.conf -p /usr/local/nginx -t</span>
<span class="string">ExecStart=/bin/nginx -c /usr/local/nginx/conf/kube-nginx.conf -p /usr/local/nginx</span>
<span class="string">ExecReload=/bin/nginx -c /usr/local/nginx/conf/kube-nginx.conf -p /usr/local/nginx -s reload</span>
<span class="string">PrivateTmp=true</span>
<span class="string">Restart=always</span>
<span class="string">RestartSec=5</span>
<span class="string">StartLimitInterval=0</span>
<span class="string">LimitNOFILE=65536</span>
<span class="string"> </span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>创建一个 systemd 单元文件，用于管理系统服务。这个文件定义了一个名为 kube-nginx 的服务，负责运行 Nginx 作为 Kubernetes API 服务器的负载均衡代理</p>
<p>Nginx 在这里被配置为 TCP 负载均衡器（非 HTTP），运行在每个 master 节点（k8s-master01、k8s-master02、k8s-master03，IP 分别为 192.168.10.11、12、13），监听本地 127.0.0.1:8443 端口，并将请求分发到三个 master 节点的 API 服务器端口 6443。</p>
<ul>
<li><p>After&#x3D;network.target ：基本网络接口配置完成</p>
</li>
<li><p>After&#x3D;network-online.target ：网络完全在线（可路由外部）</p>
</li>
<li><p>Wants&#x3D;network-online.target ：声明弱依赖，建议（但不强制）在 network-online.target 启动后运行服务</p>
</li>
<li><p>Type&#x3D;forking：</p>
<p>forking 表示主进程派生子进程（如 Nginx master 进程派生 worker），systemd 跟踪子进程 PID（从 PID 文件读取）</p>
</li>
<li><p>ExecStartPre&#x3D;&#x2F;bin&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;kube-nginx.conf -p &#x2F;usr&#x2F;local&#x2F;nginx -t</p>
<p>启动前执行的预命令。-t 测试配置文件语法</p>
</li>
<li><p>ExecStart&#x3D;&#x2F;bin&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;kube-nginx.conf -p &#x2F;usr&#x2F;local&#x2F;nginx</p>
<p>启动服务的核心命令，运行 Nginx。 博客上下文：启动 Nginx，加载 kube-nginx.conf，启用 TCP 负载均衡（8443 到 6443）</p>
</li>
<li><p>ExecReload&#x3D;&#x2F;bin&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;kube-nginx.conf -p &#x2F;usr&#x2F;local&#x2F;nginx -s reload</p>
<p>重新加载配置的命令（systemctl reload kube-nginx）。-s reload 发送信号平滑重载</p>
</li>
<li><p>PrivateTmp&#x3D;true ：为服务分配私有 &#x2F;tmp 和 &#x2F;var&#x2F;tmp 目录，隔离系统临时文件</p>
</li>
<li><p>Restart&#x3D;always ：失败或退出时自动重启。always 表示无论原因都重启</p>
</li>
<li><p>RestartSec&#x3D;5 ：重启前等待时间（秒）</p>
</li>
<li><p>StartLimitInterval&#x3D;0 ：重启时间窗口（秒），0 表示无限制。</p>
</li>
<li><p>LimitNOFILE&#x3D;65536 ：最大文件描述符数，防止 “too many open files” 错误</p>
</li>
<li><p>WantedBy&#x3D;multi-user.target : 服务在多用户模式下启用, 确保 Nginx 随系统启动。</p>
</li>
</ul>
</blockquote>
<h3 id="2-4-设置-Nginx-开机自启"><a href="#2-4-设置-Nginx-开机自启" class="headerlink" title="2.4 设置 Nginx 开机自启"></a>2.4 设置 Nginx 开机自启</h3><pre><code class="highlight bash"><span class="comment"># 刷新系统服务</span>
systemctl daemon-reload

<span class="comment"># 设置 kube-nginx 开机自启</span>
systemctl <span class="built_in">enable</span> --now kube-nginx.service

<span class="comment"># 查看 nginx 启动状态</span>
systemctl status kube-nginx.service</code></pre>



<p><strong>将 kube-nginx.service 同步到其它服务器</strong></p>
<pre><code class="highlight bash"><span class="comment"># 将kube-nginx.service，拷贝到其它 Master 节点,并让Nginx开机自启</span>
hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  rsync -a --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/systemd/system/kube-nginx.service <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/systemd/system/;
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now kube-nginx.service&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl status kube-nginx.service&quot;</span>
<span class="keyword">done</span></code></pre>





<h2 id="3-kube-apiserver-配置"><a href="#3-kube-apiserver-配置" class="headerlink" title="3. kube-apiserver 配置"></a>3. kube-apiserver 配置</h2><h3 id="3-1-创建必要的目录"><a href="#3-1-创建必要的目录" class="headerlink" title="3.1 创建必要的目录"></a>3.1 创建必要的目录</h3><p><strong>master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 所有 k8s 节点创建以下目录</span>
hosts=<span class="string">&#x27;k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir -p /etc/kubernetes/manifests/ /etc/systemd/system/kubelet.service.d /var/lib/kubelet /var/log/kubernetes&quot;</span>
<span class="keyword">done</span></code></pre>



<h3 id="3-2-配置-kube-apiserver-service"><a href="#3-2-配置-kube-apiserver-service" class="headerlink" title="3.2 配置 kube-apiserver.service"></a>3.2 配置 kube-apiserver.service</h3><p>官方文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/">https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/</a></p>
<p><strong>master01</strong></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; <span class="string">EOF</span>
<span class="string"></span>
<span class="string">[Unit]</span>
<span class="string">Description=Kubernetes API Server</span>
<span class="string">Documentation=https://github.com/kubernetes/kubernetes</span>
<span class="string">After=network.target</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">ExecStart=/usr/local/bin/kube-apiserver \\</span>
<span class="string">      --v=2  \\</span>
<span class="string">      --allow-privileged=true  \\</span>
<span class="string">      --bind-address=0.0.0.0  \\</span>
<span class="string">      --secure-port=6443  \\</span>
<span class="string">      --advertise-address=10.20.1.101 \\</span>
<span class="string">      --service-cluster-ip-range=10.96.0.0/12,fd00:1111::/112  \\</span>
<span class="string">      --service-node-port-range=30000-32767  \\</span>
<span class="string">      --etcd-servers=https://10.20.1.101:2379,https://10.20.1.102:2379,https://10.20.1.103:2379 \\</span>
<span class="string">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \\</span>
<span class="string">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \\</span>
<span class="string">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \\</span>
<span class="string">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \\</span>
<span class="string">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \\</span>
<span class="string">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \\</span>
<span class="string">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \\</span>
<span class="string">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \\</span>
<span class="string">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \\</span>
<span class="string">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \\</span>
<span class="string">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \\</span>
<span class="string">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \\</span>
<span class="string">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span>
<span class="string">      --authorization-mode=Node,RBAC  \\</span>
<span class="string">      --enable-bootstrap-token-auth=true  \\</span>
<span class="string">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \\</span>
<span class="string">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \\</span>
<span class="string">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \\</span>
<span class="string">      --requestheader-allowed-names=aggregator  \\</span>
<span class="string">      --requestheader-group-headers=X-Remote-Group  \\</span>
<span class="string">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \\</span>
<span class="string">      --requestheader-username-headers=X-Remote-User \\</span>
<span class="string">      --enable-aggregator-routing=true</span>
<span class="string">Restart=on-failure</span>
<span class="string">RestartSec=10s</span>
<span class="string">LimitNOFILE=65535</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string"></span>
<span class="string">EOF</span></code></pre>



<p><strong>master02</strong></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; <span class="string">EOF</span>
<span class="string"></span>
<span class="string">[Unit]</span>
<span class="string">Description=Kubernetes API Server</span>
<span class="string">Documentation=https://github.com/kubernetes/kubernetes</span>
<span class="string">After=network.target</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">ExecStart=/usr/local/bin/kube-apiserver \\</span>
<span class="string">      --v=2  \\</span>
<span class="string">      --allow-privileged=true  \\</span>
<span class="string">      --bind-address=0.0.0.0  \\</span>
<span class="string">      --secure-port=6443  \\</span>
<span class="string">      --advertise-address=10.20.1.102 \\</span>
<span class="string">      --service-cluster-ip-range=10.96.0.0/12,fd00:1111::/112  \\</span>
<span class="string">      --service-node-port-range=30000-32767  \\</span>
<span class="string">      --etcd-servers=https://10.20.1.101:2379,https://10.20.1.102:2379,https://10.20.1.103:2379 \\</span>
<span class="string">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \\</span>
<span class="string">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \\</span>
<span class="string">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \\</span>
<span class="string">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \\</span>
<span class="string">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \\</span>
<span class="string">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \\</span>
<span class="string">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \\</span>
<span class="string">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \\</span>
<span class="string">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \\</span>
<span class="string">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \\</span>
<span class="string">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \\</span>
<span class="string">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \\</span>
<span class="string">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span>
<span class="string">      --authorization-mode=Node,RBAC  \\</span>
<span class="string">      --enable-bootstrap-token-auth=true  \\</span>
<span class="string">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \\</span>
<span class="string">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \\</span>
<span class="string">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \\</span>
<span class="string">      --requestheader-allowed-names=aggregator  \\</span>
<span class="string">      --requestheader-group-headers=X-Remote-Group  \\</span>
<span class="string">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \\</span>
<span class="string">      --requestheader-username-headers=X-Remote-User \\</span>
<span class="string">      --enable-aggregator-routing=true</span>
<span class="string">Restart=on-failure</span>
<span class="string">RestartSec=10s</span>
<span class="string">LimitNOFILE=65535</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string"></span>
<span class="string">EOF</span></code></pre>



<p><strong>master03</strong></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; <span class="string">EOF</span>
<span class="string"></span>
<span class="string">[Unit]</span>
<span class="string">Description=Kubernetes API Server</span>
<span class="string">Documentation=https://github.com/kubernetes/kubernetes</span>
<span class="string">After=network.target</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">ExecStart=/usr/local/bin/kube-apiserver \\</span>
<span class="string">      --v=2  \\</span>
<span class="string">      --allow-privileged=true  \\</span>
<span class="string">      --bind-address=0.0.0.0  \\</span>
<span class="string">      --secure-port=6443  \\</span>
<span class="string">      --advertise-address=10.20.1.103 \\</span>
<span class="string">      --service-cluster-ip-range=10.96.0.0/12,fd00:1111::/112  \\</span>
<span class="string">      --service-node-port-range=30000-32767  \\</span>
<span class="string">      --etcd-servers=https://10.20.1.101:2379,https://10.20.1.102:2379,https://10.20.1.103:2379 \\</span>
<span class="string">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \\</span>
<span class="string">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \\</span>
<span class="string">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \\</span>
<span class="string">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \\</span>
<span class="string">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \\</span>
<span class="string">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \\</span>
<span class="string">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \\</span>
<span class="string">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \\</span>
<span class="string">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \\</span>
<span class="string">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \\</span>
<span class="string">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \\</span>
<span class="string">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \\</span>
<span class="string">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span>
<span class="string">      --authorization-mode=Node,RBAC  \\</span>
<span class="string">      --enable-bootstrap-token-auth=true  \\</span>
<span class="string">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \\</span>
<span class="string">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \\</span>
<span class="string">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \\</span>
<span class="string">      --requestheader-allowed-names=aggregator  \\</span>
<span class="string">      --requestheader-group-headers=X-Remote-Group  \\</span>
<span class="string">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \\</span>
<span class="string">      --requestheader-username-headers=X-Remote-User \\</span>
<span class="string">      --enable-aggregator-routing=true</span>
<span class="string">Restart=on-failure</span>
<span class="string">RestartSec=10s</span>
<span class="string">LimitNOFILE=65535</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string"></span>
<span class="string">EOF</span></code></pre>



<h3 id="3-3-启动-kube-apiserver"><a href="#3-3-启动-kube-apiserver" class="headerlink" title="3.3 启动 kube-apiserver"></a>3.3 启动 kube-apiserver</h3><pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master01 k8s-master02 k8s-master03&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now kube-apiserver.service&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl status kube-apiserver.service&quot;</span>
<span class="keyword">done</span></code></pre>



<blockquote>
<p><strong>kube-apiserver.service 文件解析：</strong></p>
<p> 该配置文件创建 systemd 服务文件，运行 kube-apiserver（Kubernetes 控制平面的核心组件），监听 6443 端口，处理集群 API 请求</p>
<ul>
<li><p>–v&#x3D;2</p>
<p>设置日志级别为 2（中等详细，调试用）</p>
<p>生产环境可降为 –v&#x3D;1 减少日志，或增至 –v&#x3D;4 排查问题</p>
</li>
<li><p>–allow-privileged&#x3D;true</p>
<p>API 服务器监听所有网络接口（0.0.0.0）上的 6443 端口</p>
<p>允许外部和内部客户端（如 kubectl、Nginx 负载均衡器）访问</p>
<p>若仅限本地访问，可设为 –bind-address&#x3D;127.0.0.1，但高可用集群通常需要 0.0.0.0</p>
</li>
<li><p>–secure-port&#x3D;6443</p>
<p>API 服务器监听的 HTTPS 端口（6443）</p>
<p>提供安全的 API 访问，配合 TLS 证书</p>
<p>6443 是 Kubernetes 默认端口，Nginx 负载均衡器代理到此端口。</p>
</li>
<li><p>–advertise-address&#x3D;</p>
<p>API 服务器向集群其他组件通告的 IP 地址。</p>
<p>指定当前节点的 IP（k8s-master01），用于节点间通信和客户端连接。</p>
</li>
<li><p>–service-cluster-ip-range&#x3D;10.96.0.0&#x2F;12,fd00:1111::&#x2F;112 \</p>
<p>定义 Service 的 Cluster IP 地址范围，支持双栈（IPv4 和 IPv6）。</p>
<ul>
<li>10.96.0.0&#x2F;12：IPv4 地址池（10.96.0.0 - 10.111.255.255，约 104 万个地址）。</li>
<li>fd00:1111::&#x2F;112：IPv6 唯一本地地址（ULA），提供 65,536 个地址。</li>
</ul>
<p>作用：为 Service（ClusterIP 类型）分配虚拟 IP，供服务发现和负载均衡。</p>
</li>
<li><p>–service-node-port-range&#x3D;30000-32767 \</p>
<p>NodePort 类型 Service 的端口范围。</p>
<p>限制 NodePort 分配的端口（默认 30000-32767），用于外部访问。</p>
</li>
<li><p>–etcd-servers&#x3D;</p>
<p>指定 etcd 集群的 HTTPS 端点（三个主节点，2379 端口）。</p>
</li>
<li><p>–service-account-issuer&#x3D;<a target="_blank" rel="noopener" href="https://kubernetes.default.svc.cluster.local/">https://kubernetes.default.svc.cluster.local</a> \</p>
<p>ServiceAccount token 的发行者标识</p>
</li>
<li><p>–kubelet-preferred-address-types&#x3D;InternalIP,ExternalIP,Hostname \</p>
<p>API 服务器连接 kubelet 时优先使用的地址类型。</p>
<p>按顺序尝试 InternalIP、ExternalIP、Hostname。</p>
<p>适合 Calico 网络，优先内部 IP（10.20.1.x）。</p>
</li>
<li><p>–enable-admission-plugins&#x3D;NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota \</p>
<p>启用准入控制插件</p>
<ul>
<li>NamespaceLifecycle：管理命名空间生命周期。</li>
<li>LimitRanger：限制资源使用。</li>
<li>ServiceAccount：自动注入 ServiceAccount token。</li>
<li>DefaultStorageClass：为 PVC 设置默认存储类。</li>
<li>DefaultTolerationSeconds：设置默认容忍时间。</li>
<li>NodeRestriction：限制 kubelet 权限。</li>
<li>ResourceQuota：强制资源配额。</li>
</ul>
</li>
<li><p>–authorization-mode&#x3D;Node,RBAC \</p>
<p>启用 Node 和 RBAC 授权模式。Node 授权 kubelet 请求，RBAC 管理用户和角色权限。</p>
</li>
<li><p>–enable-bootstrap-token-auth&#x3D;true \</p>
<p>启用引导令牌认证，允许新节点通过 token 加入集群。</p>
</li>
<li><p>–requestheader-allowed-names&#x3D;aggregator \</p>
<p>允许的聚合器客户端名称。</p>
</li>
<li><p>–requestheader-group-headers&#x3D;X-Remote-Group \</p>
<p>HTTP 头中传递组信息的字段。</p>
</li>
<li><p>–requestheader-extra-headers-prefix&#x3D;X-Remote-Extra- \</p>
<p>额外信息的 HTTP 头前缀。</p>
</li>
<li><p>–requestheader-username-headers&#x3D;X-Remote-User \</p>
<p>HTTP 头中传递用户名的字段。</p>
</li>
<li><p>–enable-aggregator-routing&#x3D;true</p>
<p>启用 API 聚合器路由</p>
</li>
<li><p>Restart&#x3D;on-failure</p>
<p>服务失败时重启</p>
</li>
<li><p>RestartSec&#x3D;10s</p>
<p>重启前等待 10 秒</p>
</li>
<li><p>LimitNOFILE&#x3D;65535</p>
<p>最大文件描述符数，支持高并发连接，匹配 Nginx 的 65536</p>
</li>
</ul>
</blockquote>
<h2 id="4-kube-controller-manager-配置"><a href="#4-kube-controller-manager-配置" class="headerlink" title="4. kube-controller-manager 配置"></a>4. kube-controller-manager 配置</h2><h3 id="4-1-配置-kube-controller-manager-service"><a href="#4-1-配置-kube-controller-manager-service" class="headerlink" title="4.1 配置 kube-controller-manager.service"></a>4.1 配置 kube-controller-manager.service</h3><p>官方文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-controller-manager/">https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-controller-manager/</a></p>
<ul>
<li>所有master节点配置，且配置相同</li>
<li>172.16.0.0&#x2F;12 为 pod 网段，按需求设置你自己的网段</li>
</ul>
<p><strong>master01</strong></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; <span class="string">EOF</span>
<span class="string"></span>
<span class="string">[Unit]</span>
<span class="string">Description=Kubernetes Controller Manager</span>
<span class="string">Documentation=https://github.com/kubernetes/kubernetes</span>
<span class="string">After=network.target</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">ExecStart=/usr/local/bin/kube-controller-manager \\</span>
<span class="string">      --v=2 \\</span>
<span class="string">      --bind-address=0.0.0.0 \\</span>
<span class="string">      --root-ca-file=/etc/kubernetes/pki/ca.pem \\</span>
<span class="string">      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \\</span>
<span class="string">      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \\</span>
<span class="string">      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \\</span>
<span class="string">      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \\</span>
<span class="string">      --leader-elect=true \\</span>
<span class="string">      --use-service-account-credentials=true \\</span>
<span class="string">      --node-monitor-grace-period=40s \\</span>
<span class="string">      --node-monitor-period=5s \\</span>
<span class="string">      --controllers=*,bootstrapsigner,tokencleaner \\</span>
<span class="string">      --allocate-node-cidrs=true \\</span>
<span class="string">      --service-cluster-ip-range=10.96.0.0/12,fd00:1111::/112 \\</span>
<span class="string">      --cluster-cidr=172.16.0.0/12,fc00:2222::/112 \\</span>
<span class="string">      --node-cidr-mask-size-ipv4=24 \\</span>
<span class="string">      --node-cidr-mask-size-ipv6=120 \\</span>
<span class="string">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem</span>
<span class="string"></span>
<span class="string">Restart=always</span>
<span class="string">RestartSec=10s</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string"></span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>配置解析：</strong></p>
<p>kube-controller-manager  是 Kubernetes 控制平面的核心组件之一，负责运行控制器以维护集群状态（如 ReplicaSet、Deployment 控制器）。</p>
<ul>
<li><p>ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kube-controller-manager \</p>
<p>指定启动命令，运行 kube-controller-manager 可执行文件（位于 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;），后续参数以 \ 分行。</p>
</li>
<li><p>–v&#x3D;2 \</p>
<p>设置日志级别为 2（中等详细，适合调试）</p>
<p>生产环境可设为 –v&#x3D;1 减少日志，或增至 –v&#x3D;4 排查复杂问题。</p>
</li>
<li><p>–bind-address&#x3D;0.0.0.0 \</p>
<p>Controller Manager 监听所有网络接口（0.0.0.0）上的端口（默认 10257，HTTPS）。允许外部访问健康检查或指标端点（如 &#x2F;healthz、&#x2F;metrics）。</p>
</li>
<li><p>–root-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.pem \</p>
<p>Kubernetes CA 证书路径，用于验证客户端和服务端证书。</p>
</li>
<li><p>–cluster-signing-cert-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.pem \</p>
<p>用于签署集群内证书的 CA 证书。Controller Manager 使用该 CA 为 CSR（证书签名请求）签名（如 kubelet 证书）。</p>
</li>
<li><p>–cluster-signing-key-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca-key.pem \</p>
<p>CA 证书的私钥。与 –cluster-signing-cert-file 配对，用于签署证书。</p>
</li>
<li><p>–service-account-private-key-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;sa.key \</p>
<p>服务账户（ServiceAccount）token 的签名私钥。生成 ServiceAccount token，供 Pod 认证。</p>
</li>
<li><p>–kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;controller-manager.kubeconfig \</p>
<p>Controller Manager 的 kubeconfig 文件路径，定义 API 服务器连接信息和认证凭据。</p>
<p>允许 Controller Manager 通过 kubeconfig 访问 API 服务器（6443 端口）。</p>
</li>
<li><p>–leader-elect&#x3D;true \</p>
<p>启用领导者选举，在高可用集群中，确保多个主节点的 Controller Manager 实例中只有一个活跃（其他为热备），避免冲突。</p>
</li>
<li><p>–use-service-account-credentials&#x3D;true \</p>
<p>为每个控制器使用独立的 ServiceAccount 凭据。增强安全性，限制控制器权限（而非使用默认高权限凭据）。</p>
</li>
<li><p>–node-monitor-grace-period&#x3D;40s \</p>
<p>节点控制器标记节点为 NotReady 前的宽限时间。若节点 40 秒未响应（无心跳），标记为不可用。</p>
</li>
<li><p>–node-monitor-period&#x3D;5s \</p>
<p>节点控制器检查节点状态的周期。每 5 秒检查节点健康状态。</p>
</li>
<li><p>–controllers&#x3D;*,bootstrapsigner,tokencleaner \</p>
<p>指定启用的控制器列表。</p>
<p>*：启用所有默认控制器（如 ReplicaSet、Deployment、Node 控制器）。</p>
<p>bootstrapsigner：签署引导令牌的 CSR。</p>
<p>tokencleaner：清理过期引导令牌。</p>
</li>
<li><p>–allocate-node-cidrs&#x3D;true \</p>
<p>启用节点 CIDR 分配。Controller Manager 为每个节点分配 Pod CIDR（由 –cluster-cidr 定义）</p>
</li>
<li><p>–service-cluster-ip-range&#x3D;10.96.0.0&#x2F;12,fd00:1111::&#x2F;112 \</p>
<p>Service 的 Cluster IP 地址范围（IPv4 和 IPv6）。</p>
<p>定义 Service 的虚拟 IP 池，与 kube-apiserver 的 –service-cluster-ip-range 一致。</p>
</li>
<li><p>–node-cidr-mask-size-ipv4&#x3D;24 \</p>
<p>每个节点的 IPv4 Pod CIDR 子网掩码大小，每个节点分配 &#x2F;24 子网（256 个 IP），从 172.16.0.0&#x2F;12 中划分。</p>
</li>
<li><p>–node-cidr-mask-size-ipv6&#x3D;120 \</p>
<p>每个节点的 IPv6 Pod CIDR 子网掩码大小。</p>
<p>每个节点分配 &#x2F;120 子网（256 个 IP），从 fc00:2222::&#x2F;112 中划分。</p>
</li>
<li><p>–requestheader-client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.pem \</p>
<p>API 聚合器的 CA 证书。验证聚合器客户端（如扩展 API 服务器），与 kube-apiserver 一致。</p>
</li>
<li><p>Restart&#x3D;always</p>
<p>服务无论何种原因退出都重启。确保 Controller Manager 高可用。</p>
</li>
<li><p>RestartSec&#x3D;10s</p>
<p>重启前等待 10 秒。</p>
</li>
</ul>
</blockquote>
<p><strong>配置分发到其它Master节点</strong></p>
<pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  rsync -a --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/kube-controller-manager.service <span class="variable">$user</span>@<span class="variable">$host</span>:/usr/lib/systemd/system/;
<span class="keyword">done</span></code></pre>



<h3 id="4-2-启动-kube-controller-manager"><a href="#4-2-启动-kube-controller-manager" class="headerlink" title="4.2 启动 kube-controller-manager"></a>4.2 启动 kube-controller-manager</h3><pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master01 k8s-master02 k8s-master03&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now kube-controller-manager.service&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl status kube-controller-manager.service&quot;</span>
<span class="keyword">done</span></code></pre>





<h2 id="5-kube-scheduler-配置"><a href="#5-kube-scheduler-配置" class="headerlink" title="5. kube-scheduler 配置"></a>5. kube-scheduler 配置</h2><p>所有 master 节点配置，且配置相同</p>
<h3 id="5-1-kube-scheduler-service"><a href="#5-1-kube-scheduler-service" class="headerlink" title="5.1 kube-scheduler.service"></a>5.1 kube-scheduler.service</h3><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; <span class="string">EOF</span>
<span class="string"></span>
<span class="string">[Unit]</span>
<span class="string">Description=Kubernetes Scheduler</span>
<span class="string">Documentation=https://github.com/kubernetes/kubernetes</span>
<span class="string">After=network.target</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">ExecStart=/usr/local/bin/kube-scheduler \\</span>
<span class="string">      --v=2 \\</span>
<span class="string">      --bind-address=0.0.0.0 \\</span>
<span class="string">      --leader-elect=true \\</span>
<span class="string">      --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span>
<span class="string"></span>
<span class="string">Restart=always</span>
<span class="string">RestartSec=10s</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string"></span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>配置解析：</strong></p>
<p>kube-scheduler 与 API 服务器（6443 端口）交互，通过 kubeconfig 文件访问集群状态，决定 Pod 分配。</p>
<ul>
<li><p>ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kube-scheduler \</p>
<p>指定启动命令，运行 kube-scheduler 可执行文件（位于 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;），后续参数以 \ 分行。</p>
<p>启动 Scheduler，负责根据节点资源、策略和约束（如亲和性、污点）将 Pod 调度到节点。</p>
</li>
<li><p>–v&#x3D;2 \</p>
<p>设置日志级别为 2（中等详细，适合调试）。</p>
<p>生产环境可设为 –v&#x3D;1 减少日志，或增至 –v&#x3D;4 排查复杂问题。</p>
</li>
<li><p>–bind-address&#x3D;0.0.0.0 \</p>
<p>Scheduler 监听所有网络接口（0.0.0.0）上的端口（默认 10259，HTTPS）。</p>
<p>允许外部访问健康检查或指标端点（如 &#x2F;healthz、&#x2F;metrics），常用于监控（如 Prometheus）。</p>
</li>
<li><p>–leader-elect&#x3D;true \</p>
<p>启用领导者选举。</p>
<p>在高可用集群中，确保多个主节点的 Scheduler 实例中只有一个活跃（其他为热备），避免调度冲突。</p>
</li>
<li><p>–kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;scheduler.kubeconfig \</p>
<p>Scheduler 的 kubeconfig 文件路径，定义 API 服务器连接信息和认证凭据。</p>
</li>
<li><p>Restart&#x3D;always</p>
<p>服务无论何种原因退出都重启。</p>
</li>
<li><p>RestartSec&#x3D;10s</p>
<p>重启前等待 10 秒。</p>
</li>
</ul>
</blockquote>
<p><strong>配置同步到其它 master 节点</strong></p>
<pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  rsync -a --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/kube-scheduler.service <span class="variable">$user</span>@<span class="variable">$host</span>:/usr/lib/systemd/system/;
<span class="keyword">done</span></code></pre>



<h3 id="5-2-启动-kube-scheduler"><a href="#5-2-启动-kube-scheduler" class="headerlink" title="5.2 启动 kube-scheduler"></a>5.2 启动 kube-scheduler</h3><pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master01 k8s-master02 k8s-master03&#x27;</span>
user=root
<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$host</span>; 
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now kube-scheduler.service&quot;</span>
  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl status kube-scheduler.service&quot;</span>
<span class="keyword">done</span></code></pre>





<h1 id="六、TLS-Bootstrapping-配置"><a href="#六、TLS-Bootstrapping-配置" class="headerlink" title="六、TLS Bootstrapping 配置"></a>六、TLS Bootstrapping 配置</h1><p>官方文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/">https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/</a></p>
<h2 id="1-生成-bootstrap-的-token"><a href="#1-生成-bootstrap-的-token" class="headerlink" title="1. 生成 bootstrap 的 token"></a>1. 生成 bootstrap 的 token</h2><p><strong>master01</strong></p>
<pre><code class="highlight bash">TOKEN_ID=$(openssl rand -hex 3)
TOKEN_SECRET=$(openssl rand -hex 8)
BOOTSTRAP_TOKEN=<span class="variable">$&#123;TOKEN_ID&#125;</span>.<span class="variable">$&#123;TOKEN_SECRET&#125;</span>
 
$ <span class="built_in">echo</span> <span class="variable">$BOOTSTRAP_TOKEN</span>
25062c.208e46b2a427f63a</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>生成一个 Kubernetes 引导令牌（Bootstrap Token），格式为 .，用于节点（主节点或工作节点）通过 kubeadm join 加入集群时进行身份验证</p>
</blockquote>
<h2 id="2-配置-bootstrap-kubelet-kubeconfig"><a href="#2-配置-bootstrap-kubelet-kubeconfig" class="headerlink" title="2. 配置 bootstrap-kubelet.kubeconfig"></a>2. 配置 bootstrap-kubelet.kubeconfig</h2><p><strong>master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 在指定的 kubeconfig 文件（/etc/kubernetes/bootstrap-kubelet.kubeconfig）中配置一个名为 kubernetes 的集群条目，定义如何连接到 Kubernetes API 服务器，包括 CA 证书和服务器地址</span>
kubectl config set-cluster kubernetes     \
--certificate-authority=/etc/kubernetes/pki/ca.pem     \
--embed-certs=<span class="literal">true</span>     --server=https://127.0.0.1:8443     \
--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig


<span class="comment"># 在指定的 kubeconfig 文件中创建或更新一个名为 tls-bootstrap-token-user 的用户凭据条目，配置引导令牌（25062c.208e46b2a427f63a），用于 kubelet 在节点引导过程中通过 Nginx 负载均衡器（127.0.0.1:8443）访问 API 服务器</span>
kubectl config set-credentials tls-bootstrap-token-user     \
--token=25062c.208e46b2a427f63a \
--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig

<span class="comment"># 在 kubeconfig 文件中配置上下文（context），将集群和用户凭据关联起来，供 kubelet 在节点引导过程中使用以访问 Kubernetes API 服务器</span>
kubectl config set-context tls-bootstrap-token-user@kubernetes     \
--cluster=kubernetes     \
--user=tls-bootstrap-token-user     \
--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig

<span class="comment"># 在 kubeconfig 文件中设置默认上下文，指定 kubelet 使用特定的上下文（tls-bootstrap-token-user@kubernetes）来访问 Kubernetes API 服务器，从而完成节点引导和注册。</span>
kubectl config use-context tls-bootstrap-token-user@kubernetes     \
--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig


<span class="comment"># token的位置在 bootstrap.secret.yaml，如果修改的话到这个文件修改</span>
<span class="comment"># 创建 /root/.kube 目录，用于存储 Kubernetes 管理用户的 kubeconfig 文件</span>
<span class="built_in">mkdir</span> -p /root/.kube
<span class="comment"># 将管理员的 kubeconfig 文件（/etc/kubernetes/admin.kubeconfig）复制到 /root/.kube/config，作为 kubectl 的默认配置文件</span>
<span class="built_in">cp</span> /etc/kubernetes/admin.kubeconfig /root/.kube/config


<span class="comment"># 分发 kubelet 配置文件</span>
host=(k8s-master02 k8s-master03)
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>
	ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;mkdir -p /root/.kube&quot;</span>
    rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /root/.kube/config <span class="variable">$user</span>@<span class="variable">$i</span>:/root/.kube/;
<span class="keyword">done</span></code></pre>



<h2 id="3-创建-bootstrap-secret-yaml"><a href="#3-创建-bootstrap-secret-yaml" class="headerlink" title="3. 创建 bootstrap-secret.yaml"></a>3. 创建 bootstrap-secret.yaml</h2><p>注意：bootstrap.secret.yaml的token-id、token-secret，需与上命令token保持一致(即 <code>25062c.208e46b2a427f63a</code> )</p>
<pre><code class="highlight bash"><span class="comment"># 创建目录</span>
<span class="built_in">mkdir</span> -p /etc/kubernetes/yaml

<span class="comment"># 编辑文件</span>
<span class="built_in">cat</span> &gt; /etc/kubernetes/yaml/bootstrap-secret.yaml  &lt;&lt; <span class="string">EOF</span>
<span class="string">apiVersion: v1</span>
<span class="string">kind: Secret</span>
<span class="string">metadata:</span>
<span class="string">  name: bootstrap-token-$&#123;TOKEN_ID&#125;</span>
<span class="string">  namespace: kube-system</span>
<span class="string">type: bootstrap.kubernetes.io/token</span>
<span class="string">stringData:</span>
<span class="string">  description: &quot;The default bootstrap token generated by &#x27;kubelet &#x27;.&quot;</span>
<span class="string">  token-id: $&#123;TOKEN_ID&#125;</span>
<span class="string">  token-secret: $&#123;TOKEN_SECRET&#125;</span>
<span class="string">  usage-bootstrap-authentication: &quot;true&quot;</span>
<span class="string">  usage-bootstrap-signing: &quot;true&quot;</span>
<span class="string">  auth-extra-groups:  system:bootstrappers:default-node-token,system:bootstrappers:worker,system:bootstrappers:ingress</span>
<span class="string">EOF</span>

<span class="comment"># 执行资源清单 </span>
$ kubectl create -f /etc/kubernetes/yaml/bootstrap-secret.yaml
secret/bootstrap-token-25062c created
<span class="comment"># 查看结果</span>
$ kubectl get secret -n kube-system
NAME                     TYPE                            DATA   AGE
bootstrap-token-25062c   bootstrap.kubernetes.io/token   6      10s</code></pre>



<h2 id="4-创建-kubelet-bootstrap-rbac-yaml"><a href="#4-创建-kubelet-bootstrap-rbac-yaml" class="headerlink" title="4. 创建 kubelet-bootstrap-rbac.yaml"></a>4. 创建 kubelet-bootstrap-rbac.yaml</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/yaml/kubelet-bootstrap-rbac.yaml &lt;&lt; <span class="string">EOF</span>
<span class="string">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="string">kind: ClusterRoleBinding</span>
<span class="string">metadata:</span>
<span class="string">  name: kubelet-bootstrap</span>
<span class="string">roleRef:</span>
<span class="string">  apiGroup: rbac.authorization.k8s.io</span>
<span class="string">  kind: ClusterRole</span>
<span class="string">  name: system:node-bootstrapper</span>
<span class="string">subjects:</span>
<span class="string">- apiGroup: rbac.authorization.k8s.io</span>
<span class="string">  kind: Group</span>
<span class="string">  name: system:bootstrappers:default-node-token</span>
<span class="string">---</span>
<span class="string">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="string">kind: ClusterRoleBinding</span>
<span class="string">metadata:</span>
<span class="string">  name: node-autoapprove-bootstrap</span>
<span class="string">roleRef:</span>
<span class="string">  apiGroup: rbac.authorization.k8s.io</span>
<span class="string">  kind: ClusterRole</span>
<span class="string">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span>
<span class="string">subjects:</span>
<span class="string">- apiGroup: rbac.authorization.k8s.io</span>
<span class="string">  kind: Group</span>
<span class="string">  name: system:bootstrappers:default-node-token</span>
<span class="string">---</span>
<span class="string">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="string">kind: ClusterRoleBinding</span>
<span class="string">metadata:</span>
<span class="string">  name: node-autoapprove-certificate-rotation</span>
<span class="string">roleRef:</span>
<span class="string">  apiGroup: rbac.authorization.k8s.io</span>
<span class="string">  kind: ClusterRole</span>
<span class="string">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span>
<span class="string">subjects:</span>
<span class="string">- apiGroup: rbac.authorization.k8s.io</span>
<span class="string">  kind: Group</span>
<span class="string">  name: system:nodes</span>
<span class="string">---</span>
<span class="string">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="string">kind: ClusterRole</span>
<span class="string">metadata:</span>
<span class="string">  annotations:</span>
<span class="string">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span>
<span class="string">  labels:</span>
<span class="string">    kubernetes.io/bootstrapping: rbac-defaults</span>
<span class="string">  name: system:kube-apiserver-to-kubelet</span>
<span class="string">rules:</span>
<span class="string">  - apiGroups:</span>
<span class="string">      - &quot;&quot;</span>
<span class="string">    resources:</span>
<span class="string">      - nodes/proxy</span>
<span class="string">      - nodes/stats</span>
<span class="string">      - nodes/log</span>
<span class="string">      - nodes/spec</span>
<span class="string">      - nodes/metrics</span>
<span class="string">    verbs:</span>
<span class="string">      - &quot;*&quot;</span>
<span class="string">---</span>
<span class="string">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="string">kind: ClusterRoleBinding</span>
<span class="string">metadata:</span>
<span class="string">  name: system:kube-apiserver</span>
<span class="string">  namespace: &quot;&quot;</span>
<span class="string">roleRef:</span>
<span class="string">  apiGroup: rbac.authorization.k8s.io</span>
<span class="string">  kind: ClusterRole</span>
<span class="string">  name: system:kube-apiserver-to-kubelet</span>
<span class="string">subjects:</span>
<span class="string">  - apiGroup: rbac.authorization.k8s.io</span>
<span class="string">    kind: User</span>
<span class="string">    name: kube-apiserver</span>
<span class="string">EOF</span>


<span class="comment"># 执行清单</span>
kubectl create -f /etc/kubernetes/yaml/kubelet-bootstrap-rbac.yaml</code></pre>



<h2 id="5-分发配置文件"><a href="#5-分发配置文件" class="headerlink" title="5. 分发配置文件"></a>5. 分发配置文件</h2><pre><code class="highlight bash">host=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)
user=root
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>
    rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/&#123;bootstrap-kubelet,kube-proxy&#125;.kubeconfig <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/;
<span class="keyword">done</span></code></pre>

<p><strong>注：若kubectl get node 为空，那应该就是 bootstrap-kubelet.kubeconfig 中的 token 对不上, 修改后重启kubelet</strong></p>
<h2 id="6-查看集群状态"><a href="#6-查看集群状态" class="headerlink" title="6. 查看集群状态"></a>6. 查看集群状态</h2><pre><code class="highlight bash">[root@k8s-master01 ~]$ kubectl get cs
Warning: v1 ComponentStatus is deprecated <span class="keyword">in</span> v1.19+
NAME                 STATUS    MESSAGE   ERROR
scheduler            Healthy   ok        
etcd-0               Healthy   ok        
controller-manager   Healthy   ok</code></pre>





<h1 id="七、Node-配置"><a href="#七、Node-配置" class="headerlink" title="七、Node 配置"></a>七、Node 配置</h1><h2 id="1-复制相关证书至-node-节点"><a href="#1-复制相关证书至-node-节点" class="headerlink" title="1. 复制相关证书至 node 节点"></a>1. 复制相关证书至 node 节点</h2><pre><code class="highlight bash">user=root
host=(k8s-master02 k8s-master03 k8s-node01 k8s-node02)

<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>
  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;sudo mkdir -p /etc/kubernetes/pki/&quot;</span>;
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/pki/&#123;ca.pem,ca-key.pem,front-proxy-ca.pem&#125; <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/pki/;
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/&#123;bootstrap-kubelet.kubeconfig,kube-proxy.kubeconfig&#125; <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/pki/;
<span class="keyword">done</span></code></pre>



<h2 id="2-配置-kubelet（所有节点）"><a href="#2-配置-kubelet（所有节点）" class="headerlink" title="2. 配置 kubelet（所有节点）"></a>2. 配置 kubelet（所有节点）</h2><h3 id="2-1-编辑-kubelet-service"><a href="#2-1-编辑-kubelet-service" class="headerlink" title="2.1 编辑 kubelet.service"></a>2.1 编辑 kubelet.service</h3><p><strong>Master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 当使用 docker 作为 Runtime</span>
<span class="comment"># IPv4示例</span>
<span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; <span class="string">EOF</span>
<span class="string"></span>
<span class="string">[Unit]</span>
<span class="string">Description=Kubernetes Kubelet</span>
<span class="string">Documentation=https://github.com/kubernetes/kubernetes</span>
<span class="string">After=network-online.target firewalld.service cri-docker.service docker.socket containerd.service</span>
<span class="string">Wants=network-online.target</span>
<span class="string">Requires=docker.socket containerd.service</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">ExecStart=/usr/local/bin/kubelet \\</span>
<span class="string">    --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig  \\</span>
<span class="string">    --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\</span>
<span class="string">    --config=/etc/kubernetes/kubelet-conf.yml \\</span>
<span class="string">    --container-runtime-endpoint=unix:///run/cri-dockerd.sock  \\</span>
<span class="string">    --node-labels=node.kubernetes.io/node= </span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string">EOF</span>

<span class="comment"># IPv6示例</span>
<span class="comment"># 若不使用IPv6那么忽略此项即可</span>
<span class="comment"># 下方 --node-ip 更换为每个节点的IP即可</span>
<span class="comment"># cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span>
<span class="comment"># [Unit]</span>
<span class="comment"># Description=Kubernetes Kubelet</span>
<span class="comment"># Documentation=https://github.com/kubernetes/kubernetes</span>
<span class="comment"># After=network-online.target firewalld.service cri-docker.service docker.socket # containerd.service</span>
<span class="comment"># Wants=network-online.target</span>
<span class="comment"># Requires=docker.socket containerd.service</span>

<span class="comment"># [Service]</span>
<span class="comment"># ExecStart=/usr/local/bin/kubelet \\</span>
<span class="comment">#     --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig  \\</span>
<span class="comment">#     --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\</span>
<span class="comment">#     --config=/etc/kubernetes/kubelet-conf.yml \\</span>
<span class="comment">#     --container-runtime-endpoint=unix:///run/cri-dockerd.sock  \\</span>
<span class="comment">#     --node-labels=node.kubernetes.io/node=   \\</span>
<span class="comment">#     --node-ip=192.168.1.31,2408:822a:245:8c01::fab</span>
<span class="comment"># [Install]</span>
<span class="comment"># WantedBy=multi-user.target</span>
<span class="comment"># EOF</span></code></pre>

<ul>
<li>注意node-labels&#x3D;node.kubernetes.io&#x2F;node&#x3D;<code>&#39;&#39;</code> ubuntu为<code>&#39;&#39;</code> centos为空</li>
</ul>
<blockquote>
<p><strong>命令解析：</strong></p>
<ul>
<li>–bootstrap-kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;bootstrap-kubelet.kubeconfig：引导 kubeconfig 文件路径。用于 TLS Bootstrapping（节点自动加入集群的机制）。kubelet 使用此文件向 API Server 请求证书，首次启动时使用</li>
<li>–kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;kubelet.kubeconfig：最终的 kubeconfig 文件路径。引导成功后，kubelet 会切换到这个文件，用于与 Kubernetes API Server 通信。</li>
<li>–config&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;kubelet-conf.yml：kubelet 的 YAML 配置文件路径（包含详细配置，如 cgroup 驱动、Pod 限制等）。这个文件在稍后定义。</li>
<li>–container-runtime-endpoint&#x3D;unix:&#x2F;&#x2F;&#x2F;run&#x2F;cri-dockerd.sock：容器运行时端点。指定使用 cri-dockerd 的 Unix socket（因为使用 Docker + cri-dockerd 作为 CRI 兼容运行时，而不是直接用 containerd 或 CRI-O）。</li>
<li>–node-labels&#x3D;node.kubernetes.io&#x2F;node&#x3D;：节点标签。为空值（可以自定义标签，如用于节点分组）。这里的 &#x3D; 后无内容，表示一个空标签</li>
</ul>
</blockquote>
<h3 id="2-2-编辑-kubelet-conf-yml"><a href="#2-2-编辑-kubelet-conf-yml" class="headerlink" title="2.2 编辑 kubelet-conf.yml"></a>2.2 编辑 kubelet-conf.yml</h3><p>官方文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/config-api/kubelet-config.v1beta1/">https://kubernetes.io/zh-cn/docs/reference/config-api/kubelet-config.v1beta1/</a></p>
<p><strong>Master01</strong></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/kubelet-conf.yml &lt;&lt;<span class="string">EOF</span>
<span class="string">apiVersion: kubelet.config.k8s.io/v1beta1</span>
<span class="string">kind: KubeletConfiguration</span>
<span class="string">address: 0.0.0.0</span>
<span class="string">port: 10250</span>
<span class="string">readOnlyPort: 10255</span>
<span class="string">authentication:</span>
<span class="string">  anonymous:</span>
<span class="string">    enabled: false</span>
<span class="string">  webhook:</span>
<span class="string">    cacheTTL: 2m0s</span>
<span class="string">    enabled: true</span>
<span class="string">  x509:</span>
<span class="string">    clientCAFile: /etc/kubernetes/pki/ca.pem</span>
<span class="string">authorization:</span>
<span class="string">  mode: Webhook</span>
<span class="string">  webhook:</span>
<span class="string">    cacheAuthorizedTTL: 5m0s</span>
<span class="string">    cacheUnauthorizedTTL: 30s</span>
<span class="string">cgroupDriver: systemd</span>
<span class="string">cgroupsPerQOS: true</span>
<span class="string">clusterDNS:</span>
<span class="string">- 10.96.0.10</span>
<span class="string">clusterDomain: cluster.local</span>
<span class="string">containerLogMaxFiles: 5</span>
<span class="string">containerLogMaxSize: 10Mi</span>
<span class="string">contentType: application/vnd.kubernetes.protobuf</span>
<span class="string">cpuCFSQuota: true</span>
<span class="string">cpuManagerPolicy: none</span>
<span class="string">cpuManagerReconcilePeriod: 10s</span>
<span class="string">enableControllerAttachDetach: true</span>
<span class="string">enableDebuggingHandlers: true</span>
<span class="string">enforceNodeAllocatable:</span>
<span class="string">- pods</span>
<span class="string">eventBurst: 10</span>
<span class="string">eventRecordQPS: 5</span>
<span class="string">evictionHard:</span>
<span class="string">  imagefs.available: 15%</span>
<span class="string">  memory.available: 100Mi</span>
<span class="string">  nodefs.available: 10%</span>
<span class="string">  nodefs.inodesFree: 5%</span>
<span class="string">evictionPressureTransitionPeriod: 5m0s</span>
<span class="string">failSwapOn: true</span>
<span class="string">fileCheckFrequency: 20s</span>
<span class="string">hairpinMode: promiscuous-bridge</span>
<span class="string">healthzBindAddress: 127.0.0.1</span>
<span class="string">healthzPort: 10248</span>
<span class="string">httpCheckFrequency: 20s</span>
<span class="string">imageGCHighThresholdPercent: 85</span>
<span class="string">imageGCLowThresholdPercent: 80</span>
<span class="string">imageMinimumGCAge: 2m0s</span>
<span class="string">iptablesDropBit: 15</span>
<span class="string">iptablesMasqueradeBit: 14</span>
<span class="string">kubeAPIBurst: 10</span>
<span class="string">kubeAPIQPS: 5</span>
<span class="string">makeIPTablesUtilChains: true</span>
<span class="string">maxOpenFiles: 1000000</span>
<span class="string">maxPods: 110</span>
<span class="string">nodeStatusUpdateFrequency: 10s</span>
<span class="string">oomScoreAdj: -999</span>
<span class="string">podPidsLimit: -1</span>
<span class="string">registryBurst: 10</span>
<span class="string">registryPullQPS: 5</span>
<span class="string">resolvConf: /etc/resolv.conf</span>
<span class="string">rotateCertificates: true</span>
<span class="string">runtimeRequestTimeout: 2m0s</span>
<span class="string">serializeImagePulls: true</span>
<span class="string">staticPodPath: /etc/kubernetes/manifests</span>
<span class="string">streamingConnectionIdleTimeout: 4h0m0s</span>
<span class="string">syncFrequency: 1m0s</span>
<span class="string">volumeStatsAggPeriod: 1m0s</span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>创建 Kubernetes 的 kubelet 配置文件 &#x2F;etc&#x2F;kubernetes&#x2F;kubelet-conf.yml。该文件是 kubelet 的主要配置文件，定义了 kubelet 的运行行为、资源管理、网络配置等关键参数。kubelet 是 Kubernetes 节点上的核心组件，负责管理 Pod、容器生命周期、节点资源等。</p>
<p><strong>apiVersion</strong>: 指定配置文件使用的 Kubernetes API 版本。这里是 kubelet.config.k8s.io&#x2F;v1beta1，表示 kubelet 配置的 v1beta1 版本。</p>
<p><strong>kind</strong>: 指定配置类型为 KubeletConfiguration，这是 kubelet 的专用配置类型。</p>
<p><strong>address</strong>: kubelet 的监听地址。0.0.0.0 表示监听所有网络接口，允许外部访问（如 API Server 或 kubectl）。</p>
<p><strong>port</strong>: kubelet 的主端口，用于处理 HTTPS 请求（如状态查询、命令执行）。默认值为 10250。</p>
<p><strong>readOnlyPort</strong>: 只读端口，提供无认证的只读访问（如健康检查或状态查询）。默认值为 10255。<strong>注意</strong>：在高安全性环境中，建议禁用只读端口（设置为 0）以防止未经授权的访问。</p>
<p><strong>authentication</strong>: 定义 kubelet 的认证机制。</p>
<ul>
<li><strong>anonymous.enabled</strong>: 是否允许匿名访问。false 表示禁用匿名访问，增强安全性。</li>
<li><strong>webhook.enabled</strong>: 是否启用 Webhook 认证。true 表示 kubelet 通过向 API Server 发送 Webhook 请求验证客户端身份。</li>
<li><strong>webhook.cacheTTL</strong>: Webhook 认证结果的缓存时间，设置为 2m0s（2 分钟），减少重复验证开销。</li>
<li><strong>x509.clientCAFile</strong>: 指定用于验证客户端证书的 CA 文件路径（&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.pem）。客户端（如 API Server）必须提供由该 CA 签发的证书。</li>
</ul>
<p><strong>authorization</strong>: 定义 kubelet 的授权机制。</p>
<ul>
<li><strong>mode: Webhook</strong>: 使用 Webhook 模式向 API Server 请求授权决定（基于 RBAC 或其他授权策略）。</li>
<li><strong>webhook.cacheAuthorizedTTL</strong>: 已授权请求的缓存时间，5m0s（5 分钟）。</li>
<li><strong>webhook.cacheUnauthorizedTTL</strong>: 未授权请求的缓存时间，30s（30 秒）。较短的未授权缓存时间确保快速更新拒绝策略。</li>
</ul>
<p><strong>cgroupDriver</strong>: 指定 kubelet 使用的 cgroup 驱动程序。systemd 表示使用 systemd 管理 cgroup，与 Docker 的 systemd cgroup 驱动一致（配置了 Docker 的 daemon.json 使用 native.cgroupdriver&#x3D;systemd）。</p>
<p><strong>cgroupsPerQOS</strong>: 是否为不同 QoS（服务质量）级别的 Pod 创建单独的 cgroup。true 启用此功能，确保 Guaranteed、Burstable 和 BestEffort Pod 的资源隔离。</p>
<p><strong>clusterDNS</strong>: 指定集群内 DNS 服务的 IP 地址。10.96.0.10 是 CoreDNS 的服务 IP（与安装 CoreDNS 时配置的 clusterIP 一致）。</p>
<p><strong>clusterDomain</strong>: 指定集群的 DNS 域名后缀。cluster.local 是默认值，用于解析服务名称（如 my-service.default.svc.cluster.local）。</p>
<p><strong>containerLogMaxFiles</strong>: 每个容器的最大日志文件数（轮转日志）。5 表示保留最多 5 个日志文件。</p>
<p><strong>containerLogMaxSize</strong>: 每个日志文件的最大大小。10Mi 表示 10MB，超过后会触发日志轮转。</p>
<p><strong>contentType</strong>: 指定 kubelet 与 API Server 通信时使用的内容类型。application&#x2F;vnd.kubernetes.protobuf 表示使用 Protobuf 格式（比 JSON 更高效）。</p>
<p><strong>cpuCFSQuota</strong>: 是否为容器启用 CPU CFS（Completely Fair Scheduler）配额。true 表示限制容器 CPU 使用量，基于 Pod 的 QoS 设置。</p>
<p><strong>cpuManagerPolicy</strong>: CPU 分配策略。none 表示不使用 CPU 管理器（不分配专用 CPU 核心，Pod 共享 CPU 资源）。</p>
<p><strong>cpuManagerReconcilePeriod</strong>: CPU 管理器的协调周期。10s 表示每 10 秒检查并调整 CPU 分配（尽管策略为 none，此参数仍需设置）。</p>
<p><strong>enableControllerAttachDetach</strong>: 是否允许控制器管理卷的挂载和卸载。true 表示由 kubelet 和控制器协同处理卷操作。</p>
<p><strong>enableDebuggingHandlers</strong>: 是否启用调试端点（如 &#x2F;debug&#x2F;pprof）。true 允许访问调试信息，便于性能分析。</p>
<p><strong>enforceNodeAllocatable</strong>: 指定强制限制的资源类型。pods 表示对 Pod 分配的资源进行限制，确保节点保留系统和 kubelet 所需的资源（如内存、CPU）。</p>
<p><strong>eventBurst</strong>: 事件处理的突发容量。10 表示允许短时间内处理最多 10 个事件。</p>
<p><strong>eventRecordQPS</strong>: 每秒记录的事件数。5 表示平均每秒记录 5 个事件，控制事件报告频率以避免 API Server 过载。</p>
<p><strong>evictionHard</strong>: 定义硬性驱逐阈值，当资源低于以下值时，kubelet 会驱逐 Pod 以回收资源：</p>
<ul>
<li><strong>imagefs.available</strong>: 镜像文件系统可用空间低于 15% 时触发驱逐。</li>
<li><strong>memory.available</strong>: 可用内存低于 100Mi（100MB）时触发驱逐。</li>
<li><strong>nodefs.available</strong>: 节点文件系统可用空间低于 10% 时触发驱逐。</li>
<li><strong>nodefs.inodesFree</strong>: 节点文件系统可用 inode 低于 5% 时触发驱逐。</li>
</ul>
<p><strong>evictionPressureTransitionPeriod</strong>: 驱逐压力过渡期。5m0s 表示在资源压力缓解后，等待 5 分钟才停止驱逐。</p>
<p><strong>failSwapOn</strong>: 是否允许在启用 swap 分区时启动 kubelet。true 表示如果 swap 启用，kubelet 将启动失败（当前已禁用 swap）。</p>
<p><strong>fileCheckFrequency</strong>: 检查文件变更的频率。20s 表示每 20 秒检查一次（如 Pod 配置文件）。</p>
<p><strong>hairpinMode</strong>: 指定 hairpin 流量（Pod 访问自身服务 IP）的处理方式。promiscuous-bridge 表示使用网桥的混杂模式，适用于 Calico 等 CNI 插件。</p>
<p><strong>healthzBindAddress</strong>: 健康检查监听地址。127.0.0.1 表示仅本地可访问，增强安全性。</p>
<p><strong>healthzPort</strong>: 健康检查端口。10248 是默认值，用于 &#x2F;healthz 端点。</p>
<p><strong>httpCheckFrequency</strong>: HTTP 健康检查频率。20s 表示每 20 秒检查一次。</p>
<p><strong>imageGCHighThresholdPercent</strong>: 镜像垃圾回收的上限阈值。磁盘使用率达到 85% 时触发回收。</p>
<p><strong>imageGCLowThresholdPercent</strong>: 镜像垃圾回收的下限阈值。回收后磁盘使用率低于 80% 时停止。</p>
<p><strong>imageMinimumGCAge</strong>: 镜像的最小保留时间。2m0s 表示镜像至少保留 2 分钟，防止频繁回收。</p>
<p><strong>iptablesDropBit</strong>: 用于标记丢弃数据包的 iptables 位。15 是默认值。</p>
<p><strong>iptablesMasqueradeBit</strong>: 用于 SNAT（源地址转换）的 iptables 位。14 是默认值。</p>
<p><strong>makeIPTablesUtilChains</strong>: 是否创建 iptables 工具链。true 表示 kubelet 自动管理 iptables 规则。</p>
<p><strong>kubeAPIBurst</strong>: 与 API Server 通信的突发请求数。10 表示短时间内最多发送 10 个请求。</p>
<p><strong>kubeAPIQPS</strong>: 与 API Server 通信的每秒请求数。5 表示平均每秒 5 个请求，控制负载。</p>
<p><strong>maxOpenFiles</strong>: 最大打开文件数。1000000 允许 kubelet 处理大量文件描述符。</p>
<p><strong>maxPods</strong>: 节点上最大 Pod 数。110 是默认值，限制节点负载。</p>
<p><strong>podPidsLimit</strong>: 每个 Pod 的最大 PID 数。-1 表示无限制。</p>
<p><strong>nodeStatusUpdateFrequency</strong>: 节点状态更新频率。10s 表示每 10 秒向 API Server 报告节点状态。</p>
<p><strong>oomScoreAdj</strong>: kubelet 进程的 OOM（内存不足）优先级。-999 表示低优先级，降低被杀死概率。</p>
<p><strong>registryBurst</strong>: 从镜像仓库拉取镜像的突发请求数。10 表示最多 10 个并发请求。</p>
<p><strong>registryPullQPS</strong>: 镜像拉取的每秒请求数。5 表示平均每秒 5 个请求。</p>
<p><strong>resolvConf</strong>: DNS 解析配置文件路径。&#x2F;etc&#x2F;resolv.conf 是系统默认值。</p>
<p><strong>rotateCertificates</strong>: 是否启用证书轮换。true 表示自动更新过期证书。</p>
<p><strong>runtimeRequestTimeout</strong>: 容器运行时请求超时时间。2m0s 表示 2 分钟。</p>
<p><strong>serializeImagePulls</strong>: 是否串行拉取镜像。true 表示一次拉取一个镜像，降低资源争用。</p>
<p><strong>staticPodPath</strong>: 静态 Pod 的清单目录。&#x2F;etc&#x2F;kubernetes&#x2F;manifests 用于存放静态 Pod 的 YAML 文件。</p>
<p><strong>streamingConnectionIdleTimeout</strong>: 流式连接（如 kubectl exec）的空闲超时。4h0m0s 表示 4 小时。</p>
<p><strong>syncFrequency</strong>: Pod 同步频率。1m0s 表示每分钟同步一次 Pod 状态。</p>
<p><strong>volumeStatsAggPeriod</strong>: 卷统计聚合周期。1m0s 表示每分钟收集一次卷使用数据。</p>
</blockquote>
<h3 id="2-3-同步文件到其它节点"><a href="#2-3-同步文件到其它节点" class="headerlink" title="2.3 同步文件到其它节点"></a>2.3 同步文件到其它节点</h3><pre><code class="highlight bash">user=root
host=(k8s-master02 k8s-master03 k8s-node01 k8s-node02)

<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$i</span>
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/kubelet.service <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/lib/systemd/system/;
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/kubelet-conf.yml <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/;
<span class="keyword">done</span></code></pre>



<h3 id="2-4-所有节点启动-kubelet"><a href="#2-4-所有节点启动-kubelet" class="headerlink" title="2.4 所有节点启动 kubelet"></a>2.4 所有节点启动 kubelet</h3><pre><code class="highlight bash">user=root
host=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)

<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>
  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>;
  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl enable --now kubelet&quot;</span>;
  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl status kubelet&quot;</span>;
<span class="keyword">done</span></code></pre>



<h3 id="2-5-测试"><a href="#2-5-测试" class="headerlink" title="2.5 测试"></a>2.5 测试</h3><pre><code class="highlight bash">[root@k8s-master01 ~]$ kubectl get nodes
NAME           STATUS     ROLES    AGE     VERSION
k8s-master01   NotReady   &lt;none&gt;   20m     v1.29.2
k8s-master02   NotReady   &lt;none&gt;   13m     v1.29.2
k8s-master03   NotReady   &lt;none&gt;   13m     v1.29.2
k8s-node01     NotReady   &lt;none&gt;   7m53s   v1.29.2
k8s-node02     NotReady   &lt;none&gt;   7m52s   v1.29.2</code></pre>





<h2 id="3-kube-proxy-配置（所有节点）"><a href="#3-kube-proxy-配置（所有节点）" class="headerlink" title="3. kube-proxy 配置（所有节点）"></a>3. kube-proxy 配置（所有节点）</h2><h3 id="3-1-同步-kube-proxy-kubeconfig"><a href="#3-1-同步-kube-proxy-kubeconfig" class="headerlink" title="3.1 同步 kube-proxy.kubeconfig"></a>3.1 同步 kube-proxy.kubeconfig</h3><p><strong>master01</strong></p>
<p>将 kube-proxy.kube.config 文件同步到其它所有节点</p>
<pre><code class="highlight bash">user=root
host=(k8s-master02 k8s-master03 k8s-node01 k8s-node02)

<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$i</span>
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/kube-proxy.kubeconfig <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/;
<span class="keyword">done</span></code></pre>



<h3 id="3-2-编辑-kube-proxy-service"><a href="#3-2-编辑-kube-proxy-service" class="headerlink" title="3.2 编辑 kube-proxy.service"></a>3.2 编辑 kube-proxy.service</h3><p><strong>Master01</strong></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-proxy.service &lt;&lt; <span class="string">EOF</span>
<span class="string">[Unit]</span>
<span class="string">Description=Kubernetes Kube Proxy</span>
<span class="string">Documentation=https://github.com/kubernetes/kubernetes</span>
<span class="string">After=network.target</span>
<span class="string"></span>
<span class="string">[Service]</span>
<span class="string">ExecStart=/usr/local/bin/kube-proxy \\</span>
<span class="string">  --config=/etc/kubernetes/kube-proxy.yaml \\</span>
<span class="string">  --cluster-cidr=172.16.0.0/12,fc00:2222::/112 \\</span>
<span class="string">  --v=2</span>
<span class="string">Restart=always</span>
<span class="string">RestartSec=10s</span>
<span class="string"></span>
<span class="string">[Install]</span>
<span class="string">WantedBy=multi-user.target</span>
<span class="string"></span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>kube-proxy是Kubernetes的核心组件之一，负责处理Service和Pod的网络代理（如负载均衡、NAT等），确保集群内的网络通信正常工作。</p>
<p>适用节点：所有Kubernetes节点（Master和Node），因为kube-proxy需要在每个节点上运行，以处理本地Pod的网络流量。</p>
<ul>
<li><p>ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kube-proxy</p>
<p>执行命令：指定服务的启动命令，即运行&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kube-proxy二进制文件</p>
</li>
<li><p>–config&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;kube-proxy.yaml</p>
<p>配置参数：指定kube-proxy的配置文件路径。这个YAML文件（教程中稍后定义）包含详细配置，如代理模式（IPVS）、绑定地址、连接跟踪等。使用配置文件可以分离配置，便于维护和统一所有节点。</p>
</li>
<li><p>–cluster-cidr&#x3D;172.16.0.0&#x2F;12,fc00:2222::&#x2F;112</p>
<p>172.16.0.0&#x2F;12：IPv4 Pod CIDR（私有地址段，范围从172.16.0.0到172.31.255.255，可容纳大量Pod）。</p>
<p>fc00:2222::&#x2F;112：IPv6 Pod CIDR（ULA私有地址，支持双栈网络）。</p>
</li>
</ul>
</blockquote>
<h3 id="3-3-编辑-kube-proxy-yaml"><a href="#3-3-编辑-kube-proxy-yaml" class="headerlink" title="3.3 编辑 kube-proxy.yaml"></a>3.3 编辑 kube-proxy.yaml</h3><p><strong>官方文档：</strong><a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/config-api/kube-proxy-config.v1alpha1/">https://kubernetes.io/zh-cn/docs/reference/config-api/kube-proxy-config.v1alpha1/</a></p>
<pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/kube-proxy.yaml &lt;&lt; <span class="string">EOF</span>
<span class="string">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span>
<span class="string">bindAddress: 0.0.0.0</span>
<span class="string">clientConnection:</span>
<span class="string">  acceptContentTypes: &quot;&quot;</span>
<span class="string">  burst: 10</span>
<span class="string">  contentType: application/vnd.kubernetes.protobuf</span>
<span class="string">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span>
<span class="string">  qps: 5</span>
<span class="string">clusterCIDR: 172.16.0.0/12,fc00:2222::/112</span>
<span class="string">configSyncPeriod: 15m0s</span>
<span class="string">conntrack:</span>
<span class="string">  max: null</span>
<span class="string">  maxPerCore: 32768</span>
<span class="string">  min: 131072</span>
<span class="string">  tcpCloseWaitTimeout: 1h0m0s</span>
<span class="string">  tcpEstablishedTimeout: 24h0m0s</span>
<span class="string">enableProfiling: false</span>
<span class="string">healthzBindAddress: 0.0.0.0:10256</span>
<span class="string">hostnameOverride: &quot;&quot;</span>
<span class="string">iptables:</span>
<span class="string">  masqueradeAll: false</span>
<span class="string">  masqueradeBit: 14</span>
<span class="string">  minSyncPeriod: 0s</span>
<span class="string">  syncPeriod: 30s</span>
<span class="string">ipvs:</span>
<span class="string">  masqueradeAll: true</span>
<span class="string">  minSyncPeriod: 5s</span>
<span class="string">  scheduler: &quot;rr&quot;</span>
<span class="string">  syncPeriod: 30s</span>
<span class="string">kind: KubeProxyConfiguration</span>
<span class="string">metricsBindAddress: 127.0.0.1:10249</span>
<span class="string">mode: &quot;ipvs&quot;</span>
<span class="string">nodePortAddresses: null</span>
<span class="string">oomScoreAdj: -999</span>
<span class="string">portRange: &quot;&quot;</span>
<span class="string">udpIdleTimeout: 250ms</span>
<span class="string">EOF</span></code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>kube-proxy 的配置文件，定义了 Kubernetes 集群中 kube-proxy 组件的行为。kube-proxy 运行在每个节点上，负责处理 Service 和 Pod 的网络代理（如负载均衡、NAT），支持 Kubernetes 的网络功能。</p>
<ul>
<li><p>apiVersion: kubeproxy.config.k8s.io&#x2F;v1alpha1</p>
<p>指定配置文件的 API 版本，告诉 Kubernetes 使用 kubeproxy.config.k8s.io&#x2F;v1alpha1 版本的 KubeProxyConfiguration 资源格式来解析此文件</p>
</li>
<li><p>bindAddress: 0.0.0.0</p>
<p>监听所有网络接口（IPv4 和 IPv6），允许 kube-proxy 接受来自任何网络接口的请求。0.0.0.0 确保 kube-proxy 能处理两种协议的流量</p>
</li>
<li><p>clientConnection: 定义 kube-proxy 与 Kubernetes API 服务器的通信参数</p>
<ul>
<li>acceptContentTypes: “” :指定 kube-proxy 接受的 API 响应内容类型,空字符串表示接受默认类型（通常由 contentType 定义）</li>
<li>burst: 10 允许的突发请求数（QPS 的上限）,控制 kube-proxy 向 API 服务器发送请求的速率</li>
<li>contentType: application&#x2F;vnd.kubernetes.protobuf   与 API 服务器通信时使用的内容类型,比 JSON（application&#x2F;json）更高效，减少网络带宽</li>
<li>kubeconfig: &#x2F;etc&#x2F;kubernetes&#x2F;kube-proxy.kubeconfig   访问 API 服务器的 kubeconfig 文件路径</li>
<li>qps: 5  每秒向 API 服务器发送的请求数,限制 kube-proxy 的 API 请求速率，qps: 5 表示每秒最多 5 个请求，配合 burst 控制突发</li>
</ul>
</li>
<li><p>clusterCIDR: 172.16.0.0&#x2F;12,fc00:2222::&#x2F;112  定义集群的 Pod IP 地址范围（Pod CIDR）,与 Calico 的 CALICO_IPV4POOL_CIDR 和 CALICO_IPV6POOL_CIDR 一致（calico.yaml 或 calico-ipv6.yaml）</p>
</li>
<li><p>configSyncPeriod: 15m0s   kube-proxy 同步配置的间隔时间,每 15 分钟，kube-proxy 从 API 服务器重新获取 Service 和 Endpoint 配置，更新本地代理规则</p>
</li>
<li><p>conntrack:  配置连接跟踪（Connection Tracking），用于 NAT 和负载均衡</p>
<ul>
<li>max: null  系统中连接跟踪表的最大条目数,null 表示使用系统默认值（通常由内核参数 net.nf_conntrack_max 决定）</li>
<li>maxPerCore: 32768  每个 CPU 核心的连接跟踪条目上限</li>
<li>min: 131072  连接跟踪表的最小条目数</li>
<li>tcpCloseWaitTimeout: 1h0m0s  TCP 连接在 CLOSE_WAIT 状态的超时时间,连接关闭后，等待 1 小时释放资源，防止短时间内频繁释放导致性能问题</li>
<li>tcpEstablishedTimeout: 24h0m0s  已建立的 TCP 连接的超时时间, 保持长连接（如数据库连接）24 小时，减少重新建立开销</li>
</ul>
</li>
<li><p>enableProfiling: false  是否启用 kube-proxy 的性能分析（profiling）,false 禁用 profiling，降低资源消耗</p>
</li>
<li><p>healthzBindAddress: 0.0.0.0:10256  健康检查监听地址和端口,kube-proxy 在 0.0.0.0:10256 提供 &#x2F;healthz 端点，供 kubelet 或外部工具检查状态</p>
</li>
<li><p>hostnameOverride: “”  覆盖 kube-proxy 报告的节点主机名,空字符串表示使用节点默认主机名（由 uname -n 或 kubelet 提供）</p>
</li>
<li><p>iptables:  配置 iptables 代理模式（尽管当前使用 IPVS，此配置仍保留）</p>
<ul>
<li>masqueradeAll: false  是否对所有出站流量执行 NAT 伪装（SNAT），false 表示仅对 Service 相关的流量执行 NAT，减少开销</li>
<li>masqueradeBit: 14   iptables 伪装时使用的标记位，默认值 14 用于标记 NAT 流量，防止冲突</li>
<li>minSyncPeriod: 0s  iptables 规则同步的最小间隔，0s 表示无最小间隔，允许快速同步</li>
<li>syncPeriod: 30s   iptables 规则同步的周期，每 30 秒同步 iptables 规则，确保与 API 服务器一致</li>
</ul>
</li>
<li><p>ipvs:  配置 IPVS 代理模式（本文明确使用 mode: “ipvs”）</p>
<ul>
<li>masqueradeAll: true  是否对所有出站流量执行 NAT 伪装。true 表示对所有 Pod 流量执行 SNAT，适合 IPVS 模式，确保外部访问（如 NodePort）正确。</li>
<li>minSyncPeriod: 5s  IPVS 规则同步的最小间隔。确保至少 5 秒同步一次，防止频繁更新导致性能问题。</li>
<li>scheduler: “rr”   IPVS 负载均衡调度算法。rr（Round Robin，轮询）平均分配 Service 流量到后端 Pod</li>
<li>syncPeriod: 30s  IPVS 规则同步周期。每 30 秒同步 IPVS 规则，确保与 API 服务器一致。</li>
</ul>
</li>
<li><p>kind: KubeProxyConfiguration  指定资源的类型，声明这是 kube-proxy 的配置文件</p>
</li>
<li><p>metricsBindAddress: 127.0.0.1:10249  指标（metrics）监听地址和端口，kube-proxy 在 127.0.0.1:10249 提供 Prometheus 格式的指标，供监控系统（如 Prometheus）采集</p>
</li>
<li><p>mode: “ipvs”  kube-proxy 的代理模式， ipvs 模式使用 Linux IPVS（IP Virtual Server）实现高效负载均衡。</p>
</li>
<li><p>nodePortAddresses: null  NodePort 服务的监听地址。null 表示监听所有接口（0.0.0.0）</p>
</li>
<li><p>oomScoreAdj: -999   调整 kube-proxy 进程的 OOM（Out of Memory）优先级，-999 降低被 OOM Killer 杀死的概率，优先级接近系统关键进程。</p>
</li>
<li><p>portRange: “”  分配 NodePort 的端口范围。空字符串使用默认范围（30000-32767）。</p>
</li>
<li><p>udpIdleTimeout: 250ms  UDP 连接的空闲超时时间。250 毫秒后关闭空闲 UDP 连接，释放资源。</p>
</li>
</ul>
</blockquote>
<h3 id="3-4-启动-kube-proxy"><a href="#3-4-启动-kube-proxy" class="headerlink" title="3.4 启动 kube-proxy"></a>3.4 启动 kube-proxy</h3><pre><code class="highlight bash">systemctl daemon-reload

systemctl <span class="built_in">enable</span> --now kube-proxy.service

systemctl status kube-proxy.service</code></pre>



<h3 id="3-5-同步-kube-proxy-到其它节点"><a href="#3-5-同步-kube-proxy-到其它节点" class="headerlink" title="3.5 同步 kube-proxy 到其它节点"></a>3.5 同步 kube-proxy 到其它节点</h3><pre><code class="highlight bash">user=root
host=(k8s-master02 k8s-master03 k8s-node01 k8s-node02)

<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$i</span>
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/kube-proxy.service <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/lib/systemd/system/;
  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/kube-proxy.yaml <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/;
  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>;
  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl enable --now kube-proxy.service&quot;</span>;
  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl status kube-proxy.service&quot;</span>;
<span class="keyword">done</span></code></pre>





<h1 id="八、安装-calico-网络插件"><a href="#八、安装-calico-网络插件" class="headerlink" title="八、安装 calico 网络插件"></a>八、安装 calico 网络插件</h1><h2 id="1-下载-calico-资源清单"><a href="#1-下载-calico-资源清单" class="headerlink" title="1. 下载 calico 资源清单"></a>1. 下载 calico 资源清单</h2><p><strong>Master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 创建calico目录，进入目录</span>
$ <span class="built_in">mkdir</span> -p /etc/calico/
$ <span class="built_in">cd</span> /etc/calico/

<span class="comment"># 下载calico资源清单</span>
wget https://raw.githubusercontent.com/projectcalico/calico/refs/tags/v3.28.0/manifests/calico-typha.yaml</code></pre>



<h2 id="2-编辑-calico-资源清单-IPV4"><a href="#2-编辑-calico-资源清单-IPV4" class="headerlink" title="2. 编辑 calico 资源清单-IPV4"></a>2. 编辑 calico 资源清单-IPV4</h2><p><strong>Master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 复制资源清单，用于IPV4网络</span>
$ <span class="built_in">cp</span> /etc/calico/calico-typha.yaml /etc/calico/calico.yaml


<span class="comment"># IPV4环境</span>
vim calico.yaml
<span class="comment"># calico-config ConfigMap处</span>
<span class="string">&quot;ipam&quot;</span>: &#123;
    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;calico-ipam&quot;</span>,
&#125;,
- name: IP
  value: <span class="string">&quot;autodetect&quot;</span>

- name: CALICO_IPV4POOL_CIDR
  value: <span class="string">&quot;172.16.0.0/12&quot;</span></code></pre>



<h2 id="3-编辑-calico-资源清单-IPV6"><a href="#3-编辑-calico-资源清单-IPV6" class="headerlink" title="3. 编辑 calico 资源清单-IPV6"></a>3. 编辑 calico 资源清单-IPV6</h2><p><strong>Master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 复制资源清单，用于IPV4网络</span>
$ <span class="built_in">cp</span> /etc/calico/calico-typha.yaml /etc/calico/calico-ipv6.yaml


<span class="comment"># IPV6环境</span>
vim calico-ipv6.yaml
<span class="comment"># calico-config ConfigMap处</span>
    <span class="string">&quot;ipam&quot;</span>: &#123;
        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;calico-ipam&quot;</span>,
        <span class="string">&quot;assign_ipv4&quot;</span>: <span class="string">&quot;true&quot;</span>,
        <span class="string">&quot;assign_ipv6&quot;</span>: <span class="string">&quot;true&quot;</span>
    &#125;,
    - name: IP
      value: <span class="string">&quot;autodetect&quot;</span>

    - name: IP6
      value: <span class="string">&quot;autodetect&quot;</span>

    - name: CALICO_IPV4POOL_CIDR
      value: <span class="string">&quot;172.16.0.0/12&quot;</span>

    - name: CALICO_IPV6POOL_CIDR
      value: <span class="string">&quot;fc00:2222::/112&quot;</span>

    - name: FELIX_IPV6SUPPORT
      value: <span class="string">&quot;true&quot;</span></code></pre>



<h2 id="4-执行-calico-资源清单"><a href="#4-执行-calico-资源清单" class="headerlink" title="4. 执行 calico 资源清单"></a>4. 执行 calico 资源清单</h2><pre><code class="highlight bash"><span class="comment"># 本地没有公网 IPv6 使用 calico.yaml（在master01节点执行即可）</span>
kubectl apply -f calico.yaml

<span class="comment"># 本地有公网 IPv6 使用 calico-ipv6.yaml </span>
<span class="comment"># kubectl apply -f calico-ipv6.yaml </span>

<span class="comment"># 查看结果：</span>
[root@k8s-master01 ~]$ kubectl get pods -n kube-system -o wide
NAME                                      READY   STATUS    RESTARTS        AGE     IP              NODE           NOMINATED NODE   READINESS GATES
calico-kube-controllers-8d76c5f9b-485zp   1/1     Running   2 (3m35s ago)   5m31s   172.27.14.192   k8s-node02     &lt;none&gt;           &lt;none&gt;
calico-node-d6plz                         1/1     Running   1 (3m52s ago)   5m31s   10.20.1.104     k8s-node01     &lt;none&gt;           &lt;none&gt;
calico-node-w6fvl                         1/1     Running   0               5m32s   10.20.1.103     k8s-master03   &lt;none&gt;           &lt;none&gt;
calico-node-z7zs2                         1/1     Running   0               5m32s   10.20.1.101     k8s-master01   &lt;none&gt;           &lt;none&gt;
calico-node-z8v77                         1/1     Running   1 (3m43s ago)   5m32s   10.20.1.102     k8s-master02   &lt;none&gt;           &lt;none&gt;
calico-node-zb9bv                         1/1     Running   1 (4m14s ago)   5m31s   10.20.1.105     k8s-node02     &lt;none&gt;           &lt;none&gt;
calico-typha-7cdb5b98f7-d47gx             1/1     Running   0               5m31s   10.20.1.104     k8s-node01     &lt;none&gt;           &lt;none&gt;</code></pre>

<p><strong>注意：</strong>执行资源清单会自动下载 calico 需要的镜像，这些镜像基本都在国外，下载会很慢，甚至下载不下来。</p>
<p><strong>解决办法1：</strong>使用国内仓库</p>
<pre><code class="highlight bash"><span class="comment"># 若docker镜像拉不下来，可以使用国内的仓库</span>
sed -i <span class="string">&quot;s#docker.io/calico/#m.daocloud.io/docker.io/calico/#g&quot;</span> calico.yaml 
sed -i <span class="string">&quot;s#docker.io/calico/#m.daocloud.io/docker.io/calico/#g&quot;</span> calico-ipv6.yaml

sed -i <span class="string">&quot;s#m.daocloud.io/docker.io/calico/#docker.io/calico/#g&quot;</span> calico.yaml 
sed -i <span class="string">&quot;s#m.daocloud.io/docker.io/calico/#docker.io/calico/#g&quot;</span> calico-ipv6.yaml</code></pre>



<p><strong>解决方法2：</strong>使用代理下载</p>
<p>参考：<a href="https://georgechan95.github.io/blog/b01d5c62.html">https://georgechan95.github.io/blog/b01d5c62.html</a></p>
<pre><code class="highlight bash"><span class="comment"># 下载镜像</span>
docker pull docker.io/calico/cni:v3.28.0
docker pull docker.io/calico/node:v3.28.0
docker pull docker.io/calico/kube-controllers:v3.28.0
docker pull docker.io/calico/typha:v3.28.0

<span class="comment"># 打包</span>
docker save docker.io/calico/cni:v3.28.0 -o cni-v3.28.0.tar
docker save docker.io/calico/node:v3.28.0 -o node-v3.28.0.tar
docker save docker.io/calico/kube-controllers:v3.28.0 -o kube-controllers-v3.28.0.tar
docker save docker.io/calico/typha:v3.28.0 -o typha-v3.28.0.tar

<span class="comment"># 同步到其它节点</span>
user=root
host=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)

<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>
  <span class="built_in">echo</span> <span class="variable">$i</span>
  rsync -av /opt/software/hak8s/images root@<span class="variable">$i</span>:/opt/software/
  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;docker load -i /opt/software/images/calico/cni-v3.28.0.tar&quot;</span>;
  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;docker load -i /opt/software/images/calico/node-v3.28.0.tar&quot;</span>;
  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;docker load -i /opt/software/images/calico/kube-controllers-v3.28.0.tar&quot;</span>;
  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;docker load -i /opt/software/images/calico/typha-v3.28.0.tar&quot;</span>;
<span class="keyword">done</span></code></pre>





<h1 id="九、安装-Core-DNS"><a href="#九、安装-Core-DNS" class="headerlink" title="九、安装 Core DNS"></a>九、安装 Core DNS</h1><p><strong>Helm安装脚本：</strong> <a target="_blank" rel="noopener" href="https://github.com/helm/helm/blob/main/scripts/get-helm-3">https://github.com/helm/helm/blob/main/scripts/get-helm-3</a></p>
<h2 id="1-安装Helm（仅master01）"><a href="#1-安装Helm（仅master01）" class="headerlink" title="1. 安装Helm（仅master01）"></a>1. 安装Helm（仅master01）</h2><p>参考：<a href="https://georgechan95.github.io/blog/d8e3c7b3.html">https://georgechan95.github.io/blog/d8e3c7b3.html</a></p>
<pre><code class="highlight bash"><span class="comment"># 下载 helm 二进制包</span>
$ wget https://get.helm.sh/helm-v3.14.3-linux-amd64.tar.gz

<span class="comment"># 解压</span>
$ tar -zxvf helm-v3.14.3-linux-amd64.tar.gz

<span class="comment"># 安装到bin目录</span>
$ <span class="built_in">mv</span> linux-amd64/helm /usr/local/bin/helm

<span class="comment"># 查看helm版本</span>
$ helm version
version.BuildInfo&#123;Version:<span class="string">&quot;v3.14.3&quot;</span>, GitCommit:<span class="string">&quot;f03cc04caaa8f6d7c3e67cf918929150cf6f3f12&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, GoVersion:<span class="string">&quot;go1.21.7&quot;</span>&#125;</code></pre>



<h2 id="2-安装-CoreDns"><a href="#2-安装-CoreDns" class="headerlink" title="2. 安装 CoreDns"></a>2. 安装 CoreDns</h2><h3 id="2-1-下载-CoreDns-安装包"><a href="#2-1-下载-CoreDns-安装包" class="headerlink" title="2.1 下载 CoreDns 安装包"></a>2.1 下载 CoreDns 安装包</h3><pre><code class="highlight bash"><span class="comment"># 添加 coredns 仓库</span>
helm repo add coredns https://coredns.github.io/helm
<span class="comment"># 查看仓库 coredns 版本</span>
helm search repo coredns --versions
<span class="comment"># 拉取指定版本的 coredns</span>
helm pull coredns/coredns --version 1.45.0
<span class="comment"># 解压</span>
tar -zxvf /opt/software/coredns-1.45.0.tgz -C /opt/module/</code></pre>



<h3 id="2-2-编辑配置文件"><a href="#2-2-编辑配置文件" class="headerlink" title="2.2 编辑配置文件"></a>2.2 编辑配置文件</h3><pre><code class="highlight bash"><span class="comment"># 修改IP</span>
$ <span class="built_in">cat</span> values.yaml | grep clusterIP: -A 13
  clusterIP: <span class="string">&quot;10.96.0.10&quot;</span>
<span class="comment"># clusterIPs: []</span>
<span class="comment"># loadBalancerIP: &quot;&quot;</span>
<span class="comment"># loadBalancerClass: &quot;&quot;</span>
<span class="comment"># externalIPs: []</span>
<span class="comment"># externalTrafficPolicy: &quot;&quot;</span>
<span class="comment"># ipFamilyPolicy: &quot;&quot;</span>
<span class="comment"># trafficDistribution: PreferClose</span>
  <span class="comment"># The name of the Service</span>
  <span class="comment"># If not set, a name is generated using the fullname template</span>
  name: <span class="string">&quot;&quot;</span>
  annotations: &#123;&#125;
  <span class="comment"># Pod selector</span>
  selector: &#123;&#125;</code></pre>



<h3 id="2-3-安装-CoreDns"><a href="#2-3-安装-CoreDns" class="headerlink" title="2.3 安装 CoreDns"></a>2.3 安装 CoreDns</h3><p><strong>master01</strong></p>
<pre><code class="highlight bash">$ helm install coredns /opt/module/coredns/ -n kube-system
NAME: coredns
LAST DEPLOYED: Fri Oct 24 13:47:48 2025
NAMESPACE: kube-system
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
CoreDNS is now running <span class="keyword">in</span> the cluster as a cluster-service.

It can be tested with the following:

1. Launch a Pod with DNS tools:

kubectl run -it --<span class="built_in">rm</span> --restart=Never --image=infoblox/dnstools:latest dnstools

2. Query the DNS server:

/ <span class="comment"># host kubernetes</span></code></pre>

<blockquote>
<p><strong>注意事项：</strong></p>
<p>安装 coredns 会自动从外网下载镜像，这里可能会失败。</p>
<p>方式一：</p>
<pre><code class="highlight plaintext"># 修改为国内源 docker源可选
sed -i &quot;s#coredns/#m.daocloud.io/docker.io/coredns/#g&quot; values.yaml
sed -i &quot;s#registry.k8s.io/#m.daocloud.io/registry.k8s.io/#g&quot; values.yaml</code></pre>

<p>方式二：代理服务器下载</p>
<pre><code class="highlight plaintext"># 下载
docker pull coredns/coredns:1.13.1
docker pull registry.k8s.io/cpa/cluster-proportional-autoscaler:v1.9.0
# 打包
docker save coredns/coredns:1.13.1 -o coredns-1.13.1.tar
docker save registry.k8s.io/cpa/cluster-proportional-autoscaler:v1.9.0 -o cluster-proportional-autoscaler-v1.9.0.tar

# 发送到集群解压
user=root
host=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)

for i in $&#123;host[@]&#125;; do
  echo $i
  rsync -av /opt/software/hak8s/images root@$i:/opt/software/
  ssh $user@$i &quot;docker load -i /opt/software/images/coredns/coredns-1.13.1.tar&quot;;
  ssh $user@$i &quot;docker load -i /opt/software/images/coredns/cluster-proportional-autoscaler-v1.9.0.tar&quot;;
done</code></pre>
</blockquote>
<p><strong>验证 CoreDns</strong></p>
<pre><code class="highlight bash">$ kubectl get pods -n kube-system -o wide | grep coredns
coredns-68746bb699-4mrxl                  1/1     Running   0             11m   172.25.244.193   k8s-master01   &lt;none&gt;           &lt;none&gt;

$ kubectl get nodes
NAME           STATUS   ROLES    AGE   VERSION
k8s-master01   Ready    &lt;none&gt;   41h   v1.29.2
k8s-master02   Ready    &lt;none&gt;   41h   v1.29.2
k8s-master03   Ready    &lt;none&gt;   41h   v1.29.2
k8s-node01     Ready    &lt;none&gt;   41h   v1.29.2
k8s-node02     Ready    &lt;none&gt;   41h   v1.29.2</code></pre>





<h1 id="十、安装-Metrics-Server"><a href="#十、安装-Metrics-Server" class="headerlink" title="十、安装 Metrics Server"></a>十、安装 Metrics Server</h1><p>官方文档：<a target="_blank" rel="noopener" href="https://github.com/kubernetes-sigs/metrics-server/releases/tag/v0.7.1">https://github.com/kubernetes-sigs/metrics-server/releases/tag/v0.7.1</a></p>
<h2 id="1-下载-metrics-server-资源清单"><a href="#1-下载-metrics-server-资源清单" class="headerlink" title="1. 下载 metrics-server 资源清单"></a>1. 下载 metrics-server 资源清单</h2><p><strong>master01</strong></p>
<pre><code class="highlight bash"><span class="comment"># 创建文件夹</span>
<span class="built_in">mkdir</span> -p /opt/module/metrics-server
<span class="built_in">cd</span> /opt/module/metrics-server

<span class="comment"># 下载资源清单</span>
wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.7.1/components.yaml</code></pre>



<h2 id="2-编辑-components-yaml"><a href="#2-编辑-components-yaml" class="headerlink" title="2. 编辑 components.yaml"></a>2. 编辑 components.yaml</h2><pre><code class="highlight bash"><span class="comment"># 修改配置</span>
vim components.yaml

---
<span class="comment"># 1</span>
			- args:
        - --cert-dir=/tmp
        - --secure-port=10250
        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        - --kubelet-use-node-status-port
        - --metric-resolution=15s
        - --kubelet-insecure-tls
        - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem
        - --requestheader-username-headers=X-Remote-User
        - --requestheader-group-headers=X-Remote-Group
        - --requestheader-extra-headers-prefix=X-Remote-Extra-


<span class="comment"># 2</span>
        volumeMounts:
        - mountPath: /tmp
          name: tmp-dir
        - name: ca-ssl
          mountPath: /etc/kubernetes/pki

<span class="comment"># 3</span>
      volumes:
      - emptyDir: &#123;&#125;
        name: tmp-dir
      - name: ca-ssl
        hostPath:
          path: /etc/kubernetes/pki
---</code></pre>



<h2 id="3-部署-metrics-server"><a href="#3-部署-metrics-server" class="headerlink" title="3. 部署 metrics-server"></a>3. 部署 metrics-server</h2><pre><code class="highlight bash">$ kubectl apply -f /opt/module/metrics-server/components.yaml</code></pre>

<blockquote>
<p><strong>注意事项：</strong></p>
<p>安装 metrics-server 会自动从外网下载镜像，这里可能会失败。</p>
<p>方式一：</p>
<pre><code class="highlight plaintext"># 修改为国内源 docker源可选
sed -i &quot;s#registry.k8s.io/#m.daocloud.io/registry.k8s.io/#g&quot; *.yaml</code></pre>

<p>方式二：代理服务器下载</p>
<pre><code class="highlight plaintext"># 下载
docker pull registry.k8s.io/metrics-server/metrics-server:v0.7.1

# 打包
docker save registry.k8s.io/metrics-server/metrics-server:v0.7.1 -o metrics-server-v0.7.1.tar

# 发送到集群解压
user=root
host=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)

for i in $&#123;host[@]&#125;; do
  echo $i
  rsync -av /opt/software/hak8s/images root@$i:/opt/software/
  ssh $user@$i &quot;docker load -i /opt/software/images/metrics-server/metrics-server-v0.7.1.tar&quot;;
done</code></pre>
</blockquote>
<p><strong>验证部署</strong></p>
<pre><code class="highlight bash">$ kubectl get pods -n kube-system | grep metrics-server
metrics-server-6d4cb7955c-688pj           1/1     Running   0             2m10s

$ kubectl  top node
NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
k8s-master01   77m          3%     2168Mi          61%       
k8s-master02   101m         5%     1499Mi          42%       
k8s-master03   114m         5%     1594Mi          44%       
k8s-node01     46m          2%     960Mi           27%       
k8s-node02     48m          2%     924Mi           26%</code></pre>





<h1 id="十一、安装Dashboard"><a href="#十一、安装Dashboard" class="headerlink" title="十一、安装Dashboard"></a>十一、安装Dashboard</h1><p><strong>仅在 master01 操作</strong></p>
<h2 id="1-下载并执行-dashboard-资源清单"><a href="#1-下载并执行-dashboard-资源清单" class="headerlink" title="1. 下载并执行 dashboard 资源清单"></a>1. 下载并执行 dashboard 资源清单</h2><pre><code class="highlight bash"><span class="comment"># 下载资源清单</span>
wget https://raw.githubusercontent.com/kubernetes/dashboard/refs/tags/v2.7.0/aio/deploy/recommended.yaml


<span class="comment"># 修改镜像拉取策略</span>
$ vim /opt/module/dashboard/recommended.yaml
imagePullPolicy: IfNotPresent

<span class="comment"># 执行资源清单</span>
$ kubectl apply -f /opt/module/dashboard/recommended.yaml

<span class="comment"># 查看 Pod</span>
$ kubectl get pod -n kubernetes-dashboard -o wide
NAME                                         READY   STATUS    RESTARTS   AGE   IP             NODE           NOMINATED NODE   READINESS GATES
dashboard-metrics-scraper-5657497c4c-v5jlt   1/1     Running   0          36s   172.18.195.2   k8s-master03   &lt;none&gt;           &lt;none&gt;
kubernetes-dashboard-5b749d9495-ns6q2        1/1     Running   0          43s   172.25.92.71   k8s-master02   &lt;none&gt;           &lt;none&gt;</code></pre>

<blockquote>
<p>命令解析：</p>
<p>需提前下载好镜像文件</p>
<pre><code class="highlight plaintext">docker pull kubernetesui/dashboard:v2.7.0
docker pull kubernetesui/metrics-scraper:v1.0.8

docker save kubernetesui/dashboard:v2.7.0 -o dashboard-v2.7.0.tar
docker save kubernetesui/metrics-scraper:v1.0.8 -o metrics-scraper-v1.0.8.tar

user=root
host=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)

for i in $&#123;host[@]&#125;; do
  echo $i
  rsync -av /opt/software/hak8s/images root@$i:/opt/software/
  ssh $user@$i &quot;docker load -i /opt/software/images/dashboard/dashboard-v2.7.0.tar&quot;;
  ssh $user@$i &quot;docker load -i /opt/software/images/dashboard/metrics-scraper-v1.0.8.tar&quot;;
done</code></pre>
</blockquote>
<h2 id="2-创建-ServiceAccount"><a href="#2-创建-ServiceAccount" class="headerlink" title="2. 创建 ServiceAccount"></a>2. 创建 ServiceAccount</h2><pre><code class="highlight bash"><span class="built_in">mkdir</span> -p /opt/module/dashboard/

<span class="comment"># 创建 ServiceAccount</span>
<span class="built_in">cat</span> &gt; /opt/module/dashboard/dashboard-user.yaml &lt;&lt; <span class="string">EOF</span>
<span class="string">apiVersion: v1</span>
<span class="string">kind: ServiceAccount</span>
<span class="string">metadata:</span>
<span class="string">  name: admin-user</span>
<span class="string">  namespace: kubernetes-dashboard</span>
<span class="string">---</span>
<span class="string">apiVersion: rbac.authorization.k8s.io/v1</span>
<span class="string">kind: ClusterRoleBinding</span>
<span class="string">metadata:</span>
<span class="string">  name: admin-user</span>
<span class="string">roleRef:</span>
<span class="string">  apiGroup: rbac.authorization.k8s.io</span>
<span class="string">  kind: ClusterRole</span>
<span class="string">  name: cluster-admin</span>
<span class="string">subjects:</span>
<span class="string">- kind: ServiceAccount</span>
<span class="string">  name: admin-user</span>
<span class="string">  namespace: kubernetes-dashboard</span>
<span class="string">EOF</span>

<span class="comment"># 执行资源清单，创建SA</span>
kubectl apply -f /opt/module/dashboard/dashboard-user.yaml

<span class="comment"># 验证</span>
$ kubectl get serviceaccount -A | grep admin-user
kubernetes-dashboard   admin-user                             0         57s</code></pre>

<blockquote>
<p><strong>命令解析：</strong></p>
<p>在 Kubernetes 集群中为 Dashboard 创建一个具有管理员权限的 ServiceAccount（服务账户），并通过 ClusterRoleBinding（集群角色绑定）授予其全集群管理权限（cluster-admin）。这是为了方便通过 Token 方式登录 Dashboard 进行集群管理，而非使用默认的有限权限账户。整个过程是标准的 Kubernetes RBAC（基于角色的访问控制）配置，适用于二进制部署的集群。</p>
</blockquote>
<h2 id="3-更改-dashboard-的-svc-为-NodePort"><a href="#3-更改-dashboard-的-svc-为-NodePort" class="headerlink" title="3. 更改 dashboard 的 svc 为 NodePort"></a>3. 更改 dashboard 的 svc 为 NodePort</h2><pre><code class="highlight bash">$ kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard

...
  sessionAffinity: None
  <span class="built_in">type</span>: NodePort <span class="comment"># 将Cluster为NodePort</span>
status:
  loadBalancer: &#123;&#125;
  

<span class="comment"># 保存后，验证</span>
$ kubectl get svc kubernetes-dashboard -n kubernetes-dashboard -o wide
NAME                   TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE   SELECTOR
kubernetes-dashboard   NodePort   10.101.243.82   &lt;none&gt;        443:30892/TCP   91s   k8s-app=kubernetes-dashboard</code></pre>





<h2 id="4-创建-token-访问"><a href="#4-创建-token-访问" class="headerlink" title="4. 创建 token 访问"></a>4. 创建 token 访问</h2><pre><code class="highlight bash">$ kubectl -n kubernetes-dashboard create token admin-user
eyJhbGciOiJSUzI1NiIsImtpZCI6IjVRcWNxMUt1ZzZsN3RoeTBHUzd4VzFGbktIZDBIZUNJazllQVFqdy1aSTgifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNzYxNjU5MTM1LCJpYXQiOjE3NjE2NTU1MzUsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJhZG1pbi11c2VyIiwidWlkIjoiY2ZiNTA5MmYtMGY0My00OTllLTg1MzItOTM0YTljMDY0YTJmIn19LCJuYmYiOjE3NjE2NTU1MzUsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDphZG1pbi11c2VyIn0.oHvY4JRIRoNXr_DK2wnIWEo-yQ6KLAXL4kuAxVfY-BfU6o_kI90MzG1N9t8t4HAplzXQcg_v-m4RsMyu63dy96h49WVj6Zp6WbmI2bUmeg7VgBmm43BReO-lKPdWfqUxEJ2Yt2fLSl4CbNuLyKgNxOUtJT_RDz1l_OBgFx23uNs7QrJ42miuJnkgDSXnS0_2VCyLbGYALSgWSZKXeWdjQUL-k40GghOj5I2-HEGld0j9fcl0ASiFEOuNWstP0PKZoO1qPJNrsVtqHM5PiNbhHzU6b60-sJO9keJY8K0ORdNjbTt857I3NIiAklBXsJY4dT8BOaesefa7TvBMHSFgNQ</code></pre>

<p>复制生成的token: eyJhbGciOiJSU…..</p>
<p>浏览器访问宿主机地址：<a target="_blank" rel="noopener" href="https://10.20.1.101:30892/#/login">https://10.20.1.101:30892/#/login</a></p>
<p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/28/20251028-204641.png" alt="登录 DashBoard"></p>
<p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/28/20251028-204754.png" alt="查看Pod"></p>
<h1 id="十二、安装命令补全"><a href="#十二、安装命令补全" class="headerlink" title="十二、安装命令补全"></a>十二、安装命令补全</h1><p><strong>所有节点</strong></p>
<pre><code class="highlight bash">yum install bash-completion -y
<span class="built_in">source</span> /usr/share/bash-completion/bash_completion
<span class="built_in">source</span> &lt;(kubectl completion bash)
<span class="built_in">echo</span> <span class="string">&quot;source &lt;(kubectl completion bash)&quot;</span> &gt;&gt; ~/.bashrc</code></pre>





<h1 id="十三、高可用验证"><a href="#十三、高可用验证" class="headerlink" title="十三、高可用验证"></a>十三、高可用验证</h1><h2 id="1-组件状态验证"><a href="#1-组件状态验证" class="headerlink" title="1. 组件状态验证"></a>1. 组件状态验证</h2><p><strong>验证ETCD状态</strong></p>
<pre><code class="highlight bash"><span class="comment"># 确认 etcd 高可用</span>
$ etcdctl --endpoints=<span class="string">&quot;10.20.1.101:2379,10.20.1.102:2379,10.20.1.103:2379&quot;</span> --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem --cert=/etc/kubernetes/pki/etcd/etcd.pem --key=/etc/kubernetes/pki/etcd/etcd-key.pem  endpoint status --write-out=table

+------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
|     ENDPOINT     |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |
+------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
| 10.20.1.101:2379 | adb2616df23a8bc4 |  3.5.16 |  7.0 MB |     <span class="literal">false</span> |      <span class="literal">false</span> |        39 |    1893807 |            1893807 |        |
| 10.20.1.102:2379 | 4039909ce7f85a53 |  3.5.16 |  7.0 MB |     <span class="literal">false</span> |      <span class="literal">false</span> |        39 |    1893807 |            1893807 |        |
| 10.20.1.103:2379 | eee0233fd4f83d74 |  3.5.16 |  6.7 MB |      <span class="literal">true</span> |      <span class="literal">false</span> |        39 |    1893807 |            1893807 |        |
+------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</code></pre>



<p><strong>集群健康状态</strong></p>
<pre><code class="highlight bash">[root@k8s-master01 ~]$ kubectl get cs
Warning: v1 ComponentStatus is deprecated <span class="keyword">in</span> v1.19+
NAME                 STATUS    MESSAGE   ERROR
scheduler            Healthy   ok        
controller-manager   Healthy   ok        
etcd-0               Healthy   ok


[root@k8s-master01 ~]$ kubectl get nodes
NAME           STATUS   ROLES    AGE   VERSION
k8s-master01   Ready    &lt;none&gt;   6d    v1.29.2
k8s-master02   Ready    &lt;none&gt;   6d    v1.29.2
k8s-master03   Ready    &lt;none&gt;   6d    v1.29.2
k8s-node01     Ready    &lt;none&gt;   6d    v1.29.2
k8s-node02     Ready    &lt;none&gt;   6d    v1.29.2</code></pre>



<h2 id="2-使用-dnstools-测试"><a href="#2-使用-dnstools-测试" class="headerlink" title="2. 使用 dnstools 测试"></a>2. 使用 dnstools 测试</h2><pre><code class="highlight bash">$ kubectl run -it --<span class="built_in">rm</span> --restart=Never --image=infoblox/dnstools:v3 dnstools

dnstools<span class="comment"># host kubernetes</span>
kubernetes.default.svc.cluster.local has address 10.96.0.1

dnstools<span class="comment"># dig kubernetes.default.svc.cluster.local</span>
; &lt;&lt;&gt;&gt; DiG 9.11.3 &lt;&lt;&gt;&gt; kubernetes.default.svc.cluster.local
;; global options: +cmd
;; Got answer:
;; WARNING: .<span class="built_in">local</span> is reserved <span class="keyword">for</span> Multicast DNS
;; You are currently testing what happens when an mDNS query is leaked to DNS
;; -&gt;&gt;HEADER&lt;&lt;- <span class="string">opcode: QUERY, status: NOERROR, id: 45690</span>
<span class="string">;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1</span>
<span class="string">;; WARNING: recursion requested but not available</span>
<span class="string"></span>
<span class="string">;; OPT PSEUDOSECTION:</span>
<span class="string">; EDNS: version: 0, flags:; udp: 4096</span>
<span class="string">; COOKIE: 39b672283592d58b (echoed)</span>
<span class="string">;; QUESTION SECTION:</span>
<span class="string">;kubernetes.default.svc.cluster.local. IN A</span>
<span class="string"></span>
<span class="string">;; ANSWER SECTION:</span>
<span class="string">kubernetes.default.svc.cluster.local. 20 IN A	10.96.0.1</span>
<span class="string"></span>
<span class="string">;; Query time: 0 msec</span>
<span class="string">;; SERVER: 10.96.0.10#53(10.96.0.10)</span>
<span class="string">;; WHEN: Thu Oct 30 06:56:34 UTC 2025</span>
<span class="string">;; MSG SIZE  rcvd: 129</span></code></pre>



<h2 id="3-Nginx-部署测试"><a href="#3-Nginx-部署测试" class="headerlink" title="3. Nginx 部署测试"></a>3. Nginx 部署测试</h2><p><strong>资源清单：</strong> nginx-test.yaml</p>
<pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span>
<span class="attr">kind:</span> <span class="string">Deployment</span>
<span class="attr">metadata:</span>
  <span class="attr">name:</span> <span class="string">nginx</span>
<span class="attr">spec:</span>
  <span class="attr">replicas:</span> <span class="number">3</span>
  <span class="attr">selector:</span>
    <span class="attr">matchLabels:</span>
      <span class="attr">app:</span> <span class="string">myapp</span>
  <span class="attr">template:</span>
    <span class="attr">metadata:</span>
      <span class="attr">labels:</span>
        <span class="attr">app:</span> <span class="string">myapp</span>
    <span class="attr">spec:</span>
      <span class="attr">containers:</span>
        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>
          <span class="attr">image:</span> <span class="string">nginx:1.29.3</span>
          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>
          <span class="attr">ports:</span>
            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>

<span class="meta">---</span>
<span class="meta"></span>
<span class="attr">apiVersion:</span> <span class="string">v1</span>
<span class="attr">kind:</span> <span class="string">Service</span>
<span class="attr">metadata:</span>
  <span class="attr">name:</span> <span class="string">nginx-svc</span>
  <span class="attr">namespace:</span> <span class="string">default</span>
<span class="attr">spec:</span>
  <span class="attr">ports:</span>
    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>
      <span class="attr">targetPort:</span> <span class="number">80</span>    <span class="comment"># 修正：必须是 Pod 实际监听的端口号</span>
      <span class="attr">protocol:</span> <span class="string">TCP</span>
      <span class="attr">nodePort:</span> <span class="number">30339</span>
  <span class="attr">selector:</span>
    <span class="attr">app:</span> <span class="string">myapp</span></code></pre>



<p><strong>执行资源清单：</strong></p>
<pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>
$ kubectl apply -f nginx-test.yaml

<span class="comment"># 查看 Service</span>
$ kubectl get svc 
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
kubernetes   ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP        8d
nginx-svc    NodePort    10.98.200.91   &lt;none&gt;        80:30339/TCP   3h21m

<span class="comment"># 查看 Deployment</span>
$ kubectl get deploy -o wide
NAME    READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES         SELECTOR
nginx   3/3     3            3           3h21m   nginx        nginx:1.29.3   app=myapp

<span class="comment"># 查看Pod</span>
$ kubectl get pods -o wide
NAME                    READY   STATUS    RESTARTS      AGE     IP               NODE           NOMINATED NODE   READINESS GATES
busybox                 1/1     Running   3 (17m ago)   3h18m   172.25.92.67     k8s-master02   &lt;none&gt;           &lt;none&gt;
nginx-6594975dd-fds78   1/1     Running   0             3h21m   172.18.195.2     k8s-master03   &lt;none&gt;           &lt;none&gt;
nginx-6594975dd-pvkt8   1/1     Running   0             3h21m   172.27.14.193    k8s-node02     &lt;none&gt;           &lt;none&gt;
nginx-6594975dd-v96mx   1/1     Running   0             3h21m   172.25.244.199   k8s-master01   &lt;none&gt;           &lt;none&gt;
ubuntu-test             1/1     Running   0             8m54s   172.25.244.204   k8s-master01   &lt;none&gt;           &lt;none&gt;</code></pre>



<p><strong>网络测试</strong></p>
<pre><code class="highlight bash">$ kubectl <span class="built_in">exec</span> -it nginx-6594975dd-fds78 -- /bin/bash
root@nginx-6594975dd-fds78:/<span class="comment"># curl -k https://10.96.0.1:443</span>
&#123;
  <span class="string">&quot;kind&quot;</span>: <span class="string">&quot;Status&quot;</span>,
  <span class="string">&quot;apiVersion&quot;</span>: <span class="string">&quot;v1&quot;</span>,
  <span class="string">&quot;metadata&quot;</span>: &#123;&#125;,
  <span class="string">&quot;status&quot;</span>: <span class="string">&quot;Failure&quot;</span>,
  <span class="string">&quot;message&quot;</span>: <span class="string">&quot;forbidden: User \&quot;system:anonymous\&quot; cannot get path \&quot;/\&quot;&quot;</span>,
  <span class="string">&quot;reason&quot;</span>: <span class="string">&quot;Forbidden&quot;</span>,
  <span class="string">&quot;details&quot;</span>: &#123;&#125;,
  <span class="string">&quot;code&quot;</span>: 403
&#125;</code></pre>

<blockquote>
<p>说明：</p>
<ul>
<li>Pod 网络到 <strong>Kubernetes API Server</strong> 是通的。</li>
<li>返回 403 而不是超时或连接失败，说明请求已经到达 API Server。</li>
<li>403 的原因是你没有提供认证信息（anonymous user），这是正常的，如果只是测试网络，不需要担心。</li>
</ul>
</blockquote>
<h2 id="4-Ubuntu-镜像部署测试"><a href="#4-Ubuntu-镜像部署测试" class="headerlink" title="4. Ubuntu 镜像部署测试"></a>4. Ubuntu 镜像部署测试</h2><h3 id="3-1-部署-NetworkPolicy"><a href="#3-1-部署-NetworkPolicy" class="headerlink" title="3.1 部署 NetworkPolicy"></a>3.1 部署 NetworkPolicy</h3><p>默认 Kubernates 集群 Pod 不能直连外网，需要网络策略允许，这里部署一个 NetworkPolicy 让Pod 可以访问外网</p>
<p><strong>网络策略资源清单：</strong> <code>NetworkPolicy.yaml</code></p>
<pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span>
<span class="attr">kind:</span> <span class="string">NetworkPolicy</span>
<span class="attr">metadata:</span>
  <span class="attr">name:</span> <span class="string">allow-coredns-egress</span>
  <span class="attr">namespace:</span> <span class="string">kube-system</span>
<span class="attr">spec:</span>
  <span class="attr">podSelector:</span>
    <span class="attr">matchLabels:</span>
      <span class="attr">k8s-app:</span> <span class="string">coredns</span>
  <span class="attr">policyTypes:</span>
  <span class="bullet">-</span> <span class="string">Egress</span>
  <span class="attr">egress:</span>
  <span class="bullet">-</span> <span class="attr">to:</span>
    <span class="bullet">-</span> <span class="attr">ipBlock:</span>
        <span class="attr">cidr:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">/0</span>  <span class="comment"># 外部DNS</span>
    <span class="attr">ports:</span>
    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">UDP</span>
      <span class="attr">port:</span> <span class="number">53</span>
    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>
      <span class="attr">port:</span> <span class="number">53</span>
  <span class="bullet">-</span> <span class="attr">to:</span>
    <span class="bullet">-</span> <span class="attr">ipBlock:</span>
        <span class="attr">cidr:</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span><span class="string">/12</span>  <span class="comment"># 服务CIDR (API ClusterIP)</span>
    <span class="attr">ports:</span>
    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>
      <span class="attr">port:</span> <span class="number">443</span>
  <span class="bullet">-</span> <span class="attr">to:</span>
    <span class="bullet">-</span> <span class="attr">ipBlock:</span>
        <span class="attr">cidr:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.0</span><span class="string">/24</span>  <span class="comment"># Master节点IP范围 (API后端端口)</span>
    <span class="attr">ports:</span>
    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>
      <span class="attr">port:</span> <span class="number">8443</span></code></pre>



<p><strong>执行资源清单</strong></p>
<pre><code class="highlight bash">$ kubectl apply -f NetworkPolicy.yaml</code></pre>



<h3 id="3-2-部署-Ubuntu-Pod"><a href="#3-2-部署-Ubuntu-Pod" class="headerlink" title="3.2 部署 Ubuntu Pod"></a>3.2 部署 Ubuntu Pod</h3><pre><code class="highlight bash"><span class="comment"># 运行 Ubuntu Pod</span>
$ kubectl run -it --<span class="built_in">rm</span> --restart=Never --image=ubuntu:22.04 ubuntu-test -- bash

<span class="comment"># 替换阿里云源</span>
<span class="built_in">cat</span> &gt; /etc/apt/sources.list &lt;&lt; <span class="string">&quot;EOF&quot;</span>
deb http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse
EOF

<span class="comment"># 下载工具</span>
apt update -y
apt install -y iputils-ping dnsutils curl netcat</code></pre>



<p><strong>测试网络1</strong></p>
<pre><code class="highlight bash">root@ubuntu-test:/<span class="comment"># nslookup kubernetes.default.svc.cluster.local</span>
;; Got recursion not available from 10.96.0.10
;; Got recursion not available from 10.96.0.10
;; Got recursion not available from 10.96.0.10
;; Got recursion not available from 10.96.0.10
Server:		10.96.0.10
Address:	10.96.0.10<span class="comment">#53</span>

Name:	kubernetes.default.svc.cluster.local
Address: 10.96.0.1
;; Got recursion not available from 10.96.0.10</code></pre>

<p>结论：DNS 解析成功</p>
<p><strong>测试网络2</strong></p>
<pre><code class="highlight bash">root@ubuntu-test:/<span class="comment"># dig kubernetes.default.svc.cluster.local</span>

; &lt;&lt;&gt;&gt; DiG 9.18.39-0ubuntu0.22.04.2-Ubuntu &lt;&lt;&gt;&gt; kubernetes.default.svc.cluster.local
;; global options: +cmd
;; Got answer:
;; WARNING: .<span class="built_in">local</span> is reserved <span class="keyword">for</span> Multicast DNS
;; You are currently testing what happens when an mDNS query is leaked to DNS
;; -&gt;&gt;HEADER&lt;&lt;- <span class="string">opcode: QUERY, status: NOERROR, id: 31061</span>
<span class="string">;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1</span>
<span class="string">;; WARNING: recursion requested but not available</span>
<span class="string"></span>
<span class="string">;; OPT PSEUDOSECTION:</span>
<span class="string">; EDNS: version: 0, flags:; udp: 1232</span>
<span class="string">; COOKIE: 3bdf10d9d00e32a3 (echoed)</span>
<span class="string">;; QUESTION SECTION:</span>
<span class="string">;kubernetes.default.svc.cluster.local. IN A</span>
<span class="string"></span>
<span class="string">;; ANSWER SECTION:</span>
<span class="string">kubernetes.default.svc.cluster.local. 30 IN A	10.96.0.1</span>
<span class="string"></span>
<span class="string">;; Query time: 1 msec</span>
<span class="string">;; SERVER: 10.96.0.10#53(10.96.0.10) (UDP)</span>
<span class="string">;; WHEN: Thu Oct 30 06:37:24 UTC 2025</span>
<span class="string">;; MSG SIZE  rcvd: 129</span></code></pre>

<p>结论：DNS 解析成功</p>
<p><strong>其它测试</strong></p>
<pre><code class="highlight bash"><span class="comment"># TCP 连接 443# # TCP 连接 443</span>
root@ubuntu-test:/<span class="comment"># nc -zv 10.96.0.1 443</span>
Connection to 10.96.0.1 443 port [tcp/*] succeeded!

<span class="comment"># 或 curl</span>
root@ubuntu-test:/<span class="comment"># curl -k https://10.96.0.1:443</span>
&#123;
  <span class="string">&quot;kind&quot;</span>: <span class="string">&quot;Status&quot;</span>,
  <span class="string">&quot;apiVersion&quot;</span>: <span class="string">&quot;v1&quot;</span>,
  <span class="string">&quot;metadata&quot;</span>: &#123;&#125;,
  <span class="string">&quot;status&quot;</span>: <span class="string">&quot;Failure&quot;</span>,
  <span class="string">&quot;message&quot;</span>: <span class="string">&quot;forbidden: User \&quot;system:anonymous\&quot; cannot get path \&quot;/\&quot;&quot;</span>,
  <span class="string">&quot;reason&quot;</span>: <span class="string">&quot;Forbidden&quot;</span>,
  <span class="string">&quot;details&quot;</span>: &#123;&#125;,
  <span class="string">&quot;code&quot;</span>: 403
&#125;</code></pre>







<p><strong>参考链接</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://cloudmessage.top/archives/kubernetes-1292calicorockylinux92-gao-ke-yong-dockercri-docker-er-jin-zhi-bu-shu">https://cloudmessage.top/archives/kubernetes-1292calicorockylinux92-gao-ke-yong-dockercri-docker-er-jin-zhi-bu-shu</a></p>
<p><a target="_blank" rel="noopener" href="https://www.sundayhk.com/597.html">https://www.sundayhk.com/597.html</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/cby-chen/Kubernetes/blob/main/doc/v1.29.2-CentOS-binary-install-IPv6-IPv4-Three-Masters-Two-Slaves-Offline.md">https://github.com/cby-chen/Kubernetes/blob/main/doc/v1.29.2-CentOS-binary-install-IPv6-IPv4-Three-Masters-Two-Slaves-Offline.md</a></p>
</blockquote>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以在下面评论区评论，也可以邮件至 george_95@126.com </span>
    </div>
</article>





    <div id="comments"></div>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

<script type="text/javascript">
    $.getScript('/js/gitalk.js', function () {
        var gitalk = new Gitalk({
            clientID: 'f820fe811764cacedc4f',
            clientSecret: '0ce07abb65f0e79ddb8830f32029b8a9656e0ee0',
            repo: 'georgechan95.github.io',
            owner: 'GeorgeChan95',
            admin: ['GeorgeChan95'],
            id: decodeURI(location.pathname),
            distractionFreeMode: 'true',
            language: 'zh-CN',
            perPage: parseInt('15',10)
        })
        gitalk.render('comments')
    })
</script>




    




    </div>
    <div class="copyright">
        <p class="footer-entry">
    ©2016-2020 George
</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full" data-title="切换全屏 快捷键 s"><span class="min "></span></button>
<a class="" id="rocket" ></a>

    </div>
</div>

</body>
<script src="/js/jquery.pjax.js?v=1.1.0" ></script>

<script src="/js/script.js?v=1.1.0" ></script>
<script>
    var img_resize = 'default';
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $("#post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    

    
    #post .pjax article :not(pre) > code {
        color: #24292e;
        font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
        background-color: rgba(27,31,35,.05);
        border-radius: 3px;
        font-size: 85%;
        margin: 0;
        padding: .2em .4em;
    }
    
</style>







</html>
