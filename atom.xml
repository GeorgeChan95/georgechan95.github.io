<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>George&#39;s Blog</title>
  
  <subtitle>个人邮箱：george_95@126.com</subtitle>
  <link href="https://georgechan95.github.io/atom.xml" rel="self"/>
  
  <link href="https://georgechan95.github.io/"/>
  <updated>2025-04-02T03:10:58.171Z</updated>
  <id>https://georgechan95.github.io/</id>
  
  <author>
    <name>George</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T03:00:21.261Z</published>
    <updated>2025-04-02T03:10:58.171Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"name":"lifecycle-pod","namespace":"default","labels":{"app":"myapp"}},"spec":{"containers":[{"name":"busybox-container","image":"wangyanglinux/tools:busybox","imagePullPolicy":"IfNotPresent","command":["/bin/sh","-c","touch /tmp/live ; sleep 600; rm -rf /tmp/live; sleep 3600"],"livenessProbe":{"exec":{"command":["test","-e","/tmp/live"]},"initialDelaySeconds":1,"periodSeconds":3},"lifecycle":{"postStart":{"httpGet":{"port":1234,"host":"192.168.6.139","path":"index.html"}},"preStop":{"httpGet":{"port":1234,"host":"192.168.6.139","path":"hostname.html"}}}},{"name":"myapp-container","image":"wangyanglinux/myapp:v1.0","imagePullPolicy":"IfNotPresent","livenessProbe":{"httpGet":{"port":80,"path":"/index.html"},"initialDelaySeconds":1,"periodSeconds":3,"timeoutSeconds":3},"readinessProbe":{"httpGet":{"port":80,"path":"/index1.html"},"initialDelaySeconds":1,"periodSeconds":3,"timeoutSeconds":3}}],"initContainers":[{"name":"init-myservice","image":"wangyanglinux/tools:busybox","imagePullPolicy":"IfNotPresent","command":["sh","-c","until nslookup myservice; do echo waiting for myservice; sleep 2; done;"]},{"name":"init-mydb","image":"wangyanglinux/tools:busybox","command":["sh","-c","until nslookup mydb; do echo waiting for mydb; sleep 2; done;"]}]}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;lifecycle-pod&quot;,&quot;namespace&quot;:&quot;default&quot;,&quot;labels&quot;:{&quot;app&quot;:&quot;myapp&quot;}},&quot;spec&quot;:{&quot;containers&quot;:[{&quot;n</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T02:12:05.770Z</published>
    <updated>2025-04-02T02:49:38.700Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"namespace":"default","name":"lifecycle-http-pod","labels":{"app":"myApp"}},"spec":{"containers":[{"name":"lifecycle-httpget-container","image":"wangyanglinux/myapp:v1.0","imagePullPolicy":"IfNotPresent","ports":[{"containerPort":80}],"lifecycle":{"postStart":{"httpGet":{"port":1234,"host":"192.168.6.139","path":"index.html"}},"preStop":{"httpGet":{"port":1234,"host":"192.168.6.139","path":"hostname.html"}}}}],"terminationGracePeriodSeconds":30}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;namespace&quot;:&quot;default&quot;,&quot;name&quot;:&quot;lifecycle-http-pod&quot;,&quot;labels&quot;:{&quot;app&quot;:&quot;myApp&quot;}},&quot;spec&quot;:{&quot;containers&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T01:16:27.435Z</published>
    <updated>2025-04-02T01:56:54.846Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"name":"lifecycle-exec-pod","namespace":"default","labels":{"app":"myapp"}},"spec":{"containers":[{"name":"lifecycle-exec-container","image":"wangyanglinux/myapp:v1.0","imagePullPolicy":"IfNotPresent","lifecycle":{"postStart":{"exec":{"command":["/bin/sh","-c","echo postStart > /usr/share/message"]}},"preStop":{"exec":{"command":["/bin/sh","-c","echo preStop > /usr/share/message"]}}}}]}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;lifecycle-exec-pod&quot;,&quot;namespace&quot;:&quot;default&quot;,&quot;labels&quot;:{&quot;app&quot;:&quot;myapp&quot;}},&quot;spec&quot;:{&quot;containers&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T01:04:59.976Z</published>
    <updated>2025-04-02T01:04:59.976Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"name":"readiness-exec-pod","namespace":"default","labels":{"app":"myapp","env":"test"}},"spec":{"containers":[{"name":"readiness-exec-container","image":"wangyanglinux/myapp:v1.0","imagePullPolicy":"IfNotPresent","command":["/bin/sh","-c","touch /tmp/live; sleep 30; rm -rf /tmp/live; sleep 3600"],"livenessProbe":{"exec":{"command":["test","-e","/tmp/live"]},"initialDelaySeconds":2,"periodSeconds":3}}]}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;readiness-exec-pod&quot;,&quot;namespace&quot;:&quot;default&quot;,&quot;labels&quot;:{&quot;app&quot;:&quot;myapp&quot;,&quot;env&quot;:&quot;test&quot;}},&quot;spec&quot;:</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T01:04:59.976Z</published>
    <updated>2025-04-02T01:04:59.976Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"namespace":"default","name":"readiness-tcp-pod"},"spec":{"containers":[{"name":"readiness-exec-container","image":"wangyanglinux/myapp:v1.0","imagePullPolicy":"IfNotPresent","ports":[{"containerPort":80,"name":"http"}],"livenessProbe":{"initialDelaySeconds":2,"timeoutSeconds":1,"tcpSocket":{"port":80}}}]}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;namespace&quot;:&quot;default&quot;,&quot;name&quot;:&quot;readiness-tcp-pod&quot;},&quot;spec&quot;:{&quot;containers&quot;:[{&quot;name&quot;:&quot;readiness-exec-</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T01:04:59.976Z</published>
    <updated>2025-04-02T01:04:59.976Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"name":"startup-probe-pod","namespace":"default"},"spec":{"containers":[{"name":"startup-probe-container","image":"wangyanglinux/myapp:v1.0","imagePullPolicy":"IfNotPresent","ports":[{"containerPort":80,"name":"http"}],"startupProbe":{"initialDelaySeconds":0,"successThreshold":1,"failureThreshold":30,"periodSeconds":10,"httpGet":{"port":80,"path":"/index1.html"}}}]}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;startup-probe-pod&quot;,&quot;namespace&quot;:&quot;default&quot;},&quot;spec&quot;:{&quot;containers&quot;:[{&quot;name&quot;:&quot;startup-probe-c</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T01:04:59.976Z</published>
    <updated>2025-04-02T01:04:59.977Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"name":"startup-exec-pod","namespace":"default","labels":{"app":"myapp","env":"test"}},"spec":{"containers":[{"name":"startup-exec-container","image":"wangyanglinux/myapp:v1.0","imagePullPolicy":"IfNotPresent","command":["/bin/sh","-c","touch /tmp/live; sleep 3; rm -rf /tmp/live; sleep 3600"],"startupProbe":{"exec":{"command":["test","-e","/tmp/live"]},"initialDelaySeconds":4,"periodSeconds":3}}]}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;startup-exec-pod&quot;,&quot;namespace&quot;:&quot;default&quot;,&quot;labels&quot;:{&quot;app&quot;:&quot;myapp&quot;,&quot;env&quot;:&quot;test&quot;}},&quot;spec&quot;:{&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T01:04:59.975Z</published>
    <updated>2025-04-02T01:04:59.975Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"name":"readiness-exec-pod","namespace":"default","labels":{"app":"myapp","env":"test"}},"spec":{"containers":[{"name":"readiness-exec-container","image":"wangyanglinux/myapp:v1.0","imagePullPolicy":"IfNotPresent","command":["/bin/sh","-c","touch /tmp/live; sleep 60; rm -rf /tmp/live; sleep 3600"],"readinessProbe":{"exec":{"command":["test","-e","/tmp/live"]},"initialDelaySeconds":2,"periodSeconds":3}}]}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;readiness-exec-pod&quot;,&quot;namespace&quot;:&quot;default&quot;,&quot;labels&quot;:{&quot;app&quot;:&quot;myapp&quot;,&quot;env&quot;:&quot;test&quot;}},&quot;spec&quot;:</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T01:04:59.975Z</published>
    <updated>2025-04-02T01:04:59.975Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"namespace":"default","name":"readiness-tcp-pod"},"spec":{"containers":[{"name":"readiness-exec-container","image":"wangyanglinux/myapp:v1.0","imagePullPolicy":"IfNotPresent","readinessProbe":{"initialDelaySeconds":3,"timeoutSeconds":1,"tcpSocket":{"port":80}}}]}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;namespace&quot;:&quot;default&quot;,&quot;name&quot;:&quot;readiness-tcp-pod&quot;},&quot;spec&quot;:{&quot;containers&quot;:[{&quot;name&quot;:&quot;readiness-exec-</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T01:04:59.975Z</published>
    <updated>2025-04-02T01:04:59.975Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"name":"liveness-httpget-pod","namespace":"default","labels":{"app":"myapp"}},"spec":{"containers":[{"name":"liveness-httpget-container","image":"wangyanglinux/myapp:v1.0","imagePullPolicy":"IfNotPresent","ports":[{"containerPort":80,"name":"http"}],"livenessProbe":{"initialDelaySeconds":2,"periodSeconds":3,"successThreshold":1,"failureThreshold":3,"httpGet":{"port":80,"path":"/index1.html"}}}]}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;liveness-httpget-pod&quot;,&quot;namespace&quot;:&quot;default&quot;,&quot;labels&quot;:{&quot;app&quot;:&quot;myapp&quot;}},&quot;spec&quot;:{&quot;container</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T01:04:59.975Z</published>
    <updated>2025-04-02T01:04:59.975Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"name":"readiness-httpget-pod","namespace":"default","labels":{"app":"myapp","env":"test"}},"spec":{"containers":[{"name":"readiness-httpget-container","image":"wangyanglinux/myapp:v1.0","imagePullPolicy":"IfNotPresent","readinessProbe":{"httpGet":{"port":80,"path":"/index1.html"},"initialDelaySeconds":1,"periodSeconds":30,"timeoutSeconds":1,"successThreshold":1,"failureThreshold":10}}]}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;readiness-httpget-pod&quot;,&quot;namespace&quot;:&quot;default&quot;,&quot;labels&quot;:{&quot;app&quot;:&quot;myapp&quot;,&quot;env&quot;:&quot;test&quot;}},&quot;spe</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://georgechan95.github.io/blog/undefined.html"/>
    <id>https://georgechan95.github.io/blog/undefined.html</id>
    <published>2025-04-02T01:04:59.974Z</published>
    <updated>2025-04-02T01:04:59.974Z</updated>
    
    <content type="html"><![CDATA[{"apiVersion":"v1","kind":"Pod","metadata":{"name":"init-1","labels":{"app":"initc"}},"spec":{"containers":[{"name":"myapp-container","image":"gcr.io/google-containers/busybox:1.27","command":["sh","-c","echo The app is running! && sleep 3600"]}],"initContainers":[{"name":"init-myservice","image":"gcr.io/google-containers/busybox:1.27","command":["sh","-c","until nslookup myservice; do echo waiting for myservice; sleep 2; done;"]},{"name":"init-mydb","image":"gcr.io/google-containers/busybox:1.27","command":["sh","-c","until nslookup mydb; do echo waiting for mydb; sleep 2; done;"]}]}}]]></content>
    
    
      
      
    <summary type="html">{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;init-1&quot;,&quot;labels&quot;:{&quot;app&quot;:&quot;initc&quot;}},&quot;spec&quot;:{&quot;containers&quot;:[{&quot;name&quot;:&quot;myapp-container&quot;,&quot;image</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>004-Pod的生命周期</title>
    <link href="https://georgechan95.github.io/blog/79e06aab.html"/>
    <id>https://georgechan95.github.io/blog/79e06aab.html</id>
    <published>2025-03-22T01:05:00.000Z</published>
    <updated>2025-04-02T03:28:05.700Z</updated>
    
    <content type="html"><![CDATA[<p><strong>系统环境</strong></p><blockquote><p>RockyLinux：9.3</p><p>K8s版本：1.29</p><p>Docker版本：27.4.1</p></blockquote><h1 id="1、Pod生命周期概述"><a href="#1、Pod生命周期概述" class="headerlink" title="1、Pod生命周期概述"></a>1、Pod生命周期概述</h1><p>Pod 的生命周期如下图：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/03/22/20250322-103306.png" alt="Pod 的生命周期"></p><h1 id="2、initC"><a href="#2、initC" class="headerlink" title="2、initC"></a>2、initC</h1><h2 id="2-1-initC概述"><a href="#2-1-initC概述" class="headerlink" title="2.1 initC概述"></a>2.1 initC概述</h2><p>init 容器与普通的容器非常像，除了如下三点：</p><ul><li>init 容器总是运行到成功完成为止</li><li>每个 init 容器都必须在下一个 init 容器启动之前成功完成</li><li>initC 无法定义 readinessProbe，其它以外同应用容器定义无异</li></ul><p>如果 Pod 的 Init 容器失败，Kubernetes 会不断地重启该 Pod，直到 Init 容器成功为止。然而，如果 Pod 对应的 restartPolicy 为 Never，它不会重新启动</p><p>在主容器 [mainC] 启动前,可以定义 initC 作为前置容器，用于检测主容器所需要的环境是否已准备完成(当然initC的定义不是必须的)。当在配置中定义了 initC ，则必须所有的initC都启动完成后，mainC 才能启动，否则 mainC 会一直处于阻塞中。</p><p>另外 initC 会按照 yaml文件中定义的顺序启动，只有当第一个 initC 容器启动完成后，第二个 initC 才能启动，否则第二个 initC 也会处于阻塞中。</p><p>下面是 initC 阻塞性检测的示例：</p><h2 id="2-2-pod-yaml文件"><a href="#2-2-pod-yaml文件" class="headerlink" title="2.2 pod yaml文件"></a>2.2 pod yaml文件</h2><h3 id="2-2-1-yaml文件内容"><a href="#2-2-1-yaml文件内容" class="headerlink" title="2.2.1 yaml文件内容"></a>2.2.1 yaml文件内容</h3><p><code>001-initC.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span> <span class="comment"># API版本</span><span class="attr">kind:</span> <span class="string">Pod</span> <span class="comment"># 资源类型</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">init-1</span> <span class="comment"># Pod名称</span>  <span class="attr">labels:</span> <span class="comment"># 标签</span>    <span class="attr">app:</span> <span class="string">initc</span><span class="attr">spec:</span> <span class="comment"># Pod 期望</span>  <span class="attr">containers:</span> <span class="comment"># 容器定义</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span> <span class="comment"># 容器名</span>      <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span> <span class="comment"># 该容器使用的镜像</span>      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;echo The app is running! &amp;&amp; sleep 3600&#x27;</span>]  <span class="attr">initContainers:</span> <span class="comment"># 初始化容器全部成功后，myapp-container容器才能启动成功</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-myservice</span> <span class="comment"># 第一个初始化容器，等待 myservice 的 DNS 解析成功。</span>      <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span>      <span class="attr">command:</span>        <span class="bullet">-</span> <span class="string">&#x27;sh&#x27;</span>        <span class="bullet">-</span> <span class="string">&#x27;-c&#x27;</span>        <span class="bullet">-</span> <span class="string">&#x27;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#x27;</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-mydb</span> <span class="comment"># 第二个初始化容器，等待 mydb 的 DNS 解析成功。 然后才会启动主容器 myapp-container。</span>      <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span>      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#x27;</span>]</code></pre><h3 id="2-2-2-pod-yaml文件解析"><a href="#2-2-2-pod-yaml文件解析" class="headerlink" title="2.2.2 pod yaml文件解析"></a>2.2.2 pod yaml文件解析</h3><pre><code class="highlight yaml"><span class="attr">containers:</span> <span class="comment"># 容器定义</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span> <span class="comment"># 容器名</span>    <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span> <span class="comment"># 该容器使用的镜像</span>    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;echo The app is running! &amp;&amp; sleep 3600&#x27;</span>]</code></pre><p>主容器 <code>myapp-container</code> 启动成功后会打印内容：<code>The app is running!</code> ，并且 sleep 3600 秒</p><pre><code class="highlight yaml"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-myservice</span> <span class="comment"># 第一个初始化容器，等待 myservice 的 DNS 解析成功。</span>  <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span>  <span class="attr">command:</span>    <span class="bullet">-</span> <span class="string">&#x27;sh&#x27;</span>    <span class="bullet">-</span> <span class="string">&#x27;-c&#x27;</span>    <span class="bullet">-</span> <span class="string">&#x27;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#x27;</span></code></pre><p>第一个初始化容器：<code>init-myservice</code> 启动时会解析 DNS 域名：<code>myservice</code>， 解析成功则该初始化容器成功启动，解析失败则打印日志：<code>waiting for myservice</code>， 然后 sleep 2秒后，继续解析，直到成功为止。</p><pre><code class="highlight yaml"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-mydb</span> <span class="comment"># 第二个初始化容器，等待 mydb 的 DNS 解析成功。 然后才会启动主容器 myapp-container。</span>  <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span>  <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#x27;</span>]</code></pre><p>第一个初始化容器：<code>init-mydb</code> 启动时会解析 DNS 域名：<code>mydb</code>， 解析成功则该初始化容器成功启动，解析失败则打印日志：<code>waiting for mydb</code>， 然后 sleep 2秒后，继续解析，直到成功为止。</p><h2 id="2-3-启动Pod测试"><a href="#2-3-启动Pod测试" class="headerlink" title="2.3 启动Pod测试"></a>2.3 启动Pod测试</h2><h3 id="2-3-1-启动pod"><a href="#2-3-1-启动pod" class="headerlink" title="2.3.1 启动pod"></a>2.3.1 启动pod</h3><pre><code class="highlight shell">kubectl apply -f /opt/k8s/04/001-initC.yaml</code></pre><p>此时观察Pod 启动情况</p><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl get podsNAME     READY   STATUS     RESTARTS   AGEinit-1   0/1     Init:0/2   0          2m42s<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">或者动态监控</span>[root@k8s-master01 ~]$ kubectl get pods -o wide -wNAME     READY   STATUS     RESTARTS   AGE    IP               NODE         NOMINATED NODE   READINESS GATESinit-1   0/1     Init:0/2   0          3m6s   192.168.85.193   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>此时可以看到 主容器未启动，且初始化容器未启动。</p><h3 id="2-3-2-查看初始化容器日志"><a href="#2-3-2-查看初始化容器日志" class="headerlink" title="2.3.2 查看初始化容器日志"></a>2.3.2 查看初始化容器日志</h3><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl logs -f --tail=100 init-1 -c init-myservicenslookup: can&#x27;t resolve &#x27;myservice&#x27;Server:    10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.localwaiting for myservicenslookup: can&#x27;t resolve &#x27;myservice&#x27;Server:    10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</code></pre><p><code>init-myservice</code> DNS未能解析名为 <code>myservice</code> 的服务，而此时初始化容器 <code>init-mydb</code> 还未启动。</p><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl logs -f --tail=100 init-1 -c init-mydbError from server (BadRequest): container &quot;init-mydb&quot; in pod &quot;init-1&quot; is waiting to start: PodInitializing</code></pre><h3 id="2-3-3-创建Service：myservice"><a href="#2-3-3-创建Service：myservice" class="headerlink" title="2.3.3 创建Service：myservice"></a>2.3.3 创建Service：myservice</h3><pre><code class="highlight shell">kubectl create svc clusterip myservice --tcp=80:80</code></pre><p>创建Service，名为 <code>myservice</code>，在k8s中默认名称即为域名，这样在集群中就有了一个域名为：myservice 的服务了。</p><p>此时再观察 Pod 的启动情况：</p><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl get podsNAME     READY   STATUS     RESTARTS   AGEinit-1   0/1     Init:1/2   0          13m</code></pre><p>初始化容器1已启动。</p><h3 id="2-3-4-观察初始化容器2：init-mydb"><a href="#2-3-4-观察初始化容器2：init-mydb" class="headerlink" title="2.3.4 观察初始化容器2：init-mydb"></a>2.3.4 观察初始化容器2：<code>init-mydb</code></h3><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl logs -f --tail=100 init-1 -c init-mydbServer:    10.96.0.10nslookup: can&#x27;t resolve &#x27;mydb&#x27;Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.localwaiting for mydbServer:    10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</code></pre><p><code>init-mydb</code> 容器未启动，因为无法解析域名：<code>mydb</code>，此时主容器 <code>myapp-container</code> 未启动，需要等待初始化容器都启动成功后才能启动主容器。</p><h3 id="2-3-5-创建Service：mydb"><a href="#2-3-5-创建Service：mydb" class="headerlink" title="2.3.5 创建Service：mydb"></a>2.3.5 创建Service：mydb</h3><pre><code class="highlight shell">kubectl create svc clusterip mydb --tcp=80:80</code></pre><p>此时再观察Pod启动情况</p><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl get pods -o wide -wNAME     READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESinit-1   1/1     Running   0          18m   192.168.85.193   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>初始化容器启动完成，主容器启动完成。</p><h3 id="2-3-6-查看容器启动日志"><a href="#2-3-6-查看容器启动日志" class="headerlink" title="2.3.6 查看容器启动日志"></a>2.3.6 查看容器启动日志</h3><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl logs -f --tail=100 init-1 -c myapp-containerThe app is running!</code></pre><p><strong>结论：</strong></p><ul><li>初始化容器必须全部启动完成后，主容器才能启动</li><li>初始化容器启动是有顺序的</li></ul><h1 id="3、探针"><a href="#3、探针" class="headerlink" title="3、探针"></a>3、探针</h1><h2 id="3-1-探针概述"><a href="#3-1-探针概述" class="headerlink" title="3.1 探针概述"></a>3.1 探针概述</h2><p>探针是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 调用由容器实现的 Handler。有三种类型的处理程序：</p><ul><li><code>ExecAction</code>：在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功</li><li><code>TCPSocketAction</code>：对指定端口上的容器的 IP 地址进行 TCP 检查。如果端口打开，则诊断被认为是成功的</li><li><code>HTTPGetAction</code>：对指定的端口和路径上的容器的 IP 地址执行 HTTP Get 请求。如果响应的状态码大于等于200 且小于 400，则诊断被认为是成功的</li></ul><p>每次探测都将获得以下三种结果之一：</p><ul><li>成功：容器通过了诊断。</li><li>失败：容器未通过诊断。</li><li>未知：诊断失败，因此不会采取任何行动</li></ul><h2 id="3-2-探针分类"><a href="#3-2-探针分类" class="headerlink" title="3.2 探针分类"></a>3.2 探针分类</h2><ul><li><code>startupProbe</code>：启动探测，用于检测容器是否已启动</li><li><code>livenessProbe</code>：存活探测，用于检测容器是否还存活</li><li><code>readinessProbe</code>：就绪探测，检查容器是否已就绪，可以对外提供服务了。</li></ul><h1 id="4、readinessProbe-就绪探针"><a href="#4、readinessProbe-就绪探针" class="headerlink" title="4、readinessProbe 就绪探针"></a>4、readinessProbe 就绪探针</h1><p>介绍：k8s 通过添加就绪探针，解决尤其是在扩容时保证提供给用户的服务都是可用的。</p><h2 id="4-1-选项说明"><a href="#4-1-选项说明" class="headerlink" title="4.1 选项说明"></a>4.1 选项说明</h2><ul><li><code>initialDelaySeconds</code>：容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</li><li><code>periodSeconds</code>：执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</li><li><code>timeoutSeconds</code>：探针执行检测请求后，等待响应的超时时间，默认为 1s，单位“秒”，最小值是 1</li><li><code>successThreshold</code>：探针检测失败后认为成功的最小连接成功次数，默认值为 1。必须为 1 才能激活和启动。最小值为1</li><li><code>failureThreshold</code>：探测失败的重试次数，重试一定次数后将认为失败，默认值为 3 ，最小值为 1。</li></ul><h2 id="4-2-案例：基于HTTP-Get-方式"><a href="#4-2-案例：基于HTTP-Get-方式" class="headerlink" title="4.2 案例：基于HTTP Get 方式"></a>4.2 案例：基于HTTP Get 方式</h2><p><code>002-readiness-http.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">readiness-httpget-pod</span> <span class="comment"># pod 名</span>  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment"># 名称空间</span>  <span class="attr">labels:</span> <span class="comment"># 定义多个标签</span>    <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">env:</span> <span class="string">test</span><span class="attr">spec:</span>  <span class="attr">containers:</span> <span class="comment"># 定义主容器</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-httpget-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取策略，如果存在则不拉取</span>      <span class="attr">readinessProbe:</span> <span class="comment"># 定义就绪探测</span>        <span class="attr">httpGet:</span> <span class="comment"># http请求</span>          <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># 请求端口</span>          <span class="attr">path:</span> <span class="string">/index1.html</span> <span class="comment"># 访问资源地址</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">1</span> <span class="comment"># 容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</span>        <span class="attr">periodSeconds:</span> <span class="number">30</span> <span class="comment"># 执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</span>        <span class="attr">timeoutSeconds:</span> <span class="number">1</span> <span class="comment"># 探针执行检测请求后，等待响应的超时时间，默认为 1s，单位“秒”，最小值是 1</span>        <span class="attr">successThreshold:</span> <span class="number">1</span> <span class="comment"># 探针检测失败后认为成功的最小连接成功次数，默认值为 1。必须为 1 才能激活和启动。最小值为1</span>        <span class="attr">failureThreshold:</span> <span class="number">10</span> <span class="comment"># 探测失败的重试次数，重试一定次数后将认为失败，默认值为 3 ，最小值为 1</span></code></pre><p><strong>创建Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">创建Pod</span>kubectl apply -f /opt/k8s/04/002-readiness-http.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行情况</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get podsNAME                    READY   STATUS    RESTARTS   AGEreadiness-httpget-pod   0/1     Running   0          8s</code></pre><p>Pod已启动，但是未就绪，下面查看日志，直到Pod未就绪的原因</p><p><strong>查看Pod日志</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">查看Pod日志</span>kubectl logs -f readiness-httpget-pod<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">日志内容如下</span>192.168.142.202 - - [22/Mar/2025:23:59:58 +0800] &quot;GET /index1.html HTTP/1.1&quot; 404 153 &quot;-&quot; &quot;kube-probe/1.29&quot;2025/03/22 23:59:58 [error] 7#7: *1 open() &quot;/usr/local/nginx/html/index1.html&quot; failed (2: No such file or directory), client: 192.168.142.202, server: localhost, request: &quot;GET /index1.html HTTP/1.1&quot;, host: &quot;192.168.58.196:80&quot;</code></pre><p>可以发现Pod在做就绪检测，访问 <a href="http://192.168.58.196/index1.html">http://192.168.58.196:80/index1.html</a> 结果404，就绪检测未通过，因此Pod处于未就绪状态。</p><p><strong>进入Pod内容，创建资源文件，让Pod就绪检测通过</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">进入Pod容器内部</span>[root@k8s-master01 /opt/k8s/04]$ kubectl exec -it readiness-httpget-pod /bin/bash<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">创建资源文件</span>readiness-httpget-pod:/# cd /usr/local/nginx/html/readiness-httpget-pod:/usr/local/nginx/html# ls50x.html       hostname.html  index.htmlreadiness-httpget-pod:/usr/local/nginx/html# cp index.html index1.html readiness-httpget-pod:/usr/local/nginx/html# exitexit<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">再次查看Pod运行状态，Pod已处于就绪状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get podsNAME                    READY   STATUS    RESTARTS   AGEreadiness-httpget-pod   1/1     Running   0          95s</code></pre><h2 id="4-3-案例：基于EXEC方式"><a href="#4-3-案例：基于EXEC方式" class="headerlink" title="4.3 案例：基于EXEC方式"></a>4.3 案例：基于EXEC方式</h2><p>就绪检测在容器从启动到关闭的整个周期内都是有效的，例如容器刚启动时，就绪检测通过了，</p><p><code>003-readiness-exec.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">readiness-exec-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">env:</span> <span class="string">test</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取策略，如果存在则不拉取</span>      <span class="comment"># 主容器启动成功后自动创建目录 /tmp/live, 60秒后删除该目录，</span>      <span class="attr">command:</span> [<span class="string">&#x27;/bin/sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;touch /tmp/live; sleep 60; rm -rf /tmp/live; sleep 3600&#x27;</span>]      <span class="attr">readinessProbe:</span>        <span class="attr">exec:</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&#x27;test&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;-e&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;/tmp/live&#x27;</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">2</span> <span class="comment"># 容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span> <span class="comment"># 执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</span></code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 003-readiness-exec.yaml <span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get podsNAME                 READY   STATUS    RESTARTS   AGEreadiness-exec-pod   1/1     Running   0          5s</code></pre><p>由于主容器 <code>readiness-exec-container</code> 在启动成功后创建目录 <code>/tmp/live</code> ，因此 exec 就绪检测在容器刚启动时会通过。但在容器启动60秒后会删除目录 <code>/tmp/live</code>，由于就绪检测会持续不断的进行，因此此时就绪检测会失败。</p><p><strong>再次查看Pod运行状态</strong></p><pre><code class="highlight shell">[root@k8s-master01 /opt/k8s/04]$ kubectl get podsNAME                 READY   STATUS    RESTARTS   AGEreadiness-exec-pod   0/1     Running   0          15m</code></pre><p>Pod此时处于未就绪状态</p><h2 id="4-4-案例：基于-TCP-Check-方式"><a href="#4-4-案例：基于-TCP-Check-方式" class="headerlink" title="4.4 案例：基于 TCP Check 方式"></a>4.4 案例：基于 TCP Check 方式</h2><p><code>004-readiness-tcp.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">readiness-tcp-pod</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">readinessProbe:</span> <span class="comment"># 定义就绪检测</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">3</span>        <span class="attr">timeoutSeconds:</span> <span class="number">1</span>        <span class="attr">tcpSocket:</span> <span class="comment"># 探测 tcp 端口</span>          <span class="attr">port:</span> <span class="number">80</span></code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 004-readiness-tcp.yaml <span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get podsNAME                READY   STATUS    RESTARTS   AGEreadiness-tcp-pod   1/1     Running   0          10s</code></pre><h1 id="5、livenessProbe-存活探针"><a href="#5、livenessProbe-存活探针" class="headerlink" title="5、livenessProbe 存活探针"></a>5、livenessProbe 存活探针</h1><p>介绍：k8s 通过添加存活探针，解决虽然活着但是已经死了的问题。</p><h2 id="5-1-选项说明："><a href="#5-1-选项说明：" class="headerlink" title="5.1 选项说明："></a>5.1 选项说明：</h2><ul><li><code>initialDelaySeconds</code>：容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</li><li><code>periodSeconds</code>：执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</li><li><code>timeoutSeconds</code>：探针执行检测请求后，等待响应的超时时间，默认为 1s，单位“秒”，最小值是 1</li><li><code>successThreshold</code>：探针检测失败后认为成功的最小连接成功次数，默认值为 1。必须为 1 才能激活和启动。最小值为1</li><li><code>failureThreshold</code>：探测失败的重试次数，重试一定次数后将认为失败，默认值为 3 ，最小值为 1。</li></ul><h2 id="5-2-案例：基于-HTTP-Get-方式"><a href="#5-2-案例：基于-HTTP-Get-方式" class="headerlink" title="5.2 案例：基于 HTTP Get 方式"></a>5.2 案例：基于 HTTP Get 方式</h2><p><code>005-liveness-httpget.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">liveness-httpget-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness-httpget-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器暴露的端口，这里是 80 端口（通常用于 HTTP 服务）</span>          <span class="attr">name:</span> <span class="string">http</span> <span class="comment"># 为这个端口命名，方便引用（例如在 Service 中）。</span>      <span class="attr">livenessProbe:</span> <span class="comment"># 定义存活探针（Liveness Probe），用于检查容器是否健康。如果探针失败，Kubernetes 会重启容器。</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">2</span> <span class="comment"># 容器启动后，探针延迟 2 秒开始首次检查。这给应用留出启动时间。</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span> <span class="comment"># 探针检查的频率，每 3 秒执行一次。</span>        <span class="attr">successThreshold:</span> <span class="number">1</span> <span class="comment"># 探针成功的次数阈值，设置为 1 表示一次成功即认为容器健康。</span>        <span class="attr">failureThreshold:</span> <span class="number">3</span> <span class="comment"># 探针失败的次数阈值，设置为 3 表示连续 3 次失败后，Kubernetes 会重启容器。</span>        <span class="attr">httpGet:</span> <span class="comment"># 定义探针类型为 HTTP GET 请求。</span>          <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># 请求的目标端口，这里是容器的 80 端口。</span>          <span class="attr">path:</span> <span class="string">/index1.html</span> <span class="comment"># 请求的路径，探针会访问 http://&lt;容器IP&gt;:80/index1.html。如果返回状态码 200-399，则认为容器健康。</span></code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 005-liveness-httpget.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get pods -o wide -wNAME                   READY   STATUS    RESTARTS      AGE    IP               NODE         NOMINATED NODE   READINESS GATESliveness-httpget-pod   1/1     Running   5 (65s ago)   100s   192.168.85.198   k8s-node01   &lt;none&gt;           &lt;none&gt;liveness-httpget-pod   0/1     CrashLoopBackOff   5 (23s ago)   109s   192.168.85.198   k8s-node01   &lt;none&gt;           &lt;none&gt;liveness-httpget-pod   1/1     Running            6 (113s ago)   3m19s   192.168.85.198   k8s-node01   &lt;none&gt;           &lt;none&gt;liveness-httpget-pod   0/1     CrashLoopBackOff   6 (23s ago)    3m28s   192.168.85.198   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>Pod由最开始的 Running 状态，然后容器启动2秒后存活探针开始工作，检测 http:&#x2F;&#x2F;&lt;容器IP&gt;:80&#x2F;index1.html 资源不存在，于是间隔 periodSeconds 时长再次检测，连续失败 failureThreshold 次，容器重启。循环这个操作。</p><h2 id="5-3-案例：基于-Exec-方式"><a href="#5-3-案例：基于-Exec-方式" class="headerlink" title="5.3 案例：基于 Exec 方式"></a>5.3 案例：基于 Exec 方式</h2><p><code>006-liveness-exec.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">readiness-exec-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">env:</span> <span class="string">test</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取策略，如果存在则不拉取</span>      <span class="comment"># 主容器启动成功后自动创建目录 /tmp/live, 60秒后删除该目录，</span>      <span class="attr">command:</span> [<span class="string">&#x27;/bin/sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;touch /tmp/live; sleep 30; rm -rf /tmp/live; sleep 3600&#x27;</span>]      <span class="attr">livenessProbe:</span>        <span class="attr">exec:</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&#x27;test&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;-e&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;/tmp/live&#x27;</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">2</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span></code></pre><p><strong>启动Pod，查看运行状态</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 006-liveness-exec.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">监控Pod运行状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get pods -o wide -wNAME                 READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESreadiness-exec-pod   1/1     Running   0          12s   192.168.85.199   k8s-node01   &lt;none&gt;           &lt;none&gt;readiness-exec-pod   1/1     Running   1 (23s ago)   71s   192.168.85.199   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>Pod刚启动时，会自动创建目录 <code>/tmp/live</code>, <code>initialDelaySeconds</code> 秒后开始存活探测，此时Pod的存活探测是通过的。30秒后容器把目录  <code>/tmp/live</code> 删掉了，由于存活探测是持续轮询执行的，这时的存活探测就是失败的，当连续3次（默认failureThreshold是3）的探测失败后，容器会重启。</p><h2 id="5-4-案例：基于-TCP-Check-方式"><a href="#5-4-案例：基于-TCP-Check-方式" class="headerlink" title="5.4 案例：基于 TCP Check 方式"></a>5.4 案例：基于 TCP Check 方式</h2><p><code>007-liveness-tcp.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">readiness-tcp-pod</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>          <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">livenessProbe:</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">2</span>        <span class="attr">timeoutSeconds:</span> <span class="number">1</span>        <span class="attr">tcpSocket:</span>          <span class="attr">port:</span> <span class="number">80</span></code></pre><p><strong>启动Pod，查看状态</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 007-liveness-tcp.yaml <span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod的运行状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get pods -o wide -wNAME                READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESreadiness-tcp-pod   1/1     Running   0          14s   192.168.85.200   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h1 id="6、startupProbe-启动探针"><a href="#6、startupProbe-启动探针" class="headerlink" title="6、startupProbe 启动探针"></a>6、startupProbe 启动探针</h1><p>介绍：k8s 在 1.16 版本后增加 startupProbe 探针，主要解决在复杂的程序中 readinessProbe、livenessProbe 探针无法更好的判断程序是否启动、是否存活。</p><h2 id="6-1-选项说明"><a href="#6-1-选项说明" class="headerlink" title="6.1 选项说明"></a>6.1 选项说明</h2><ul><li>initialDelaySeconds：容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</li><li>periodSeconds：执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</li><li>timeoutSeconds：探针执行检测请求后，等待响应的超时时间，默认为 1s，单位“秒”，最小值是 1</li><li>successThreshold：探针检测失败后认为成功的最小连接成功次数，默认值为 1。必须为 1 才能激活和启动。最小值为1</li><li>failureThreshold：探测失败的重试次数，重试一定次数后将认为失败，默认值为 3 ，最小值为 1。</li></ul><h2 id="6-2-案例：基于-HTTP-Get-方式"><a href="#6-2-案例：基于-HTTP-Get-方式" class="headerlink" title="6.2 案例：基于 HTTP Get 方式"></a>6.2 案例：基于 HTTP Get 方式</h2><p><code>008-startup-probe.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">startup-probe-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">startup-probe-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>          <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">startupProbe:</span> <span class="comment"># 定义启动探针</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">0</span>        <span class="attr">successThreshold:</span> <span class="number">1</span>        <span class="attr">failureThreshold:</span> <span class="number">30</span>        <span class="attr">periodSeconds:</span> <span class="number">10</span>        <span class="attr">httpGet:</span>          <span class="attr">port:</span> <span class="number">80</span>          <span class="attr">path:</span> <span class="string">/index1.html</span></code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 008-startup-probe.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">监控Pod运行状态</span>[root@k8s-master01 ~]$ kubectl get pods -o wide -wNAME                READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESstartup-probe-pod   0/1     Running   0          97s   192.168.85.201   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>由于容器内没有 index1.html 资源，启动探测失败，因此Pod处于未就绪状态。</p><p><strong>进入容器，创建 index1.html</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">进入容器</span>[root@k8s-master01 /opt/k8s/04]$ kubectl exec -it startup-probe-pod /bin/bashstartup-probe-pod:/# cd /usr/local/nginx/html/startup-probe-pod:/usr/local/nginx/html# ls50x.html       hostname.html  index.html<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">创建 index1.html</span>startup-probe-pod:/usr/local/nginx/html# cp index.html index1.html</code></pre><p><strong>再次查看Pod运行状态</strong></p><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl get pods -o wide -wNAME                READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESstartup-probe-pod   0/1     Running   0          97s   192.168.85.201   k8s-node01   &lt;none&gt;           &lt;none&gt;startup-probe-pod   1/1     Running   0          111s   192.168.85.201   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>此时Pod变成已就绪状态。由于 <code>008-startup-probe.yaml</code> 文件中没有定义就绪检测，因此启动探测成功后，默认就绪检测成功。</p><p><strong>注意：应用程序将会有最多 5 分钟 failureThreshold * periodSeconds（30 * 10 &#x3D; 300s）的时间来完成其启动过程。</strong></p><h2 id="6-3-案例：基于EXEC方式"><a href="#6-3-案例：基于EXEC方式" class="headerlink" title="6.3 案例：基于EXEC方式"></a>6.3 案例：基于EXEC方式</h2><p><code>009-startup-exec.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">startup-exec-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">env:</span> <span class="string">test</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">startup-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取策略，如果存在则不拉取</span>      <span class="comment"># 主容器启动成功后自动创建目录 /tmp/live, 3秒后删除该目录，</span>      <span class="attr">command:</span> [<span class="string">&#x27;/bin/sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;touch /tmp/live; sleep 3; rm -rf /tmp/live; sleep 3600&#x27;</span>]      <span class="attr">startupProbe:</span>        <span class="attr">exec:</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&#x27;test&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;-e&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;/tmp/live&#x27;</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">4</span> <span class="comment"># 延迟4秒后启动探测，此时 /tmp/live 文件夹已被删除</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span></code></pre><p><strong>启动Pod，查看状态</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 009-startup-exec.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行状态</span>[root@k8s-master01 ~]$ kubectl get pods -o wide -wNAME               READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESstartup-exec-pod   0/1     Running   0          6s    192.168.85.203   k8s-node01   &lt;none&gt;           &lt;none&gt;startup-exec-pod   0/1     Running   1 (22s ago)   43s   192.168.85.203   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>启动探测失败，Pod未就绪。</p><h1 id="7、钩子"><a href="#7、钩子" class="headerlink" title="7、钩子"></a>7、钩子</h1><h2 id="7-1-钩子概述"><a href="#7-1-钩子概述" class="headerlink" title="7.1 钩子概述"></a>7.1 钩子概述</h2><p>Pod hook（钩子）是由 Kubernetes 管理的 kubelet 发起的，当容器中的**进程启动前(其实是启动后，对应：postStart)<strong>或者容器中的</strong>进程终止之前(对应：preStop)*<em>运行，这是包含在容器的生命周期之中。</em>可以同时为 Pod 中的所有容器都配置 hook*</p><p>Hook 的类型包括两种：</p><ul><li><code>exec</code>：执行一段命令</li><li><code>HTTP</code>：发送 HTTP 请求</li></ul><h2 id="7-2-案例：基于-Exec-方式"><a href="#7-2-案例：基于-Exec-方式" class="headerlink" title="7.2 案例：基于 Exec 方式"></a>7.2 案例：基于 Exec 方式</h2><p><code>010-hook-exec.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">lifecycle-exec-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lifecycle-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1</span>      <span class="attr">lifecycle:</span>        <span class="attr">postStart:</span> <span class="comment"># 启动后钩子</span>          <span class="attr">exec:</span>            <span class="attr">command:</span>              <span class="bullet">-</span> <span class="string">&#x27;/bin/sh&#x27;</span>              <span class="bullet">-</span> <span class="string">&#x27;-c&#x27;</span>              <span class="bullet">-</span> <span class="string">&#x27;echo postStart &gt; /usr/share/message&#x27;</span>        <span class="attr">preStop:</span> <span class="comment"># 关闭前钩子</span>          <span class="attr">exec:</span>            <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;echo preStop &gt; /usr/share/message&quot;</span>]</code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 010-hook-exec.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行情况</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get pods -o wide -wNAME                 READY   STATUS              RESTARTS   AGE   IP       NODE         NOMINATED NODE   READINESS GATESlifecycle-exec-pod   0/1     ContainerCreating   0          4s    &lt;none&gt;   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-exec-pod   0/1     ContainerCreating   0          9s    &lt;none&gt;   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-exec-pod   1/1     Running             0          16s   172.16.58.195   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>Pod已成功启动，并就绪</p><p><strong>测试启动后钩子是否生效</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">进入Pod</span>kubectl exec -it lifecycle-exec-pod /bin/bash<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">在容器内查看启动后钩子执行的脚本是否生效</span>lifecycle-exec-pod:/# cat /usr/share/messagepostStart</code></pre><p>可以发现 “postStart” 已被写入文件中</p><p><strong>测试关闭前钩子是否生效</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">1.进入Pod容器中</span>kubectl exec -it lifecycle-exec-pod /bin/bash<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">2.在容器内写一段脚本持续读取输出 /usr/share/message</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">脚本内容如下：</span><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">无限循环执行 <span class="built_in">cat</span> /usr/share/message</span>while true; do    cat /usr/share/messagedone<span class="meta prompt_"></span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">3.给脚本授权（容器内操作）</span>chmod +x 123.sh<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">4.执行脚本（容器内操作）</span>sh 123.sh<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">5.新起一个shell终端，执行关闭Pod操作</span>kubectl delete -f 010-hook-exec.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">6.查看脚本打印内容</span>......preStoppreStoppreStop......</code></pre><p>可以看到关闭前钩子在容器被杀死前，执行了 <code>echo preStop &gt; /usr/share/message</code> </p><h2 id="7-3-案例：基于HTTP-Get请求"><a href="#7-3-案例：基于HTTP-Get请求" class="headerlink" title="7.3 案例：基于HTTP Get请求"></a>7.3 案例：基于HTTP Get请求</h2><p><strong>测试容器</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">开启一个测试 webServer</span><span class="meta prompt_">$ </span><span class="language-bash">docker run -itd --<span class="built_in">rm</span> -p 1234:80 --name=<span class="built_in">test</span> wangyanglinux/myapp:v1.0</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">监控测试容器的日志打印情况</span><span class="meta prompt_">$ </span><span class="language-bash">docker logs -f --<span class="built_in">tail</span> 1000 <span class="built_in">test</span></span></code></pre><p><code>011-hook-http.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">lifecycle-http-pod</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myApp</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lifecycle-httpget-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">lifecycle:</span>        <span class="attr">postStart:</span> <span class="comment"># 启动后钩子</span>          <span class="attr">httpGet:</span> <span class="comment"># 基于Http Get 请求方式</span>            <span class="attr">port:</span> <span class="number">1234</span> <span class="comment"># http 访问端口</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span> <span class="comment"># http访问Host地址</span>            <span class="attr">path:</span> <span class="string">index.html</span> <span class="comment"># http访问资源路径</span>        <span class="attr">preStop:</span>          <span class="attr">httpGet:</span>            <span class="attr">port:</span> <span class="number">1234</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span>            <span class="attr">path:</span> <span class="string">hostname.html</span></code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f 011-hook-http.yaml</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看测试容器的日志</span>[root@k8s-master01 /opt/k8s/04]$ docker logs -f --tail 1000 test192.168.6.141 - - [02/Apr/2025:10:26:16 +0800] &quot;GET /index.html HTTP/1.1&quot; 200 48 &quot;-&quot; &quot;kube-lifecycle/1.29&quot;</code></pre><p>pod启动成功，并执行了 postStart 定义的Http Get请求，访问了 <a href="http://192.168.6.139:1234/index.html">http://192.168.6.139:1234/index.html</a> </p><p><strong>停止Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">删除Pod</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl delete -f 011-hook-http.yaml</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看测试容器的日志</span>[root@k8s-master01 /opt/k8s/04]$ docker logs -f --tail 1000 test192.168.6.141 - - [02/Apr/2025:10:26:16 +0800] &quot;GET /index.html HTTP/1.1&quot; 200 48 &quot;-&quot; &quot;kube-lifecycle/1.29&quot;192.168.6.141 - - [02/Apr/2025:10:28:44 +0800] &quot;GET /hostname.html HTTP/1.1&quot; 200 13 &quot;-&quot; &quot;kube-lifecycle/1.29&quot;</code></pre><p>Pod在关闭前，执行了 preStop 定义的Http Get 请求，访问了 <a href="http://192.168.6.139:1234/hostname.html">http://192.168.6.139:1234/hostname.html</a> </p><h2 id="7-4-关于-preStop-的延伸"><a href="#7-4-关于-preStop-的延伸" class="headerlink" title="7.4 关于 preStop 的延伸"></a>7.4 关于 preStop 的延伸</h2><p>在 k8s 中，理想的状态是 pod 优雅释放，但是并不是每一个 Pod 都会这么顺利</p><ul><li>Pod 卡死，处理不了优雅退出的命令或者操作</li><li>优雅退出的逻辑有 BUG，陷入死循环</li><li>代码问题，导致执行的命令没有效果</li></ul><p>对于以上问题，k8s 的 Pod 终止流程中还有一个 “最多可以容忍的时间”，即 grace period ( 在 <code>pod.spec.terminationGracePeriodSeconds</code> 字段定义)，这个值默认是 30 秒，当我们执行 <code>kubectl delete</code>  的时候也可以通过 <code>--grace-period</code> 参数显示指定一个优雅退出时间来覆盖 Pod 中的配置，如果我们配置的 grace period 超过时间之后，k8s 就只能选择强制 kill Pod。值得注意的是，这与preStop Hook和 SIGTERM 信号并行发生。k8s 不会等待 preStop Hook 完成。如果你的应用程序完成关闭并在terminationGracePeriod 完成之前退出，k8s  会立即进入下一步</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">lifecycle-http-pod</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myApp</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lifecycle-httpget-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">lifecycle:</span>        <span class="attr">postStart:</span> <span class="comment"># 启动后钩子</span>          <span class="attr">httpGet:</span> <span class="comment"># 基于Http Get 请求方式</span>            <span class="attr">port:</span> <span class="number">1234</span> <span class="comment"># http 访问端口</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span> <span class="comment"># http访问Host地址</span>            <span class="attr">path:</span> <span class="string">index.html</span> <span class="comment"># http访问资源路径</span>        <span class="attr">preStop:</span>          <span class="attr">httpGet:</span>            <span class="attr">port:</span> <span class="number">1234</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span>            <span class="attr">path:</span> <span class="string">hostname.html</span>  <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span> <span class="comment"># 如果执行 kubectl delete 不能顺利将pod关闭，最长30秒强制杀死pod</span></code></pre><h1 id="8、Pod生命周期完整演示"><a href="#8、Pod生命周期完整演示" class="headerlink" title="8、Pod生命周期完整演示"></a>8、Pod生命周期完整演示</h1><p><code>012-lifecycle-all.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">lifecycle-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox-container</span> <span class="comment"># 主容器1</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/tools:busybox</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;touch /tmp/live ; sleep 600; rm -rf /tmp/live; sleep 3600&quot;</span>]      <span class="attr">livenessProbe:</span> <span class="comment"># 主容器1存活探针</span>        <span class="attr">exec:</span> <span class="comment"># 基于 exec执行命令，探测主容器内文件是否存在</span>          <span class="attr">command:</span> [<span class="string">&quot;test&quot;</span>,<span class="string">&quot;-e&quot;</span>,<span class="string">&quot;/tmp/live&quot;</span>]        <span class="attr">initialDelaySeconds:</span> <span class="number">1</span> <span class="comment"># 容器启动1秒后探测</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span> <span class="comment"># 循环3秒</span>      <span class="attr">lifecycle:</span>        <span class="attr">postStart:</span>          <span class="attr">httpGet:</span>            <span class="attr">port:</span> <span class="number">1234</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span>            <span class="attr">path:</span> <span class="string">index.html</span>        <span class="attr">preStop:</span>          <span class="attr">httpGet:</span>            <span class="attr">port:</span> <span class="number">1234</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span>            <span class="attr">path:</span> <span class="string">hostname.html</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">livenessProbe:</span>        <span class="attr">httpGet:</span>          <span class="attr">port:</span> <span class="number">80</span>          <span class="attr">path:</span> <span class="string">/index.html</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">1</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span>        <span class="attr">timeoutSeconds:</span> <span class="number">3</span> <span class="comment"># http Get 请求超时时间(秒)</span>      <span class="attr">readinessProbe:</span>        <span class="attr">httpGet:</span>          <span class="attr">port:</span> <span class="number">80</span>          <span class="attr">path:</span> <span class="string">/index1.html</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">1</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span>        <span class="attr">timeoutSeconds:</span> <span class="number">3</span>  <span class="attr">initContainers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-myservice</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/tools:busybox</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#x27;</span>]    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-mydb</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/tools:busybox</span>      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#x27;</span>]</code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 012-lifecycle-all.yaml <span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod日志</span>kubectl logs -f --tail=100 lifecycle-pod<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看initC日志</span>kubectl logs -f --tail=100 lifecycle-pod -c init-myservicekubectl logs -f --tail=100 lifecycle-pod -c init-mydb<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">创建initC需要的service</span>kubectl create svc clusterip myservice --tcp=80:80kubectl logs -f --tail=100 lifecycle-pod -c init-myservicekubectl logs -f --tail=100 lifecycle-pod -c init-mydbkubectl create svc clusterip mydb --tcp=80:80<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">进入主容器</span>kubectl exec -it lifecycle-pod -c myapp-container /bin/bash<span class="meta prompt_"># </span><span class="language-bash">创建主容器就绪检测所需资源</span>cd /usr/local/nginx/html/cp index.html index1.html</code></pre><p>完成以上操作后，此Pod才能真正完整运行起来。</p><p><strong>Pod运行监控</strong></p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod -o wide -w</span>NAME            READY   STATUS     RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESlifecycle-pod   0/2     Init:0/2   0          43s   172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-pod   0/2     Init:1/2   0          3m21s   172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-pod   0/2     Init:1/2   0          3m26s   172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-pod   0/2     PodInitializing   0          4m7s    172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-pod   1/2     Running           0          4m17s   172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-pod   2/2     Running           0          5m45s   172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;系统环境&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;RockyLinux：9.3&lt;/p&gt;
&lt;p&gt;K8s版本：1.29&lt;/p&gt;
&lt;p&gt;Docker版本：27.4.1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;1、Pod生命周期概述&quot;&gt;</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>Docker配置网络代理实现外网镜像下载</title>
    <link href="https://georgechan95.github.io/blog/b01d5c62.html"/>
    <id>https://georgechan95.github.io/blog/b01d5c62.html</id>
    <published>2025-01-08T15:00:00.000Z</published>
    <updated>2025-01-08T05:48:23.767Z</updated>
    
    <content type="html"><![CDATA[<p><strong>系统环境</strong></p><blockquote><p>系统：Rocky Linux 9.3</p><p>Docker：27.4.1</p><p>服务器已配置代理，并且可访问外网，具体操作见：<a href="https://georgechan95.github.io/blog/7f174b3e.html">Rocky9安装Shadowsocks实现科学上网</a></p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a><strong>背景</strong></h1><ul><li>部分镜像在国外，国内无法下载</li><li>容器在运行时需要从国外网站下载依赖</li><li>构建自定义镜像时需要访问国外网络</li></ul><h1 id="配置-Dockerd-代理"><a href="#配置-Dockerd-代理" class="headerlink" title="配置 Dockerd 代理"></a>配置 Dockerd 代理</h1><h2 id="新建-docker-代理配置文件"><a href="#新建-docker-代理配置文件" class="headerlink" title="新建 docker 代理配置文件"></a>新建 docker 代理配置文件</h2><p>在执行 docker pull 时，是由守护进程 dockerd 来执行。因此，代理需要配在 dockerd 的环境中。而这个环境，则是受 systemd 所管控，因此实际是 systemd 的配置。</p><pre><code class="highlight shell">sudo mkdir -p /etc/systemd/system/docker.service.dsudo touch /etc/systemd/system/docker.service.d/proxy.conf</code></pre><p>在这个 proxy.conf 文件（可以是任意 *.conf 的形式）中，添加以下内容：</p><pre><code class="highlight shell">[Service]Environment=&quot;HTTP_PROXY=http://127.0.0.1:8118/&quot;Environment=&quot;HTTPS_PROXY=http://127.0.0.1:8118/&quot;Environment=&quot;NO_PROXY=localhost,127.0.0.1&quot;</code></pre><ul><li><p>配置解析</p><p>由于Docker所在服务器已配置代理，可以科学上网，所以代理服务器IP为：127.0.0.1，指代本机。</p><p>服务器配置代理使用的是 Privoxy，默认代理端口：8118</p></li></ul><h2 id="配置生效"><a href="#配置生效" class="headerlink" title="配置生效"></a>配置生效</h2><p>重启docker以及守护进程</p><pre><code class="highlight sheLl">sudo systemctl daemon-reloadsudo systemctl restart docker</code></pre><h2 id="测试镜像拉取"><a href="#测试镜像拉取" class="headerlink" title="测试镜像拉取"></a>测试镜像拉取</h2><p>下载一个国内无法拉取的谷歌镜像，如果成功则表明代理生效。</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">拉取谷歌镜像</span>root@shadowsockts:~# docker pull k8s.gcr.io/kube-proxy:v1.17.17<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看镜像</span>root@shadowsockts:~# docker imagesREPOSITORY              TAG        IMAGE ID       CREATED         SIZEcalico/typha            v3.26.3    5993c7d25ac5   15 months ago   67.4MBk8s.gcr.io/kube-proxy   v1.17.17   3ef67d180564   3 years ago     117MB</code></pre><h1 id="Container-代理"><a href="#Container-代理" class="headerlink" title="Container 代理"></a>Container 代理</h1><p>在容器运行阶段，如果需要代理上网，则需要配置 ~&#x2F;.docker&#x2F;config.json 。以下配置，只在Docker 17.07及以上版本生效。</p><h2 id="修改防火墙配置"><a href="#修改防火墙配置" class="headerlink" title="修改防火墙配置"></a>修改防火墙配置</h2><blockquote><p>方式一：临时关闭防火墙</p><p>禁用 firewalld 和临时关闭 iptables，否则容器无法进行网络代理，防火墙会拦截代理请求</p><pre><code class="highlight shell">systemctl stop firewalld &amp; systemctl disable firewalldsystemctl stop iptables</code></pre></blockquote><blockquote><p>方式二：添加 iptables 规则，允许代理端口通过</p><pre><code class="highlight shell">iptables -I INPUT -p tcp --dport 8118 -j ACCEPTiptables -I FORWARD -p tcp --dport 8118 -j ACCEPTiptables -I OUTPUT -p tcp --dport 8118 -j ACCEPT<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash"><span class="comment"># 如果使用 iptables-services：</span></span>service iptables save<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">如果使用 firewalld：</span>firewall-cmd --runtime-to-permanentfirewall-cmd --reload</code></pre><p>我这里防火墙使用的是 iptables， 如果使用 firewalld 规则配置则不同。</p></blockquote><h2 id="修改-Privoxy-配置文件"><a href="#修改-Privoxy-配置文件" class="headerlink" title="修改 Privoxy 配置文件"></a>修改 Privoxy 配置文件</h2><pre><code class="highlight shell">vim /etc/privoxy/config<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">添加监听IP，192.168.6.221 为Privoxy所在服务器真实IP</span>listen-address  192.168.6.221:8118</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/08/20250108-114726.png" alt="Privoxy 配置文件"></p><h2 id="重启-Privoxy"><a href="#重启-Privoxy" class="headerlink" title="重启 Privoxy"></a>重启 Privoxy</h2><pre><code class="highlight shell">systemctl restart privoxy</code></pre><h2 id="创建-Docker-配置文件"><a href="#创建-Docker-配置文件" class="headerlink" title="创建 Docker 配置文件"></a>创建 Docker 配置文件</h2><p>在 Docker 客户端上，在启动容器的用户的主目录中创建或编辑 ~&#x2F;.docker&#x2F;config.json 文件</p><pre><code class="highlight shell">mkdir ~/.dockervim ~/.docker/config.json<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">编辑内容如下：</span>&#123;    &quot;proxies&quot;:&#123;        &quot;default&quot;:&#123;            &quot;httpProxy&quot;:&quot;http://192.168.6.221:8118&quot;,            &quot;httpsProxy&quot;:&quot;https://192.168.6.221:8118&quot;,            &quot;noProxy&quot;:&quot;localhost&quot;        &#125;    &#125;&#125;<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">重启docker</span>sudo systemctl daemon-reloadsudo systemctl restart docker</code></pre><blockquote><p><strong>将上面 prioxy 服务所在IP 替换成代理服务器真实IP和端口</strong></p></blockquote><ul><li><p>配置解析</p><pre><code class="highlight plaintext">192.168.6.221 为网络代理服务器IP8118 是服务器代理端口。这个是用户级的配置，除了 proxies，docker login 等相关信息也会在其中。而且还可以配置信息展示的格式、插件参数等。此外，容器的网络代理，也可以直接在其运行时通过 -e 注入 http_proxy 等环境变量。这两种方法分别适合不同场景。config.json 非常方便，默认在所有配置修改后启动的容器生效，适合个人开发环境。在CI/CD的自动构建环境、或者实际上线运行的环境中，这种方法就不太合适，用 -e 注入这种显式配置会更好，减轻对构建、部署环境的依赖。当然，在这些环境中，最好用良好的设计避免配置代理上网。</code></pre></li></ul><h2 id="测试-Docker-Container-代理"><a href="#测试-Docker-Container-代理" class="headerlink" title="测试 Docker Container 代理"></a>测试 Docker Container 代理</h2><blockquote><p>创建一个容器，进入容器测试是否可以访问外网</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">创建容器</span>docker run -itd --name centos --restart always centos:7<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">进入容器</span>docker exec -it centos /bin/bash<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看容器内代理配置</span>[root@9d38f88f2411 /]# echo $http_proxyhttp://192.168.204.151:8118[root@9d38f88f2411 /]# echo $https_proxyhttp://192.168.204.151:8118<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">在容器内访问谷歌</span>curl https://www.google.com<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">容器内查看ip</span>[root@shadowsockts /]# curl cip.ccIP: 112.169.175.22地址: 韩国  韩国数据二: 韩国 | KT电信数据三: 韩国 | 韩国电信URL: http://www.cip.cc/112.169.175.22</code></pre></blockquote><h2 id="配置Container代理方式二"><a href="#配置Container代理方式二" class="headerlink" title="配置Container代理方式二"></a>配置Container代理方式二</h2><p>启动容器时，作为环境变量添加进去, 仅对当前启动容器有效。 <strong>这种方式比较常用</strong></p><pre><code class="highlight shell">docker run -itd \    --name centos \    --restart always \    --env &quot;httpProxy:http://192.168.204.151:8118&quot; \    --env &quot;httpsProxy:https://192.168.204.151:8118&quot; \    --env &quot;noProxy:localhost&quot; \    centos:7</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a><strong>参考</strong></h2><p><a href="https://kebingzao.com/2019/02/22/docker-container-proxy/">https://kebingzao.com/2019/02/22/docker-container-proxy/</a></p><p><a href="https://neucrack.com/p/286">https://neucrack.com/p/286</a></p><p><a href="https://hksanduo.github.io/2020/03/07/2020-03-07-docker-container-use-socks5-proxy/">https://hksanduo.github.io/2020/03/07/2020-03-07-docker-container-use-socks5-proxy/</a></p><h1 id="Docker-Build-代理"><a href="#Docker-Build-代理" class="headerlink" title="Docker Build 代理"></a>Docker Build 代理</h1><pre><code class="highlight shell">docker build . \    --build-arg &quot;HTTP_PROXY=http://192.168.204.151:8118&quot; \    --build-arg &quot;HTTPS_PROXY=https://192.168.204.151:8118&quot; \    --build-arg &quot;NO_PROXY=localhost,127.0.0.1,.example.com&quot; \    -t your/image:tag</code></pre><h2 id="参考-1"><a href="#参考-1" class="headerlink" title="参考"></a><strong>参考</strong></h2><p><a href="https://cloud.tencent.com/developer/article/1806455">https://cloud.tencent.com/developer/article/1806455</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;系统环境&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;系统：Rocky Linux 9.3&lt;/p&gt;
&lt;p&gt;Docker：27.4.1&lt;/p&gt;
&lt;p&gt;服务器已配置代理，并且可访问外网，具体操作见：&lt;a href=&quot;https://georgech</summary>
      
    
    
    
    <category term="Docker" scheme="https://georgechan95.github.io/categories/Docker/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="科学上网" scheme="https://georgechan95.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
    
  </entry>
  
  <entry>
    <title>Rocky9安装Shadowsocks实现科学上网</title>
    <link href="https://georgechan95.github.io/blog/7f174b3e.html"/>
    <id>https://georgechan95.github.io/blog/7f174b3e.html</id>
    <published>2025-01-08T13:09:00.000Z</published>
    <updated>2025-01-08T05:20:34.474Z</updated>
    
    <content type="html"><![CDATA[<p><strong>系统环境</strong></p><blockquote><p>系统：Rocky Linux 9.3</p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在一些软件的安装过程中，存在部分安装包和依赖在国外，又由于长城防火墙的拦截，导致下载非常缓慢，经常出现由于网络的原因导致安装失败的情况。为此可以借助一些科学上网的工具，使得服务器可以突破网络限制，实现流畅的访问外网，让服务器软件安装过程更加顺利。</p><p>我这里是通过安装 <code>Shadowsocks</code>，并设置可访问外网的服务器配置（需提前购买外网云服务，即：梯子，<a href="https://azabudai.org/auth/register?code=tGfK">注册链接:</a> <a href="https://azabudai.org/auth/register?code=tGfK">https://azabudai.org/auth/register?code=tGfK</a> 邀请码：<code>tGfK</code> ），再安装Privoxy，设置系统代理实现外网访问。</p><h1 id="安装-PIP"><a href="#安装-PIP" class="headerlink" title="安装 PIP"></a>安装 PIP</h1><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">更新系统软件包</span>dnf update -y<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">安装python</span>dnf install python39 -y<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看python安装版本</span>python3.9 --version<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">安装pip</span>dnf install python3.9-pip<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看pip3版本</span>pip3 --version<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">更新pip3安装版本</span>pip3 install --upgrade pip<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看pip3版本</span>pip3 --version<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看pip3帮助信息</span>pip3 --help</code></pre><h1 id="安装和配置-Shadowsocks"><a href="#安装和配置-Shadowsocks" class="headerlink" title="安装和配置 Shadowsocks"></a>安装和配置 Shadowsocks</h1><h2 id="使用-pip3-安装-Shadowsocks"><a href="#使用-pip3-安装-Shadowsocks" class="headerlink" title="使用 pip3 安装 Shadowsocks"></a>使用 pip3 安装 Shadowsocks</h2><pre><code class="highlight shell">sudo pip3 install -y shadowsocks</code></pre><h2 id="配置-shadowsocks"><a href="#配置-shadowsocks" class="headerlink" title="配置 shadowsocks"></a>配置 shadowsocks</h2><blockquote><p>新建配置文件夹和文件</p><pre><code class="highlight shell">sudo mkdir /etc/shadowsockssudo vim /etc/shadowsocks/shadowsocks.json</code></pre><ul><li><p>配置内容如下：</p><pre><code class="highlight json"><span class="punctuation">&#123;</span>    <span class="attr">&quot;server&quot;</span><span class="punctuation">:</span> <span class="string">&quot;替换成自己的服务器ip或域名&quot;</span><span class="punctuation">,</span>    <span class="attr">&quot;local_address&quot;</span><span class="punctuation">:</span> <span class="string">&quot;127.0.0.1&quot;</span><span class="punctuation">,</span>    <span class="attr">&quot;local_port&quot;</span><span class="punctuation">:</span> <span class="number">1080</span><span class="punctuation">,</span>    <span class="attr">&quot;timeout&quot;</span><span class="punctuation">:</span> <span class="number">300</span><span class="punctuation">,</span>    <span class="attr">&quot;workers&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span>    <span class="attr">&quot;server_port&quot;</span><span class="punctuation">:</span> <span class="number">31558</span><span class="punctuation">,</span>    <span class="attr">&quot;password&quot;</span><span class="punctuation">:</span> <span class="string">&quot;替换成自己的服务器密码&quot;</span><span class="punctuation">,</span>    <span class="attr">&quot;method&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rc4-md5&quot;</span><span class="punctuation">,</span>    <span class="attr">&quot;plugin&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">&#125;</span></code></pre></li><li><p>配置解析</p><pre><code class="highlight shell">server：Shadowsocks 服务器地址server_port：Shadowsocks 服务器端口local_address：本地 Sock5 代理地址local_port：本地 Sock5 代理端口password：Shadowsocks 连接密码timeout：超时等待时间（秒）method：加密方式workers：工作线程数</code></pre></li></ul></blockquote><h2 id="启动脚本"><a href="#启动脚本" class="headerlink" title="启动脚本"></a>启动脚本</h2><p>创建启动脚本 <code>/etc/systemd/system/shadowsocks.service</code></p><p>这里请确认你的 sslocal 的所在位置，自行修改脚本文件中的 <code>/usr/local/bin/sslocal</code>，<strong>位置不对启动服务时会报 203 错误</strong></p><blockquote><p>确认 sslocal 所在路径</p><pre><code class="highlight shell">[root@localhost ~]# ls /usr/local/bin/sslocal/usr/local/bin/sslocal</code></pre></blockquote><blockquote><p>创建Shadowsocks启动脚本</p><pre><code class="highlight shell">sudo vim /etc/systemd/system/shadowsocks.service</code></pre><ul><li><p>内容如下：</p><pre><code class="highlight shell">[Unit]Description=Shadowsocks  [Service]TimeoutStartSec=0ExecStart=/usr/local/bin/sslocal -c /etc/shadowsocks/shadowsocks.json  [Install]WantedBy=multi-user.target</code></pre></li></ul></blockquote><blockquote><p>启动脚本授权</p><pre><code class="highlight shell">chmod 755 /usr/local/bin/sslocal</code></pre></blockquote><h2 id="shadowsocks-启动命令"><a href="#shadowsocks-启动命令" class="headerlink" title="shadowsocks 启动命令"></a>shadowsocks 启动命令</h2><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">开机自启动</span>sudo systemctl enable shadowsocks.service<span class="meta prompt_"># </span><span class="language-bash">启动服务</span>sudo systemctl start shadowsocks.service<span class="meta prompt_"># </span><span class="language-bash">查看状态</span>sudo systemctl status shadowsocks.service<span class="meta prompt_"># </span><span class="language-bash">停止服务</span>sudo systemctl stop shadowsocks.service</code></pre><h2 id="启动-shadowsocks-发现错误"><a href="#启动-shadowsocks-发现错误" class="headerlink" title="启动 shadowsocks 发现错误"></a>启动 shadowsocks 发现错误</h2><p>执行 <code>sudo systemctl status shadowsocks.service</code> 出现报错：</p><pre><code class="highlight shell">× shadowsocks.service - Shadowsocks     Loaded: loaded (/etc/systemd/system/shadowsocks.service; enabled; preset: disabled)     Active: failed (Result: exit-code) since Wed 2025-01-08 09:58:27 CST; 5s ago   Duration: 70ms    Process: 4756 ExecStart=/usr/local/bin/sslocal -c /etc/shadowsocks/shadowsocks.json (code=exited, status=1/FAILURE)   Main PID: 4756 (code=exited, status=1/FAILURE)        CPU: 66msJan 08 09:58:27 localhost.localdomain sslocal[4756]:     load_openssl()Jan 08 09:58:27 localhost.localdomain sslocal[4756]:   File &quot;/usr/local/lib/python3.9/site-packages/shadowsocks/crypto/openssl.py&quot;, line 52, in load_opensslJan 08 09:58:27 localhost.localdomain sslocal[4756]:     libcrypto.EVP_CIPHER_CTX_cleanup.argtypes = (c_void_p,)Jan 08 09:58:27 localhost.localdomain sslocal[4756]:   File &quot;/usr/lib64/python3.9/ctypes/__init__.py&quot;, line 387, in __getattr__Jan 08 09:58:27 localhost.localdomain sslocal[4756]:     func = self.__getitem__(name)Jan 08 09:58:27 localhost.localdomain sslocal[4756]:   File &quot;/usr/lib64/python3.9/ctypes/__init__.py&quot;, line 392, in __getitem__Jan 08 09:58:27 localhost.localdomain sslocal[4756]:     func = self._FuncPtr((name_or_ordinal, self))Jan 08 09:58:27 localhost.localdomain sslocal[4756]: AttributeError: /lib64/libcrypto.so.3: undefined symbol: EVP_CIPHER_CTX_cleanupJan 08 09:58:27 localhost.localdomain systemd[1]: shadowsocks.service: Main process exited, code=exited, status=1/FAILUREJan 08 09:58:27 localhost.localdomain systemd[1]: shadowsocks.service: Failed with result &#x27;exit-code&#x27;.[root@localhost ~]# vim /usr/local/lib/python3.9/site-packages/shadowsocks/crypto/openssl.py</code></pre><blockquote><p><strong>解决方式：</strong> 把所有的 <code>EVP_CIPHER_CTX_cleanup</code> 都改成 <code>EVP_CIPHER_CTX_reset</code> 就行。</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">替换文本内容</span>sudo sed -i &#x27;s/EVP_CIPHER_CTX_cleanup/EVP_CIPHER_CTX_reset/g&#x27; /usr/local/lib/python3.9/site-packages/shadowsocks/crypto/openssl.py<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">重启 shadowsockts</span>sudo systemctl restart shadowsocks.service</code></pre><p>参考：<a href="https://www.yangyang.cloud/blog/2020/09/23/solved-shadowsocks-undefined-symbol/">https://www.yangyang.cloud/blog/2020/09/23/solved-shadowsocks-undefined-symbol/</a></p><p>参考：<a href="http://qiushao.net/2019/11/14/Linux/ubuntu-shadowsocks/">http://qiushao.net/2019/11/14/Linux/ubuntu-shadowsocks/</a></p></blockquote><p>修改完之后，发现依然报错：</p><blockquote><p><strong>报错内容：</strong></p><pre><code class="highlight shell">INFO: loading config from /etc/shadowsocks/shadowsocks.json2025-01-08 10:18:44 INFO     loading libcrypto from libcrypto.so.3Traceback (most recent call last):  File &quot;/usr/local/bin/sslocal&quot;, line 8, in &lt;module&gt;    sys.exit(main())  File &quot;/usr/local/lib/python3.9/site-packages/shadowsocks/local.py&quot;, line 39, in main    config = shell.get_config(True)  File &quot;/usr/local/lib/python3.9/site-packages/shadowsocks/shell.py&quot;, line 262, in get_config    check_config(config, is_local)  File &quot;/usr/local/lib/python3.9/site-packages/shadowsocks/shell.py&quot;, line 124, in check_config    encrypt.try_cipher(config[&#x27;password&#x27;], config[&#x27;method&#x27;])  File &quot;/usr/local/lib/python3.9/site-packages/shadowsocks/encrypt.py&quot;, line 44, in try_cipher    Encryptor(key, method)  File &quot;/usr/local/lib/python3.9/site-packages/shadowsocks/encrypt.py&quot;, line 82, in __init__    self.cipher = self.get_cipher(key, method, 1,  File &quot;/usr/local/lib/python3.9/site-packages/shadowsocks/encrypt.py&quot;, line 109, in get_cipher    return m[2](method, key, iv, op)  File &quot;/usr/local/lib/python3.9/site-packages/shadowsocks/crypto/rc4_md5.py&quot;, line 33, in create_cipher    return openssl.OpenSSLCrypto(b&#x27;rc4&#x27;, rc4_key, b&#x27;&#x27;, op)  File &quot;/usr/local/lib/python3.9/site-packages/shadowsocks/crypto/openssl.py&quot;, line 92, in __init__    raise Exception(&#x27;can not initialize cipher context&#x27;)Exception: can not initialize cipher contextSegmentation fault (core dumped)</code></pre><ul><li><p>解决方式：开启 RC4-MD5 支持</p><p>参考链接：<a href="https://blog.vinsonws.cn/2023/05/25/openssl-openssl3-%E5%A6%82%E4%BD%95%E5%BC%80%E5%90%AF-rc4-md5-%E6%94%AF%E6%8C%81/">https://blog.vinsonws.cn/2023/05/25/openssl-openssl3-%E5%A6%82%E4%BD%95%E5%BC%80%E5%90%AF-rc4-md5-%E6%94%AF%E6%8C%81/</a></p><ul><li><p>编辑 openssl.cnf</p><pre><code class="highlight shell">vi /etc/ssl/openssl.cnf</code></pre><p>在 provider_sect 下添加 legacy &#x3D; legacy_sect</p><pre><code class="highlight shell">[provider_sect]legacy = legacy_sect</code></pre><p>然后，将</p><pre><code class="highlight shell">[default_sect]<span class="meta prompt_"># </span><span class="language-bash">activate = 1</span></code></pre><p>替换为</p><pre><code class="highlight shell">[default_sect]activate = 1[legacy_sect]activate = 1</code></pre><p>重新启动程序测试</p><pre><code class="highlight shell">[root@localhost ~]# /usr/local/bin/sslocal -c /etc/shadowsocks/shadowsocks.jsonINFO: loading config from /etc/shadowsocks/shadowsocks.json2025-01-08 10:26:30 INFO     loading libcrypto from libcrypto.so.32025-01-08 10:26:30 INFO     starting local at 127.0.0.1:1080</code></pre><p>启动 shadowsockts</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">重启 shadowsockts</span>sudo systemctl restart shadowsocks.service</code></pre></li></ul></li></ul></blockquote><h1 id="安装和配置-Privoxy"><a href="#安装和配置-Privoxy" class="headerlink" title="安装和配置 Privoxy"></a>安装和配置 Privoxy</h1><h2 id="安装-Privoxy"><a href="#安装-Privoxy" class="headerlink" title="安装 Privoxy"></a>安装 Privoxy</h2><pre><code class="highlight shell">dnf install -y privoxy</code></pre><h2 id="修改-privoxy-配置"><a href="#修改-privoxy-配置" class="headerlink" title="修改 privoxy 配置"></a>修改 privoxy 配置</h2><pre><code class="highlight shell">修改配置 vim /etc/privoxy/config<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">搜索 forward-socks5t，将 forward-socks5t / 127.0.0.1:9050 . 取消注释并修改为</span>forward-socks5t / 127.0.0.1:1080 .  # 注意最后有个点<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">然后取消以下几行代码注释，本地网络不翻墙</span>forward         192.168.*.*/     .forward            10.*.*.*/     .forward           127.*.*.*/     .forward           localhost/     .</code></pre><h2 id="启动-privoxy"><a href="#启动-privoxy" class="headerlink" title="启动 privoxy"></a>启动 privoxy</h2><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">设置开机自启</span>systemctl enable privoxy<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">启动privoxy(这一步需要在读取配置文件之前执行))</span>systemctl start privoxy<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看privoxy状态</span>systemctl status privoxy<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">停止</span>systemctl stop privoxy</code></pre><p>privoxy 读取配置</p><pre><code class="highlight shell">privoxy /etc/privoxy/config</code></pre><h1 id="配置系统环境变量"><a href="#配置系统环境变量" class="headerlink" title="配置系统环境变量"></a>配置系统环境变量</h1><h2 id="修改-etc-profile"><a href="#修改-etc-profile" class="headerlink" title="修改 &#x2F;etc&#x2F;profile"></a>修改 &#x2F;etc&#x2F;profile</h2><pre><code class="highlight shell">vim /etc/profile<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">添加如下内容:</span>export http_proxy=http://127.0.0.1:8118export https_proxy=http://127.0.0.1:8118export all_proxy=http://127.0.0.1:8118</code></pre><h2 id="使配置生效"><a href="#使配置生效" class="headerlink" title="使配置生效"></a>使配置生效</h2><pre><code class="highlight shell">source /etc/profile</code></pre><h2 id="测试网络代理"><a href="#测试网络代理" class="headerlink" title="测试网络代理"></a>测试网络代理</h2><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">测试wget下载谷歌首页</span>wget www.google.com<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">测试 curl</span>curl https://www.google.com</code></pre><h2 id="停止网络代理"><a href="#停止网络代理" class="headerlink" title="停止网络代理"></a>停止网络代理</h2><p>不需要使用代理时停止网络代理，节约流量。</p><p>注释掉网络代理设置，并使环境变量生效</p><pre><code class="highlight shell">vim /etc/profile<span class="meta prompt_"># </span><span class="language-bash">注释掉网络代理环境变量</span><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">export</span> http_proxy=http://127.0.0.1:8118</span><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">export</span> https_proxy=http://127.0.0.1:8118</span><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">export</span> all_proxy=http://127.0.0.1:8118</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">使配置生效</span>source /etc/profileunset http_proxyunset https_proxyunset all_proxy</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://ry.huaji.store/2020/08/Linux-magic-network/">https://ry.huaji.store/2020/08/Linux-magic-network/</a></li><li><a href="https://andblog.cn/2587">https://andblog.cn/2587</a></li><li><a href="https://witee.github.io/2019/02/19/centos7%E4%BD%BF%E7%94%A8privoxy%E9%85%8D%E5%90%88shadowsocks%E7%BF%BB%E5%A2%99/">https://witee.github.io/2019/02/19/centos7%E4%BD%BF%E7%94%A8privoxy%E9%85%8D%E5%90%88shadowsocks%E7%BF%BB%E5%A2%99/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;系统环境&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;系统：Rocky Linux 9.3&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/</summary>
      
    
    
    
    <category term="linux" scheme="https://georgechan95.github.io/categories/linux/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="科学上网" scheme="https://georgechan95.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>003-基于Rocky9.3系统使用kubeadm安装k8s1.29集群</title>
    <link href="https://georgechan95.github.io/blog/b00f53e9.html"/>
    <id>https://georgechan95.github.io/blog/b00f53e9.html</id>
    <published>2025-01-03T14:05:00.000Z</published>
    <updated>2025-01-08T06:21:16.851Z</updated>
    
    <content type="html"><![CDATA[<p><strong>系统环境</strong></p><blockquote><p>RockyLinux：9.3</p><p>K8s版本：1.29</p><p>Docker版本：27.4.1</p></blockquote><p><strong>软件包来源</strong></p><blockquote><p>系统镜像下载官网：<a href="https://rockylinux.org/zh-CN/download">https://rockylinux.org/zh-CN/download</a></p><p>镜像下载地址：<a href="https://dl.rockylinux.org/vault/rocky/9.3/isos/x86_64/">https://dl.rockylinux.org/vault/rocky/9.3/isos/x86_64/</a></p><p>安装镜像文件：Rocky-9.3-x86_64-minimal.iso</p></blockquote><h1 id="1、集群规划"><a href="#1、集群规划" class="headerlink" title="1、集群规划"></a>1、集群规划</h1><p>基于 Linux Rocky 9.3 系统使用 <code>kubeadm</code> 搭建一主两从的 k8s 集群。</p><table><thead><tr><th>IP地址</th><th>主机名</th><th>角色</th><th>系统版本</th><th>CPU&#x2F;内存&#x2F;磁盘</th></tr></thead><tbody><tr><td>192.168.6.223</td><td>k8s-master01</td><td>管理节点</td><td>Rocky Linux 9.3</td><td>2U&#x2F;4G&#x2F;100G</td></tr><tr><td>192.168.6.225</td><td>k8s-node01</td><td>部署节点</td><td>Rocky Linux 9.3</td><td>2U&#x2F;4G&#x2F;100G</td></tr><tr><td>192.168.6.226</td><td>k8s-node02</td><td>部署节点</td><td>Rocky Linux 9.3</td><td>2U&#x2F;4G&#x2F;100G</td></tr></tbody></table><h1 id="2、集群基础环境配置"><a href="#2、集群基础环境配置" class="headerlink" title="2、集群基础环境配置"></a>2、集群基础环境配置</h1><h2 id="2-1-主机名设置"><a href="#2-1-主机名设置" class="headerlink" title="2.1 主机名设置"></a>2.1 主机名设置</h2><p>设置集群中各个节点的主机名</p><blockquote><p>master01 节点执行</p><pre><code class="highlight shell">hostnamectl set-hostname k8s-master01</code></pre></blockquote><blockquote><p>node01 节点执行</p><pre><code class="highlight shell">hostnamectl set-hostname k8s-node01</code></pre></blockquote><blockquote><p>node02 节点执行</p><pre><code class="highlight shell">hostnamectl set-hostname k8s-node02</code></pre></blockquote><h2 id="2-2-修改hosts文件"><a href="#2-2-修改hosts文件" class="headerlink" title="2.2 修改hosts文件"></a>2.2 修改hosts文件</h2><p>配置集群各节点 hostname 和 ip 的映射</p><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">cat &gt;&gt; /etc/hosts &lt;&lt; &quot;EOF&quot;192.168.6.223 k8s-master01192.168.6.225 k8s-node01192.168.6.226 k8s-node02EOF</code></pre></blockquote><h2 id="2-3-修改终端颜色"><a href="#2-3-修改终端颜色" class="headerlink" title="2.3 修改终端颜色"></a>2.3 修改终端颜色</h2><p>这里只是修改shell终端显示文本的颜色，非必要步骤。</p><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">cat &lt;&lt; EOF &gt;&gt; ~/.bashrcPS1=&quot;\[\e[37;47m\][\[\e[32;47m\]\u\[\e[34;47m\]@\h \[\e[36;47m\]\w\[\e[0m\]]\\$ &quot;EOF<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">让修改立即见效</span>source ~/.bashrc</code></pre></blockquote><blockquote><p><strong>命令解析：</strong>这段命令用于修改当前用户的 <strong>Bash Shell 提示符</strong>（<code>PS1</code>），并将其设置写入到 <code>~/.bashrc</code> 文件中，以便在每次登录或启动 Shell 时自动加载该配置。</p><pre><code class="highlight plaintext">PS1=&quot;...&quot;定义 Shell 的主提示符格式（Prompt String 1），即你在终端中输入命令时显示的提示符。</code></pre><p>最终效果如下：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/04/20250104-112243.png" alt="终端颜色修改"></p></blockquote><h2 id="2-4-更换系统软件源"><a href="#2-4-更换系统软件源" class="headerlink" title="2.4 更换系统软件源"></a>2.4 更换系统软件源</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">更新源</span>sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \    -e &#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27; \    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo    <span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">刷新dnf缓存</span>dnf makecache<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">验证源更新</span>dnf repolist</code></pre></blockquote><ul><li><p>命令解析</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">使用 sed 命令修改 Rocky Linux 的 YUM/DNF 源配置文件，切换到阿里云的镜像源。</span>sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \    -e &#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27; \    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo    <span class="meta prompt_"># </span><span class="language-bash">将以 mirrorlist= 开头的行注释掉（在前面加 <span class="comment">#）</span></span>-e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27;<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">将以 <span class="comment">#baseurl= 开头并指向默认 Rocky Linux 源的行取消注释，并替换为阿里云镜像源 URL。</span></span>&#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27;<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">-i.bak：直接修改文件，并为原文件创建备份（扩展名为 .bak）。</span><span class="meta prompt_"># </span><span class="language-bash">修改 /etc/yum.repos.d/ 目录下所有以 rocky 或 Rocky 开头的 .repo 文件。</span><span class="meta prompt_"># </span><span class="language-bash">修改完成后，原始文件会被备份为 .bak 文件。</span>-i.bak /etc/yum.repos.d/[Rr]ocky*.repo<span class="meta prompt_"></span><span class="meta prompt_"></span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">更新本地缓存，确保系统可以快速查询软件包信息。</span>dnf makecache</code></pre></li></ul><h2 id="2-5-修改防火墙"><a href="#2-5-修改防火墙" class="headerlink" title="2.5 修改防火墙"></a>2.5 修改防火墙</h2><p>防火墙修改 firewalld 为 iptables</p><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">systemctl stop firewalldsystemctl disable firewalldyum -y install iptables-servicessystemctl start iptablesiptables -Fsystemctl enable iptablesservice iptables save</code></pre></blockquote><ul><li><p>命令解析</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">停止运行 firewalld</span>systemctl stop firewalld<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">禁止 firewalld 开机自启</span>systemctl disable firewalld<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">安装 iptables 服务，用于管理 Linux 的防火墙规则</span>yum -y install iptables-services<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">使防火墙规则立即生效，并开始运行 iptables 防火墙服务。</span>systemctl start iptables<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">删除当前的防火墙规则，通常用于重置或清理防火墙规则。</span>iptables -F<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置 iptables 服务开机自启动，确保服务器重启后，iptables 服务会自动加载防火墙规则。</span>systemctl enable iptables<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">将当前 iptables 的规则配置保存到文件中（通常是 /etc/sysconfig/iptables），以便在系统重启或 iptables 服务重新启动后，能够自动加载保存的规则。</span>service iptables save</code></pre></li></ul><h2 id="2-6-禁用-Selinux"><a href="#2-6-禁用-Selinux" class="headerlink" title="2.6 禁用 Selinux"></a>2.6 禁用 Selinux</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">setenforce 0sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/configgrubby --update-kernel ALL --args selinux=0</code></pre></blockquote><ul><li><p>命令解析</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">将 SELinux 的模式设置为 Permissive（宽容模式）。</span><span class="meta prompt_"># </span><span class="language-bash">0：表示设置为 Permissive 模式，此模式下 SELinux 不会强制执行安全策略，而是记录违规日志。</span><span class="meta prompt_"># </span><span class="language-bash">1：表示 Enforcing 模式，此模式下 SELinux 会强制执行安全策略。</span>setenforce 0<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">修改 SELinux 配置文件 /etc/selinux/config，将 SELINUX 设置为 disabled。永久禁用 SELinux，即使系统重启也不会再启用。</span>sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">通过 grubby 工具将 selinux=0 参数添加到所有内核启动配置中。</span>grubby --update-kernel ALL --args selinux=0grubby --info DEFAULT<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看是否禁用，</span>grubby --info DEFAULT<span class="meta prompt_"># </span><span class="language-bash">回滚内核层禁用操作，、</span>grubby --update-kernel ALL --remove-args selinux</code></pre></li><li><p>修改完成后重启系统</p><pre><code class="highlight shell">reboot</code></pre></li></ul><h2 id="2-7-设置时区"><a href="#2-7-设置时区" class="headerlink" title="2.7 设置时区"></a>2.7 设置时区</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">timedatectl set-timezone Asia/Shanghai</code></pre></blockquote><h2 id="2-8-集群时间同步设置"><a href="#2-8-集群时间同步设置" class="headerlink" title="2.8 集群时间同步设置"></a>2.8 集群时间同步设置</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">timedatectldnf install -y chronysystemctl enable chronyd.servicesystemctl restart chronyd.servicesystemctl status chronyd.servicevim /etc/chrony.conf<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">修改完chrony配置后，重启chrony服务</span>systemctl enable chronyd  --now</code></pre><ul><li><p>chrony配置内容如下</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">添加阿里云NTP服务器</span>pool ntp1.aliyun.com iburstpool ntp2.aliyun.com iburstpool cn.pool.ntp.org iburst    <span class="meta prompt_"># </span><span class="language-bash">允许指定网段访问此时间服务器，不然只允许本地网络</span>allow 192.168.0.0/16</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-195813.png" alt="chrony配置内容"></p></li></ul></blockquote><ul><li><p>命令解析</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">检查时区和时间</span>timedatectl<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">安装chrony进行时间同步，ntpdate在Rocky 9中不再支持</span>dnf install -y chrony<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">启用chronyd服务</span>systemctl enable chronyd.service<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">重启chronyd服务</span>systemctl restart chronyd.service<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看chronyd服务状态</span>systemctl status chronyd.service</code></pre></li></ul><h2 id="2-9-修改系统最大打开文件数"><a href="#2-9-修改系统最大打开文件数" class="headerlink" title="2.9 修改系统最大打开文件数"></a>2.9 修改系统最大打开文件数</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><p>在 <code>/etc/security/limits.conf</code> 文件的末尾追加以下内容</p><pre><code class="highlight shell">*softnofile65535*hardnofile65535</code></pre><p>目的：修改最大打开文件数限制</p></blockquote><h2 id="2-10-安装必要的库和修改-sysctl-conf-内核参数配置"><a href="#2-10-安装必要的库和修改-sysctl-conf-内核参数配置" class="headerlink" title="2.10 安装必要的库和修改 sysctl.conf 内核参数配置"></a>2.10 安装必要的库和修改 <code>sysctl.conf</code> 内核参数配置</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">dnf install -y epel-releasednf install -y bridge-utilsmodprobe br_netfilterecho &#x27;br_netfilter&#x27; &gt;&gt; /etc/modules-load.d/bridge.confcat &gt;&gt; /etc/sysctl.conf &lt;&lt;EOFnet.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-ip6tables=1net.ipv4.ip_forward=1net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_tw_buckets = 20480net.ipv4.tcp_max_syn_backlog = 20480net.core.netdev_max_backlog = 262144net.ipv4.tcp_fin_timeout = 20EOF<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">重新加载 /etc/sysctl.conf 中的所有内核参数配置，并使其立即生效。</span>sysctl -p</code></pre></blockquote><ul><li><p>命令解释</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">安装 EPEL（Extra Packages <span class="keyword">for</span> Enterprise Linux） 仓库的 Release 包。</span><span class="meta prompt_"># </span><span class="language-bash">EPEL 是由 Fedora 社区维护的一个软件仓库，提供许多额外的软件包，这些包在默认的 RHEL（或其衍生版如 CentOS、Rocky Linux 等）中没有包含。</span>yum install -y epel-release<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">安装 bridge-utils 软件包。</span><span class="meta prompt_"># </span><span class="language-bash">bridge-utils 是一个 Linux 工具集，用于创建和管理网络桥接（bridging）。</span>yum install -y bridge-utils<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">加载 br_netfilter 内核模块。</span><span class="meta prompt_"># </span><span class="language-bash">该模块用于启用网络桥接（bridge）时的流量过滤功能。</span><span class="meta prompt_"># </span><span class="language-bash">允许通过桥接的网络流量被 iptables 规则管理。</span><span class="meta prompt_"># </span><span class="language-bash">在容器或虚拟化环境中，确保桥接网络的流量可以被正确处理。</span>modprobe br_netfilter<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">将 br_netfilter 模块名称添加到 /etc/modules-load.d/bridge.conf 文件中。</span><span class="meta prompt_"># </span><span class="language-bash">配置系统在启动时自动加载 br_netfilter 模块。</span>echo &#x27;br_netfilter&#x27; &gt;&gt; /etc/modules-load.d/bridge.conf<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">向 /etc/sysctl.conf 文件添加配置，使桥接流量可以通过 iptables 规则管理。</span><span class="meta prompt_"># </span><span class="language-bash">启用桥接网络上的 IPv4 流量通过 iptables 的规则处理。</span>net.bridge.bridge-nf-call-iptables=1<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">向 /etc/sysctl.conf 文件添加配置，使桥接流量中的 IPv6 流量可以通过 ip6tables 规则管理。</span>net.bridge.bridge-nf-call-ip6tables=1<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">向 /etc/sysctl.conf 文件添加配置，启用 IP 转发功能。</span><span class="meta prompt_"># </span><span class="language-bash">用途：在容器网络或 Kubernetes 集群中，允许跨子网通信。</span>net.ipv4.ip_forward=1<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">启用 TCP SYN Cookie 技术，用于防范 SYN Flood 攻击。</span><span class="meta prompt_"># </span><span class="language-bash">在服务器收到大量的 TCP SYN 请求但无法分配足够资源时，启用 SYN Cookie 可通过一种临时编码方式验证连接合法性，避免资源耗尽。</span>net.ipv4.tcp_syncookies = 1<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置系统同时保持的 TCP TIME_WAIT 状态的连接数上限。达到上限后，系统会直接丢弃多余的连接（而不是继续占用资源）。</span><span class="meta prompt_"># </span><span class="language-bash">默认值180000,对于高并发的 Web 服务器或反向代理，适当调低该值（如 20480）以避免 TIME_WAIT 数量过多。</span>net.ipv4.tcp_max_tw_buckets = 20480<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置 TCP 三次握手中 SYN 请求的队列长度上限。</span><span class="meta prompt_"># </span><span class="language-bash">当服务器接收的 SYN 请求超过该值时，新的连接请求会被丢弃。</span><span class="meta prompt_"># </span><span class="language-bash">如果服务器负载较高且连接数较多，可以调高到 20480 或更高。</span>net.ipv4.tcp_max_syn_backlog = 20480<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置网络设备接收队列的最大长度。</span><span class="meta prompt_"># </span><span class="language-bash">如果接收队列中的数据包数量超过该值，内核将直接丢弃后续数据包。</span><span class="meta prompt_"># </span><span class="language-bash">在高流量环境中，设置为较高值（如 262144）以避免丢包，提高吞吐量。</span>net.core.netdev_max_backlog = 262144<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置 TCP 连接处于 FIN_WAIT2 状态的超时时间（单位：秒）。</span><span class="meta prompt_"># </span><span class="language-bash">FIN_WAIT2 状态表示服务端已发送 FIN 包等待客户端确认，此状态会持续占用资源。</span><span class="meta prompt_"># </span><span class="language-bash">默认值：通常为 60 秒。</span><span class="meta prompt_"># </span><span class="language-bash">在高并发服务器上，将该值调低（如 20）以减少 FIN_WAIT2 状态的资源占用。</span>net.ipv4.tcp_fin_timeout = 20<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">重新加载 /etc/sysctl.conf 中的所有内核参数配置，并使其立即生效。</span>sysctl -p</code></pre></li></ul><h2 id="2-11-关闭-swap-分区"><a href="#2-11-关闭-swap-分区" class="headerlink" title="2.11 关闭 swap 分区"></a>2.11 关闭 swap 分区</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">swapoff -ased -i &#x27;s:/dev/mapper/rl-swap:#/dev/mapper/rl-swap:g&#x27; /etc/fstab</code></pre></blockquote><ul><li><p>命令解释</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash"> 立即关闭系统中所有的交换分区</span>swapoff -a<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">注释掉 /etc/fstab 文件中定义的交换分区挂载条目，防止系统在重启后重新启用交换分区。</span>sed -i &#x27;s:/dev/mapper/rl-swap:#/dev/mapper/rl-swap:g&#x27; /etc/fstab<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">验证交换分区是否关系</span>free -h输出中 Swap 一栏的值会变为 0。</code></pre></li></ul><h1 id="3、集群各个节点安装Docker服务"><a href="#3、集群各个节点安装Docker服务" class="headerlink" title="3、集群各个节点安装Docker服务"></a>3、集群各个节点安装Docker服务</h1><h2 id="3-1-添加-docker-ce-yum-源"><a href="#3-1-添加-docker-ce-yum-源" class="headerlink" title="3.1 添加 docker-ce yum 源"></a>3.1 添加 docker-ce yum 源</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">sudo dnf config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.reposudo sed -i &#x27;s+download.docker.com+mirrors.aliyun.com/docker-ce+&#x27; /etc/yum.repos.d/docker-ce.reposudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</code></pre></blockquote><ul><li><p>命令解析</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">使用 dnf config-manager 命令添加 Docker 软件包的官方仓库（在这里是阿里云的镜像）。</span>sudo dnf config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">修改 docker-ce.repo 文件中的镜像源地址，将默认的 download.docker.com 替换为阿里云的镜像地址 mirrors.aliyun.com/docker-ce。</span>sudo sed -i &#x27;s+download.docker.com+mirrors.aliyun.com/docker-ce+&#x27; /etc/yum.repos.d/docker-ce.repo<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">安装最新版本docker</span>sudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</code></pre></li></ul><h2 id="3-2-开启Docker服务"><a href="#3-2-开启Docker服务" class="headerlink" title="3.2 开启Docker服务"></a>3.2 开启Docker服务</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">systemctl start dockersystemctl enable docker</code></pre></blockquote><h2 id="3-3-配置-daemon-json"><a href="#3-3-配置-daemon-json" class="headerlink" title="3.3 配置 daemon.json"></a>3.3 配置 daemon.json</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">cat &gt;&gt;/etc/docker/daemon.json &lt;&lt;EOF&#123;  &quot;log-driver&quot;: &quot;json-file&quot;,  &quot;log-opts&quot;: &#123;        &quot;max-size&quot;: &quot;100m&quot;,        &quot;max-file&quot;: &quot;10&quot;  &#125;,  &quot;data-root&quot;:&quot;/data/docker&quot;,  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],  &quot;registry-mirrors&quot;: [   &quot;https://kfp63jaj.mirror.aliyuncs.com&quot;,    &quot;https://hub-mirror.c.163.com&quot;,    &quot;https://mirror.baidubce.com&quot;  ]&#125;EOF</code></pre></blockquote><ul><li><p>配置解析</p><pre><code class="highlight shell">&quot;data-root&quot;: &quot;/data/docker&quot;指定 Docker 数据的存储目录为 /data/docker。包括容器、镜像、卷等内容。默认存储在 /var/lib/docker，此配置用于更改默认路径。&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]配置 Docker 使用 systemd 作为 Cgroup 驱动程序。推荐在使用现代 Linux 发行版（如 Rocky Linux 9）或 Kubernetes 时采用此配置，以实现更好的资源管理和兼容性。&quot;log-driver&quot;: &quot;json-file&quot;指定 Docker 的日志驱动为 json-file。json-file 是 Docker 默认的日志存储方式，将日志保存在 JSON 文件中。&quot;log-opts&quot;: &#123;&#125;配置日志驱动的选项：&quot;max-size&quot;: &quot;100m&quot;：每个日志文件的最大大小为 100MB。&quot;max-file&quot;: &quot;100&quot;：最多保留 100 个日志文件（滚动日志机制）。&quot;insecure-registries&quot;: [&quot;harbor.xinxainghf.com&quot;]配置不安全的私有镜像仓库地址（即未启用 HTTPS 的仓库）。例如，harbor.xinxainghf.com 是一个私有仓库地址。&quot;registry-mirrors&quot;: [&quot;https://kfp63jaj.mirror.aliyuncs.com&quot;]配置 Docker 镜像加速器。镜像地址为阿里云镜像服务，加速从官方 Docker Hub 拉取镜像的速度。</code></pre></li></ul><h2 id="3-4-创建-Docker-服务的自定义配置目录"><a href="#3-4-创建-Docker-服务的自定义配置目录" class="headerlink" title="3.4 创建 Docker 服务的自定义配置目录"></a>3.4 创建 Docker 服务的自定义配置目录</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">mkdir -p /etc/systemd/system/docker.service.d</code></pre><p>用于存放 Docker 服务的自定义配置文件。</p></blockquote><h2 id="3-5-重新加载-Docker-配置"><a href="#3-5-重新加载-Docker-配置" class="headerlink" title="3.5 重新加载 Docker 配置"></a>3.5 重新加载 Docker 配置</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">systemctl daemon-reloadsystemctl restart docker</code></pre><ul><li><p>验证配置是否生效</p><pre><code class="highlight shell">docker info</code></pre></li></ul></blockquote><h1 id="4、安装-cri-docker"><a href="#4、安装-cri-docker" class="headerlink" title="4、安装 cri-docker"></a>4、安装 cri-docker</h1><p>从 kubernetes 1.24 开始，dockershim 已经从 kubelet 中移除（ dockershim 是 Kubernetes 的一个组件，主要目的是为了通过 CRI 操作 Docker），但因为历史问题 docker 却不支持 kubernetes 主推的CRI（容器运行时接口）标准，所以 docker 不能再作为 kubernetes 的容器运行时了，即从 kubernetesv1.24 开始不再使用 docker 了，默认使用的容器运行时是 containerd 。目前 containerd 比较新，可能存在一些功能不稳定的情况，所以这里我们使用容器运行时还是选择 docker。</p><p>如果想继续使用 docker 的话，可以在 kubelet 和 docker 之间加上一个中间层 cri-docker 。cri-docker 是一个支持CRI标准的 shim（垫片）。一头通过CRI跟kubelet 交互，另一头跟 docker api 交互，从而间接的实现了 kubernetes 以 docker 作为容器运行时。这里需要在全部节点执行 cri-docker 安装。</p><h2 id="4-1-下载-cri-docker"><a href="#4-1-下载-cri-docker" class="headerlink" title="4.1 下载 cri-docker"></a>4.1 下载 cri-docker</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">创建目录,并下载 cri-docker 安装文件到目录中</span>mkdir -p /opt/softwarecd /opt/softwarewget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.16/cri-dockerd-0.3.16.amd64.tgz</code></pre></blockquote><h2 id="4-2-解压-cri-docker"><a href="#4-2-解压-cri-docker" class="headerlink" title="4.2 解压 cri-docker"></a>4.2 解压 cri-docker</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">tar -xvf /opt/software/cri-dockerd-0.3.16.amd64.tgz --strip-components=1 -C /usr/local/bin/</code></pre></blockquote><h2 id="4-3-下载并修改-cri-docker-配置文件"><a href="#4-3-下载并修改-cri-docker-配置文件" class="headerlink" title="4.3 下载并修改 cri-docker 配置文件"></a>4.3 下载并修改 cri-docker 配置文件</h2><h3 id="4-3-1-下载-cri-docker-配置文件"><a href="#4-3-1-下载-cri-docker-配置文件" class="headerlink" title="4.3.1 下载 cri-docker 配置文件"></a>4.3.1 下载 cri-docker 配置文件</h3><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><p>在浏览器下载文件，通过xftp传到服务器上</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">下载 cri-docker.service</span><span class="meta prompt_"># </span><span class="language-bash">cri-docker.service 下载地址：https://github.com/Mirantis/cri-dockerd/blob/v0.3.16/packaging/systemd/cri-docker.service</span>mv /opt/software/cri-docker.service /etc/systemd/system/<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">下载 cri-docker.socket</span><span class="meta prompt_"># </span><span class="language-bash">cri-docker.socket 下载地址：https://github.com/Mirantis/cri-dockerd/blob/v0.3.16/packaging/systemd/cri-docker.socket</span>mv /opt/software/cri-docker.socket /etc/systemd/system/</code></pre></blockquote><h3 id="4-3-2-修改-cri-docker-配置文件"><a href="#4-3-2-修改-cri-docker-配置文件" class="headerlink" title="4.3.2 修改 cri-docker 配置文件"></a>4.3.2 修改 cri-docker 配置文件</h3><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p></blockquote><p><strong>修改 cri-docker.service 的启动命令 ExecStart</strong></p><pre><code class="highlight plaintext">vim /etc/systemd/system/cri-docker.service</code></pre><ul><li><p>修改内容如下：</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">ExecStart=/usr/bin/cri-dockerd --container-runtime-endpoint fd://</span>ExecStart=/usr/local/bin/cri-dockerd --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9 --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --cri-dockerd-root-directory=/data/dockershim --cri-dockerd-root-directory=/data/docker</code></pre><ul><li><p>配置解析</p><pre><code class="highlight plaintext">ExecStart作用: 定义 Systemd 启动服务时执行的命令。此命令会在服务启动时运行。/usr/local/bin/cri-dockerd解释: cri-dockerd 的可执行文件路径。作用: 启动 cri-dockerd 服务，为 Kubernetes 提供 CRI（容器运行时接口）支持。--pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9解释: 定义 Pod 的基础容器镜像。--container-runtime-endpoint=unix:///var/run/cri-dockerd.sock解释: 定义 CRI 的监听端点。作用: cri-dockerd 使用 Unix Socket 文件 /var/run/cri-dockerd.sock 提供与 Kubernetes 的交互接口。--cri-dockerd-root-directory=/data/dockershim解释: 定义 cri-dockerd 的根目录，用于存储临时文件或配置数据。作用: /data/dockershim 是修改后的 cri-dockerd 数据目录，默认存放在 /var/lib/dockershim，用于存放与 Docker 和 Kubernetes 通信相关的数据。--cri-dockerd-root-directory=/data/docker解释: 定义 Docker 的根目录。作用: Docker 的所有容器数据、镜像数据都存放在 /data/docker 目录下。</code></pre></li></ul></li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-213036.png" alt="cri-docker.service"></p><ul><li><p>修改cri-docker.socket的ListenStream参数</p><pre><code class="highlight shell">vim /etc/systemd/system/cri-docker.socket</code></pre><ul><li><p>修改内容如下：</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">ListenStream=%t/cri-dockerd.sock</span>ListenStream=/var/run/cri-dockerd.sock</code></pre><ul><li><p>配置解析</p><pre><code class="highlight shell">ListenStream作用:定义 cri-dockerd 服务监听的通信地址和端口。在这里，指定了一个 Unix Socket 文件 /var/run/cri-dockerd.sock。/var/run/cri-dockerd.sock解释:这是一个 Unix Domain Socket 文件路径。Unix Sockets 是一种轻量级的进程间通信（IPC）方式，通常用于本地通信（与网络无关）。cri-dockerd 和 Kubernetes 的 kubelet 通过这个 Socket 文件进行交互。</code></pre></li></ul></li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-213125.png" alt="cri-dockerd.sock"></p></li></ul><p><strong>注意每个节点 cri-docker 都需要这么配置</strong></p><h2 id="4-4-启动-cri-docker-对应服务"><a href="#4-4-启动-cri-docker-对应服务" class="headerlink" title="4.4 启动 cri-docker 对应服务"></a>4.4 启动 cri-docker 对应服务</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">systemctl daemon-reloadsystemctl enable cri-dockersystemctl start cri-dockersystemctl is-active cri-docker</code></pre></blockquote><ul><li><p>命令解析</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">告诉 Systemd 重新加载所有服务配置文件。</span>systemctl daemon-reload<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置 cri-docker 服务为 开机自启。</span>systemctl enable cri-docker<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">启动 cri-docker 服务。</span>systemctl start cri-docker<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">检查 cri-docker 服务是否正在运行。</span>systemctl is-active cri-docker</code></pre></li></ul><h1 id="5、使用-kubeadm-基于-Docker-Runtime-部署-kubernetes-集群"><a href="#5、使用-kubeadm-基于-Docker-Runtime-部署-kubernetes-集群" class="headerlink" title="5、使用 kubeadm 基于 Docker Runtime 部署 kubernetes 集群"></a>5、使用 kubeadm 基于 Docker Runtime 部署 kubernetes 集群</h1><h2 id="5-1-配置阿里云K8S源"><a href="#5-1-配置阿里云K8S源" class="headerlink" title="5.1 配置阿里云K8S源"></a>5.1 配置阿里云K8S源</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/enabled=1gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/repodata/repomd.xml.keyEOF</code></pre></blockquote><h2 id="5-2-安装K8S集群管理工具"><a href="#5-2-安装K8S集群管理工具" class="headerlink" title="5.2 安装K8S集群管理工具"></a>5.2 安装K8S集群管理工具</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">yum install -y kubelet kubeadm kubectl</code></pre></blockquote><h2 id="5-3-配置k8s-Cgoup控制组"><a href="#5-3-配置k8s-Cgoup控制组" class="headerlink" title="5.3 配置k8s Cgoup控制组"></a>5.3 配置k8s Cgoup控制组</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">vim /etc/sysconfig/kubelet</code></pre><ul><li><p>配置内容如下：</p><pre><code class="highlight shell">KUBELET_EXTRA_ARGS=&quot;--cgroup-driver=systemd&quot;</code></pre></li></ul></blockquote><ul><li><p>配置解析</p><pre><code class="highlight plaintext">KUBELET_EXTRA_ARGS含义:KUBELET_EXTRA_ARGS 是一个变量，用于为 kubelet 添加自定义的启动参数。这些参数会被系统初始化脚本或服务文件加载并传递给 kubelet 进程。--cgroup-driver=systemd作用:指定 kubelet 使用的 cgroup 驱动（Cgroup Driver）。Cgroup Driver 是 Kubernetes 用来与 Linux 内核 cgroup（控制组）交互的机制，负责资源（CPU、内存等）的限制和管理。该参数将驱动类型设置为 systemd，表示使用 systemd 来管理 cgroup。</code></pre></li></ul><h2 id="5-4-配置kubelet自启动"><a href="#5-4-配置kubelet自启动" class="headerlink" title="5.4 配置kubelet自启动"></a>5.4 配置kubelet自启动</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">systemctl enable kubelet.service</code></pre></blockquote><h2 id="5-5-初始化集群"><a href="#5-5-初始化集群" class="headerlink" title="5.5 初始化集群"></a>5.5 初始化集群</h2><h3 id="5-5-1-打印-master-节点所需的镜像文件"><a href="#5-5-1-打印-master-节点所需的镜像文件" class="headerlink" title="5.5.1 打印 master 节点所需的镜像文件"></a>5.5.1 打印 master 节点所需的镜像文件</h3><blockquote><p>只在 master01 服务器节点执行</p><pre><code class="highlight shell">kubeadm config images list</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-215555.png" alt="所需的镜像文件"></p></blockquote><h3 id="5-5-2-打印集群初始化配置文件"><a href="#5-5-2-打印集群初始化配置文件" class="headerlink" title="5.5.2 打印集群初始化配置文件"></a>5.5.2 打印集群初始化配置文件</h3><blockquote><p>只在 master01 服务器节点执行</p><pre><code class="highlight shell">kubeadm config print init-defaults &gt; kubeadm-config.yaml</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-215821.png" alt="集群初始化配置文件"></p></blockquote><h3 id="5-5-3-修改集群初始化配置文件"><a href="#5-5-3-修改集群初始化配置文件" class="headerlink" title="5.5.3 修改集群初始化配置文件"></a>5.5.3 修改集群初始化配置文件</h3><p>主要修改<code>advertiseAddress</code>,<code>criSocket</code>, <code>imageRepository</code>、<code>etcd.local.</code>dataDir 这4个参数，如下：</p><blockquote><p>只在 master01 服务器节点执行</p><pre><code class="highlight shell">vim /opt/software/kubeadm-config.yaml</code></pre><ul><li><p>修改内容如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta3</span><span class="attr">bootstrapTokens:</span><span class="bullet">-</span> <span class="attr">groups:</span>  <span class="bullet">-</span> <span class="string">system:bootstrappers:kubeadm:default-node-token</span>  <span class="attr">token:</span> <span class="string">abcdef.0123456789abcdef</span>  <span class="attr">ttl:</span> <span class="string">24h0m0s</span>  <span class="attr">usages:</span>  <span class="bullet">-</span> <span class="string">signing</span>  <span class="bullet">-</span> <span class="string">authentication</span><span class="attr">kind:</span> <span class="string">InitConfiguration</span><span class="attr">localAPIEndpoint:</span>  <span class="attr">advertiseAddress:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.223</span> <span class="comment"># 修改为集群初始化的master节点IP地址</span>  <span class="attr">bindPort:</span> <span class="number">6443</span><span class="attr">nodeRegistration:</span>  <span class="attr">criSocket:</span> <span class="string">unix:///var/run/cri-dockerd.sock</span> <span class="comment"># 高版本默认使用containerd，这里修改成使用dcoker</span>  <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>  <span class="attr">name:</span> <span class="string">node</span>  <span class="attr">taints:</span> <span class="literal">null</span><span class="meta">---</span><span class="attr">apiServer:</span>  <span class="attr">timeoutForControlPlane:</span> <span class="string">4m0s</span><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta3</span><span class="attr">certificatesDir:</span> <span class="string">/etc/kubernetes/pki</span><span class="attr">clusterName:</span> <span class="string">kubernetes</span><span class="attr">controllerManager:</span> &#123;&#125;<span class="attr">dns:</span> &#123;&#125;<span class="attr">etcd:</span>  <span class="attr">local:</span>    <span class="attr">dataDir:</span> <span class="string">/data/etcd</span> <span class="comment"># 修改 etcd 的数据存储目录</span><span class="comment">#imageRepository: registry.k8s.io</span><span class="attr">imageRepository:</span> <span class="string">registry.cn-hangzhou.aliyuncs.com/google_containers</span> <span class="comment"># 这里修改成使用阿里云容器镜像</span><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span><span class="attr">kubernetesVersion:</span> <span class="number">1.29</span><span class="number">.0</span><span class="attr">networking:</span>  <span class="attr">dnsDomain:</span> <span class="string">cluster.local</span>  <span class="attr">serviceSubnet:</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span><span class="string">/12</span><span class="attr">scheduler:</span> &#123;&#125;</code></pre></li></ul></blockquote><ul><li><p>配置解析</p><pre><code class="highlight yaml"><span class="comment"># 指定配置文件的 API 版本，这里使用的是 v1beta3（Kubernetes 1.22+ 支持）。</span><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta3</span><span class="attr">bootstrapTokens:</span><span class="bullet">-</span> <span class="attr">groups:</span>  <span class="comment"># 设置令牌的用户组，用于节点加入时的权限分配。</span>  <span class="bullet">-</span> <span class="string">system:bootstrappers:kubeadm:default-node-token</span>  <span class="comment"># 定义用于节点加入的令牌，由两部分组成：6 位前缀 + 16 位随机数。</span>  <span class="attr">token:</span> <span class="string">abcdef.0123456789abcdef</span>  <span class="comment"># 定义令牌的有效期，这里设置为 24 小时。</span>  <span class="attr">ttl:</span> <span class="string">24h0m0s</span>  <span class="attr">usages:</span>  <span class="comment"># signing：用于签署客户端证书请求。</span>  <span class="bullet">-</span> <span class="string">signing</span>  <span class="comment"># authentication：用于身份验证。</span>  <span class="bullet">-</span> <span class="string">authentication</span><span class="attr">kind:</span> <span class="string">InitConfiguration</span><span class="attr">localAPIEndpoint:</span> <span class="comment"># 配置本地 API 服务器的监听地址和端口：</span>  <span class="attr">advertiseAddress:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.223</span> <span class="comment"># 修改为集群初始化的master节点IP地址</span>  <span class="comment"># API 服务器的监听端口（默认是 6443）。</span>  <span class="attr">bindPort:</span> <span class="number">6443</span><span class="attr">nodeRegistration:</span>  <span class="comment"># 定义容器运行时接口（CRI）的 Socket 路径。</span>  <span class="attr">criSocket:</span> <span class="string">unix:///var/run/cri-dockerd.sock</span> <span class="comment"># 高版本默认使用containerd，这里修改成使用dcoker</span>  <span class="comment"># 配置镜像拉取策略，IfNotPresent 表示本地没有镜像时才拉取。</span>  <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>  <span class="comment"># 注册的节点名称。</span>  <span class="attr">name:</span> <span class="string">node</span>  <span class="comment"># 设置节点的污点，这里为 null，表示不对节点进行污点设置。</span>  <span class="attr">taints:</span> <span class="literal">null</span><span class="meta">---</span><span class="attr">apiServer:</span> <span class="comment"># 配置 API 服务器的相关参数</span>  <span class="comment"># 控制平面组件的超时时间，设置为 4 分钟。</span>  <span class="attr">timeoutForControlPlane:</span> <span class="string">4m0s</span><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta3</span><span class="comment"># 集群证书的存放路径：/etc/kubernetes/pki：默认路径。</span><span class="attr">certificatesDir:</span> <span class="string">/etc/kubernetes/pki</span><span class="comment"># 集群的标识名称。</span><span class="attr">clusterName:</span> <span class="string">kubernetes</span><span class="attr">controllerManager:</span> &#123;&#125;<span class="attr">dns:</span> &#123;&#125;<span class="attr">etcd:</span>  <span class="attr">local:</span>    <span class="comment"># 配置 etcd 数据存储信息</span>    <span class="attr">dataDir:</span> <span class="string">/data/etcd</span> <span class="comment"># 修改 etcd 的数据存储目录</span><span class="comment"># 定义镜像仓库地址</span><span class="comment">#imageRepository: registry.k8s.io</span><span class="attr">imageRepository:</span> <span class="string">registry.cn-hangzhou.aliyuncs.com/google_containers</span> <span class="comment"># 这里修改成使用阿里云容器镜像</span><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span><span class="comment"># 需要安装的 Kubernetes 主版本</span><span class="attr">kubernetesVersion:</span> <span class="number">1.29</span><span class="number">.0</span><span class="attr">networking:</span> <span class="comment"># 配置集群的网络信息</span>  <span class="comment"># DNS 的后缀域名（默认是 cluster.local）。</span>  <span class="attr">dnsDomain:</span> <span class="string">cluster.local</span>  <span class="comment"># 群中 Service 的虚拟 IP 子网，通常为 /12 子网。</span>  <span class="attr">serviceSubnet:</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span><span class="string">/12</span><span class="attr">scheduler:</span> &#123;&#125;</code></pre></li></ul><h3 id="5-5-4-使用以上配置文件进行集群初始化"><a href="#5-5-4-使用以上配置文件进行集群初始化" class="headerlink" title="5.5.4 使用以上配置文件进行集群初始化"></a>5.5.4 使用以上配置文件进行集群初始化</h3><blockquote><p>只在 master01 服务器节点执行</p><pre><code class="highlight shell">kubeadm init --config /opt/software/kubeadm-config.yaml --upload-certs</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-222023.png" alt="集群初始化"></p><p>初始化成功之后就会出现如下图打印</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-222052.png" alt="集群初始化成功"></p></blockquote><ul><li><p>命令解析</p><pre><code class="highlight plaintext">kubeadm init初始化 Kubernetes 集群的控制平面节点（Master）。这是 Kubernetes 集群部署的第一步。--config kubeadm-config.yaml指定使用自定义的配置文件 kubeadm-config.yaml 来初始化集群。配置文件中可以自定义网络、版本、镜像仓库、etcd 配置等关键参数。--upload-certs作用：将 Kubernetes 控制平面的证书（如 CA、API Server 证书等）加密后上传到集群内的 etcd 中。便于后续添加其他控制平面节点（即高可用部署时添加多个 Master 节点）。实现原理：Kubernetes 使用对称加密的方式，将证书加密后存储在集群中。生成一个临时的加密密钥，用于解密证书。后续节点加入命令：kubeadm join 时，通过指定该密钥，可以从集群中下载并解密这些证书，从而加入为控制平面节点。如果是单 Master 节点，可以不加 --upload-certs。但是如果未来计划扩展为高可用集群，建议使用 --upload-certs。</code></pre></li><li><p>master节点token过期处理</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">work token 过期后，重新申请</span>kubeadm token create --print-join-command</code></pre></li></ul><h3 id="5-5-5-配置环境变量"><a href="#5-5-5-配置环境变量" class="headerlink" title="5.5.5 配置环境变量"></a>5.5.5 配置环境变量</h3><p>集群初始化成功之后的打印中提示了我们 需要进行一下环境变量配置</p><blockquote><p>只在 master01 服务器节点执行</p><pre><code class="highlight shell">mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">如果是root用户操作，执行</span>export KUBECONFIG=/etc/kubernetes/admin.conf</code></pre></blockquote><ul><li><p>命令解析</p><pre><code class="highlight shell">mkdir -p $HOME/.kube功能：创建一个目录 $HOME/.kube，用来存放 Kubernetes 客户端 (kubectl) 的配置文件。选项：-p：确保目录路径中的每一级都被创建，如果目录已经存在则不会报错。背景：kubectl 需要一个配置文件（通常是 config）来连接 Kubernetes 集群并进行管理。<span class="meta prompt_">$</span><span class="language-bash">HOME/.kube 是 kubectl 默认查找配置文件的路径。</span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config功能：将 Kubernetes 的集群配置文件 /etc/kubernetes/admin.conf 复制到当前用户的 $HOME/.kube/config。选项：-i：提示确认是否覆盖目标文件（如果目标文件已经存在）。背景：admin.conf 是由 kubeadm init 生成的配置文件，包含：集群的 API Server 地址认证信息（如 CA 证书、用户证书）配置上下文信息（上下文表示当前访问的集群和用户）默认情况下，该文件存储在 /etc/kubernetes/ 下，并且只有 root 用户可以访问。为了方便当前用户运行 kubectl 命令，需要将其复制到用户的主目录下。sudo chown $(id -u):$(id -g) $HOME/.kube/config功能：修改 $HOME/.kube/config 文件的所有者为当前用户和用户组。参数解析：<span class="meta prompt_">$</span><span class="language-bash">(<span class="built_in">id</span> -u)：返回当前用户的 UID。</span><span class="meta prompt_">$</span><span class="language-bash">(<span class="built_in">id</span> -g)：返回当前用户的 GID。</span>完整流程的意义创建 .kube 目录，用于存放 Kubernetes 配置文件。将集群的配置文件复制到用户目录中，使 kubectl 可以连接和管理集群。修改配置文件的权限，方便用户无权限问题地运行 kubectl 命令。</code></pre></li></ul><h3 id="5-5-6-所有woker节点加入到集群中"><a href="#5-5-6-所有woker节点加入到集群中" class="headerlink" title="5.5.6 所有woker节点加入到集群中"></a>5.5.6 所有woker节点加入到集群中</h3><blockquote><p>在 node01、node02 这2台服务器执行</p><pre><code class="highlight shell">kubeadm join 192.168.6.223:6443 --token abcdef.0123456789abcdef \--discovery-token-ca-cert-hash sha256:2abbc2082ec6ca53c24154e82e3d18d0d8bcd6410af674a1197d0c2ba75e47d6 \ --cri-socket=unix:///var/run/cri-dockerd.sock</code></pre><p>此命令来源于集群初始化时，控制台打印内容，添加了 –cri-socket&#x3D;unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;cri-dockerd.sock</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-223427.png" alt="node01加入集群"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-223515.png" alt="node02加入集群"></p></blockquote><ul><li><p>master节点查看集群</p><pre><code class="highlight shell">kubectl get nodes</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-223611.png" alt="master节点查看集群"></p></li></ul><h1 id="6、部署网络插件"><a href="#6、部署网络插件" class="headerlink" title="6、部署网络插件"></a>6、部署网络插件</h1><h2 id="6-1-calico安装"><a href="#6-1-calico安装" class="headerlink" title="6.1 calico安装"></a>6.1 calico安装</h2><p>K8s使用calico部署集群网络,只需要在Master节点安装即可。</p><p>下载地址：<a href="https://github.com/projectcalico/calico">https://github.com/projectcalico/calico</a></p><blockquote><p>只在 master01 服务器节点执行</p><pre><code class="highlight shell">curl https://raw.githubusercontent.com/projectcalico/calico/v3.26.3/manifests/calico-typha.yaml -o /opt/software/calico.yaml</code></pre></blockquote><h2 id="6-2-创建calico网络"><a href="#6-2-创建calico网络" class="headerlink" title="6.2 创建calico网络"></a>6.2 创建calico网络</h2><blockquote><p>只在 master01 服务器节点执行</p><pre><code class="highlight shell">kubectl apply -f /opt/software/calico.yaml</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-225119.png" alt="创建calico网络"></p></blockquote><h2 id="6-3-验证集群可用性"><a href="#6-3-验证集群可用性" class="headerlink" title="6.3 验证集群可用性"></a>6.3 验证集群可用性</h2><blockquote><p>只在 master01 服务器节点执行</p><pre><code class="highlight shell">kubectl get nodes</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-225225.png" alt="验证集群可用性"></p><p>node1 与 node2 几点都处于 NotReady 状态，这是因为集群正在拉取 calico 所需的镜像，而这个镜像在国外，所以很慢，甚至会失败。</p><p>需要的镜像在 &#x2F;opt&#x2F;software&#x2F;calico.yaml 这个文件中，可以先下载好，再导入到服务器中。</p><p><strong>集群可用时</strong></p><p>如果所需镜像都下载完成，并成功启动后，执行 <code>kubectl get nodes</code> 显示如下：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/08/20250108-135619.png" alt="验证集群可用性"></p></blockquote><p>在安装 k8s 集群时，关于如何下载外网镜像是个绕不过去的问题。这里只说一种最稳妥的方式，就是给服务器配置网络代理，实现从官方下载镜像。</p><p>具体方式见：</p><blockquote><p>第一步：服务器配置外网代理,保证服务器可以正常访问谷歌等外网</p><ul><li><a href="https://georgechan95.github.io/blog/7f174b3e.html">Rocky9安装Shadowsocks实现科学上网</a></li></ul><p>第二步：配置Docker网络代理，实现k8s镜像的正常拉取</p><ul><li><a href="https://georgechan95.github.io/blog/b01d5c62.html">Docker配置网络代理实现外网镜像下载</a></li></ul></blockquote><h2 id="6-4-查看集群健康情况"><a href="#6-4-查看集群健康情况" class="headerlink" title="6.4 查看集群健康情况"></a>6.4 查看集群健康情况</h2><blockquote><p>只在 master01 服务器节点执行</p><pre><code class="highlight shell">kubectl get cs</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-225329.png" alt="查看集群健康情况"></p></blockquote><h2 id="6-5-查看kubernetes集群pod运行情况"><a href="#6-5-查看kubernetes集群pod运行情况" class="headerlink" title="6.5 查看kubernetes集群pod运行情况"></a>6.5 查看kubernetes集群pod运行情况</h2><blockquote><p>只在 master01 服务器节点执行</p><pre><code class="highlight shell">kubectl get pods -n kube-system</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-225718.png" alt="查看kubernetes集群pod运行情况"></p></blockquote><h2 id="6-6-worker节点配置"><a href="#6-6-worker节点配置" class="headerlink" title="6.6 worker节点配置"></a>6.6 worker节点配置</h2><p>当我们在Worker节点上执行kubectl命令管理时会报如下错误：</p><blockquote><p>在node节点执行</p><pre><code class="highlight shell">kubectl get pods -n kube-system</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/08/20250108-135945.png" alt="node节点执行kubectl命令报错"></p></blockquote><p><strong>解决方式：</strong></p><p>只要把 master上的管理文件 <code>/etc/kubernetes/admin.conf</code> 拷贝到 Worker 节点的 <code>$HOME/.kube/config</code> 就可以让 Worker 节点也可以实现 kubectl 命令管理。</p><blockquote><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">在 node1 节点执行</span>[root@k8s-node01 ~]$ mkdir /root/.kube<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">在node2节点执行</span>[root@k8s-node02 ~]$ mkdir /root/.kube<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">在master节点执行</span>[root@k8s-master01 ~]$ scp /etc/kubernetes/admin.conf root@192.168.6.225:/root/.kube/config[root@k8s-master01 ~]$ scp /etc/kubernetes/admin.conf root@192.168.6.226:/root/.kube/config</code></pre><ul><li><p>在node节点测试 kubectl 命令</p><pre><code class="highlight shell">[root@k8s-node01 ~]$ kubectl get pods -n kube-system</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/08/20250108-140700.png" alt="在node节点测试 kubectl 命令"></p></li></ul></blockquote><p><strong>至此，使用 kubeadm 完成了k8s集群的安装。</strong></p><h1 id="7、K8S集群的启停管理"><a href="#7、K8S集群的启停管理" class="headerlink" title="7、K8S集群的启停管理"></a>7、K8S集群的启停管理</h1><p>默认K8S我们只要设置了 <code>systemctl enable kubelet.service</code> 后，会在开机自动启动K8S集群，如果想要停止 kubernetes 集群，我们可以通过 <code>systemctl stop kubelet.service</code> 命令停止集群，但是必须先将节点上的docker停止。</p><p>不管你是通过哪种方式安装的K8S集群， 只要记住一句口诀就行了：<strong>启动K8S集群，先启动集群上所有的容器服务(不管是Docker还是Containerd)，停止K8S集群，先停止集群上所有的容器服务。</strong></p><h2 id="7-1-停止K8S集群"><a href="#7-1-停止K8S集群" class="headerlink" title="7.1 停止K8S集群"></a>7.1 停止K8S集群</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">systemctl stop dockersystemctl stop kubelet.service</code></pre></blockquote><h2 id="7-2-启动K8S集群"><a href="#7-2-启动K8S集群" class="headerlink" title="7.2 启动K8S集群"></a>7.2 启动K8S集群</h2><blockquote><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight shell">systemctl start dockersystemctl start kubelet.service</code></pre></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;系统环境&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;RockyLinux：9.3&lt;/p&gt;
&lt;p&gt;K8s版本：1.29&lt;/p&gt;
&lt;p&gt;Docker版本：27.4.1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;软件包来源&lt;/str</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>002-Rocky9.3系统初始化设置和Docker安装</title>
    <link href="https://georgechan95.github.io/blog/3c79d8d9.html"/>
    <id>https://georgechan95.github.io/blog/3c79d8d9.html</id>
    <published>2025-01-02T05:25:00.000Z</published>
    <updated>2025-01-04T02:44:14.317Z</updated>
    
    <content type="html"><![CDATA[<p><strong>系统环境</strong></p><blockquote><p>RockyLinux：9.3</p><p>镜像下载官网：<a href="https://rockylinux.org/zh-CN/download">https://rockylinux.org/zh-CN/download</a></p><p>镜像下载地址：<a href="https://dl.rockylinux.org/vault/rocky/9.3/isos/x86_64/">https://dl.rockylinux.org/vault/rocky/9.3/isos/x86_64/</a></p><p>安装镜像文件：Rocky-9.3-x86_64-minimal.iso</p></blockquote><h1 id="1、环境初始化"><a href="#1、环境初始化" class="headerlink" title="1、环境初始化"></a>1、环境初始化</h1><h2 id="1-1-配置静态IP"><a href="#1-1-配置静态IP" class="headerlink" title="1.1 配置静态IP"></a>1.1 配置静态IP</h2><ul><li><p>查看当前要设置的网卡</p><pre><code class="highlight shell">ip addr</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-133612.png" alt="查看网卡信息"></p></li><li><p>编辑网卡配置</p><pre><code class="highlight shell">vi /etc/NetworkManager/system-connections/ens34.nmconnection</code></pre><ul><li><p>添加如下配置</p><pre><code class="highlight shell">[ipv4]method=manualaddress1=192.168.6.221/24,192.168.6.1dns=114.114.114.114;8.8.8.8</code></pre></li><li><p>配置解析</p><pre><code class="highlight shell">[ipv4]<span class="meta prompt_"># </span><span class="language-bash">ip设置为手动配置</span>method=manual<span class="meta prompt_"># </span><span class="language-bash">设置IP为：192.168.6.222</span><span class="meta prompt_"># </span><span class="language-bash">/24 表示子网掩码为：255.255.255.0</span><span class="meta prompt_"># </span><span class="language-bash">,192.168.6.1 表示网关地址为：192.168.6.1</span>address1=192.168.6.222/24,192.168.6.1<span class="meta prompt_"># </span><span class="language-bash">dns地址</span>dns=114.114.114.114;8.8.8.8</code></pre></li></ul><h2 id="1-2-重启设备和连接配置"><a href="#1-2-重启设备和连接配置" class="headerlink" title="1.2 重启设备和连接配置"></a>1.2 重启设备和连接配置</h2><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">重新应用网络设备 ens34 的当前配置</span>nmcli device reapply ens34<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">重新加载 ens34 的网络连接配置。在网络配置文件被手动更改后，通过此命令重新加载连接设置，使更改生效。</span>nmcli connection reload ens34<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">使用 nmcli 命令激活网络设备</span>nmcli device connect ens34<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看IP配置是否成功</span>ip addrping www.baidu.com</code></pre><ul><li><p>其它命令</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">断开网络设备 ens34 的网络连接。</span>nmcli device disconnect ens34<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">激活连接（Connection）如果设备已连接，但未启用对应的网络连接配置，可以激活配置：</span>nmcli connection up ens34<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">检查设备状态</span>nmcli device status<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">如果希望设备在每次系统启动时自动启用，可以执行以下命令：</span>nmcli connection modify ens34 connection.autoconnect yes</code></pre></li></ul></li></ul><h2 id="1-3-更换系统软件源"><a href="#1-3-更换系统软件源" class="headerlink" title="1.3 更换系统软件源"></a>1.3 更换系统软件源</h2><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">更新源</span>sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \    -e &#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27; \    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo    <span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">刷新dnf缓存</span>dnf makecache<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">验证源更新</span>dnf repolist</code></pre><ul><li><p>命令解析</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">使用 sed 命令修改 Rocky Linux 的 YUM/DNF 源配置文件，切换到阿里云的镜像源。</span>sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \    -e &#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27; \    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo    <span class="meta prompt_"># </span><span class="language-bash">将以 mirrorlist= 开头的行注释掉（在前面加 <span class="comment">#）</span></span>-e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27;<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">将以 <span class="comment">#baseurl= 开头并指向默认 Rocky Linux 源的行取消注释，并替换为阿里云镜像源 URL。</span></span>&#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27;<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">-i.bak：直接修改文件，并为原文件创建备份（扩展名为 .bak）。</span><span class="meta prompt_"># </span><span class="language-bash">修改 /etc/yum.repos.d/ 目录下所有以 rocky 或 Rocky 开头的 .repo 文件。</span><span class="meta prompt_"># </span><span class="language-bash">修改完成后，原始文件会被备份为 .bak 文件。</span>-i.bak /etc/yum.repos.d/[Rr]ocky*.repo<span class="meta prompt_"></span><span class="meta prompt_"></span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">更新本地缓存，确保系统可以快速查询软件包信息。</span>dnf makecache</code></pre></li></ul><h2 id="1-4-修改防火墙"><a href="#1-4-修改防火墙" class="headerlink" title="1.4 修改防火墙"></a>1.4 修改防火墙</h2><p>防火墙修改 firewalld 为 iptables</p><pre><code class="highlight shell">systemctl stop firewalldsystemctl disable firewalldyum -y install iptables-servicessystemctl start iptablesiptables -Fsystemctl enable iptablesservice iptables save</code></pre><ul><li><p>命令解析</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">停止运行 firewalld</span>systemctl stop firewalld<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">禁止 firewalld 开机自启</span>systemctl disable firewalld<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">安装 iptables 服务，用于管理 Linux 的防火墙规则</span>yum -y install iptables-services<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">使防火墙规则立即生效，并开始运行 iptables 防火墙服务。</span>systemctl start iptables<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">删除当前的防火墙规则，通常用于重置或清理防火墙规则。</span>iptables -F<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置 iptables 服务开机自启动，确保服务器重启后，iptables 服务会自动加载防火墙规则。</span>systemctl enable iptables<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">将当前 iptables 的规则配置保存到文件中（通常是 /etc/sysconfig/iptables），以便在系统重启或 iptables 服务重新启动后，能够自动加载保存的规则。</span>service iptables save</code></pre></li></ul><h2 id="1-5-禁用-Selinux"><a href="#1-5-禁用-Selinux" class="headerlink" title="1.5 禁用 Selinux"></a>1.5 禁用 Selinux</h2><pre><code class="highlight shell">setenforce 0sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/configgrubby --update-kernel ALL --args selinux=0</code></pre><ul><li><p>命令解析</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">将 SELinux 的模式设置为 Permissive（宽容模式）。</span><span class="meta prompt_"># </span><span class="language-bash">0：表示设置为 Permissive 模式，此模式下 SELinux 不会强制执行安全策略，而是记录违规日志。</span><span class="meta prompt_"># </span><span class="language-bash">1：表示 Enforcing 模式，此模式下 SELinux 会强制执行安全策略。</span>setenforce 0<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">修改 SELinux 配置文件 /etc/selinux/config，将 SELINUX 设置为 disabled。永久禁用 SELinux，即使系统重启也不会再启用。</span>sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">通过 grubby 工具将 selinux=0 参数添加到所有内核启动配置中。</span>grubby --update-kernel ALL --args selinux=0grubby --info DEFAULT<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看是否禁用，</span>grubby --info DEFAULT<span class="meta prompt_"># </span><span class="language-bash">回滚内核层禁用操作，、</span>grubby --update-kernel ALL --remove-args selinux</code></pre></li><li><p>修改完成后重启系统</p><pre><code class="highlight shell">reboot</code></pre></li></ul><h2 id="1-6-设置时区"><a href="#1-6-设置时区" class="headerlink" title="1.6 设置时区"></a>1.6 设置时区</h2><pre><code class="highlight shell">timedatectl set-timezone Asia/Shanghai</code></pre><h1 id="2、安装Docker"><a href="#2、安装Docker" class="headerlink" title="2、安装Docker"></a>2、安装Docker</h1><h2 id="2-1-安装必要的库和网络设置"><a href="#2-1-安装必要的库和网络设置" class="headerlink" title="2.1 安装必要的库和网络设置"></a>2.1 安装必要的库和网络设置</h2><pre><code class="highlight shell">yum install -y epel-releaseyum install -y bridge-utilsmodprobe br_netfilterecho &#x27;br_netfilter&#x27; &gt;&gt; /etc/modules-load.d/bridge.confcat &gt;&gt; /etc/sysctl.conf &lt;&lt;EOFnet.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-ip6tables=1net.ipv4.ip_forward=1net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_tw_buckets = 20480net.ipv4.tcp_max_syn_backlog = 20480net.core.netdev_max_backlog = 262144net.ipv4.tcp_fin_timeout = 20EOFsysctl -p</code></pre><ul><li><p>命令解释</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">安装 EPEL（Extra Packages <span class="keyword">for</span> Enterprise Linux） 仓库的 Release 包。</span><span class="meta prompt_"># </span><span class="language-bash">EPEL 是由 Fedora 社区维护的一个软件仓库，提供许多额外的软件包，这些包在默认的 RHEL（或其衍生版如 CentOS、Rocky Linux 等）中没有包含。</span>yum install -y epel-release<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">安装 bridge-utils 软件包。</span><span class="meta prompt_"># </span><span class="language-bash">bridge-utils 是一个 Linux 工具集，用于创建和管理网络桥接（bridging）。</span>yum install -y bridge-utils<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">加载 br_netfilter 内核模块。</span><span class="meta prompt_"># </span><span class="language-bash">该模块用于启用网络桥接（bridge）时的流量过滤功能。</span><span class="meta prompt_"># </span><span class="language-bash">允许通过桥接的网络流量被 iptables 规则管理。</span><span class="meta prompt_"># </span><span class="language-bash">在容器或虚拟化环境中，确保桥接网络的流量可以被正确处理。</span>modprobe br_netfilter<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">将 br_netfilter 模块名称添加到 /etc/modules-load.d/bridge.conf 文件中。</span><span class="meta prompt_"># </span><span class="language-bash">配置系统在启动时自动加载 br_netfilter 模块。</span>echo &#x27;br_netfilter&#x27; &gt;&gt; /etc/modules-load.d/bridge.conf<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">向 /etc/sysctl.conf 文件添加配置，使桥接流量可以通过 iptables 规则管理。</span><span class="meta prompt_"># </span><span class="language-bash">启用桥接网络上的 IPv4 流量通过 iptables 的规则处理。</span>net.bridge.bridge-nf-call-iptables=1<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">向 /etc/sysctl.conf 文件添加配置，使桥接流量中的 IPv6 流量可以通过 ip6tables 规则管理。</span>net.bridge.bridge-nf-call-ip6tables=1<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">向 /etc/sysctl.conf 文件添加配置，启用 IP 转发功能。</span><span class="meta prompt_"># </span><span class="language-bash">用途：在容器网络或 Kubernetes 集群中，允许跨子网通信。</span>net.ipv4.ip_forward=1<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">启用 TCP SYN Cookie 技术，用于防范 SYN Flood 攻击。</span><span class="meta prompt_"># </span><span class="language-bash">在服务器收到大量的 TCP SYN 请求但无法分配足够资源时，启用 SYN Cookie 可通过一种临时编码方式验证连接合法性，避免资源耗尽。</span>net.ipv4.tcp_syncookies = 1<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置系统同时保持的 TCP TIME_WAIT 状态的连接数上限。达到上限后，系统会直接丢弃多余的连接（而不是继续占用资源）。</span><span class="meta prompt_"># </span><span class="language-bash">默认值180000,对于高并发的 Web 服务器或反向代理，适当调低该值（如 20480）以避免 TIME_WAIT 数量过多。</span>net.ipv4.tcp_max_tw_buckets = 20480<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置 TCP 三次握手中 SYN 请求的队列长度上限。</span><span class="meta prompt_"># </span><span class="language-bash">当服务器接收的 SYN 请求超过该值时，新的连接请求会被丢弃。</span><span class="meta prompt_"># </span><span class="language-bash">如果服务器负载较高且连接数较多，可以调高到 20480 或更高。</span>net.ipv4.tcp_max_syn_backlog = 20480<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置网络设备接收队列的最大长度。</span><span class="meta prompt_"># </span><span class="language-bash">如果接收队列中的数据包数量超过该值，内核将直接丢弃后续数据包。</span><span class="meta prompt_"># </span><span class="language-bash">在高流量环境中，设置为较高值（如 262144）以避免丢包，提高吞吐量。</span>net.core.netdev_max_backlog = 262144<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置 TCP 连接处于 FIN_WAIT2 状态的超时时间（单位：秒）。</span><span class="meta prompt_"># </span><span class="language-bash">FIN_WAIT2 状态表示服务端已发送 FIN 包等待客户端确认，此状态会持续占用资源。</span><span class="meta prompt_"># </span><span class="language-bash">默认值：通常为 60 秒。</span><span class="meta prompt_"># </span><span class="language-bash">在高并发服务器上，将该值调低（如 20）以减少 FIN_WAIT2 状态的资源占用。</span>net.ipv4.tcp_fin_timeout = 20<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">重新加载 /etc/sysctl.conf 中的所有内核参数配置，并使其立即生效。</span>sysctl -p</code></pre></li></ul><h2 id="2-2-安装docker"><a href="#2-2-安装docker" class="headerlink" title="2.2 安装docker"></a>2.2 安装docker</h2><p>添加 docker-ce yum 源</p><pre><code class="highlight shell">sudo dnf config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.reposudo sed -i &#x27;s+download.docker.com+mirrors.aliyun.com/docker-ce+&#x27; /etc/yum.repos.d/docker-ce.reposudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</code></pre><ul><li><p>命令解析</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">使用 dnf config-manager 命令添加 Docker 软件包的官方仓库（在这里是阿里云的镜像）。</span>sudo dnf config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">修改 docker-ce.repo 文件中的镜像源地址，将默认的 download.docker.com 替换为阿里云的镜像地址 mirrors.aliyun.com/docker-ce。</span>sudo sed -i &#x27;s+download.docker.com+mirrors.aliyun.com/docker-ce+&#x27; /etc/yum.repos.d/docker-ce.repo<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">安装最新版本docker</span>sudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</code></pre></li></ul><h2 id="2-3-开启Docker服务"><a href="#2-3-开启Docker服务" class="headerlink" title="2.3 开启Docker服务"></a>2.3 开启Docker服务</h2><pre><code class="highlight shell">systemctl start dockersystemctl enable docker</code></pre><h2 id="2-4-配置-daemon-json"><a href="#2-4-配置-daemon-json" class="headerlink" title="2.4 配置 daemon.json"></a>2.4 配置 daemon.json</h2><pre><code class="highlight shell">cat &gt;&gt;/etc/docker/daemon.json &lt;&lt;EOF&#123;  &quot;log-driver&quot;: &quot;json-file&quot;,  &quot;log-opts&quot;: &#123;        &quot;max-size&quot;: &quot;100m&quot;,        &quot;max-file&quot;: &quot;10&quot;  &#125;,  &quot;data-root&quot;:&quot;/data/docker&quot;,  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],  &quot;registry-mirrors&quot;: [   &quot;https://kfp63jaj.mirror.aliyuncs.com&quot;,    &quot;https://hub-mirror.c.163.com&quot;,    &quot;https://mirror.baidubce.com&quot;  ]&#125;EOF</code></pre><ul><li><p>配置解析</p><pre><code class="highlight shell">&quot;data-root&quot;: &quot;/data/docker&quot;指定 Docker 数据的存储目录为 /data/docker。包括容器、镜像、卷等内容。默认存储在 /var/lib/docker，此配置用于更改默认路径。&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]配置 Docker 使用 systemd 作为 Cgroup 驱动程序。推荐在使用现代 Linux 发行版（如 Rocky Linux 9）或 Kubernetes 时采用此配置，以实现更好的资源管理和兼容性。&quot;log-driver&quot;: &quot;json-file&quot;指定 Docker 的日志驱动为 json-file。json-file 是 Docker 默认的日志存储方式，将日志保存在 JSON 文件中。&quot;log-opts&quot;: &#123;&#125;配置日志驱动的选项：&quot;max-size&quot;: &quot;100m&quot;：每个日志文件的最大大小为 100MB。&quot;max-file&quot;: &quot;100&quot;：最多保留 100 个日志文件（滚动日志机制）。&quot;insecure-registries&quot;: [&quot;harbor.xinxainghf.com&quot;]配置不安全的私有镜像仓库地址（即未启用 HTTPS 的仓库）。例如，harbor.xinxainghf.com 是一个私有仓库地址。&quot;registry-mirrors&quot;: [&quot;https://kfp63jaj.mirror.aliyuncs.com&quot;]配置 Docker 镜像加速器。镜像地址为阿里云镜像服务，加速从官方 Docker Hub 拉取镜像的速度。</code></pre></li></ul><h2 id="2-5-创建-Docker-服务的自定义配置目录"><a href="#2-5-创建-Docker-服务的自定义配置目录" class="headerlink" title="2.5 创建 Docker 服务的自定义配置目录"></a>2.5 创建 Docker 服务的自定义配置目录</h2><pre><code class="highlight shell">mkdir -p /etc/systemd/system/docker.service.d</code></pre><p>用于存放 Docker 服务的自定义配置文件。</p><h2 id="2-6-重新加载-Docker-配置"><a href="#2-6-重新加载-Docker-配置" class="headerlink" title="2.6 重新加载 Docker 配置"></a>2.6 重新加载 Docker 配置</h2><pre><code class="highlight shell">systemctl daemon-reloadsystemctl restart docker</code></pre><ul><li><p>验证配置是否生效</p><pre><code class="highlight shell">docker info</code></pre></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;系统环境&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;RockyLinux：9.3&lt;/p&gt;
&lt;p&gt;镜像下载官网：&lt;a href=&quot;https://rockylinux.org/zh-CN/download&quot;&gt;https://rockylinux</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>001-ESXi8安装Rocky9.3虚拟机</title>
    <link href="https://georgechan95.github.io/blog/7e3a5200.html"/>
    <id>https://georgechan95.github.io/blog/7e3a5200.html</id>
    <published>2025-01-02T01:34:00.000Z</published>
    <updated>2025-01-02T10:53:44.586Z</updated>
    
    <content type="html"><![CDATA[<p><strong>系统环境</strong></p><blockquote><p>ESXI：8.0</p><p>RockyLinux：9.3</p><p>镜像下载官网：<a href="https://rockylinux.org/zh-CN/download">https://rockylinux.org/zh-CN/download</a></p><p>镜像下载地址：<a href="https://dl.rockylinux.org/vault/rocky/9.3/isos/x86_64/">https://dl.rockylinux.org/vault/rocky/9.3/isos/x86_64/</a></p><p>安装镜像文件：Rocky-9.3-x86_64-minimal.iso</p></blockquote><h1 id="1、创建虚拟机"><a href="#1、创建虚拟机" class="headerlink" title="1、创建虚拟机"></a>1、创建虚拟机</h1><h2 id="1-1-创建新虚拟机"><a href="#1-1-创建新虚拟机" class="headerlink" title="1.1 创建新虚拟机"></a>1.1 创建新虚拟机</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-111758.png" alt="创建新虚拟机"></p><h2 id="1-2-设置虚拟机名称和操作系统"><a href="#1-2-设置虚拟机名称和操作系统" class="headerlink" title="1.2 设置虚拟机名称和操作系统"></a>1.2 设置虚拟机名称和操作系统</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-111812.png" alt="设置虚拟机名称和操作系统"></p><h2 id="1-3-选择磁盘"><a href="#1-3-选择磁盘" class="headerlink" title="1.3 选择磁盘"></a>1.3 选择磁盘</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-111829.png" alt="选择磁盘"></p><h2 id="1-4-自定义虚拟机硬件设置，选择镜像文件"><a href="#1-4-自定义虚拟机硬件设置，选择镜像文件" class="headerlink" title="1.4 自定义虚拟机硬件设置，选择镜像文件"></a>1.4 自定义虚拟机硬件设置，选择镜像文件</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-111938.png" alt="自定义虚拟机硬件设置，选择镜像文件"></p><h2 id="1-5-查看虚拟机设置"><a href="#1-5-查看虚拟机设置" class="headerlink" title="1.5 查看虚拟机设置"></a>1.5 查看虚拟机设置</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-112008.png" alt="查看虚拟机设置"></p><h1 id="2、开始系统安装"><a href="#2、开始系统安装" class="headerlink" title="2、开始系统安装"></a>2、开始系统安装</h1><h2 id="2-1-打开虚拟机电源"><a href="#2-1-打开虚拟机电源" class="headerlink" title="2.1 打开虚拟机电源"></a>2.1 打开虚拟机电源</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-130300.png" alt="打开虚拟机电源"></p><h2 id="2-2-键盘上下键，光标移动到-Install-Rocky-Linux-9-3-，回车开始安装系统"><a href="#2-2-键盘上下键，光标移动到-Install-Rocky-Linux-9-3-，回车开始安装系统" class="headerlink" title="2.2 键盘上下键，光标移动到 Install Rocky Linux 9.3 ，回车开始安装系统"></a>2.2 键盘上下键，光标移动到 Install Rocky Linux 9.3 ，回车开始安装系统</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-130444.png" alt="Install Rocky Linux 9.3"></p><h2 id="2-3-等待系统加载"><a href="#2-3-等待系统加载" class="headerlink" title="2.3 等待系统加载"></a>2.3 等待系统加载</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-130421.png" alt="等待系统加载"></p><h2 id="2-4-选择语言为中文，目的是这样会自动把时区设置到中国"><a href="#2-4-选择语言为中文，目的是这样会自动把时区设置到中国" class="headerlink" title="2.4 选择语言为中文，目的是这样会自动把时区设置到中国"></a>2.4 选择语言为中文，目的是这样会自动把时区设置到中国</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-130501.png" alt="选择语言为中文"></p><h2 id="2-5-设置root和硬盘"><a href="#2-5-设置root和硬盘" class="headerlink" title="2.5 设置root和硬盘"></a>2.5 设置root和硬盘</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-130628.png" alt="设置root，和硬盘"></p><h2 id="2-6-设置root密码，允许root远程登录"><a href="#2-6-设置root密码，允许root远程登录" class="headerlink" title="2.6 设置root密码，允许root远程登录"></a>2.6 设置root密码，允许root远程登录</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-130711.png" alt="设置root密码，允许root远程登录"></p><h2 id="2-7-选择磁盘"><a href="#2-7-选择磁盘" class="headerlink" title="2.7 选择磁盘"></a>2.7 选择磁盘</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-131738.png" alt="选择磁盘"></p><h2 id="2-8-设置完成后，正式开始安装"><a href="#2-8-设置完成后，正式开始安装" class="headerlink" title="2.8 设置完成后，正式开始安装"></a>2.8 设置完成后，正式开始安装</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-130828.png" alt="设置完成后，正式开始安装"></p><h2 id="2-9-等待安装完成"><a href="#2-9-等待安装完成" class="headerlink" title="2.9 等待安装完成"></a>2.9 等待安装完成</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-130851.png" alt="等待安装完成"></p><h2 id="2-10-安装完成，重启系统"><a href="#2-10-安装完成，重启系统" class="headerlink" title="2.10 安装完成，重启系统"></a>2.10 安装完成，重启系统</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-131511.png" alt="安装完成，重启系统"></p><h2 id="2-11-等待系统重启中"><a href="#2-11-等待系统重启中" class="headerlink" title="2.11 等待系统重启中"></a>2.11 等待系统重启中</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-131611.png" alt="等待系统重启中"></p><h2 id="2-12-重启完成，开始登录"><a href="#2-12-重启完成，开始登录" class="headerlink" title="2.12 重启完成，开始登录"></a>2.12 重启完成，开始登录</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/02/20250102-131648.png" alt="重启完成，开始登录"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;系统环境&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ESXI：8.0&lt;/p&gt;
&lt;p&gt;RockyLinux：9.3&lt;/p&gt;
&lt;p&gt;镜像下载官网：&lt;a href=&quot;https://rockylinux.org/zh-CN/download&quot;&gt;ht</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>25-责任链模式</title>
    <link href="https://georgechan95.github.io/blog/77d85f50.html"/>
    <id>https://georgechan95.github.io/blog/77d85f50.html</id>
    <published>2024-12-03T13:08:00.000Z</published>
    <updated>2024-12-03T08:57:39.735Z</updated>
    
    <content type="html"><![CDATA[<p><strong>责任链模式是一种对象的行为模式。在责任链模式里，很多对象由每一个对象对其下家的引用而连接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处理此请求。发出这个请求的客户端并不知道链上的哪一个对象最终处理这个请求，这使得系统可以在不影响客户端的情况下动态地重新组织和分配责任。</strong></p><p>一、从击鼓传花谈起</p><p>击鼓传花是一种热闹而又紧张的饮酒游戏。在酒宴上宾客依次坐定位置，由一人击鼓，击鼓的地方与传花的地方是分开的，以示公正。开始击鼓时，花束就开始依次传递，鼓声一落，如果花束在某人手中，则该人就得饮酒。</p><p>比如说，贾母、贾赦、贾政、贾宝玉和贾环是五个参加击鼓传花游戏的传花者，他们组成一个环链。击鼓者将花传给贾母，开始传花游戏。花由贾母传给贾赦，由贾赦传给贾政，由贾政传给贾宝玉，又贾宝玉传给贾环，由贾环传回给贾母，如此往复，如下图所示。当鼓声停止时，手中有花的人就得执行酒令。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2024/12/03/20241203-155845.png" alt="击鼓传花"></p><p>击鼓传花便是责任链模式的应用。责任链可能是一条直线、一个环链或者一个树结构的一部分。</p><p>二、责任链模式的结构</p><p>下面使用了一个责任链模式的最简单的实现。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2024/12/03/20241203-155934.png" alt="责任链模式结构图"></p><p>责任链模式涉及到的角色如下所示：</p><ul><li><p><strong>抽象处理者(Handler)角色：</strong>定义出一个处理请求的接口。如果需要，接口可以定义出一个方法以设定和返回对下家的引用。这个角色通常由一个Java抽象类或者Java接口实现。上图中Handler类的聚合关系给出了具体子类对下家的引用，抽象方法 <code>handleRequest()</code> 规范了子类处理请求的操作。</p></li><li><p><strong>具体处理者(ConcreteHandler)角色：</strong>具体处理者接到请求后，可以选择将请求处理掉，或者将请求传给下家。由于具体处理者持有对下家的引用，因此，如果需要，具体处理者可以访问下家。</p></li></ul><p><strong>代码实现如下：</strong></p><pre><code class="highlight java"><span class="comment">/**</span><span class="comment"> * 抽象处理者角色</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Handler</span> &#123;    <span class="comment">// 持有后继的责任对象</span>    <span class="keyword">private</span> Handler successor;    <span class="comment">/**</span><span class="comment">     * 处理请求方法的示例，这里没有传参，实际上可根据需要传参</span><span class="comment">     */</span>    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">handleRequest</span><span class="params">()</span>;    <span class="comment">/**</span><span class="comment">     * 获取后继责任对象</span><span class="comment">     * <span class="doctag">@return</span></span><span class="comment">     */</span>    <span class="keyword">public</span> Handler <span class="title function_">getSuccessor</span><span class="params">()</span> &#123;        <span class="keyword">return</span> successor;    &#125;    <span class="comment">/**</span><span class="comment">     * 设置后继责任对象</span><span class="comment">     * <span class="doctag">@param</span> successor</span><span class="comment">     */</span>    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSuccessor</span><span class="params">(Handler successor)</span> &#123;        <span class="built_in">this</span>.successor = successor;    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 具体处理者角色</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConcreteHandler</span> <span class="keyword">extends</span> <span class="title class_">Handler</span> &#123;    <span class="comment">/**</span><span class="comment">     * 请求处理方法</span><span class="comment">     */</span>    <span class="meta">@Override</span>    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleRequest</span><span class="params">()</span> &#123;        <span class="keyword">if</span> (getSuccessor() != <span class="literal">null</span>) &#123; <span class="comment">// 如果有后继处理者</span>            System.out.println(<span class="string">&quot;放过请求&quot;</span>);            <span class="comment">// 调用后继处理者，处理请求</span>            getSuccessor().handleRequest();        &#125; <span class="keyword">else</span> &#123; <span class="comment">// 自己处理请求</span>            System.out.println(<span class="string">&quot;处理请求&quot;</span>);        &#125;    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 测试类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Client</span> &#123;    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;        <span class="comment">// 创建责任链上的具体处理者对象</span>        <span class="type">Handler</span> <span class="variable">handler1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ConcreteHandler</span>();        <span class="type">Handler</span> <span class="variable">handler2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ConcreteHandler</span>();        <span class="comment">// 组装责任链</span>        handler1.setSuccessor(handler2);        <span class="comment">// 处理请求</span>        handler1.handleRequest();    &#125;&#125;</code></pre><blockquote><p>运行结果：</p><pre><code class="highlight shell">放过请求处理请求</code></pre></blockquote><p>可以看出，客户端创建了两个处理者对象，并指定第一个处理者对象的下家是第二个处理者对象，而第二个处理者对象没有下家。然后客户端将请求传递给第一个处理者对象。</p><p>由于本示例的传递逻辑非常简单：只要有下家，就传给下家处理；如果没有下家，就自行处理。因此，第一个处理者对象接到请求后，会将请求传递给第二个处理者对象。由于第二个处理者对象没有下家，于是自行处理请求。活动时序图如下所示。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2024/12/03/20241203-161859.png" alt="责任链处理时序图"></p><p>二、使用场景</p><p>来考虑这样一个功能: <strong>申请聚餐费用的管理。</strong></p><p>很多公司都是这样的福利，就是项目组或者是部门可以向公司申请一些聚餐费用，用于组织项目组成员或者是部门成员进行聚餐活动。</p><p>申请聚餐费用的大致流程一般是：由申请人先填写申请单，然后交给领导审批，如果申请批准下来，领导会通知申请人审批通过，然后申请人去财务领取费用，如果没有批准下来，领导会通知申请人审批未通过，此事也就此作罢。</p><p>不同级别的领导，对于审批的额度是不一样的，比如，项目经理只能审批500元以内的申请；部门经理能审批1000元以内的申请；而总经理可以审核任意额度的申请。</p><p>也就是说，当某人提出聚餐费用申请的请求后，该请求会经由项目经理、部门经理、总经理之中的某一位领导来进行相应的处理，但是提出申请的人并不知道最终会由谁来处理他的请求，一般申请人是把自己的申请提交给项目经理，或许最后是由总经理来处理他的请求。</p><p>可以使用责任链模式来实现上述功能：当某人提出聚餐费用申请的请求后，该请求会在 <strong>项目经理—〉部门经理—〉总经理</strong> 这样一条领导处理链上进行传递，发出请求的人并不知道谁会来处理他的请求，每个领导会根据自己的职责范围，来判断是处理请求还是把请求交给更高级别的领导，只要有领导处理了，传递就结束了。</p><p>需要把每位领导的处理独立出来，实现成单独的职责处理对象，然后为它们提供一个公共的、抽象的父职责对象，这样就可以在客户端来动态地组合职责链，实现不同的功能要求了。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2024/12/03/20241203-162843.png" alt="责任链模式UML"></p><p><strong>代码实现如下：</strong></p><pre><code class="highlight java"><span class="comment">/**</span><span class="comment"> * 抽象处理者角色类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Handler</span> &#123;    <span class="comment">/**</span><span class="comment">     * 持有下一个处理请求的对象</span><span class="comment">     */</span>    <span class="keyword">private</span> <span class="type">Handler</span> <span class="variable">successor</span> <span class="operator">=</span> <span class="literal">null</span>;    <span class="comment">/**</span><span class="comment">     * 获取下一个处理请求的对象</span><span class="comment">     *</span><span class="comment">     * <span class="doctag">@return</span></span><span class="comment">     */</span>    <span class="keyword">public</span> Handler <span class="title function_">getSuccessor</span><span class="params">()</span> &#123;        <span class="keyword">return</span> successor;    &#125;    <span class="comment">/**</span><span class="comment">     * 设置下一个处理请求的对象</span><span class="comment">     *</span><span class="comment">     * <span class="doctag">@param</span> successor</span><span class="comment">     */</span>    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSuccessor</span><span class="params">(Handler successor)</span> &#123;        <span class="built_in">this</span>.successor = successor;    &#125;    <span class="comment">/**</span><span class="comment">     * 处理聚餐费用的申请</span><span class="comment">     *</span><span class="comment">     * <span class="doctag">@param</span> user 申请人</span><span class="comment">     * <span class="doctag">@param</span> fee  申请的钱数</span><span class="comment">     * <span class="doctag">@return</span> 成功或失败的具体通知</span><span class="comment">     */</span>    <span class="keyword">public</span> <span class="keyword">abstract</span> String <span class="title function_">handleFeeRequest</span><span class="params">(String user, <span class="type">double</span> fee)</span>;&#125;<span class="comment">/**</span><span class="comment"> * 具体处理者-项目经理</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProjectManager</span> <span class="keyword">extends</span> <span class="title class_">Handler</span> &#123;    <span class="meta">@Override</span>    <span class="keyword">public</span> String <span class="title function_">handleFeeRequest</span><span class="params">(String user, <span class="type">double</span> fee)</span> &#123;        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;        <span class="comment">//项目经理权限比较小，只能在500以内</span>        <span class="keyword">if</span> (fee &lt; <span class="number">500</span>) &#123;            <span class="comment">//为了测试，简单点，只同意张三的请求</span>            <span class="keyword">if</span> (<span class="string">&quot;张三&quot;</span>.equals(user)) &#123;                str = <span class="string">&quot;成功：项目经理同意【&quot;</span> + user + <span class="string">&quot;】的聚餐费用，金额为&quot;</span> + fee + <span class="string">&quot;元&quot;</span>;            &#125; <span class="keyword">else</span> &#123;                <span class="comment">//其他人一律不同意</span>                str = <span class="string">&quot;失败：项目经理不同意【&quot;</span> + user + <span class="string">&quot;】的聚餐费用，金额为&quot;</span> + fee + <span class="string">&quot;元&quot;</span>;            &#125;        &#125; <span class="keyword">else</span> &#123;            <span class="comment">//超过500，继续传递给级别更高的人处理</span>            <span class="keyword">if</span> (getSuccessor() != <span class="literal">null</span>) &#123;                <span class="keyword">return</span> getSuccessor().handleFeeRequest(user, fee);            &#125;        &#125;        <span class="keyword">return</span> str;    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 具体处理者-部门经理</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DeptManager</span> <span class="keyword">extends</span> <span class="title class_">Handler</span> &#123;    <span class="meta">@Override</span>    <span class="keyword">public</span> String <span class="title function_">handleFeeRequest</span><span class="params">(String user, <span class="type">double</span> fee)</span> &#123;        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;        <span class="comment">//部门经理的权限只能在1000以内</span>        <span class="keyword">if</span> (fee &lt; <span class="number">1000</span>) &#123;            <span class="comment">//为了测试，简单点，只同意张三的请求</span>            <span class="keyword">if</span> (<span class="string">&quot;张三&quot;</span>.equals(user)) &#123;                str = <span class="string">&quot;成功：部门经理同意【&quot;</span> + user + <span class="string">&quot;】的聚餐费用，金额为&quot;</span> + fee + <span class="string">&quot;元&quot;</span>;            &#125; <span class="keyword">else</span> &#123;                <span class="comment">//其他人一律不同意</span>                str = <span class="string">&quot;失败：部门经理不同意【&quot;</span> + user + <span class="string">&quot;】的聚餐费用，金额为&quot;</span> + fee + <span class="string">&quot;元&quot;</span>;            &#125;        &#125; <span class="keyword">else</span> &#123;            <span class="comment">//超过1000，继续传递给级别更高的人处理</span>            <span class="keyword">if</span> (getSuccessor() != <span class="literal">null</span>) &#123;                <span class="keyword">return</span> getSuccessor().handleFeeRequest(user, fee);            &#125;        &#125;        <span class="keyword">return</span> str;    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 具体处理者-总经理</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GeneralManager</span> <span class="keyword">extends</span> <span class="title class_">Handler</span> &#123;    <span class="meta">@Override</span>    <span class="keyword">public</span> String <span class="title function_">handleFeeRequest</span><span class="params">(String user, <span class="type">double</span> fee)</span> &#123;        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;        <span class="comment">//总经理的权限很大，只要请求到了这里，他都可以处理</span>        <span class="keyword">if</span> (fee &gt;= <span class="number">1000</span>) &#123;            <span class="comment">//为了测试，简单点，只同意张三的请求</span>            <span class="keyword">if</span> (<span class="string">&quot;张三&quot;</span>.equals(user)) &#123;                str = <span class="string">&quot;成功：总经理同意【&quot;</span> + user + <span class="string">&quot;】的聚餐费用，金额为&quot;</span> + fee + <span class="string">&quot;元&quot;</span>;            &#125; <span class="keyword">else</span> &#123;                <span class="comment">//其他人一律不同意</span>                str = <span class="string">&quot;失败：总经理不同意【&quot;</span> + user + <span class="string">&quot;】的聚餐费用，金额为&quot;</span> + fee + <span class="string">&quot;元&quot;</span>;            &#125;        &#125; <span class="keyword">else</span> &#123;            <span class="comment">//如果还有后继的处理对象，继续传递</span>            <span class="keyword">if</span> (getSuccessor() != <span class="literal">null</span>) &#123;                <span class="keyword">return</span> getSuccessor().handleFeeRequest(user, fee);            &#125;        &#125;        <span class="keyword">return</span> str;    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 测试类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Client</span> &#123;    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;        <span class="comment">//先要组装责任链</span>        <span class="type">Handler</span> <span class="variable">h1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GeneralManager</span>();        <span class="type">Handler</span> <span class="variable">h2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DeptManager</span>();        <span class="type">Handler</span> <span class="variable">h3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ProjectManager</span>();        h3.setSuccessor(h2);        h2.setSuccessor(h1);        <span class="comment">//开始测试</span>        <span class="type">String</span> <span class="variable">test1</span> <span class="operator">=</span> h3.handleFeeRequest(<span class="string">&quot;张三&quot;</span>, <span class="number">300</span>);        System.out.println(<span class="string">&quot;test1 = &quot;</span> + test1);        <span class="type">String</span> <span class="variable">test2</span> <span class="operator">=</span> h3.handleFeeRequest(<span class="string">&quot;李四&quot;</span>, <span class="number">300</span>);        System.out.println(<span class="string">&quot;test2 = &quot;</span> + test2);        System.out.println(<span class="string">&quot;---------------------------------------&quot;</span>);        <span class="type">String</span> <span class="variable">test3</span> <span class="operator">=</span> h3.handleFeeRequest(<span class="string">&quot;张三&quot;</span>, <span class="number">700</span>);        System.out.println(<span class="string">&quot;test3 = &quot;</span> + test3);        <span class="type">String</span> <span class="variable">test4</span> <span class="operator">=</span> h3.handleFeeRequest(<span class="string">&quot;李四&quot;</span>, <span class="number">700</span>);        System.out.println(<span class="string">&quot;test4 = &quot;</span> + test4);        System.out.println(<span class="string">&quot;---------------------------------------&quot;</span>);        <span class="type">String</span> <span class="variable">test5</span> <span class="operator">=</span> h3.handleFeeRequest(<span class="string">&quot;张三&quot;</span>, <span class="number">1500</span>);        System.out.println(<span class="string">&quot;test5 = &quot;</span> + test5);        <span class="type">String</span> <span class="variable">test6</span> <span class="operator">=</span> h3.handleFeeRequest(<span class="string">&quot;李四&quot;</span>, <span class="number">1500</span>);        System.out.println(<span class="string">&quot;test6 = &quot;</span> + test6);    &#125;&#125;</code></pre><blockquote><p>运行结果：</p><pre><code class="highlight shell">test1 = 成功：项目经理同意【张三】的聚餐费用，金额为300.0元test2 = 失败：项目经理不同意【李四】的聚餐费用，金额为300.0元---------------------------------------test3 = 成功：部门经理同意【张三】的聚餐费用，金额为700.0元test4 = 失败：部门经理不同意【李四】的聚餐费用，金额为700.0元---------------------------------------test5 = 成功：总经理同意【张三】的聚餐费用，金额为1500.0元test6 = 失败：总经理不同意【李四】的聚餐费用，金额为1500.0元</code></pre></blockquote><p>三、纯的与不纯的责任链模式</p><ul><li><p>一个纯的责任链模式要求一个具体的处理者对象只能在两个行为中选择一个：一是承担责任，而是把责任推给下家。不允许出现某一个具体处理者对象在承担了一部分责任后又 把责任向下传的情况。</p></li><li><p>在一个纯的责任链模式里面，一个请求必须被某一个处理者对象所接收；在一个不纯的责任链模式里面，一个请求可以最终不被任何接收端对象所接收。</p></li><li><p>纯的责任链模式的实际例子很难找到，一般看到的例子均是不纯的责任链模式的实现。有些人认为不纯的责任链根本不是责任链模式，这也许是有道理的。但是在实际的系统里，纯的责任链很难找到。如果坚持责任链不纯便不是责任链模式，那么责任链模式便不会有太大意义了。</p></li></ul><p>四、责任链模式在Tomcat中的应用</p><p>众所周知Tomcat中的Filter就是使用了责任链模式，创建一个Filter除了要在web.xml文件中做相应配置外，还需要实现javax.servlet.Filter接口。</p><pre><code class="highlight java"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestFilter</span> <span class="keyword">implements</span> <span class="title class_">Filter</span>&#123;    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doFilter</span><span class="params">(ServletRequest request, ServletResponse response,</span><span class="params">            FilterChain chain)</span> <span class="keyword">throws</span> IOException, ServletException &#123;                chain.doFilter(request, response);    &#125;    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">destroy</span><span class="params">()</span> &#123;    &#125;    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">(FilterConfig filterConfig)</span> <span class="keyword">throws</span> ServletException &#123;    &#125;&#125;</code></pre><p>使用DEBUG模式所看到的结果如下</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2024/12/03/20241203-164526.png" alt="Filter责任链"></p><p>其实在真正执行到TestFilter类之前，会经过很多Tomcat内部的类。<strong>顺带提一下其实Tomcat的容器设置也是责任链模式，注意被红色方框所圈中的类，从Engine到Host再到Context一直到Wrapper都是通过一个链传递请求</strong>。被绿色方框所圈中的地方有一个名为ApplicationFilterChain的类，ApplicationFilterChain类所扮演的就是抽象处理者角色，而具体处理者角色由各个Filter扮演。</p><p><em>第一个疑问是ApplicationFilterChain将所有的Filter存放在哪里？</em></p><p>答案是保存在ApplicationFilterChain类中的一个ApplicationFilterConfig对象的数组中。</p><pre><code class="highlight java"><span class="comment">/**</span><span class="comment"> * Filters.</span><span class="comment"> */</span><span class="keyword">private</span> ApplicationFilterConfig[] filters =     <span class="keyword">new</span> <span class="title class_">ApplicationFilterConfig</span>[<span class="number">0</span>];</code></pre><p><em>那ApplicationFilterConfig对象又是什么呢？</em></p><p>ApplicationFilterConfig是一个Filter容器。以下是ApplicationFilterConfig类的声明：</p><pre><code class="highlight java"><span class="comment">/**</span><span class="comment"> * Implementation of a &lt;code&gt;javax.servlet.FilterConfig&lt;/code&gt; useful in</span><span class="comment"> * managing the filter instances instantiated when a web application</span><span class="comment"> * is first started.</span><span class="comment"> *</span><span class="comment"> * <span class="doctag">@author</span> Craig R. McClanahan</span><span class="comment"> * <span class="doctag">@version</span> $Id: ApplicationFilterConfig.java 1201569 2011-11-14 01:36:07Z kkolinko $</span><span class="comment"> */</span></code></pre><p>当一个web应用首次启动时ApplicationFilterConfig会自动实例化，它会从该web应用的web.xml文件中读取配置的Filter的信息，然后装进该容器。</p><p><em>刚刚看到在ApplicationFilterChain类中所创建的ApplicationFilterConfig数组长度为零，那它是在什么时候被重新赋值的呢？</em></p><pre><code class="highlight java"><span class="keyword">private</span> ApplicationFilterConfig[] filters =         <span class="keyword">new</span> <span class="title class_">ApplicationFilterConfig</span>[<span class="number">0</span>];</code></pre><p>是在调用ApplicationFilterChain类的addFilter()方法时。</p><pre><code class="highlight java"><span class="comment">/**</span><span class="comment"> * The int which gives the current number of filters in the chain.</span><span class="comment"> */</span><span class="keyword">private</span> <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> <span class="number">0</span>;</code></pre><pre><code class="highlight java"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">INCREMENT</span> <span class="operator">=</span> <span class="number">10</span>;</code></pre><pre><code class="highlight java"><span class="keyword">void</span> <span class="title function_">addFilter</span><span class="params">(ApplicationFilterConfig filterConfig)</span> &#123;    <span class="comment">// Prevent the same filter being added multiple times</span>    <span class="keyword">for</span>(ApplicationFilterConfig filter:filters)        <span class="keyword">if</span>(filter==filterConfig)            <span class="keyword">return</span>;    <span class="keyword">if</span> (n == filters.length) &#123;        ApplicationFilterConfig[] newFilters =            <span class="keyword">new</span> <span class="title class_">ApplicationFilterConfig</span>[n + INCREMENT];        System.arraycopy(filters, <span class="number">0</span>, newFilters, <span class="number">0</span>, n);        filters = newFilters;    &#125;    filters[n++] = filterConfig;&#125;</code></pre><p>变量n用来记录当前过滤器链里面拥有的过滤器数目，默认情况下n等于0，ApplicationFilterConfig对象数组的长度也等于0，所以当第一次调用addFilter()方法时，if (n &#x3D;&#x3D; filters.length)的条件成立，ApplicationFilterConfig数组长度被改变。之后filters[n++] &#x3D; filterConfig;将变量filterConfig放入ApplicationFilterConfig数组中并将当前过滤器链里面拥有的过滤器数目+1。</p><p><em>那ApplicationFilterChain的addFilter()方法又是在什么地方被调用的呢？</em></p><p>是在ApplicationFilterFactory类的createFilterChain()方法中。</p><pre><code class="highlight java"><span class="keyword">public</span> ApplicationFilterChain <span class="title function_">createFilterChain</span>        <span class="params">(ServletRequest request, Wrapper wrapper, Servlet servlet)</span> &#123;    <span class="comment">// get the dispatcher type</span>    <span class="type">DispatcherType</span> <span class="variable">dispatcher</span> <span class="operator">=</span> <span class="literal">null</span>;    <span class="keyword">if</span> (request.getAttribute(DISPATCHER_TYPE_ATTR) != <span class="literal">null</span>) &#123;        dispatcher = (DispatcherType) request.getAttribute(DISPATCHER_TYPE_ATTR);    &#125;    <span class="type">String</span> <span class="variable">requestPath</span> <span class="operator">=</span> <span class="literal">null</span>;    <span class="type">Object</span> <span class="variable">attribute</span> <span class="operator">=</span> request.getAttribute(DISPATCHER_REQUEST_PATH_ATTR);    <span class="keyword">if</span> (attribute != <span class="literal">null</span>)&#123;        requestPath = attribute.toString();    &#125;    <span class="comment">// If there is no servlet to execute, return null</span>    <span class="keyword">if</span> (servlet == <span class="literal">null</span>)        <span class="keyword">return</span> (<span class="literal">null</span>);    <span class="type">boolean</span> <span class="variable">comet</span> <span class="operator">=</span> <span class="literal">false</span>;    <span class="comment">// Create and initialize a filter chain object</span>    <span class="type">ApplicationFilterChain</span> <span class="variable">filterChain</span> <span class="operator">=</span> <span class="literal">null</span>;    <span class="keyword">if</span> (request <span class="keyword">instanceof</span> Request) &#123;        <span class="type">Request</span> <span class="variable">req</span> <span class="operator">=</span> (Request) request;        comet = req.isComet();        <span class="keyword">if</span> (Globals.IS_SECURITY_ENABLED) &#123;            <span class="comment">// Security: Do not recycle</span>            filterChain = <span class="keyword">new</span> <span class="title class_">ApplicationFilterChain</span>();            <span class="keyword">if</span> (comet) &#123;                req.setFilterChain(filterChain);            &#125;        &#125; <span class="keyword">else</span> &#123;            filterChain = (ApplicationFilterChain) req.getFilterChain();            <span class="keyword">if</span> (filterChain == <span class="literal">null</span>) &#123;                filterChain = <span class="keyword">new</span> <span class="title class_">ApplicationFilterChain</span>();                req.setFilterChain(filterChain);            &#125;        &#125;    &#125; <span class="keyword">else</span> &#123;        <span class="comment">// Request dispatcher in use</span>        filterChain = <span class="keyword">new</span> <span class="title class_">ApplicationFilterChain</span>();    &#125;    filterChain.setServlet(servlet);    filterChain.setSupport        (((StandardWrapper)wrapper).getInstanceSupport());    <span class="comment">// Acquire the filter mappings for this Context</span>    <span class="type">StandardContext</span> <span class="variable">context</span> <span class="operator">=</span> (StandardContext) wrapper.getParent();    FilterMap filterMaps[] = context.findFilterMaps();    <span class="comment">// If there are no filter mappings, we are done</span>    <span class="keyword">if</span> ((filterMaps == <span class="literal">null</span>) || (filterMaps.length == <span class="number">0</span>))        <span class="keyword">return</span> (filterChain);    <span class="comment">// Acquire the information we will need to match filter mappings</span>    <span class="type">String</span> <span class="variable">servletName</span> <span class="operator">=</span> wrapper.getName();    <span class="comment">// Add the relevant path-mapped filters to this filter chain</span>    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; filterMaps.length; i++) &#123;        <span class="keyword">if</span> (!matchDispatcher(filterMaps[i] ,dispatcher)) &#123;            <span class="keyword">continue</span>;        &#125;        <span class="keyword">if</span> (!matchFiltersURL(filterMaps[i], requestPath))            <span class="keyword">continue</span>;        <span class="type">ApplicationFilterConfig</span> <span class="variable">filterConfig</span> <span class="operator">=</span> (ApplicationFilterConfig)            context.findFilterConfig(filterMaps[i].getFilterName());        <span class="keyword">if</span> (filterConfig == <span class="literal">null</span>) &#123;            <span class="comment">// FIXME - log configuration problem</span>            <span class="keyword">continue</span>;        &#125;        <span class="type">boolean</span> <span class="variable">isCometFilter</span> <span class="operator">=</span> <span class="literal">false</span>;        <span class="keyword">if</span> (comet) &#123;            <span class="keyword">try</span> &#123;                isCometFilter = filterConfig.getFilter() <span class="keyword">instanceof</span> CometFilter;            &#125; <span class="keyword">catch</span> (Exception e) &#123;                <span class="comment">// Note: The try catch is there because getFilter has a lot of</span>                <span class="comment">// declared exceptions. However, the filter is allocated much</span>                <span class="comment">// earlier</span>                <span class="type">Throwable</span> <span class="variable">t</span> <span class="operator">=</span> ExceptionUtils.unwrapInvocationTargetException(e);                ExceptionUtils.handleThrowable(t);            &#125;            <span class="keyword">if</span> (isCometFilter) &#123;                filterChain.addFilter(filterConfig);            &#125;        &#125; <span class="keyword">else</span> &#123;            filterChain.addFilter(filterConfig);        &#125;    &#125;    <span class="comment">// Add filters that match on servlet name second</span>    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; filterMaps.length; i++) &#123;        <span class="keyword">if</span> (!matchDispatcher(filterMaps[i] ,dispatcher)) &#123;            <span class="keyword">continue</span>;        &#125;        <span class="keyword">if</span> (!matchFiltersServlet(filterMaps[i], servletName))            <span class="keyword">continue</span>;        <span class="type">ApplicationFilterConfig</span> <span class="variable">filterConfig</span> <span class="operator">=</span> (ApplicationFilterConfig)            context.findFilterConfig(filterMaps[i].getFilterName());        <span class="keyword">if</span> (filterConfig == <span class="literal">null</span>) &#123;            <span class="comment">// FIXME - log configuration problem</span>            <span class="keyword">continue</span>;        &#125;        <span class="type">boolean</span> <span class="variable">isCometFilter</span> <span class="operator">=</span> <span class="literal">false</span>;        <span class="keyword">if</span> (comet) &#123;            <span class="keyword">try</span> &#123;                isCometFilter = filterConfig.getFilter() <span class="keyword">instanceof</span> CometFilter;            &#125; <span class="keyword">catch</span> (Exception e) &#123;                <span class="comment">// Note: The try catch is there because getFilter has a lot of</span>                <span class="comment">// declared exceptions. However, the filter is allocated much</span>                <span class="comment">// earlier</span>            &#125;            <span class="keyword">if</span> (isCometFilter) &#123;                filterChain.addFilter(filterConfig);            &#125;        &#125; <span class="keyword">else</span> &#123;            filterChain.addFilter(filterConfig);        &#125;    &#125;    <span class="comment">// Return the completed filter chain</span>    <span class="keyword">return</span> (filterChain);&#125;</code></pre><p>可以将如上代码分为两段，51行之前为第一段( <code>StandardContext context = (StandardContext) wrapper.getParent();</code> )，51行之后为第二段。</p><p>第一段的主要目的是创建ApplicationFilterChain对象以及一些参数设置。</p><p>第二段的主要目的是从上下文中获取所有Filter信息，之后使用for循环遍历并调用 <code>filterChain.addFilter(filterConfig);</code> 将filterConfig放入ApplicationFilterChain对象的ApplicationFilterConfig数组中。</p><p>那ApplicationFilterFactory类的createFilterChain()方法又是在什么地方被调用的呢？</p><p>是在StandardWrapperValue类的invoke()方法中被调用的。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2024/12/03/20241203-165319.png" alt="StandardWrapperValue"></p><p>由于invoke()方法较长，所以将很多地方省略。</p><pre><code class="highlight java"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title function_">invoke</span><span class="params">(Request request, Response response)</span>        <span class="keyword">throws</span> IOException, ServletException &#123;...省略中间代码　　　　 <span class="comment">// Create the filter chain for this request</span>    <span class="type">ApplicationFilterFactory</span> <span class="variable">factory</span> <span class="operator">=</span>        ApplicationFilterFactory.getInstance();    <span class="type">ApplicationFilterChain</span> <span class="variable">filterChain</span> <span class="operator">=</span>        factory.createFilterChain(request, wrapper, servlet);...省略中间代码     filterChain.doFilter(request.getRequest(), response.getResponse());...省略中间代码&#125;</code></pre><p>那正常的流程应该是这样的：</p><p>在<code>StandardWrapperValue</code>类的<code>invoke()</code>方法中调用<code>ApplicationFilterChai</code>类的<code>createFilterChain()</code>方法———&gt;在<code>ApplicationFilterChai</code>类的<code>createFilterChain()</code>方法中调用<code>ApplicationFilterChain</code>类的<code>addFilter()</code>方法———&gt;在<code>ApplicationFilterChain</code>类的<code>addFilter()</code>方法中给<code>ApplicationFilterConfig</code>数组赋值。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2024/12/03/20241203-165514.png" alt="调用流程"></p><p>根据上面的代码可以看出StandardWrapperValue类的invoke()方法在执行完createFilterChain()方法后，会继续执行ApplicationFilterChain类的doFilter()方法，然后在doFilter()方法中会调用internalDoFilter()方法。</p><p>以下是internalDoFilter()方法的部分代码</p><pre><code class="highlight java"><span class="comment">// Call the next filter if there is one</span><span class="keyword">if</span> (pos &lt; n) &#123;　　　　　　　<span class="comment">//拿到下一个Filter，将指针向下移动一位            //pos它来标识当前ApplicationFilterChain（当前过滤器链）执行到哪个过滤器</span>    <span class="type">ApplicationFilterConfig</span> <span class="variable">filterConfig</span> <span class="operator">=</span> filters[pos++];    <span class="type">Filter</span> <span class="variable">filter</span> <span class="operator">=</span> <span class="literal">null</span>;    <span class="keyword">try</span> &#123;　　　　　　　　　 <span class="comment">//获取当前指向的Filter的实例</span>        filter = filterConfig.getFilter();        support.fireInstanceEvent(InstanceEvent.BEFORE_FILTER_EVENT,                                  filter, request, response);        <span class="keyword">if</span> (request.isAsyncSupported() &amp;&amp; <span class="string">&quot;false&quot;</span>.equalsIgnoreCase(                filterConfig.getFilterDef().getAsyncSupported())) &#123;            request.setAttribute(Globals.ASYNC_SUPPORTED_ATTR,                    Boolean.FALSE);        &#125;        <span class="keyword">if</span>( Globals.IS_SECURITY_ENABLED ) &#123;            <span class="keyword">final</span> <span class="type">ServletRequest</span> <span class="variable">req</span> <span class="operator">=</span> request;            <span class="keyword">final</span> <span class="type">ServletResponse</span> <span class="variable">res</span> <span class="operator">=</span> response;            <span class="type">Principal</span> <span class="variable">principal</span> <span class="operator">=</span>                 ((HttpServletRequest) req).getUserPrincipal();            Object[] args = <span class="keyword">new</span> <span class="title class_">Object</span>[]&#123;req, res, <span class="built_in">this</span>&#125;;            SecurityUtil.doAsPrivilege                (<span class="string">&quot;doFilter&quot;</span>, filter, classType, args, principal);        &#125; <span class="keyword">else</span> &#123;　　　　　　　　　　　　<span class="comment">//调用Filter的doFilter()方法  </span>            filter.doFilter(request, response, <span class="built_in">this</span>);        &#125;</code></pre><p>这里的filter.doFilter(request, response, this);就是调用我们前面创建的TestFilter中的doFilter()方法。而TestFilter中的doFilter()方法会继续调用chain.doFilter(request, response);方法，而这个chain其实就是ApplicationFilterChain,所以调用过程又回到了上面调用dofilter和调用internalDoFilter方法，这样执行直到里面的过滤器全部执行。</p><p>如果定义两个过滤器，则Debug结果如下：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2024/12/03/20241203-165659.png" alt="Debug"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;责任链模式是一种对象的行为模式。在责任链模式里，很多对象由每一个对象对其下家的引用而连接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处理此请求。发出这个请求的客户端并不知道链上的哪一个对象最终处理这个请求，这使得系统可以在不影响客户端的情况下</summary>
      
    
    
    
    <category term="设计模式" scheme="https://georgechan95.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
    <category term="设计模式" scheme="https://georgechan95.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>24-策略模式</title>
    <link href="https://georgechan95.github.io/blog/fcec839d.html"/>
    <id>https://georgechan95.github.io/blog/fcec839d.html</id>
    <published>2024-12-02T10:16:00.000Z</published>
    <updated>2024-12-03T05:08:38.752Z</updated>
    
    <content type="html"><![CDATA[<p><strong>策略模式属于对象的行为模式。其用意是针对一组算法，将每一个算法封装到具有共同接口的独立的类中，从而使得它们可以相互替换。策略模式使得算法可以在不影响到客户端的情况下发生变化。</strong></p><h1 id="一、策略模式的结构"><a href="#一、策略模式的结构" class="headerlink" title="一、策略模式的结构"></a>一、策略模式的结构</h1><p>策略模式是对算法的包装，是把使用算法的责任和算法本身分割开来，委派给不同的对象管理。策略模式通常把一个系列的算法包装到一系列的策略类里面，作为一个抽象策略类的子类。用一句话来说，就是：“准备一组算法，并将每一个算法封装起来，使得它们可以互换”。下面就以一个示意性的实现讲解策略模式实例的结构。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2024/12/03/20241203-123412.png" alt="策略模式结构"></p><p>这个模式涉及到三个角色：</p><ul><li><strong>环境(Context)角色：</strong>持有一个Strategy的引用。</li><li><strong>抽象策略(Strategy)角色：</strong>这是一个抽象角色，通常由一个接口或抽象类实现。此角色给出所有的具体策略类所需的接口。</li><li><strong>具体策略(ConcreteStrategy)角色：</strong>包装了相关的算法或行为。</li></ul><p><strong>代码实现如下：</strong></p><pre><code class="highlight java"><span class="comment">/**</span><span class="comment"> * 环境角色类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Context</span> &#123;    <span class="comment">// 持有一个具体的策略对象</span>    <span class="keyword">private</span> Strategy strategy;    <span class="keyword">public</span> <span class="title function_">Context</span><span class="params">(Strategy strategy)</span> &#123;        <span class="built_in">this</span>.strategy = strategy;    &#125;    <span class="comment">/**</span><span class="comment">     * 调用策略方法</span><span class="comment">     */</span>    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">contextInterface</span><span class="params">()</span> &#123;        strategy.strategyInterface();    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 抽象策略类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Strategy</span> &#123;    <span class="comment">/**</span><span class="comment">     * 策略方法</span><span class="comment">     */</span>    <span class="keyword">void</span> <span class="title function_">strategyInterface</span><span class="params">()</span>;&#125;<span class="comment">/**</span><span class="comment"> * 具体策略类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConcreteStrategyA</span> <span class="keyword">implements</span> <span class="title class_">Strategy</span> &#123;    <span class="meta">@Override</span>    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">strategyInterface</span><span class="params">()</span> &#123;    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 具体策略类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConcreteStrategyB</span> <span class="keyword">implements</span> <span class="title class_">Strategy</span> &#123;    <span class="meta">@Override</span>    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">strategyInterface</span><span class="params">()</span> &#123;    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 具体策略类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConcreteStrategyC</span> <span class="keyword">implements</span> <span class="title class_">Strategy</span> &#123;    <span class="meta">@Override</span>    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">strategyInterface</span><span class="params">()</span> &#123;    &#125;&#125;</code></pre><h1 id="二、使用场景"><a href="#二、使用场景" class="headerlink" title="二、使用场景"></a>二、使用场景</h1><p>假设现在要设计一个贩卖各类书籍的电子商务网站的购物车系统。一个最简单的情况就是把所有货品的单价乘上数量，但是实际情况肯定比这要复杂。比如，本网站可能对所有的高级会员提供每本20%的促销折扣；对中级会员提供每本10%的促销折扣；对初级会员没有折扣。</p><p>根据描述，折扣是根据以下的几个算法中的一个进行的：</p><ul><li>算法一：对初级会员没有折扣。</li><li>算法二：对中级会员提供10%的促销折扣。</li><li>算法三：对高级会员提供20%的促销折扣。</li></ul><p>使用策略模式来实现的结构图如下：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2024/12/03/20241203-125237.png" alt="策略模式UML"></p><p><strong>代码实现如下：</strong></p><pre><code class="highlight java"><span class="comment">/**</span><span class="comment"> * 抽象折扣类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">MemberStrategy</span> &#123;    <span class="comment">/**</span><span class="comment">     * 计算图书的价格</span><span class="comment">     * <span class="doctag">@param</span> booksPrice 图书的原价</span><span class="comment">     * <span class="doctag">@return</span> 计算出打折后的价格</span><span class="comment">     */</span>    <span class="type">double</span> <span class="title function_">calcPrice</span><span class="params">(<span class="type">double</span> booksPrice)</span>;&#125;<span class="comment">/**</span><span class="comment"> * 初级会员折扣类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PrimaryMemberStrategy</span> <span class="keyword">implements</span> <span class="title class_">MemberStrategy</span> &#123;    <span class="meta">@Override</span>    <span class="keyword">public</span> <span class="type">double</span> <span class="title function_">calcPrice</span><span class="params">(<span class="type">double</span> booksPrice)</span> &#123;        System.out.println(<span class="string">&quot;对于初级会员的没有折扣&quot;</span>);        <span class="keyword">return</span> booksPrice;    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 中级会员折扣类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">IntermediateMemberStrategy</span> <span class="keyword">implements</span> <span class="title class_">MemberStrategy</span> &#123;    <span class="meta">@Override</span>    <span class="keyword">public</span> <span class="type">double</span> <span class="title function_">calcPrice</span><span class="params">(<span class="type">double</span> booksPrice)</span> &#123;        System.out.println(<span class="string">&quot;对于中级会员的折扣为10%&quot;</span>);        <span class="keyword">return</span> booksPrice * <span class="number">0.9</span>;    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 高级会员折扣类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AdvancedMemberStrategy</span> <span class="keyword">implements</span> <span class="title class_">MemberStrategy</span> &#123;    <span class="meta">@Override</span>    <span class="keyword">public</span> <span class="type">double</span> <span class="title function_">calcPrice</span><span class="params">(<span class="type">double</span> booksPrice)</span> &#123;        System.out.println(<span class="string">&quot;对于高级会员的折扣为20%&quot;</span>);        <span class="keyword">return</span> booksPrice * <span class="number">0.8</span>;    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 价格计算类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Price</span> &#123;    <span class="comment">// 持有一个具体的策略对象</span>    <span class="keyword">private</span> MemberStrategy memberStrategy;    <span class="keyword">public</span> <span class="title function_">Price</span><span class="params">(MemberStrategy memberStrategy)</span> &#123;        <span class="built_in">this</span>.memberStrategy = memberStrategy;    &#125;    <span class="comment">/**</span><span class="comment">     * 计算图书的价格</span><span class="comment">     * <span class="doctag">@param</span> booksPrice 图书的原价</span><span class="comment">     * <span class="doctag">@return</span> 计算出打折后的价格</span><span class="comment">     */</span>    <span class="keyword">public</span> <span class="type">double</span> <span class="title function_">quote</span><span class="params">(<span class="type">double</span> booksPrice)</span> &#123;        <span class="keyword">return</span> <span class="built_in">this</span>.memberStrategy.calcPrice(booksPrice);    &#125;&#125;<span class="comment">/**</span><span class="comment"> * 测试类</span><span class="comment"> */</span><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Client</span> &#123;    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;        <span class="comment">//选择并创建需要使用的策略对象</span>        <span class="type">MemberStrategy</span> <span class="variable">strategy</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AdvancedMemberStrategy</span>();        <span class="comment">//创建环境</span>        <span class="type">Price</span> <span class="variable">price</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Price</span>(strategy);        <span class="comment">//计算价格</span>        <span class="type">double</span> <span class="variable">quote</span> <span class="operator">=</span> price.quote(<span class="number">300</span>);        System.out.println(<span class="string">&quot;图书的最终价格为：&quot;</span> + quote);    &#125;&#125;</code></pre><blockquote><p>运行结果：</p><pre><code class="highlight shell">对于高级会员的折扣为20%图书的最终价格为：240.0</code></pre></blockquote><p>从上面的示例可以看出，策略模式仅仅封装算法，提供新的算法插入到已有系统中，以及老算法从系统中“退休”的方法，策略模式并不决定在何时使用何种算法。在什么情况下使用什么算法是由客户端决定的。</p><h1 id="三、认识策略模式"><a href="#三、认识策略模式" class="headerlink" title="三、认识策略模式"></a>三、认识策略模式</h1><ul><li><p><strong>策略模式的重心</strong></p><p>策略模式的重心不是如何实现算法，而是如何组织、调用这些算法，从而让程序结构更灵活，具有更好的维护性和扩展性。</p></li><li><p><strong>算法的平等性</strong></p><p>策略模式一个很大的特点就是各个策略算法的平等性。对于一系列具体的策略算法，大家的地位是完全一样的，正因为这个平等性，才能实现算法之间可以相互替换。所有的策略算法在实现上也是相互独立的，相互之间是没有依赖的。</p><p>所以可以这样描述这一系列策略算法：策略算法是相同行为的不同实现。</p></li><li><p><strong>运行时策略的唯一性</strong></p><p>运行期间，策略模式在每一个时刻只能使用一个具体的策略实现对象，虽然可以动态地在不同的策略实现中切换，但是同时只能使用一个。</p></li><li><p><strong>公有的行为</strong></p><p>经常见到的是，所有的具体策略类都有一些公有的行为。这时候，就应当把这些公有的行为放到共同的抽象策略角色Strategy类里面。当然这时候抽象策略角色必须要用Java抽象类实现，而不能使用接口。</p><p>这其实也是典型的将代码向继承等级结构的上方集中的标准做法。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2024/12/03/20241203-130623.png" alt="使用抽象类实现共有行为"></p></li></ul><h1 id="四、策略模式的优-缺点"><a href="#四、策略模式的优-缺点" class="headerlink" title="四、策略模式的优&#x2F;缺点"></a>四、策略模式的优&#x2F;缺点</h1><ul><li>优点<ul><li>策略模式提供了管理相关的算法族的办法。策略类的等级结构定义了一个算法或行为族。恰当使用继承可以把公共的代码移到父类里面，从而避免代码重复。</li><li>使用策略模式可以避免使用多重条件(if-else)语句。多重条件语句不易维护，它把采取哪一种算法或采取哪一种行为的逻辑与算法或行为的逻辑混合在一起，统统列在一个多重条件语句里面，比使用继承的办法还要原始和落后</li></ul></li><li>缺点<ul><li>客户端必须知道所有的策略类，并自行决定使用哪一个策略类。这就意味着客户端必须理解这些算法的区别，以便适时选择恰当的算法类。换言之，策略模式只适用于客户端知道算法或行为的情况。</li><li>由于策略模式把每个具体的策略实现都单独封装成为类，如果备选的策略很多的话，那么对象的数目就会很可观。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;策略模式属于对象的行为模式。其用意是针对一组算法，将每一个算法封装到具有共同接口的独立的类中，从而使得它们可以相互替换。策略模式使得算法可以在不影响到客户端的情况下发生变化。&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;一、策略模式的结构&quot;&gt;&lt;a href=&quot;</summary>
      
    
    
    
    <category term="设计模式" scheme="https://georgechan95.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
    <category term="设计模式" scheme="https://georgechan95.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
</feed>
