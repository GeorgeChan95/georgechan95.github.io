<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>George&#39;s Blog</title>
  
  <subtitle>个人邮箱：george_95@126.com</subtitle>
  <link href="https://georgechan95.github.io/atom.xml" rel="self"/>
  
  <link href="https://georgechan95.github.io/"/>
  <updated>2025-10-30T07:13:01.979Z</updated>
  <id>https://georgechan95.github.io/</id>
  
  <author>
    <name>George</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>025-K8S-二进制高可用部署</title>
    <link href="https://georgechan95.github.io/blog/8f6b48eb.html"/>
    <id>https://georgechan95.github.io/blog/8f6b48eb.html</id>
    <published>2025-09-30T22:33:00.000Z</published>
    <updated>2025-10-30T07:13:01.979Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、系统环境"><a href="#一、系统环境" class="headerlink" title="一、系统环境"></a>一、系统环境</h1><ul><li>操作系统：Rocky Linux 9.3</li><li>内核版本：5.14.0-284.11.1.el9_2.x86_64</li><li>容器运行时：Docker + CRI-Docker</li><li>Kubernetes 版本：1.29.2</li><li>网络插件：Calico</li></ul><h1 id="二、集群规划"><a href="#二、集群规划" class="headerlink" title="二、集群规划"></a>二、集群规划</h1><p>基于二进制安装包，部署三主两从的高可用集群。</p><table><thead><tr><th>主机名称</th><th>IPV4地址</th><th>CPU&#x2F;内存&#x2F;磁盘</th><th>说明</th><th>软件</th></tr></thead><tbody><tr><td></td><td>10.20.1.203</td><td>2C&#x2F;4G&#x2F;200G</td><td>外网节点(可翻墙)</td><td>下载各种所需安装包</td></tr><tr><td>Master01</td><td>10.20.1.100</td><td>2C&#x2F;4G&#x2F;200G</td><td>master节点</td><td>apiserver、controller-manager、scheduler、etcd、 kubelet、kube-proxy、nginx</td></tr><tr><td>Master02</td><td>10.20.1.101</td><td>2C&#x2F;4G&#x2F;200G</td><td>master节点</td><td>apiserver、controller-manager、scheduler、etcd、 kubelet、kube-proxy、nginx</td></tr><tr><td>Master03</td><td>10.20.1.102</td><td>2C&#x2F;4G&#x2F;200G</td><td>master节点</td><td>apiserver、controller-manager、scheduler、etcd、 kubelet、kube-proxy、nginx</td></tr><tr><td>Node01</td><td>10.20.1.103</td><td>2C&#x2F;4G&#x2F;200G</td><td>node节点</td><td>kubelet、kube-proxy、nginx</td></tr><tr><td>Node02</td><td>10.20.1.104</td><td>2C&#x2F;4G&#x2F;200G</td><td>node节点</td><td>kubelet、kube-proxy、nginx</td></tr></tbody></table><h1 id="三、基础环境配置-所有节点"><a href="#三、基础环境配置-所有节点" class="headerlink" title="三、基础环境配置(所有节点)"></a>三、基础环境配置(所有节点)</h1><h2 id="1-主机名设置"><a href="#1-主机名设置" class="headerlink" title="1. 主机名设置"></a>1. 主机名设置</h2><p>设置集群中各个节点的主机名</p><p><strong>Master01 节点</strong></p><pre><code class="highlight bash">hostnamectl set-hostname k8s-master01</code></pre><p><strong>Master02 节点</strong></p><pre><code class="highlight bash">hostnamectl set-hostname k8s-master02</code></pre><p><strong>Master03 节点</strong></p><pre><code class="highlight bash">hostnamectl set-hostname k8s-master03</code></pre><p><strong>Node01 节点</strong></p><pre><code class="highlight bash">hostnamectl set-hostname k8s-node01</code></pre><p><strong>Node02 节点</strong></p><pre><code class="highlight bash">hostnamectl set-hostname k8s-node02</code></pre><h2 id="2-配置静态IP"><a href="#2-配置静态IP" class="headerlink" title="2. 配置静态IP"></a>2. 配置静态IP</h2><p>集群内的每个几点都需要配置唯一的IP地址，这里同时配置了 IPV4地址 和 IPV6地址。</p><p><strong>Master01 节点</strong></p><pre><code class="highlight bash">[root@k8s-master01 ~]<span class="comment"># cat /etc/NetworkManager/system-connections/ens34.nmconnection</span>[ipv4]method=manualaddress1=10.20.1.101/24;10.20.1.1dns=61.132.163.68;114.114.114.114[ipv6]method=manualaddresses=2400:3200::101/64gateway=2400:3200::1dns=2400:3200::1;2400:3200:baba::1;2001:4860:4860::8888;2001:4860:4860::8844</code></pre><p><strong>Master02 节点</strong></p><pre><code class="highlight bash">[root@k8s-master02 ~]<span class="comment"># cat /etc/NetworkManager/system-connections/ens34.nmconnection</span>[ipv4]method=manualaddress1=10.20.1.102/24;10.20.1.1dns=61.132.163.68;114.114.114.114[ipv6]method=manualaddresses=2400:3200::102/64gateway=2400:3200::1dns=2400:3200::1;2400:3200:baba::1;2001:4860:4860::8888;2001:4860:4860::8844</code></pre><p><strong>Master03 节点</strong></p><pre><code class="highlight bash">[root@k8s-master03 ~]<span class="comment"># cat /etc/NetworkManager/system-connections/ens34.nmconnection</span>[ipv4]method=manualaddress1=10.20.1.103/24;10.20.1.1dns=61.132.163.68;114.114.114.114[ipv6]method=manualaddresses=2400:3200::103/64gateway=2400:3200::1dns=2400:3200::1;2400:3200:baba::1;2001:4860:4860::8888;2001:4860:4860::8844</code></pre><p><strong>Node01 节点</strong></p><pre><code class="highlight bash">[root@k8s-node01 ~]<span class="comment"># cat /etc/NetworkManager/system-connections/ens34.nmconnection</span>[ipv4]method=manualaddress1=10.20.1.104/24;10.20.1.1dns=61.132.163.68;114.114.114.114[ipv6]method=manualaddresses=2400:3200::104/64gateway=2400:3200::1dns=2400:3200::1;2400:3200:baba::1;2001:4860:4860::8888;2001:4860:4860::8844</code></pre><p><strong>Node02 节点</strong></p><pre><code class="highlight bash">[root@k8s-node02 ~]<span class="comment"># cat /etc/NetworkManager/system-connections/ens34.nmconnection</span>[ipv4]method=manualaddress1=10.20.1.105/24;10.20.1.1dns=61.132.163.68;114.114.114.114[ipv6]method=manualaddresses=2400:3200::105/64gateway=2400:3200::1dns=2400:3200::1;2400:3200:baba::1;2001:4860:4860::8888;2001:4860:4860::8844</code></pre><h2 id="3-修改hosts文件"><a href="#3-修改hosts文件" class="headerlink" title="3. 修改hosts文件"></a>3. 修改hosts文件</h2><p>配置集群各节点 hostname 和 ip 的映射</p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt; <span class="string">&quot;EOF&quot;</span>10.20.1.101 k8s-master01 m110.20.1.102 k8s-master02 m210.20.1.103 k8s-master03 m310.20.1.104 k8s-node01 n110.20.1.105 k8s-node02 n22400:3200::101 k8s-master01 m12400:3200::102 k8s-master02 m22400:3200::103 k8s-master03 m32400:3200::104 k8s-node01 n12400:3200::105 k8s-node02 n2EOF</code></pre><p><strong>验证 hosts 文件配置</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> /etc/hostsping k8s-master01 -c 4  <span class="comment"># 默认使用 IPv4</span>ping6 k8s-master01 -c 4  <span class="comment"># 使用 IPv6</span></code></pre><h2 id="4-修改终端颜色"><a href="#4-修改终端颜色" class="headerlink" title="4. 修改终端颜色"></a>4. 修改终端颜色</h2><p>这里只是修改shell终端显示文本的颜色，非必要步骤。</p><pre><code class="highlight bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF &gt;&gt; ~/.bashrc</span><span class="string">PS1=&quot;\[\e[37;47m\][\[\e[32;47m\]\u\[\e[34;47m\]@\h \[\e[36;47m\]\w\[\e[0m\]]\\$ &quot;</span><span class="string">EOF</span><span class="comment"># 让修改立即见效</span><span class="built_in">source</span> ~/.bashrc</code></pre><blockquote><p><strong>命令解析：</strong></p><p>这段命令用于修改当前用户的 <strong>Bash Shell 提示符</strong>（<code>PS1</code>），并将其设置写入到 <code>~/.bashrc</code> 文件中，以便在每次登录或启动 Shell 时自动加载该配置。</p><pre><code class="highlight plaintext">PS1=&quot;...&quot;定义 Shell 的主提示符格式（Prompt String 1），即你在终端中输入命令时显示的提示符。</code></pre><p>最终效果如下：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/04/20250104-112243.png" alt="终端颜色修改"></p></blockquote><h2 id="5-更换系统软件源"><a href="#5-更换系统软件源" class="headerlink" title="5. 更换系统软件源"></a>5. 更换系统软件源</h2><p>将 Rocky 默认源替换成阿里源，提升软件安装速度。</p><pre><code class="highlight bash"><span class="comment"># 更新源</span>sed -e <span class="string">&#x27;s|^mirrorlist=|#mirrorlist=|g&#x27;</span> \    -e <span class="string">&#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27;</span> \    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo    <span class="comment"># 刷新dnf缓存</span>dnf makecache<span class="comment"># 验证源更新</span>dnf repolist</code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext"># 使用 sed 命令修改 Rocky Linux 的 YUM/DNF 源配置文件，切换到阿里云的镜像源。sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \    -e &#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27; \    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo    # 将以 mirrorlist= 开头的行注释掉（在前面加 #）-e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27;# 将以 #baseurl= 开头并指向默认 Rocky Linux 源的行取消注释，并替换为阿里云镜像源 URL。&#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27;# -i.bak：直接修改文件，并为原文件创建备份（扩展名为 .bak）。# 修改 /etc/yum.repos.d/ 目录下所有以 rocky 或 Rocky 开头的 .repo 文件。# 修改完成后，原始文件会被备份为 .bak 文件。-i.bak /etc/yum.repos.d/[Rr]ocky*.repo# 更新本地缓存，确保系统可以快速查询软件包信息。dnf makecache</code></pre></blockquote><h2 id="6-修改防火墙"><a href="#6-修改防火墙" class="headerlink" title="6. 修改防火墙"></a>6. 修改防火墙</h2><p>关闭默认防火墙firewalld，配置 iptables 防火墙</p><pre><code class="highlight bash">systemctl stop firewalldsystemctl <span class="built_in">disable</span> firewalldyum -y install iptables-servicessystemctl start iptablesiptables -Fsystemctl <span class="built_in">enable</span> iptablesservice iptables save</code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext"># 停止运行 firewalldsystemctl stop firewalld# 禁止 firewalld 开机自启systemctl disable firewalld# 安装 iptables 服务，用于管理 Linux 的防火墙规则yum -y install iptables-services# 使防火墙规则立即生效，并开始运行 iptables 防火墙服务。systemctl start iptables# 删除当前的防火墙规则，通常用于重置或清理防火墙规则。iptables -F# 设置 iptables 服务开机自启动，确保服务器重启后，iptables 服务会自动加载防火墙规则。systemctl enable iptables# 将当前 iptables 的规则配置保存到文件中（通常是 /etc/sysconfig/iptables），以便在系统重启或 iptables 服务重新启动后，能够自动加载保存的规则。service iptables save</code></pre></blockquote><h2 id="7-禁用-Selinux"><a href="#7-禁用-Selinux" class="headerlink" title="7. 禁用 Selinux"></a>7. 禁用 Selinux</h2><pre><code class="highlight bash">setenforce 0sed -i <span class="string">&quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot;</span> /etc/selinux/configgrubby --update-kernel ALL --args selinux=0</code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext"># 将 SELinux 的模式设置为 Permissive（宽容模式）。# 0：表示设置为 Permissive 模式，此模式下 SELinux 不会强制执行安全策略，而是记录违规日志。# 1：表示 Enforcing 模式，此模式下 SELinux 会强制执行安全策略。setenforce 0# 修改 SELinux 配置文件 /etc/selinux/config，将 SELINUX 设置为 disabled。永久禁用 SELinux，即使系统重启也不会再启用。sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config# 通过 grubby 工具将 selinux=0 参数添加到所有内核启动配置中。grubby --update-kernel ALL --args selinux=0grubby --info DEFAULT# 查看是否禁用，grubby --info DEFAULT# 回滚内核层禁用操作，、grubby --update-kernel ALL --remove-args selinux</code></pre></blockquote><h2 id="8-设置时区"><a href="#8-设置时区" class="headerlink" title="8. 设置时区"></a>8. 设置时区</h2><pre><code class="highlight bash">timedatectl set-timezone Asia/Shanghai</code></pre><h2 id="9-关闭-swap-分区"><a href="#9-关闭-swap-分区" class="headerlink" title="9. 关闭 swap 分区"></a>9. 关闭 swap 分区</h2><pre><code class="highlight bash">swapoff -ased -i <span class="string">&#x27;s:/dev/mapper/rl-swap:#/dev/mapper/rl-swap:g&#x27;</span> /etc/fstab</code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">#  立即关闭系统中所有的交换分区swapoff -a# 注释掉 /etc/fstab 文件中定义的交换分区挂载条目，防止系统在重启后重新启用交换分区。sed -i &#x27;s:/dev/mapper/rl-swap:#/dev/mapper/rl-swap:g&#x27; /etc/fstab# 验证交换分区是否关系free -h输出中 Swap 一栏的值会变为 0。</code></pre></blockquote><h2 id="10-安装基本工具"><a href="#10-安装基本工具" class="headerlink" title="10. 安装基本工具"></a>10. 安装基本工具</h2><pre><code class="highlight bash">dnf -y install openssh-server wget tree bash-completion psmisc vim net-tools lrzsz nfs-utils epel-release telnet rsync yum-utils device-mapper-persistent-data lvm2 git tar curl network-scripts</code></pre><h2 id="11-修改系统最大打开文件数"><a href="#11-修改系统最大打开文件数" class="headerlink" title="11. 修改系统最大打开文件数"></a>11. 修改系统最大打开文件数</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt;&gt; /etc/security/limits.conf &lt;&lt;<span class="string">EOF</span><span class="string">* soft nofile 655360</span><span class="string">* hard nofile 131072</span><span class="string">* soft nproc 655350</span><span class="string">* hard nproc 655350</span><span class="string">* soft memlock unlimited</span><span class="string">* hard memlock unlimited</span><span class="string">EOF</span> <span class="built_in">echo</span> <span class="string">&quot;ulimit -SHn 65535&quot;</span> &gt;&gt; /etc/profile<span class="built_in">source</span> /etc/profile</code></pre><blockquote><p><strong>命令解析：</strong></p><p>soft nofile 655360<br>soft表示软限制，nofile 表示一个进程可打开的最大文件数，默认值为1024。这里的软限制设置为655360，即一个进程可打开的最大文件数为655360。</p><p>hard nofile 131072<br>hard表示硬限制，即系统设置的最大值。nofile表示一个进程可打开的最大文件数，默认值为4096。这里的硬限制设置为131072，即系统设置的最大文件数为131072。</p><p>soft nproc 655350<br>soft表示软限制，nproc表示一个用户可创建的最大进程数，默认值为30720。这里的软限制设置为655350，即一个用户可创建的最大进程数为655350。</p><p>hard nproc 655350<br>hard表示硬限制，即系统设置的最大值。nproc表示一个用户可创建的最大进程数，默认值为4096。这里的硬限制设置为655350，即系统设置的最大进程数为655350。</p><p>soft memlock unlimited<br>seft表示软限制，memlock表示一个进程可锁定在RAM中的最大内存，默认值为64 KB。这里的软限制设置为unlimited，即一个进程可锁定的最大内存为无限制。</p><p>hard memlock unlimited<br>hard表示硬限制，即系统设置的最大值。memlock表示一个进程可锁定在RAM中的最大内存，默认值为64 KB。这里的硬限制设置为unlimited，即系统设置的最大内存锁定为无限制。</p></blockquote><h2 id="12-安装-ipvs"><a href="#12-安装-ipvs" class="headerlink" title="12. 安装 ipvs"></a>12. 安装 ipvs</h2><pre><code class="highlight bash"><span class="comment"># 安装 ipvs</span>yum install ipvsadm ipset sysstat conntrack libseccomp -y<span class="built_in">cat</span> &gt;&gt; /etc/modules-load.d/ipvs.conf &lt;&lt;<span class="string">EOF </span><span class="string">ip_vs</span><span class="string">ip_vs_rr</span><span class="string">ip_vs_wrr</span><span class="string">ip_vs_sh</span><span class="string">nf_conntrack</span><span class="string">ip_tables</span><span class="string">ip_set</span><span class="string">xt_set</span><span class="string">ipt_set</span><span class="string">ipt_rpfilter</span><span class="string">ipt_REJECT</span><span class="string">ipip</span><span class="string">EOF</span>systemctl restart systemd-modules-load.servicelsmod | grep -e ip_vs -e nf_conntrack</code></pre><blockquote><p><strong>命名解析：</strong></p><ul><li><p>ipvsadm  命令行工具，用于管理IPVS（IP Virtual Server）</p></li><li><p>ipset  内核级工具，用于高效管理IP地址、端口或MAC地址的集合（sets）</p></li><li><p>sysstat  系统性能监控工具包，包括sar、iostat、mpstat等命令，用于收集和报告CPU、内存、磁盘I&#x2F;O、网络等系统统计数据</p></li><li><p>conntrack  命令行工具（conntrack-tools的一部分），用于管理Netfilter的连接跟踪表（connection tracking table）</p></li><li><p>libseccomp  这是一个库，用于支持seccomp（Secure Computing Mode），seccomp是Linux内核功能，用于限制进程的系统调用（syscall），从而增强安全性（如沙箱化）</p></li></ul><p>cat &gt;&gt; ….. 显示的加载内核模块</p><ul><li>ip_vs  核心IPVS模块，提供虚拟服务器功能，用于L4负载均衡</li><li>ip_vs_rr  IPVS的 round-robin 调度算法模块（轮询）</li><li>ip_vs_wrr  IPVS的 weighted round-robin 调度算法模块（加权轮询）</li><li>ip_vs_sh  IPVS的 source hashing 调度算法模块（源地址哈希）</li><li>nf_conntrack  Netfilter连接跟踪模块，跟踪网络连接状态（用于NAT和防火墙）</li><li>ip_tables  iptables的核心模块，用于IPv4包过滤和NAT</li><li>ip_set  IP集合管理模块，支持高效的IP列表处理</li><li>xt_set  iptables的扩展模块，用于与ip_set集成</li><li>ipt_set  iptables的set匹配模块（类似xt_set，但特定于IPv4）</li><li>ipt_rpfilter  iptables的反向路径过滤模块，防止IP欺骗攻击</li><li>ipt_REJECT  iptables的REJECT目标模块，用于拒绝包并发送拒绝消息</li><li>ipip  隧道模块，用于封装IP包（类似VPN隧道）</li></ul><p><code>systemctl restart systemd-modules-load.service</code>：立即加载这些模块（因为&#x2F;etc&#x2F;modules-load.d&#x2F;目录下的.conf文件会被systemd-modules-load服务读取）</p><p><code>lsmod | grep -e ip_vs -e nf_conntrack</code> ：检查模块是否加载成功。</p></blockquote><h2 id="13-开启路由转发"><a href="#13-开启路由转发" class="headerlink" title="13. 开启路由转发"></a>13. 开启路由转发</h2><pre><code class="highlight bash"><span class="built_in">echo</span> <span class="string">&#x27;net.ipv4.ip_forward=1&#x27;</span> &gt;&gt; /etc/sysctl.confsysctl -p</code></pre><h2 id="14-排除-calico-网卡被-NetworkManager-所管理"><a href="#14-排除-calico-网卡被-NetworkManager-所管理" class="headerlink" title="14. 排除 calico 网卡被 NetworkManager 所管理"></a>14. 排除 calico 网卡被 NetworkManager 所管理</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/NetworkManager/conf.d/calico.conf &lt;&lt; <span class="string">EOF</span><span class="string">[keyfile]</span><span class="string">unmanaged-devices=interface-name:cali*;interface-name:tunl*;interface-name:vxlan.calico;interface-name:vxlan-v6.calico;interface-name:wireguard.cali;interface-name:wg-v6.cali</span><span class="string">EOF</span>systemctl restart NetworkManager</code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">这个参数用于指定不由 NetworkManager 管理的设备。它由以下两个部分组成interface-name:cali*表示以 &quot;cali&quot; 开头的接口名称被排除在 NetworkManager 管理之外。例如，&quot;cali0&quot;, &quot;cali1&quot; 等接口不受 NetworkManager 管理interface-name:tunl*表示以 &quot;tunl&quot; 开头的接口名称被排除在 NetworkManager 管理之外。例如，&quot;tunl0&quot;, &quot;tunl1&quot; 等接口不受 NetworkManager 管理interface-name:vxlan.calico匹配名为vxlan.calico的接口，Calico在VXLAN模式下可能使用该接口名进行跨节点通信（VXLAN是一种覆盖网络技术）interface-name:vxlan-v6.calico匹配名为vxlan-v6.calico的接口，这是Calico在支持IPv6的VXLAN模式下使用的接口名interface-name:wireguard.cali匹配名为wireguard.cali的接口，Calico支持使用WireGuard（一种高性能VPN协议）进行加密通信，这个接口用于WireGuard隧道。interface-name:wg-v6.cali匹配名为wg-v6.cali的接口，这是Calico在IPv6网络中使用的WireGuard接口通过使用这个参数，可以将特定的接口排除在 NetworkManager 的管理范围之外，以便其他工具或进程可以独立地管理和配置这些接口</code></pre></blockquote><h2 id="15-修改内核参数"><a href="#15-修改内核参数" class="headerlink" title="15. 修改内核参数"></a>15. 修改内核参数</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class="string">EOF</span><span class="string">net.ipv4.ip_forward = 1</span><span class="string">net.bridge.bridge-nf-call-iptables = 1</span><span class="string">fs.may_detach_mounts = 1</span><span class="string">vm.overcommit_memory=1</span><span class="string">vm.panic_on_oom=0</span><span class="string">fs.inotify.max_user_watches=89100</span><span class="string">fs.file-max=52706963</span><span class="string">fs.nr_open=52706963</span><span class="string">net.netfilter.nf_conntrack_max=2310720</span><span class="string">net.ipv4.tcp_keepalive_time = 600</span><span class="string">net.ipv4.tcp_keepalive_probes = 3</span><span class="string">net.ipv4.tcp_keepalive_intvl =15</span><span class="string">net.ipv4.tcp_max_tw_buckets = 36000</span><span class="string">net.ipv4.tcp_tw_reuse = 1</span><span class="string">net.ipv4.tcp_max_orphans = 327680</span><span class="string">net.ipv4.tcp_orphan_retries = 3</span><span class="string">net.ipv4.tcp_syncookies = 1</span><span class="string">net.ipv4.tcp_max_syn_backlog = 16384</span><span class="string">net.ipv4.ip_conntrack_max = 65536</span><span class="string">net.ipv4.tcp_max_syn_backlog = 16384</span><span class="string">net.ipv4.tcp_timestamps = 0</span><span class="string">net.core.somaxconn = 16384</span><span class="string">net.ipv6.conf.all.disable_ipv6 = 0</span><span class="string">net.ipv6.conf.default.disable_ipv6 = 0</span><span class="string">net.ipv6.conf.lo.disable_ipv6 = 0</span><span class="string">net.ipv6.conf.all.forwarding = 1</span><span class="string">EOF</span>sysctl --system</code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">这些是Linux系统的一些参数设置，用于配置和优化网络、文件系统和虚拟内存等方面的功能。以下是每个参数的详细解释：net.ipv4.ip_forward = 1这个参数启用了IPv4的IP转发功能，允许服务器作为网络路由器转发数据包。net.bridge.bridge-nf-call-iptables = 1当使用网络桥接技术时，将数据包传递到iptables进行处理。fs.may_detach_mounts = 1允许在挂载文件系统时，允许被其他进程使用。vm.overcommit_memory=1该设置允许原始的内存过量分配策略，当系统的内存已经被完全使用时，系统仍然会分配额外的内存。vm.panic_on_oom=0当系统内存不足（OOM）时，禁用系统崩溃和重启。fs.inotify.max_user_watches=89100设置系统允许一个用户的inotify实例可以监控的文件数目的上限。fs.file-max=52706963设置系统同时打开的文件数的上限。fs.nr_open=52706963设置系统同时打开的文件描述符数的上限。net.netfilter.nf_conntrack_max=2310720设置系统可以创建的网络连接跟踪表项的最大数量。net.ipv4.tcp_keepalive_time = 600设置TCP套接字的空闲超时时间（秒），超过该时间没有活动数据时，内核会发送心跳包。net.ipv4.tcp_keepalive_probes = 3设置未收到响应的TCP心跳探测次数。net.ipv4.tcp_keepalive_intvl = 15设置TCP心跳探测的时间间隔（秒）。net.ipv4.tcp_max_tw_buckets = 36000设置系统可以使用的TIME_WAIT套接字的最大数量。net.ipv4.tcp_tw_reuse = 1启用TIME_WAIT套接字的重新利用，允许新的套接字使用旧的TIME_WAIT套接字。net.ipv4.tcp_max_orphans = 327680设置系统可以同时存在的TCP套接字垃圾回收包裹数的最大数量。net.ipv4.tcp_orphan_retries = 3设置系统对于孤立的TCP套接字的重试次数。net.ipv4.tcp_syncookies = 1启用TCP SYN cookies保护，用于防止SYN洪泛攻击。net.ipv4.tcp_max_syn_backlog = 16384设置新的TCP连接的半连接数（半连接队列）的最大长度。net.ipv4.ip_conntrack_max = 65536设置系统可以创建的网络连接跟踪表项的最大数量。net.ipv4.tcp_timestamps = 0关闭TCP时间戳功能，用于提供更好的安全性。net.core.somaxconn = 16384设置系统核心层的连接队列的最大值。net.ipv6.conf.all.disable_ipv6 = 0启用IPv6协议。net.ipv6.conf.default.disable_ipv6 = 0启用IPv6协议。net.ipv6.conf.lo.disable_ipv6 = 0启用IPv6协议。net.ipv6.conf.all.forwarding = 1允许IPv6数据包转发。</code></pre></blockquote><h2 id="16-集群时间同步设置"><a href="#16-集群时间同步设置" class="headerlink" title="16. 集群时间同步设置"></a>16. 集群时间同步设置</h2><p>在3主2从的集群环境中，配置3台 master 节点向使用 chony 通过外部网络同步时间校正自身的时间，并作为时间主服务器给集群中的其它 node 节点校正时间。</p><p><em>主节点时间权重不同</em></p><p><strong>Master01 节点</strong></p><pre><code class="highlight bash">yum install chrony -y<span class="built_in">cat</span> &gt; /etc/chrony.conf &lt;&lt; <span class="string">EOF </span><span class="string">pool ntp1.aliyun.com iburst</span><span class="string">pool ntp2.aliyun.com iburst</span><span class="string">pool ntp3.aliyun.com iburst</span><span class="string">pool ntp4.aliyun.com iburst</span><span class="string">driftfile /var/lib/chrony/drift</span><span class="string">makestep 1.0 3</span><span class="string">rtcsync</span><span class="string">allow 10.20.1.0/24</span><span class="string">local stratum 10</span><span class="string">keyfile /etc/chrony.keys</span><span class="string">leapsectz right/UTC</span><span class="string">logdir /var/log/chrony</span><span class="string">EOF</span>systemctl restart chronyd ; systemctl <span class="built_in">enable</span> chronyd</code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">pool ntp.aliyun.com iburst指定使用ntp.aliyun.com作为时间服务器池，iburst选项表示在初始同步时会发送多个请求以加快同步速度。driftfile /var/lib/chrony/drift指定用于保存时钟漂移信息的文件路径。makestep 1.0 3设置当系统时间与服务器时间偏差大于1秒时，会以1秒的步长进行调整。如果偏差超过3秒，则立即进行时间调整。rtcsync启用硬件时钟同步功能，可以提高时钟的准确性。allow 10.20.1.0/24允许10.20.1.0/24网段范围内的主机与chrony进行时间同步。local stratum 10将本地时钟设为stratum 10，stratum值表示时钟的准确度，值越小表示准确度越高。keyfile /etc/chrony.keys指定使用的密钥文件路径，用于对时间同步进行身份验证。leapsectz right/UTC指定时区为UTC。logdir /var/log/chrony指定日志文件存放目录。</code></pre></blockquote><p><strong>Master02 节点</strong></p><pre><code class="highlight bash">yum install chrony -y<span class="built_in">cat</span> &gt; /etc/chrony.conf &lt;&lt; <span class="string">EOF </span><span class="string">pool ntp1.aliyun.com iburst</span><span class="string">pool ntp2.aliyun.com iburst</span><span class="string">pool ntp3.aliyun.com iburst</span><span class="string">pool ntp4.aliyun.com iburst</span><span class="string">driftfile /var/lib/chrony/drift</span><span class="string">makestep 1.0 3</span><span class="string">rtcsync</span><span class="string">allow 10.20.1.0/24</span><span class="string">local stratum 12</span><span class="string">keyfile /etc/chrony.keys</span><span class="string">leapsectz right/UTC</span><span class="string">logdir /var/log/chrony</span><span class="string">EOF</span>systemctl restart chronyd ; systemctl <span class="built_in">enable</span> chronyd</code></pre><p><strong>Master03 节点</strong></p><pre><code class="highlight bash">yum install chrony -y<span class="built_in">cat</span> &gt; /etc/chrony.conf &lt;&lt; <span class="string">EOF </span><span class="string">pool ntp1.aliyun.com iburst</span><span class="string">pool ntp2.aliyun.com iburst</span><span class="string">pool ntp3.aliyun.com iburst</span><span class="string">pool ntp4.aliyun.com iburst</span><span class="string">driftfile /var/lib/chrony/drift</span><span class="string">makestep 1.0 3</span><span class="string">rtcsync</span><span class="string">allow 10.20.1.0/24</span><span class="string">local stratum 15</span><span class="string">keyfile /etc/chrony.keys</span><span class="string">leapsectz right/UTC</span><span class="string">logdir /var/log/chrony</span><span class="string">EOF</span>systemctl restart chronyd ; systemctl <span class="built_in">enable</span> chronyd</code></pre><p><strong>Node01节点 和 Node02节点</strong></p><pre><code class="highlight bash">yum install chrony -y<span class="built_in">cat</span> &gt; /etc/chrony.conf &lt;&lt; <span class="string">EOF </span><span class="string">pool 10.20.1.101 iburst</span><span class="string">pool 10.20.1.102 iburst</span><span class="string">pool 10.20.1.103 iburst</span><span class="string">driftfile /var/lib/chrony/drift</span><span class="string">makestep 1.0 3</span><span class="string">rtcsync</span><span class="string">keyfile /etc/chrony.keys</span><span class="string">leapsectz right/UTC</span><span class="string">logdir /var/log/chrony</span><span class="string">EOF</span>systemctl restart chronyd ; systemctl <span class="built_in">enable</span> chronyd<span class="comment">#使用客户端进行验证</span>chronyc sources -v</code></pre><h2 id="17-配置免密登录"><a href="#17-配置免密登录" class="headerlink" title="17. 配置免密登录"></a>17. 配置免密登录</h2><p>配置 k8s-master01 节点免密登录到其它节点，方便后续从 master01 节点往其它节点发送文件。</p><p><strong>master-01</strong></p><pre><code class="highlight bash">yum install -y expectssh-keygen -t rsa -P <span class="string">&quot;&quot;</span> -f /root/.ssh/id_rsa<span class="built_in">export</span> user=root<span class="built_in">export</span> pass=123456host=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02 m1 m2 m3 n1 n2) <span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>;<span class="keyword">do</span> expect -c <span class="string">&quot;</span><span class="string">spawn ssh-copy-id -i /root/.ssh/id_rsa.pub <span class="variable">$user</span>@<span class="variable">$host</span></span><span class="string">    expect &#123;</span><span class="string">        \&quot;*yes/no*\&quot; &#123;send \&quot;yes\r\&quot;; exp_continue&#125;</span><span class="string">        \&quot;*password*\&quot; &#123;send \&quot;<span class="variable">$pass</span>\r\&quot;; exp_continue&#125;</span><span class="string">        \&quot;*Password*\&quot; &#123;send \&quot;<span class="variable">$pass</span>\r\&quot;;&#125;</span><span class="string">    &#125;&quot;</span>;<span class="keyword">done</span></code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext"># 一个自动化交互工具，用于处理需要用户输入的命令行交互yum install -y expect# 生成RSA类型的SSH密钥对（公钥和私钥），并存储在指定路径。-P &quot;&quot;：设置空密码（无口令保护），便于自动化使用ssh-keygen -t rsa -P &quot;&quot; -f /root/.ssh/id_rsaexport user=rootexport pass=123456# 定义一个Bash数组host，包含集群中所有节点的主机名和别名host=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)# 遍历host数组，对每个节点执行expect脚本for host in $&#123;host[@]&#125;;do expect -c &quot;# 启动ssh-copy-id命令，将公钥文件/root/.ssh/id_rsa.pub分发到目标节点spawn ssh-copy-id -i /root/.ssh/id_rsa.pub $user@$host    expect &#123;    # 匹配：当ssh-copy-id提示是否信任目标主机    # 动作：发送yes并换行（\r），确认连接    # exp_continue：继续匹配后续模式（不退出expect）        \&quot;*yes/no*\&quot; &#123;send \&quot;yes\r\&quot;; exp_continue&#125;                # 匹配：当提示输入密码（大写Password）        # 动作：发送变量$pass（即123456）并换行        # exp_continue：继续匹配后续模式。        \&quot;*password*\&quot; &#123;send \&quot;$pass\r\&quot;; exp_continue&#125;        \&quot;*Password*\&quot; &#123;send \&quot;$pass\r\&quot;;&#125;    &#125;&quot;;done</code></pre></blockquote><h2 id="18-安装-Docker"><a href="#18-安装-Docker" class="headerlink" title="18. 安装 Docker"></a>18. 安装 Docker</h2><h3 id="18-1-安装-Docker-二进制包"><a href="#18-1-安装-Docker-二进制包" class="headerlink" title="18.1 安装 Docker 二进制包"></a>18.1 安装 Docker 二进制包</h3><p><strong>k8s-master01</strong></p><pre><code class="highlight bash"><span class="comment"># 二进制包下载地址：https://download.docker.com/linux/static/stable/x86_64/</span><span class="comment"># 创建目录，后续下载的文件都放在这里</span><span class="built_in">mkdir</span> -p /opt/software/ /opt/module/ &amp;&amp; <span class="built_in">chmod</span> 777 -R /opt/software/ /opt/module/<span class="comment"># 更新 openssh-server</span>dnf -y install  openssh-server<span class="comment"># 下载 Docker</span>wget https://download.docker.com/linux/static/stable/x86_64/docker-28.4.0.tgz<span class="comment"># 解压二进制包</span>tar xf docker-*.tgz<span class="comment"># 拷贝解压后的二进制包到 /usr/bin 目录下</span><span class="built_in">cp</span> docker/* /usr/bin/<span class="comment"># 将 Docker 复制到其它服务器中</span>hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root <span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span>   <span class="built_in">echo</span> <span class="variable">$i</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> docker/* <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/bin/; <span class="keyword">done</span><span class="comment"># 验证</span>$ docker --versionDocker version 28.4.0, build d8eb465<span class="comment"># 查看 containerd 版本</span>$ containerd --versioncontainerd github.com/containerd/containerd v1.7.28 b98a3aace656320842a23f4a392a33f46af97866</code></pre><h3 id="18-2-配置-containerd-service"><a href="#18-2-配置-containerd-service" class="headerlink" title="18.2 配置 containerd.service"></a>18.2 配置 containerd.service</h3><ul><li><p><strong>containerd 的作用</strong>：它是一个独立的守护进程（daemon），处理低级任务，如镜像拉取、容器启动&#x2F;停止、快照管理、网络&#x2F;存储挂载等。它基于 OCI（Open Container Initiative）标准，与 runC（Docker 的另一个组件，用于实际执行容器）协作。</p></li><li><p><strong>dockerd 的作用</strong>：Docker Daemon (dockerd) 不再直接管理容器，而是作为一个高层管理器，通过 gRPC 接口与 containerd 通信。dockerd 处理用户命令（如 docker run）、镜像构建、网络&#x2F;卷管理等，并将容器相关操作委托给 containerd。</p></li></ul><p>Docker底层依赖 containerd ，如果不安装 containerd ，Docker 会启动失败，因为 dockerd 需要连接到 containerd.sock（由 containerd 服务生成）。这会导致整个链条崩溃：cri-dockerd → dockerd → containerd。</p><p>即使 Kubernetes 通过 cri-dockerd 使用 Docker，Docker 本身还是依赖 containerd 来实际执行容器操作。没有 containerd，cri-dockerd 和 Docker 都无法工作。</p><pre><code class="highlight bash"><span class="comment"># 下载 containerd.service, 版本需要与 docker 二进制包中的 containerd 一致</span><span class="comment"># https://github.com/containerd/containerd/blob/main/containerd.service</span>wget https://raw.githubusercontent.com/containerd/containerd/refs/tags/v1.7.28/containerd.service<span class="comment"># containerd 路径修改后，内容如下：</span><span class="built_in">cat</span> &gt;/etc/systemd/system/containerd.service &lt;&lt;<span class="string">EOF</span><span class="string">[Unit]</span><span class="string">Description=containerd container runtime</span><span class="string">Documentation=https://containerd.io</span><span class="string">After=network.target local-fs.target dbus.service</span><span class="string"></span><span class="string">[Service]</span><span class="string">ExecStartPre=-/sbin/modprobe overlay</span><span class="string">ExecStart=/usr/bin/containerd</span><span class="string"></span><span class="string">Type=notify</span><span class="string">Delegate=yes</span><span class="string">KillMode=process</span><span class="string">Restart=always</span><span class="string">RestartSec=5</span><span class="string">LimitNPROC=infinity</span><span class="string">LimitCORE=infinity</span><span class="string">LimitNOFILE=infinity</span><span class="string">TasksMax=infinity</span><span class="string">OOMScoreAdjust=-999</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string">EOF</span><span class="comment"># 设置 containerd 开机自启</span>systemctl <span class="built_in">enable</span> --now containerd.service<span class="comment"># 将 containerd.service 复制到其它服务器中</span>hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span>   <span class="built_in">echo</span> <span class="variable">$i</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/systemd/system/containerd.service <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/systemd/system/; <span class="keyword">done</span><span class="comment"># 配置设置每一台服务器 containerd 开机自启</span>hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span><span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now containerd.service&quot;</span><span class="keyword">done</span><span class="comment"># 验证</span>systemctl is-enabled containerd.service</code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">[Unit]Description=containerd container runtime：指定服务的描述信息。Documentation=https://containerd.io：指定服务的文档链接。After=network.target local-fs.target：指定服务的启动顺序，在网络和本地文件系统启动之后再启动该服务。[Service]ExecStartPre=-/sbin/modprobe overlay：在启动服务之前执行的命令，使用-表示忽略错误。ExecStart=/usr/bin/containerd：指定服务的启动命令。Type=notify：指定服务的类型，notify表示服务会在启动完成后向systemd发送通知。Delegate=yes：允许服务代理其他服务的应答，例如收到关机命令后终止其他服务。KillMode=process：指定服务终止时的行为，process表示终止服务进程。Restart=always：指定服务终止后是否自动重启，always表示总是自动重启。RestartSec=5：指定服务重启的时间间隔，单位为秒。LimitNPROC=infinity：限制服务的最大进程数，infinity表示没有限制。LimitCORE=infinity：限制服务的最大核心数，infinity表示没有限制。LimitNOFILE=1048576：限制服务的最大文件数，指定为1048576。TasksMax=infinity：限制服务的最大任务数，infinity表示没有限制。OOMScoreAdjust=-999：指定服务的OOM（Out of Memory）得分，负数表示降低被终止的概率。[Install]WantedBy=multi-user.target：指定服务的安装方式，multi-user.target表示该服务在多用户模式下安装。</code></pre></blockquote><h3 id="18-3-配置-docker-service"><a href="#18-3-配置-docker-service" class="headerlink" title="18.3 配置 docker.service"></a>18.3 配置 docker.service</h3><p>下载地址：<a href="https://github.com/moby/moby/blob/master/contrib/init/systemd/docker.service">https://github.com/moby/moby/blob/master/contrib/init/systemd/docker.service</a></p><pre><code class="highlight bash"><span class="comment"># 下载 docker.service</span>wget https://raw.githubusercontent.com/moby/moby/refs/tags/v28.4.0/contrib/init/systemd/docker.service<span class="comment"># 修改后写入到指定目录中</span><span class="built_in">cat</span> &gt; /etc/systemd/system/docker.service &lt;&lt;<span class="string">EOF</span><span class="string">[Unit]</span><span class="string">Description=Docker Application Container Engine</span><span class="string">Documentation=https://docs.docker.com</span><span class="string">After=network-online.target nss-lookup.target docker.socket firewalld.service containerd.service time-set.target cri-docker.service</span><span class="string">Wants=network-online.target containerd.service</span><span class="string">Requires=docker.socket containerd.service</span><span class="string">StartLimitBurst=3</span><span class="string">StartLimitIntervalSec=60</span><span class="string"></span><span class="string">[Service]</span><span class="string">Type=notify</span><span class="string">ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</span><span class="string">ExecReload=/bin/kill -s HUP $MAINPID</span><span class="string">TimeoutStartSec=0</span><span class="string">RestartSec=2</span><span class="string">Restart=always</span><span class="string">LimitNPROC=infinity</span><span class="string">LimitCORE=infinity</span><span class="string">TasksMax=infinity</span><span class="string">Delegate=yes</span><span class="string">KillMode=process</span><span class="string">OOMScoreAdjust=-500</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string">EOF</span><span class="comment"># 将 docker.service 复制到其它服务器中</span>hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span>   <span class="built_in">echo</span> <span class="variable">$i</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/systemd/system/docker.service <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/systemd/system/; <span class="keyword">done</span></code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">[Unit]Description: 描述服务的作用，这里是Docker Application Container Engine，即Docker应用容器引擎。Documentation: 提供关于此服务的文档链接，这里是Docker官方文档链接。After: 说明该服务在哪些其他服务之后启动，这里是在网络在线、firewalld服务和containerd服务后启动。Wants: 说明该服务想要的其他服务，这里是网络在线服务。Requires: 说明该服务需要的其他服务，这里是docker.socket和containerd.service。[Service]Type: 服务类型，这里是notify，表示服务在启动完成时发送通知。ExecStart: 命令，启动该服务时会执行的命令，这里是/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock，即启动dockerd并指定一些参数，其中-H指定dockerd的监听地址为fd://，--containerd指定containerd的sock文件位置。ExecReload: 重载命令，当接收到HUP信号时执行的命令，这里是/bin/kill -s HUP $MAINPID，即发送HUP信号给主进程ID。TimeoutSec: 服务超时时间，这里是0，表示没有超时限制。RestartSec: 重启间隔时间，这里是2秒，表示重启失败后等待2秒再重启。Restart: 重启策略，这里是always，表示总是重启。StartLimitBurst: 启动限制次数，这里是3，表示在启动失败后最多重试3次。StartLimitInterval: 启动限制时间间隔，这里是60秒，表示两次启动之间最少间隔60秒。LimitNOFILE: 文件描述符限制，这里是infinity，表示没有限制。LimitNPROC: 进程数限制，这里是infinity，表示没有限制。LimitCORE: 核心转储限制，这里是infinity，表示没有限制。TasksMax: 最大任务数，这里是infinity，表示没有限制。Delegate: 修改权限，这里是yes，表示启用权限修改。KillMode: 杀死模式，这里是process，表示杀死整个进程组。OOMScoreAdjust: 用于调整进程在系统内存紧张时的优先级调整，这里是-500，表示将OOM分数降低500。[Install]WantedBy: 安装目标，这里是multi-user.target，表示在多用户模式下安装。在WantedBy参数中，我们可以使用以下参数：multi-user.target：指定该服务应该在多用户模式下启动。graphical.target：指定该服务应该在图形化界面模式下启动。default.target：指定该服务应该在系统的默认目标（runlevel）下启动。rescue.target：指定该服务应该在系统救援模式下启动。poweroff.target：指定该服务应该在关机时启动。reboot.target：指定该服务应该在重启时启动。halt.target：指定该服务应该在停止时启动。shutdown.target：指定该服务应该在系统关闭时启动。这些参数可以根据需要选择一个或多个，以告知系统在何时启动该服务。</code></pre></blockquote><h3 id="18-4-准备-docker-的-socket-文件"><a href="#18-4-准备-docker-的-socket-文件" class="headerlink" title="18.4 准备 docker 的 socket 文件"></a>18.4 准备 docker 的 socket 文件</h3><p>下载地址：<a href="https://github.com/moby/moby/blob/v28.4.0/contrib/init/systemd/docker.socket">https://github.com/moby/moby/blob/v28.4.0/contrib/init/systemd/docker.socket</a></p><pre><code class="highlight bash"><span class="comment"># 下载 docker.socket</span>wget https://raw.githubusercontent.com/moby/moby/refs/tags/v28.4.0/contrib/init/systemd/docker.socket<span class="comment"># 修改后写入到指定路径</span><span class="built_in">cat</span> &gt; /etc/systemd/system/docker.socket &lt;&lt;<span class="string">EOF</span><span class="string">[Unit]</span><span class="string">Description=Docker Socket for the API</span><span class="string"></span><span class="string">[Socket]</span><span class="string"># If /var/run is not implemented as a symlink to /run, you may need to</span><span class="string"># specify ListenStream=/var/run/docker.sock instead.</span><span class="string">ListenStream=/var/run/docker.sock</span><span class="string">SocketMode=0660</span><span class="string">SocketUser=root</span><span class="string">SocketGroup=docker</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=sockets.target</span><span class="string">EOF</span><span class="comment"># 将 docker.socket 复制到其它服务器中</span>hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span>   <span class="built_in">echo</span> <span class="variable">$i</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/systemd/system/docker.socket <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/systemd/system/; <span class="keyword">done</span></code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">这是一个用于Docker API的socket配置文件，包含了以下参数：[Unit]Description：描述了该socket的作用，即为Docker API的socket。[Socket]ListenStream：指定了 socket 的监听地址，该 socket 会监听在 /var/run/docker.sock 上，即 Docker 守护程序使用的默认 sock 文件。SocketMode：指定了socket文件的权限模式，此处为0660，即用户和用户组有读写权限，其他用户无权限。SocketUser：指定了socket文件的所有者，此处为root用户。SocketGroup：指定了socket文件的所属用户组，此处为docker用户组。[Install]WantedBy：指定了该socket被启用时的目标，此处为sockets.target，表示当sockets.target启动时启用该socket。该配置文件的作用是为 Docker 提供 API 访问的通道，它监听在 /var/run/docker.sock 上，具有 root 用户权限，但只接受 docker 用户组的成员的连接，并且其他用户无法访问。这样，只有 docker 用户组的成员可以通过该 socket 与 Docker 守护进程进行通信。</code></pre></blockquote><h3 id="18-5-配置-Docker-加速器"><a href="#18-5-配置-Docker-加速器" class="headerlink" title="18.5 配置 Docker 加速器"></a>18.5 配置 Docker 加速器</h3><pre><code class="highlight bash"><span class="comment"># 创建 docker 配置目录 和 数据目录</span><span class="built_in">mkdir</span> /etc/docker/ /data/docker -pv<span class="comment"># 写入docker配置，这里也修改了docker默认的数据目录</span><span class="built_in">cat</span> &gt; /etc/docker/daemon.json &lt;&lt;<span class="string">EOF</span><span class="string">&#123;</span><span class="string">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><span class="string">  &quot;registry-mirrors&quot;: [</span><span class="string">    &quot;https://kfp63jaj.mirror.aliyuncs.com&quot;,</span><span class="string">    &quot;https://hub-mirror.c.163.com&quot;,</span><span class="string">    &quot;https://mirror.baidubce.com&quot;</span><span class="string">  ],</span><span class="string">  &quot;max-concurrent-downloads&quot;: 10,</span><span class="string">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><span class="string">  &quot;log-level&quot;: &quot;warn&quot;,</span><span class="string">  &quot;log-opts&quot;: &#123;</span><span class="string">    &quot;max-size&quot;: &quot;10m&quot;,</span><span class="string">    &quot;max-file&quot;: &quot;3&quot;</span><span class="string">    &#125;,</span><span class="string">  &quot;data-root&quot;: &quot;/data/docker&quot;</span><span class="string">&#125;</span><span class="string">EOF</span><span class="comment"># 配置设置每一台服务器都创建docker的配置目录和数据目录</span>hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span><span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir /etc/docker/ /data/docker -pv&quot;</span><span class="keyword">done</span><span class="comment"># 将 daemon.json 复制到其它服务器中</span>hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span>   <span class="built_in">echo</span> <span class="variable">$i</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/docker/daemon.json <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/docker/; <span class="keyword">done</span></code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">该参数文件中包含以下参数：exec-opts: 用于设置Docker守护进程的选项，native.cgroupdriver=systemd表示使用systemd作为Cgroup驱动程序。registry-mirrors: 用于指定Docker镜像的镜像注册服务器。在这里有三个镜像注册服务器：https://docker.m.daocloud.io、https://docker.mirrors.ustc.edu.cn和http://hub-mirror.c.163.com。max-concurrent-downloads: 用于设置同时下载镜像的最大数量，默认值为3，这里设置为10。log-driver: 用于设置Docker守护进程的日志驱动程序，这里设置为json-file。log-level: 用于设置日志的级别，这里设置为warn。log-opts: 用于设置日志驱动程序的选项，这里有两个选项：max-size和max-file。max-size表示每个日志文件的最大大小，这里设置为10m，max-file表示保存的最大日志文件数量，这里设置为3。data-root: 用于设置Docker守护进程的数据存储根目录，默认为/var/lib/docker，这里设置为 /data/docker。</code></pre></blockquote><h3 id="18-6-启动-Docker"><a href="#18-6-启动-Docker" class="headerlink" title="18.6 启动 Docker"></a>18.6 启动 Docker</h3><pre><code class="highlight bash"><span class="comment"># 创建一个名为 docker 的组</span>groupadd docker<span class="comment"># 通知systemd重新加载所有单元配置文件（unit files），以识别新创建或修改的配置文件</span>systemctl daemon-reload<span class="comment"># 启用并立即启动Docker的socket单元（docker.socket），使其在系统启动时自动运行，并现在开始监听。</span>systemctl <span class="built_in">enable</span> --now docker.socket<span class="comment"># 启用并立即启动Docker守护进程服务（docker.service），使其在系统启动时自动运行，并现在开始运行。</span>systemctl <span class="built_in">enable</span> --now docker.service<span class="comment"># 验证：查看 docker 服务状态</span>systemctl status docker.service<span class="comment"># 验证：查看docker信息</span>docker info<span class="comment"># 集群中的其他服务器也启动 Docker </span>hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span><span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;groupadd docker&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now docker.socket&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now docker.service&quot;</span><span class="keyword">done</span></code></pre><h2 id="19-安装-cri-docker"><a href="#19-安装-cri-docker" class="headerlink" title="19. 安装 cri-docker"></a>19. 安装 cri-docker</h2><h3 id="19-1-安装-cri-docker-二进制包"><a href="#19-1-安装-cri-docker-二进制包" class="headerlink" title="19.1 安装 cri-docker 二进制包"></a>19.1 安装 cri-docker 二进制包</h3><p>cri-docker 与 docker的版本匹配关系：<a href="https://github.com/Mirantis/cri-dockerd/releases/tag/v0.4.0">https://github.com/Mirantis/cri-dockerd/releases/tag/v0.4.0</a></p><ul><li>Bump github.com&#x2F;docker&#x2F;docker to 27.0.2+incompatible by <a href="https://github.com/cncal">@cncal</a> in <a href="https://github.com/Mirantis/cri-dockerd/pull/381">#381</a></li></ul><pre><code class="highlight bash"><span class="comment"># 下载 cri-docker 二进制包</span>wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.4.0/cri-dockerd-0.4.0.amd64.tgz<span class="comment"># 解压</span>tar xvf cri-dockerd-*.amd64.tgz <span class="comment"># 复制到 /usr/bin/</span><span class="built_in">cp</span> cri-dockerd/cri-dockerd /usr/bin/<span class="comment"># 授权</span><span class="built_in">chmod</span> +x /usr/bin/cri-dockerd<span class="comment"># 将 cri-dockerd 复制到其它服务器中</span>hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span>   <span class="built_in">echo</span> <span class="variable">$i</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/bin/cri-dockerd <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/bin/; <span class="keyword">done</span><span class="comment"># 验证</span>$ cri-dockerd --versioncri-dockerd 0.4.0 (b9b8893)</code></pre><h3 id="19-2-配置-cri-docker-service"><a href="#19-2-配置-cri-docker-service" class="headerlink" title="19.2 配置 cri-docker.service"></a>19.2 配置 cri-docker.service</h3><p>从 github 获取文件：<a href="https://github.com/Mirantis/cri-dockerd/tree/master/packaging/systemd">https://github.com/Mirantis/cri-dockerd/tree/master/packaging/systemd</a></p><pre><code class="highlight bash"><span class="comment"># 下载 cri-docker.service 文件</span>wget https://raw.githubusercontent.com/Mirantis/cri-dockerd/refs/tags/v0.4.0/packaging/systemd/cri-docker.service<span class="comment"># 修改 ExecStart 启动命令后，写入到指定目录</span><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/cri-docker.service &lt;&lt;<span class="string">EOF</span><span class="string">[Unit]</span><span class="string">Description=CRI Interface for Docker Application Container Engine</span><span class="string">Documentation=https://docs.mirantis.com</span><span class="string">After=network-online.target firewalld.service docker.service</span><span class="string">Wants=network-online.target</span><span class="string">Requires=cri-docker.socket</span><span class="string"></span><span class="string">[Service]</span><span class="string">Type=notify</span><span class="string"># 修啊该启动命令</span><span class="string">ExecStart=/usr/bin/cri-dockerd --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9 --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --cri-dockerd-root-directory=/data/dockershim --cri-dockerd-root-directory=/data/docker</span><span class="string"></span><span class="string">ExecReload=/bin/kill -s HUP $MAINPID</span><span class="string">TimeoutSec=0</span><span class="string">RestartSec=2</span><span class="string">Restart=always</span><span class="string">StartLimitBurst=3</span><span class="string">StartLimitInterval=60s</span><span class="string">LimitNOFILE=infinity</span><span class="string">LimitNPROC=infinity</span><span class="string">LimitCORE=infinity</span><span class="string">TasksMax=infinity</span><span class="string">Delegate=yes</span><span class="string">KillMode=process</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string">EOF</span><span class="comment"># 将 cri-docker.service 复制到其它服务器中</span>hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span>   <span class="built_in">echo</span> <span class="variable">$i</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/cri-docker.service <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/lib/systemd/system/; <span class="keyword">done</span></code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">[Unit]Description：该参数用于描述该单元的功能，这里描述的是CRI与Docker应用容器引擎的接口。Documentation：该参数指定了相关文档的网址，供用户参考。After：该参数指定了此单元应该在哪些其他单元之后启动，确保在网络在线、防火墙和Docker服务启动之后再启动此单元。Wants：该参数指定了此单元希望也启动的所有单元，此处是希望在网络在线之后启动。Requires：该参数指定了此单元需要依赖的单元，此处是cri-docker.socket单元。[Service]Type：该参数指定了服务的类型，这里是notify，表示当服务启动完成时向系统发送通知。ExecStart：该参数指定了将要运行的命令和参数，此处是执行/usr/bin/cri-dockerd 命令，并指定了网络插件为cni和Pod基础设施容器的镜像为registry.aliyuncs.com/google_containers/pause:3.9。  - --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock   - 定义 CRI 的监听端点。  - --cri-dockerd-root-directory=/data/dockershim  - 定义 cri-dockerd 的根目录，用于存储临时文件或配置数据。  - --cri-dockerd-root-directory=/data/docker  - 定义 Docker 的根目录。ExecReload：该参数指定在服务重载时运行的命令，此处是发送HUP信号给主进程。TimeoutSec：该参数指定了服务启动的超时时间，此处为0，表示无限制。RestartSec：该参数指定了自动重启服务的时间间隔，此处为2秒。Restart：该参数指定了在服务发生错误时自动重启，此处是始终重启。StartLimitBurst：该参数指定了在给定时间间隔内允许的启动失败次数，此处为3次。StartLimitInterval：该参数指定启动失败的时间间隔，此处为60秒。LimitNOFILE：该参数指定了允许打开文件的最大数量，此处为无限制。LimitNPROC：该参数指定了允许同时运行的最大进程数，此处为无限制。LimitCORE：该参数指定了允许生成的core文件的最大大小，此处为无限制。TasksMax：该参数指定了此服务的最大任务数，此处为无限制。Delegate：该参数指定了是否将控制权委托给指定服务，此处为是。KillMode：该参数指定了在终止服务时如何处理进程，此处是通过终止进程来终止服务。[Install]WantedBy：该参数指定了希望这个单元启动的多用户目标。在这里，这个单元希望在multi-user.target启动。</code></pre></blockquote><h3 id="19-3-配置-cri-docker-socket"><a href="#19-3-配置-cri-docker-socket" class="headerlink" title="19.3 配置 cri-docker.socket"></a>19.3 配置 cri-docker.socket</h3><p>从 github 获取文件：<a href="https://github.com/Mirantis/cri-dockerd/tree/master/packaging/systemd">https://github.com/Mirantis/cri-dockerd/tree/master/packaging/systemd</a></p><pre><code class="highlight bash"><span class="comment"># 下载</span>wget https://raw.githubusercontent.com/Mirantis/cri-dockerd/refs/tags/v0.4.0/packaging/systemd/cri-docker.socket<span class="comment"># 修改 ListenStream，并写入到指令目录</span><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/cri-docker.socket &lt;&lt;<span class="string">EOF</span><span class="string">[Unit]</span><span class="string">Description=CRI Docker Socket for the API</span><span class="string">PartOf=cri-docker.service</span><span class="string"></span><span class="string">[Socket]</span><span class="string">ListenStream=/var/run/cri-dockerd.sock</span><span class="string">SocketMode=0660</span><span class="string">SocketUser=root</span><span class="string">SocketGroup=docker</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=sockets.target</span><span class="string">EOF</span><span class="comment"># 将 cri-docker.socket 复制到其它服务器中</span>hots=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span>   <span class="built_in">echo</span> <span class="variable">$i</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/cri-docker.socket <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/lib/systemd/system/; <span class="keyword">done</span></code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">该配置文件是用于systemd的单元配置文件(unit file)，用于定义一个socket单元。[Unit]Description：表示该单元的描述信息。PartOf：表示该单元是cri-docker.service的一部分。[Socket]ListenStream：指定了该socket要监听的地址和端口，这里要与 cri-docker.service 配置的 ExecStart 指定的套接字一致，都为 /var/run/cri-dockerd.sock。Unix域套接字用于在同一台主机上的进程之间通信。SocketMode：指定了socket文件的权限模式，此处为0660，即用户和用户组有读写权限，其他用户无权限。SocketUser：指定了socket文件的所有者，此处为root用户。SocketGroup：指定了socket文件的所属用户组，此处为docker用户组。[Install]WantedBy：部分定义了该单元的安装配置信息。WantedBy=sockets.target表示当sockets.target单元启动时，自动启动该socket单元。sockets.target是一个系统服务，用于管理所有的socket单元。</code></pre></blockquote><h3 id="19-4-启动-cri-docker"><a href="#19-4-启动-cri-docker" class="headerlink" title="19.4 启动 cri-docker"></a>19.4 启动 cri-docker</h3><pre><code class="highlight bash"><span class="comment"># 通知systemd重新加载所有单元配置文件（unit files），以识别新创建或修改的配置文件</span>systemctl daemon-reload<span class="comment"># 设置开机自启</span>systemctl <span class="built_in">enable</span> --now cri-docker.service<span class="comment"># 验证，查看状态</span>systemctl status cri-docker.service<span class="comment"># 集群中的其他服务器也启动 Docker </span>hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span><span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now cri-docker.service&quot;</span><span class="keyword">done</span></code></pre><h1 id="四、K8S-与-ETCD-下载及安装（在-master01-节点上操作）"><a href="#四、K8S-与-ETCD-下载及安装（在-master01-节点上操作）" class="headerlink" title="四、K8S 与 ETCD 下载及安装（在 master01 节点上操作）"></a>四、K8S 与 ETCD 下载及安装（在 master01 节点上操作）</h1><p>当前选择安装 K8S 版本：1.29.2，ETCD 版本：3.5.16</p><p><strong>查看 K8S 与 ETCD 的版本匹配关系以及二进制包下载地址</strong></p><p><a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md</a></p><p><a href="https://github.com/kubernetes/kubernetes/blob/release-1.29/cluster/images/etcd/Makefile">https://github.com/kubernetes/kubernetes/blob/release-1.29/cluster/images/etcd/Makefile</a></p><p><strong>需要下载的镜像</strong> </p><p><a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md#container-images-13">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md#container-images-13</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/11/20251011-124215.png" alt="K8S 1.29.2 需要下载的镜像"></p><h2 id="1-安装-K8S-二进制包"><a href="#1-安装-K8S-二进制包" class="headerlink" title="1. 安装 K8S 二进制包"></a>1. 安装 K8S 二进制包</h2><p>下载地址：<a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md#v1292">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md#v1292</a></p><pre><code class="highlight bash"><span class="comment"># 下载 K8S 二进制包</span>wget https://dl.k8s.io/v1.29.2/kubernetes-server-linux-amd64.tar.gz<span class="comment"># 解压文件到指定目录</span>tar -xf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/local/bin kubernetes/server/bin/kube&#123;<span class="built_in">let</span>,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;<span class="comment"># 查看解压的文件</span>$ <span class="built_in">ls</span> /usr/local/bin/kube-apiserver  kube-controller-manager  kube-proxy  kube-scheduler  kubectl  kubelet<span class="comment"># 将解压后的 K8S 二进制包复制到其它服务器中</span><span class="comment"># 拷贝 master 组件</span>hots=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span>   <span class="built_in">echo</span> <span class="variable">$i</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/local/bin/kube* <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/local/bin/; <span class="keyword">done</span><span class="comment"># 拷贝 worker 组件</span>hots=<span class="string">&#x27;k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span>   <span class="built_in">echo</span> <span class="variable">$i</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/local/bin/kube&#123;<span class="built_in">let</span>,-proxy&#125; <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/local/bin/; <span class="keyword">done</span><span class="comment"># 验证</span>$ kubelet --versionKubernetes v1.29.2</code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">这是一个 tar 命令，用于解压指定的 kubernetes-server-linux-amd64.tar.gz 文件，并将其中的特定文件提取到 /usr/local/bin 目录下。命令的解释如下：tar：用于处理 tar 压缩文件的命令。-xf：表示解压操作。kubernetes-server-linux-amd64.tar.gz：要解压的文件名。--strip-components=3：表示解压时忽略压缩文件中的前3级目录结构，提取文件时直接放到目标目录中。-C /usr/local/bin：指定提取文件的目标目录为 /usr/local/bin。kubernetes/server/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;：要解压和提取的文件名模式，用花括号括起来表示模式中的多个可能的文件名。总的来说，这个命令的作用是将 kubernetes-server-linux-amd64.tar.gz 文件中的 kubelet、kubectl、kube-apiserver、kube-controller-manager、kube-scheduler和kube-proxy 六个文件提取到 /usr/local/bin 目录下，同时忽略文件路径中的前三级目录结构。</code></pre></blockquote><h2 id="2-安装-ETCD-二进制包"><a href="#2-安装-ETCD-二进制包" class="headerlink" title="2. 安装 ETCD 二进制包"></a>2. 安装 ETCD 二进制包</h2><p>下载地址：<a href="https://github.com/etcd-io/etcd/releases/tag/v3.5.16">https://github.com/etcd-io/etcd/releases/tag/v3.5.16</a></p><pre><code class="highlight bash"><span class="comment"># 下载 ETCD 二进制安装包</span>wget https://github.com/etcd-io/etcd/releases/download/v3.5.16/etcd-v3.5.16-linux-amd64.tar.gz<span class="comment"># 解压etcd安装文件</span>tar -xf etcd*.tar.gz &amp;&amp; <span class="built_in">mv</span> etcd-*/etcd /usr/local/bin/ &amp;&amp; <span class="built_in">mv</span> etcd-*/etcdctl /usr/local/bin/<span class="comment"># 将解压后的 K8S 二进制包复制到其它服务器中</span>hots=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$hots</span>; <span class="keyword">do</span>   <span class="built_in">echo</span> <span class="variable">$i</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/local/bin/etcd* <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/local/bin/; <span class="keyword">done</span><span class="comment"># 验证：查看/usr/local/bin下内容</span>$ etcdctl versionetcdctl version: 3.5.16API version: 3.5</code></pre><h2 id="3-生成相关证书"><a href="#3-生成相关证书" class="headerlink" title="3. 生成相关证书"></a>3. 生成相关证书</h2><h3 id="3-1-安装证书工具"><a href="#3-1-安装证书工具" class="headerlink" title="3.1 安装证书工具"></a>3.1 安装证书工具</h3><p><strong>k8s-master01</strong></p><pre><code class="highlight bash"><span class="comment"># master01 节点下载证书生成工具</span>wget https://github.com/cloudflare/cfssl/releases/download/v1.6.4/cfssl_1.6.4_linux_amd64 -O /usr/local/bin/cfsslwget https://github.com/cloudflare/cfssl/releases/download/v1.6.4/cfssljson_1.6.4_linux_amd64 -O /usr/local/bin/cfssljson<span class="built_in">chmod</span> +x /usr/local/bin/cfssl /usr/local/bin/cfssljson</code></pre><h3 id="3-2-生成-ETCD-证书"><a href="#3-2-生成-ETCD-证书" class="headerlink" title="3.2 生成 ETCD 证书"></a>3.2 生成 ETCD 证书</h3><h4 id="3-2-1-ca-config-json"><a href="#3-2-1-ca-config-json" class="headerlink" title="3.2.1 ca-config.json"></a>3.2.1 ca-config.json</h4><p><strong>k8s-master01</strong></p><pre><code class="highlight bash"><span class="comment"># 创建目录，存放生成的证书</span><span class="built_in">mkdir</span> /etc/etcd/ssl -p<span class="comment"># 写入生成证书所需的配置文件,master01 节点生成 etcd 证书</span><span class="built_in">cat</span> &gt; /etc/etcd/ssl/ca-config.json &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;signing&quot;: &#123;</span><span class="string">    &quot;default&quot;: &#123;</span><span class="string">      &quot;expiry&quot;: &quot;876000h&quot;</span><span class="string">    &#125;,</span><span class="string">    &quot;profiles&quot;: &#123;</span><span class="string">      &quot;kubernetes&quot;: &#123;</span><span class="string">        &quot;usages&quot;: [</span><span class="string">            &quot;signing&quot;,</span><span class="string">            &quot;key encipherment&quot;,</span><span class="string">            &quot;server auth&quot;,</span><span class="string">            &quot;client auth&quot;</span><span class="string">        ],</span><span class="string">        &quot;expiry&quot;: &quot;876000h&quot;</span><span class="string">      &#125;</span><span class="string">    &#125;</span><span class="string">  &#125;</span><span class="string">&#125;</span><span class="string">EOF</span></code></pre><blockquote><p><strong>命令解析：</strong></p><p><code>ca-config.json</code>文件是使用CFSSL（CloudFlare’s PKI&#x2F;TLS toolkit）工具生成证书的核心配置文件。它主要用于定义证书签名的全局策略和配置文件（profiles），确保生成的证书具有一致的安全属性、用途和有效期。</p><pre><code class="highlight plaintext">在这里，有两个部分：signing 和 profiles。signing 包含了默认签名配置和配置文件。默认签名配置 default 指定了证书的过期时间为 876000h 。876000h 表示证书有效期为 100 年。profiles 部分定义了不同的证书配置文件。在这里，只有一个配置文件 kubernetes 。它包含了以下 usages 和过期时间 expiry：signing：用于对其他证书进行签名key encipherment：用于加密和解密传输数据server auth：用于服务器身份验证client auth：用于客户端身份验证对于 kubernetes 配置文件，证书的过期时间也是 876000h，即100年。</code></pre></blockquote><h4 id="3-2-2-etcd-ca-csr-json"><a href="#3-2-2-etcd-ca-csr-json" class="headerlink" title="3.2.2 etcd-ca-csr.json"></a>3.2.2 etcd-ca-csr.json</h4><p><strong>k8s-master01</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/etcd/ssl/etcd-ca-csr.json  &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;CN&quot;: &quot;etcd&quot;,</span><span class="string">  &quot;key&quot;: &#123;</span><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span><span class="string">    &quot;size&quot;: 2048</span><span class="string">  &#125;,</span><span class="string">  &quot;names&quot;: [</span><span class="string">    &#123;</span><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span><span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;O&quot;: &quot;etcd&quot;,</span><span class="string">      &quot;OU&quot;: &quot;Etcd Security&quot;</span><span class="string">    &#125;</span><span class="string">  ],</span><span class="string">  &quot;ca&quot;: &#123;</span><span class="string">    &quot;expiry&quot;: &quot;876000h&quot;</span><span class="string">  &#125;</span><span class="string">&#125;</span><span class="string">EOF</span></code></pre><blockquote><p><strong>命令解析：</strong></p><p>etcd-ca-csr.json 是 Certificate Signing Request (CSR) 文件，用于生成 ETCD 的根 CA 证书（etcd-ca.pem 和 etcd-ca-key.pem）。根 CA 证书是 ETCD 集群的安全基石，用于签署 ETCD 节点证书（etcd.pem 和 etcd-key.pem）和其他相关证书，确保集群内部通信的加密和身份验证。</p><pre><code class="highlight plaintext">JSON 配置文件指定了生成证书签名请求所需的数据。&quot;CN&quot;: &quot;etcd&quot; 指定了希望生成的证书的 CN 字段（Common Name），即证书的主题，通常是该证书标识的实体的名称。&quot;key&quot;: &#123;&#125; 指定了生成证书所使用的密钥的配置信息。&quot;algo&quot;: &quot;rsa&quot; 指定了密钥的算法为 RSA，&quot;size&quot;: 2048 指定了密钥的长度为 2048 位。&quot;names&quot;: [] 包含了生成证书时所需的实体信息。在这个例子中，只包含了一个实体，其相关信息如下：&quot;C&quot;: &quot;CN&quot; 指定了实体的国家/地区代码，这里是中国。&quot;ST&quot;: &quot;Beijing&quot; 指定了实体所在的省/州。&quot;L&quot;: &quot;Beijing&quot; 指定了实体所在的城市。&quot;O&quot;: &quot;etcd&quot; 指定了实体的组织名称。&quot;OU&quot;: &quot;Etcd Security&quot; 指定了实体所属的组织单位。&quot;ca&quot;: &#123;&#125; 指定了生成证书时所需的CA（Certificate Authority）配置信息。&quot;expiry&quot;: &quot;876000h&quot; 指定了证书的有效期，这里是876000小时。生成证书签名请求时，可以使用这个 JSON 配置文件作为输入，根据配置文件中的信息生成相应的 CSR 文件。然后，可以将 CSR 文件发送给 CA 进行签名，以获得有效的证书。生成 etcd 证书和 etcd 证书的 key（如果你觉得以后可能会扩容，可以在 ip 那多写几个预留出来）若没有IPv6 可删除可保留</code></pre></blockquote><h4 id="3-2-3-生成-ETCD-的根-CA-证书"><a href="#3-2-3-生成-ETCD-的根-CA-证书" class="headerlink" title="3.2.3 生成 ETCD 的根 CA 证书"></a>3.2.3 生成 ETCD 的根 CA 证书</h4><p><strong>k8s-master01</strong></p><pre><code class="highlight bash"><span class="comment"># 生成 ETCD 的根 CA 证书</span>cfssl gencert -initca /etc/etcd/ssl/etcd-ca-csr.json | cfssljson -bare /etc/etcd/ssl/etcd-ca<span class="comment"># 查看生成的 ETCD 的根 CA 证书</span>$ ll /etc/etcd/ssl/total 20-rw-r--r--. 1 root root  294 Oct 11 19:03 ca-config.json-rw-r--r--. 1 root root  249 Oct 11 19:20 etcd-ca-csr.json-rw-------. 1 root root 1679 Oct 11 19:21 etcd-ca-key.pem-rw-r--r--. 1 root root 1050 Oct 11 19:21 etcd-ca.csr-rw-r--r--. 1 root root 1318 Oct 11 19:21 etcd-ca.pem</code></pre><blockquote><pre><code class="highlight plaintext">具体的解释如下：cfssl 是一个用于生成 TLS/SSL 证书的工具，它支持 PKI、JSON 格式配置文件以及与许多其他集成工具的配合使用。gencert 参数表示生成证书的操作。-initca 参数表示初始化一个CA（证书颁发机构）。CA 是用于签发其他证书的根证书。etcd-ca-csr.json 是一个 JSON 格式的配置文件，其中包含了CA的详细信息，如私钥、公钥、有效期等。这个文件提供了生成 CA 证书所需的信息。| 符号表示将上一个命令的输出作为下一个命令的输入。cfssljson 是 cfssl 工具的一个子命令，用于格式化 cfssl 生成的 JSON 数据。 -bare 参数表示直接输出裸证书，即只生成证书文件，不包含其他格式的文件。/etc/etcd/ssl/etcd-ca 是指定生成的证书文件的路径和名称。所以，这条命令的含义是使用 cfssl 工具根据配置文件 etcd-ca-csr.json 生成一个 CA 证书，并将证书文件保存在 /etc/etcd/ssl/etcd-ca 路径下。</code></pre></blockquote><h4 id="3-2-4-etcd-csr-json"><a href="#3-2-4-etcd-csr-json" class="headerlink" title="3.2.4 etcd-csr.json"></a>3.2.4 etcd-csr.json</h4><p><strong>k8s-master01</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/etcd/ssl/etcd-csr.json &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;CN&quot;: &quot;etcd&quot;,</span><span class="string">  &quot;key&quot;: &#123;</span><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span><span class="string">    &quot;size&quot;: 2048</span><span class="string">  &#125;,</span><span class="string">  &quot;names&quot;: [</span><span class="string">    &#123;</span><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span><span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;O&quot;: &quot;etcd&quot;,</span><span class="string">      &quot;OU&quot;: &quot;Etcd Security&quot;</span><span class="string">    &#125;</span><span class="string">  ]</span><span class="string">&#125;</span><span class="string">EOF</span></code></pre><blockquote><p>命令解析：</p><p>etcd-csr.json 用于生成 ETCD 节点的 TLS 证书（etcd.pem 和 etcd-key.pem），这些证书由 ETCD 的根 CA（通过 etcd-ca-csr.json 生成的 etcd-ca.pem）签署。</p><pre><code class="highlight plaintext">这段代码是一个 JSON 格式的配置文件，用于生成一个证书签名请求（Certificate Signing Request，CSR）。首先，&quot;CN&quot;字段指定了该证书的通用名称（Common Name），这里设为&quot;etcd&quot;。接下来，&quot;key&quot;字段指定了密钥的算法（&quot;algo&quot;字段）和长度（&quot;size&quot;字段），此处使用的是RSA算法，密钥长度为2048位。最后，&quot;names&quot;字段是一个数组，其中包含了一个名字对象，用于指定证书中的一些其他信息。这个名字对象包含了以下字段：&quot;C&quot;字段指定了国家代码（Country），这里设置为&quot;CN&quot;。&quot;ST&quot;字段指定了省份（State）或地区，这里设置为&quot;Beijing&quot;。&quot;L&quot;字段指定了城市（Locality），这里设置为&quot;Beijing&quot;。&quot;O&quot;字段指定了组织（Organization），这里设置为&quot;etcd&quot;。&quot;OU&quot;字段指定了组织单元（Organizational Unit），这里设置为&quot;Etcd Security&quot;。这些字段将作为证书的一部分，用于标识和验证证书的使用范围和颁发者等信息。</code></pre></blockquote><h4 id="3-2-5-生成-ETCD-节点证书"><a href="#3-2-5-生成-ETCD-节点证书" class="headerlink" title="3.2.5 生成 ETCD 节点证书"></a>3.2.5 生成 ETCD 节点证书</h4><p><strong>k8s-master01</strong></p><pre><code class="highlight bash"><span class="comment"># 生成 ETCD 节点证书</span>cfssl gencert \-ca=/etc/etcd/ssl/etcd-ca.pem \-ca-key=/etc/etcd/ssl/etcd-ca-key.pem \-config=/etc/etcd/ssl/ca-config.json \-hostname=127.0.0.1,k8s-master01,k8s-master02,k8s-master03,10.20.1.101,10.20.1.102,10.20.1.103,2400:3200::101,2400:3200::102,2400:3200::103,::1 \-profile=kubernetes \/etc/etcd/ssl/etcd-csr.json | cfssljson -bare /etc/etcd/ssl/etcd</code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">这是一条使用cfssl生成etcd节点证书的命令，下面是各个参数的解释：-ca=/etc/etcd/ssl/etcd-ca.pem：指定用于签名etcd证书的CA文件的路径。-ca-key=/etc/etcd/ssl/etcd-ca-key.pem：指定用于签名etcd证书的CA私钥文件的路径。-config=ca-config.json：指定CA配置文件的路径，该文件定义了证书的有效期、加密算法等设置。-hostname=xxxx：指定要为etcd生成证书的主机名和IP地址列表。-profile=kubernetes：指定使用的证书配置文件，该文件定义了证书的用途和扩展属性。etcd-csr.json：指定etcd证书请求的JSON文件的路径，该文件包含了证书请求的详细信息。| cfssljson -bare /etc/etcd/ssl/etcd：通过管道将cfssl命令的输出传递给cfssljson命令，并使用-bare参数指定输出文件的前缀路径，这里将生成etcd证书的.pem和-key.pem文件。这条命令的作用是使用指定的CA证书和私钥，根据证书请求的JSON文件和配置文件生成etcd的证书文件。</code></pre></blockquote><h4 id="3-2-6-将证书复制到其他节点"><a href="#3-2-6-将证书复制到其他节点" class="headerlink" title="3.2.6 将证书复制到其他节点"></a>3.2.6 将证书复制到其他节点</h4><p><strong>k8s-master01</strong></p><pre><code class="highlight bash"><span class="comment"># 将生成的 ETCD 证书复制到其他节点</span>hosts=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span><span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir /etc/etcd/ssl -p&quot;</span>  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/etcd/ssl/* <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/etcd/ssl/; <span class="keyword">done</span></code></pre><h3 id="3-3-生成-K8S-相关证书"><a href="#3-3-生成-K8S-相关证书" class="headerlink" title="3.3 生成 K8S 相关证书"></a>3.3 生成 K8S 相关证书</h3><h4 id="3-3-1-ca-config-json"><a href="#3-3-1-ca-config-json" class="headerlink" title="3.3.1 ca-config.json"></a>3.3.1 ca-config.json</h4><p><strong>k8s-master01</strong></p><pre><code class="highlight bash"><span class="comment"># 创建目录，用于存放 K8S 相关证书</span><span class="built_in">mkdir</span> -p /etc/kubernetes/pki<span class="built_in">cat</span> &gt; /etc/kubernetes/pki/ca-config.json &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;signing&quot;: &#123;</span><span class="string">    &quot;default&quot;: &#123;</span><span class="string">      &quot;expiry&quot;: &quot;876000h&quot;</span><span class="string">    &#125;,</span><span class="string">    &quot;profiles&quot;: &#123;</span><span class="string">      &quot;kubernetes&quot;: &#123;</span><span class="string">        &quot;usages&quot;: [</span><span class="string">            &quot;signing&quot;,</span><span class="string">            &quot;key encipherment&quot;,</span><span class="string">            &quot;server auth&quot;,</span><span class="string">            &quot;client auth&quot;</span><span class="string">        ],</span><span class="string">        &quot;expiry&quot;: &quot;876000h&quot;</span><span class="string">      &#125;</span><span class="string">    &#125;</span><span class="string">  &#125;</span><span class="string">&#125;</span><span class="string">EOF</span></code></pre><blockquote><p><strong>命令解析：</strong></p><p><code>ca-config.json</code>文件是使用CFSSL（CloudFlare’s PKI&#x2F;TLS toolkit）工具生成证书的核心配置文件。它主要用于定义证书签名的全局策略和配置文件（profiles），确保生成的证书具有一致的安全属性、用途和有效期。</p><pre><code class="highlight plaintext">在这里，有两个部分：signing 和 profiles。signing 包含了默认签名配置和配置文件。默认签名配置 default 指定了证书的过期时间为 876000h 。876000h 表示证书有效期为 100 年。profiles 部分定义了不同的证书配置文件。在这里，只有一个配置文件 kubernetes 。它包含了以下 usages 和过期时间 expiry：signing：用于对其他证书进行签名key encipherment：用于加密和解密传输数据server auth：用于服务器身份验证client auth：用于客户端身份验证对于 kubernetes 配置文件，证书的过期时间也是 876000h，即100年。</code></pre></blockquote><h4 id="3-3-2-ca-csr-json"><a href="#3-3-2-ca-csr-json" class="headerlink" title="3.3.2 ca-csr.json"></a>3.3.2 ca-csr.json</h4><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/pki/ca-csr.json &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><span class="string">  &quot;key&quot;: &#123;</span><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span><span class="string">    &quot;size&quot;: 2048</span><span class="string">  &#125;,</span><span class="string">  &quot;names&quot;: [</span><span class="string">    &#123;</span><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span><span class="string">      &quot;ST&quot;: &quot;Guangdong&quot;,</span><span class="string">      &quot;L&quot;: &quot;Guangzhou&quot;,</span><span class="string">      &quot;O&quot;: &quot;Kubernetes&quot;,</span><span class="string">      &quot;OU&quot;: &quot;System&quot;</span><span class="string">    &#125;</span><span class="string">  ],</span><span class="string">  &quot;ca&quot;: &#123;</span><span class="string">    &quot;expiry&quot;: &quot;876000h&quot;</span><span class="string">  &#125;</span><span class="string">&#125;</span><span class="string">EOF</span></code></pre><blockquote><p><strong>命令解析：</strong></p><p>ca-csr.json 用于生成 Kubernetes 集群的根 CA 证书（ca.pem 和 ca-key.pem）。根 CA 证书是 Kubernetes 安全体系的核心，用于签署集群内所有组件的证书（如 API Server、kubelet、admin 用户等），支持 TLS 加密和 Mutual TLS 认证。</p><pre><code class="highlight plaintext">这是一个用于生成 Kubernetes 相关证书的配置文件。该配置文件中包含以下信息：CN：CommonName，即用于标识证书的通用名称。在此配置中，CN 设置为 &quot;kubernetes&quot;，表示该证书是用于 Kubernetes。key：用于生成证书的算法和大小。在此配置中，使用的算法是 RSA，大小是 2048 位。names：用于证书中的名称字段的详细信息。在此配置中，有以下字段信息：C：Country，即国家。在此配置中，设置为 &quot;CN&quot;。ST：State，即省/州。在此配置中，设置为 &quot;Beijing&quot;。L：Locality，即城市。在此配置中，设置为 &quot;Beijing&quot;。O：Organization，即组织。在此配置中，设置为 &quot;Kubernetes&quot;。OU：Organization Unit，即组织单位。在此配置中，设置为 &quot;Kubernetes-manual&quot;。ca：用于证书签名的证书颁发机构（CA）的配置信息。在此配置中，设置了证书的有效期为 876000 小时。这个配置文件可以用于生成 Kubernetes 相关的证书，以确保集群中的通信安全性。</code></pre></blockquote><h4 id="3-3-3-生成-Kubernetes-集群的根-CA-证书"><a href="#3-3-3-生成-Kubernetes-集群的根-CA-证书" class="headerlink" title="3.3.3 生成 Kubernetes 集群的根 CA 证书"></a>3.3.3 生成 Kubernetes 集群的根 CA 证书</h4><pre><code class="highlight bash">cfssl gencert -initca /etc/kubernetes/pki/ca-csr.json | cfssljson -bare /etc/kubernetes/pki/ca</code></pre><blockquote><p><strong>命令解析：</strong></p><pre><code class="highlight plaintext">具体的解释如下：cfssl是一个用于生成TLS/SSL证书的工具，它支持PKI、JSON格式配置文件以及与许多其他集成工具的配合使用。gencert参数表示生成证书的操作。-initca参数表示初始化一个CA（证书颁发机构）。CA是用于签发其他证书的根证书。ca-csr.json是一个JSON格式的配置文件，其中包含了CA的详细信息，如私钥、公钥、有效期等。这个文件提供了生成CA证书所需的信息。| 符号表示将上一个命令的输出作为下一个命令的输入。cfssljson是cfssl工具的一个子命令，用于格式化cfssl生成的JSON数据。 -bare参数表示直接输出裸证书，即只生成证书文件，不包含其他格式的文件。/etc/kubernetes/pki/ca是指定生成的证书文件的路径和名称。所以，这条命令的含义是使用cfssl工具根据配置文件ca-csr.json生成一个CA证书，并将证书文件保存在/etc/kubernetes/pki/ca路径下。</code></pre></blockquote><h4 id="3-3-4-apiserver-csr-json"><a href="#3-3-4-apiserver-csr-json" class="headerlink" title="3.3.4 apiserver-csr.json"></a>3.3.4 apiserver-csr.json</h4><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/pki/apiserver-csr.json &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;CN&quot;: &quot;kube-apiserver&quot;,</span><span class="string">  &quot;key&quot;: &#123;</span><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span><span class="string">    &quot;size&quot;: 2048</span><span class="string">  &#125;,</span><span class="string">  &quot;names&quot;: [</span><span class="string">    &#123;</span><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span><span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;O&quot;: &quot;Kubernetes&quot;,</span><span class="string">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><span class="string">    &#125;</span><span class="string">  ]</span><span class="string">&#125;</span><span class="string">EOF</span></code></pre><blockquote><p>命令解析：</p><p>apiserver-csr.json 用于生成 Kubernetes API Server 的 TLS 证书（apiserver.pem 和 apiserver-key.pem），这些证书由 Kubernetes 的根 CA（通过 ca-csr.json 生成的 ca.pem）签署。</p><p>证书用于：</p><ul><li>服务器端认证：确保 API Server 的身份可信，客户端（如 kubectl、kubelet）可以通过 CA 证书（ca.pem）验证 API Server。</li><li>客户端认证：支持 Mutual TLS，API Server 验证客户端证书（如 admin、kubelet）的合法性。</li><li>加密通信：通过 TLS 加密 API Server 与客户端之间的通信，防止数据泄露或篡改。</li></ul></blockquote><h4 id="3-3-5-生成-apiserver-证书"><a href="#3-3-5-生成-apiserver-证书" class="headerlink" title="3.3.5 生成 apiserver 证书"></a>3.3.5 生成 apiserver 证书</h4><pre><code class="highlight bash">cfssl gencert \-ca=/etc/kubernetes/pki/ca.pem \-ca-key=/etc/kubernetes/pki/ca-key.pem \-config=/etc/kubernetes/pki/ca-config.json \-hostname=10.96.0.1,127.0.0.1,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,10.20.1.101,10.20.1.102,10.20.1.103,10.20.1.104,10.20.1.105,10.20.1.106,10.20.1.107,10.20.1.108,10.20.1.109,2400:3200::101,2400:3200::102,2400:3200::103,2400:3200::104,2400:3200::105,2400:3200::106,2400:3200::107,2400:3200::108,2400:3200::109 \-profile=kubernetes \/etc/kubernetes/pki/apiserver-csr.json | cfssljson -bare /etc/kubernetes/pki/apiserver</code></pre><h4 id="3-3-6-apiserver-聚合证书"><a href="#3-3-6-apiserver-聚合证书" class="headerlink" title="3.3.6 apiserver 聚合证书"></a>3.3.6 apiserver 聚合证书</h4><p>访问 kube-apiserver 的另一种方式就是使用 kube-proxy 来代理访问, 而该证书就是用来支持 SSL 代理访问的。在该种访问模式下，我们是以http的方式发起请求到代理服务的, 此时, 代理服务会将该请求发送给 kube-apiserver , 在此之前, 代理会将发送给 kube-apiserver 的请求头里加入证书信息。</p><pre><code class="highlight plaintext">客户端 -- 发起请求 ---&gt; 代理 -- Add Header信息:发起请求 --&gt; kube-apiserve</code></pre><p>如果apiserver所在的主机上没有运行kube-proxy，既无法通过服务的ClusterIP进行访问，需要 <code>--enable-aggregator-routing=true</code></p><h5 id="3-3-6-1-front-proxy-ca-csr-json"><a href="#3-3-6-1-front-proxy-ca-csr-json" class="headerlink" title="3.3.6.1 front-proxy-ca-csr.json"></a>3.3.6.1 front-proxy-ca-csr.json</h5><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/pki/front-proxy-ca-csr.json  &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><span class="string">  &quot;key&quot;: &#123;</span><span class="string">     &quot;algo&quot;: &quot;rsa&quot;,</span><span class="string">     &quot;size&quot;: 2048</span><span class="string">  &#125;,</span><span class="string">  &quot;ca&quot;: &#123;</span><span class="string">    &quot;expiry&quot;: &quot;876000h&quot;</span><span class="string">  &#125;</span><span class="string">&#125;</span><span class="string">EOF</span></code></pre><blockquote><p><strong>命令解析：</strong></p><p>front-proxy-ca-csr.json 用于生成 Kubernetes 的 Front Proxy CA 证书（front-proxy-ca.pem 和 front-proxy-ca-key.pem）。Front Proxy CA 是 Kubernetes 集群中用于 前端代理认证 的独立 CA，专门用于签署前端代理客户端证书（如 front-proxy-client.pem），以支持 API Server 的请求头认证机制。</p></blockquote><h5 id="3-3-6-2-生成-Kubernetes-Front-Proxy-根-CA-证书"><a href="#3-3-6-2-生成-Kubernetes-Front-Proxy-根-CA-证书" class="headerlink" title="3.3.6.2 生成 Kubernetes Front Proxy 根 CA 证书"></a>3.3.6.2 生成 Kubernetes Front Proxy 根 CA 证书</h5><p>包括证书文件（front-proxy-ca.pem）、私钥文件（front-proxy-ca-key.pem）和 CSR 文件（front-proxy-ca.csr）</p><pre><code class="highlight bash"><span class="comment"># 指示 CFSSL 生成根 CA 证书（而非普通证书）</span>cfssl gencert -initca /etc/kubernetes/pki/front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca<span class="comment"># 生成 前端代理客户端证书 的 CSR 配置文件</span><span class="built_in">cat</span> &gt; /etc/kubernetes/pki/front-proxy-client-csr.json &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;CN&quot;: &quot;front-proxy-client&quot;,</span><span class="string">  &quot;key&quot;: &#123;</span><span class="string">     &quot;algo&quot;: &quot;rsa&quot;,</span><span class="string">     &quot;size&quot;: 2048</span><span class="string">  &#125;</span><span class="string">&#125;</span><span class="string">EOF</span><span class="comment"># 生成前端代理客户端证书</span>cfssl gencert  \-ca=/etc/kubernetes/pki/front-proxy-ca.pem   \-ca-key=/etc/kubernetes/pki/front-proxy-ca-key.pem   \-config=/etc/kubernetes/pki/ca-config.json   \-profile=kubernetes /etc/kubernetes/pki/front-proxy-client-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-client</code></pre><blockquote><p><strong>命令解析1：</strong></p><pre><code class="highlight bash">cfssl gencert -initca front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca</code></pre><ul><li><p>这个命令使用 CFSSL 工具生成 Kubernetes Front Proxy CA 证书（根 CA 证书），包括证书文件（front-proxy-ca.pem）、私钥文件（front-proxy-ca-key.pem）和 CSR 文件（front-proxy-ca.csr）。</p></li><li><p>Front Proxy CA 的背景：在 Kubernetes 高可用集群中，Front Proxy CA 是用于 请求头认证（RequestHeader Authentication） 的独立 CA。它专门用于签署前端代理客户端证书（如 front-proxy-client.pem），以支持 API Server 的聚合层（Aggregation Layer）。这对于扩展组件（如 Metrics Server）至关重要，确保客户端（如 Metrics Server）可以通过 HTTP 请求头提供身份信息，并由 API Server 验证。</p></li><li><p>上下文：博客中，此证书用于 Metrics Server 的部署（components.yaml 中引用 –requestheader-client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.pem），确保高可用集群（3 Master 节点 + 2 Node 节点）的扩展 API 安全。</p></li></ul><p><strong>命令解析2：</strong></p><p>cat &gt; front-proxy-client-csr.json &lt;&lt; EOF … EOF</p><p>生成 前端代理客户端证书 的 CSR 配置文件</p><ul><li><p>前端代理客户端证书的作用：用于 Metrics Server 或其他聚合 API 客户端的身份认证。客户端证书（front-proxy-client.pem 和 front-proxy-client-key.pem）由 Front Proxy CA 签署，API Server 使用它验证请求头中的客户端身份，确保只有可信客户端可以访问聚合 API</p></li><li><p>为什么需要？Kubernetes 的聚合层要求客户端提供证书以通过 RequestHeader 认证。Metrics Server 配置中引用了这些证书，确保安全访问 API Server。</p></li><li><p>上下文：博客中，此证书用于 Metrics Server 的 TLS 通信，支持高可用集群的扩展功能。</p></li></ul><p><strong>命令解析3：</strong></p><p>cfssl gencert  <br>-ca&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.pem   <br>-ca-key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca-key.pem   <br>-config&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca-config.json   <br>-profile&#x3D;kubernetes &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-client-csr.json | cfssljson -bare &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-client</p><ul><li>使用 CFSSL 生成 前端代理客户端证书（front-proxy-client.pem 和 front-proxy-client-key.pem），由 Front Proxy CA 签署。</li><li>客户端证书的作用：Metrics Server 等聚合客户端使用此证书在请求头中证明身份，API Server 通过 Front Proxy CA 验证，确保安全访问聚合 API（如 &#x2F;apis&#x2F;metrics.k8s.io&#x2F;）</li><li>Metrics Server 的配置（–requestheader-username-headers 等）依赖此证书，支持 RequestHeader 认证。</li><li>在高可用集群中，此证书分发到所有 Master 节点，供 kube-apiserver 使用</li></ul></blockquote><h4 id="3-3-7-生成-controller-manage-的证书"><a href="#3-3-7-生成-controller-manage-的证书" class="headerlink" title="3.3.7 生成 controller-manage 的证书"></a>3.3.7 生成 controller-manage 的证书</h4><pre><code class="highlight bash"><span class="comment"># 生成 Kubernetes Controller Manager 客户端证书 的 Certificate Signing Request (CSR) 配置文件</span><span class="built_in">cat</span> &gt; /etc/kubernetes/pki/manager-csr.json &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,</span><span class="string">  &quot;key&quot;: &#123;</span><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span><span class="string">    &quot;size&quot;: 2048</span><span class="string">  &#125;,</span><span class="string">  &quot;names&quot;: [</span><span class="string">    &#123;</span><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span><span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;O&quot;: &quot;system:kube-controller-manager&quot;,</span><span class="string">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><span class="string">    &#125;</span><span class="string">  ]</span><span class="string">&#125;</span><span class="string">EOF</span><span class="comment"># 使用 CFSSL 生成 Controller Manager 客户端证书（controller-manager.pem 和 controller-manager-key.pem），由 Kubernetes 根 CA（ca.pem）签署</span>cfssl gencert \   -ca=/etc/kubernetes/pki/ca.pem \   -ca-key=/etc/kubernetes/pki/ca-key.pem \   -config=/etc/kubernetes/pki/ca-config.json \   -profile=kubernetes \   /etc/kubernetes/pki/manager-csr.json | cfssljson -bare /etc/kubernetes/pki/controller-manager   <span class="comment"># 配置 Controller Manager 的 kubeconfig 文件（/etc/kubernetes/controller-manager.kubeconfig），定义集群信息，指定 API Server 的地址和 CA 证书。</span>kubectl config set-cluster kubernetes \     --certificate-authority=/etc/kubernetes/pki/ca.pem \     --embed-certs=<span class="literal">true</span> \     --server=https://127.0.0.1:8443 \     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig<span class="comment"># 设置 kubeconfig 的上下文，将集群、用户和命名空间绑定，定义 Controller Manager 的访问环境</span>kubectl config set-context system:kube-controller-manager@kubernetes \    --cluster=kubernetes \    --user=system:kube-controller-manager \    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig<span class="comment"># 设置 Controller Manager 的用户凭据，指定其客户端证书和私钥，用于与 API Server 的身份认证</span>kubectl config set-credentials system:kube-controller-manager \    --client-certificate=/etc/kubernetes/pki/controller-manager.pem \    --client-key=/etc/kubernetes/pki/controller-manager-key.pem \    --embed-certs=<span class="literal">true</span> \    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig<span class="comment"># 设置 kubeconfig 文件的默认上下文，确保 Controller Manager 使用 system:kube-controller-manager@kubernetes 上下文访问 API Server</span>kubectl config use-context system:kube-controller-manager@kubernetes \     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig</code></pre><h4 id="3-3-8-生成-kube-scheduler-的证书"><a href="#3-3-8-生成-kube-scheduler-的证书" class="headerlink" title="3.3.8 生成 kube-scheduler 的证书"></a>3.3.8 生成 kube-scheduler 的证书</h4><pre><code class="highlight bash"><span class="comment"># 生成 Kubernetes Scheduler 客户端证书 的 Certificate Signing Request (CSR) 配置文件</span><span class="built_in">cat</span> &gt; /etc/kubernetes/pki/scheduler-csr.json &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;CN&quot;: &quot;system:kube-scheduler&quot;,</span><span class="string">  &quot;key&quot;: &#123;</span><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span><span class="string">    &quot;size&quot;: 2048</span><span class="string">  &#125;,</span><span class="string">  &quot;names&quot;: [</span><span class="string">    &#123;</span><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span><span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;O&quot;: &quot;system:kube-scheduler&quot;,</span><span class="string">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><span class="string">    &#125;</span><span class="string">  ]</span><span class="string">&#125;</span><span class="string">EOF</span><span class="comment"># 使用 CFSSL 生成 Scheduler 客户端证书（scheduler.pem 和 scheduler-key.pem），由 Kubernetes 根 CA（ca.pem）签署</span>cfssl gencert \   -ca=/etc/kubernetes/pki/ca.pem \   -ca-key=/etc/kubernetes/pki/ca-key.pem \   -config=/etc/kubernetes/pki/ca-config.json \   -profile=kubernetes \   /etc/kubernetes/pki/scheduler-csr.json | cfssljson -bare /etc/kubernetes/pki/scheduler<span class="comment"># 配置 Scheduler 的 kubeconfig 文件（/etc/kubernetes/scheduler.kubeconfig），定义集群信息，指定 API Server 的地址和 CA 证书。</span>kubectl config set-cluster kubernetes \     --certificate-authority=/etc/kubernetes/pki/ca.pem \     --embed-certs=<span class="literal">true</span> \     --server=https://127.0.0.1:8443 \     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig<span class="comment"># 设置 Scheduler 的用户凭据，指定其客户端证书和私钥，用于与 API Server 的身份认证。</span>kubectl config set-credentials system:kube-scheduler \     --client-certificate=/etc/kubernetes/pki/scheduler.pem \     --client-key=/etc/kubernetes/pki/scheduler-key.pem \     --embed-certs=<span class="literal">true</span> \     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig<span class="comment"># 设置 kubeconfig 的上下文，将集群、用户和命名空间绑定，定义 Scheduler 的访问环境。</span>kubectl config set-context system:kube-scheduler@kubernetes \     --cluster=kubernetes \     --user=system:kube-scheduler \     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig<span class="comment"># 设置 kubeconfig 文件的默认上下文，确保 Scheduler 使用 system:kube-scheduler@kubernetes 上下文访问 API Server</span>kubectl config use-context system:kube-scheduler@kubernetes \     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</code></pre><h4 id="3-3-9-生成-admin-的证书配置"><a href="#3-3-9-生成-admin-的证书配置" class="headerlink" title="3.3.9 生成 admin 的证书配置"></a>3.3.9 生成 admin 的证书配置</h4><pre><code class="highlight bash"><span class="comment"># 生成一个 证书签名请求（Certificate Signing Request） 的配置文件，供 cfssl 工具使用</span><span class="built_in">cat</span> &gt; /etc/kubernetes/pki/admin-csr.json &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;CN&quot;: &quot;admin&quot;,</span><span class="string">  &quot;key&quot;: &#123;</span><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span><span class="string">    &quot;size&quot;: 2048</span><span class="string">  &#125;,</span><span class="string">  &quot;names&quot;: [</span><span class="string">    &#123;</span><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span><span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;O&quot;: &quot;system:masters&quot;,</span><span class="string">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><span class="string">    &#125;</span><span class="string">  ]</span><span class="string">&#125;</span><span class="string">EOF</span><span class="comment"># 生成了管理员证书和密钥，用于 kubectl 访问 API Server 时进行身份认证</span>cfssl gencert \   -ca=/etc/kubernetes/pki/ca.pem \   -ca-key=/etc/kubernetes/pki/ca-key.pem \   -config=/etc/kubernetes/pki/ca-config.json \   -profile=kubernetes \   /etc/kubernetes/pki/admin-csr.json | cfssljson -bare /etc/kubernetes/pki/admin<span class="comment"># 设置集群信息</span>kubectl config set-cluster kubernetes     \  --certificate-authority=/etc/kubernetes/pki/ca.pem     \  --embed-certs=<span class="literal">true</span>     \  --server=https://127.0.0.1:8443     \  --kubeconfig=/etc/kubernetes/admin.kubeconfig<span class="comment"># 设置用户凭证</span>kubectl config set-credentials kubernetes-admin  \  --client-certificate=/etc/kubernetes/pki/admin.pem     \  --client-key=/etc/kubernetes/pki/admin-key.pem     \  --embed-certs=<span class="literal">true</span>     \  --kubeconfig=/etc/kubernetes/admin.kubeconfig<span class="comment"># 绑定上下文</span>kubectl config set-context kubernetes-admin@kubernetes    \  --cluster=kubernetes     \  --user=kubernetes-admin     \  --kubeconfig=/etc/kubernetes/admin.kubeconfig<span class="comment"># 启用当前上下文</span>kubectl config use-context kubernetes-admin@kubernetes  --kubeconfig=/etc/kubernetes/admin.kubeconfig</code></pre><h4 id="3-3-10-创建-kube-proxy-证书"><a href="#3-3-10-创建-kube-proxy-证书" class="headerlink" title="3.3.10 创建 kube-proxy 证书"></a>3.3.10 创建 kube-proxy 证书</h4><pre><code class="highlight bash"><span class="comment"># 生成 kube-proxy 证书签名请求文件 (CSR),这个文件会被用来生成证书请求</span><span class="built_in">cat</span> &gt; /etc/kubernetes/pki/kube-proxy-csr.json  &lt;&lt; <span class="string">EOF </span><span class="string">&#123;</span><span class="string">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span><span class="string">  &quot;key&quot;: &#123;</span><span class="string">    &quot;algo&quot;: &quot;rsa&quot;,</span><span class="string">    &quot;size&quot;: 2048</span><span class="string">  &#125;,</span><span class="string">  &quot;names&quot;: [</span><span class="string">    &#123;</span><span class="string">      &quot;C&quot;: &quot;CN&quot;,</span><span class="string">      &quot;ST&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;L&quot;: &quot;Beijing&quot;,</span><span class="string">      &quot;O&quot;: &quot;system:kube-proxy&quot;,</span><span class="string">      &quot;OU&quot;: &quot;Kubernetes-manual&quot;</span><span class="string">    &#125;</span><span class="string">  ]</span><span class="string">&#125;</span><span class="string">EOF</span><span class="comment"># 使用前面创建好的集群 CA 根证书来签发 kube-proxy 的客户端证书</span>cfssl gencert \   -ca=/etc/kubernetes/pki/ca.pem \   -ca-key=/etc/kubernetes/pki/ca-key.pem \   -config=/etc/kubernetes/pki/ca-config.json \   -profile=kubernetes \   /etc/kubernetes/pki/kube-proxy-csr.json | cfssljson -bare /etc/kubernetes/pki/kube-proxy<span class="comment"># 生成 kube-proxy 的 kubeconfig 文件, kube-proxy 在启动时需要使用一个 kubeconfig 文件来连接 API Server</span><span class="comment"># 设置集群信息</span>kubectl config set-cluster kubernetes     \  --certificate-authority=/etc/kubernetes/pki/ca.pem     \  --embed-certs=<span class="literal">true</span>     \  --server=https://127.0.0.1:8443     \  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig<span class="comment"># 设置用户凭证</span>kubectl config set-credentials kube-proxy  \  --client-certificate=/etc/kubernetes/pki/kube-proxy.pem     \  --client-key=/etc/kubernetes/pki/kube-proxy-key.pem     \  --embed-certs=<span class="literal">true</span>     \  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig<span class="comment"># 绑定上下文（Context）</span>kubectl config set-context kube-proxy@kubernetes    \  --cluster=kubernetes     \  --user=kube-proxy     \  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig<span class="comment"># 启用当前上下文</span>kubectl config use-context kube-proxy@kubernetes  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig</code></pre><h4 id="3-3-11-生成-ServiceAccount（简称-SA）签名密钥对"><a href="#3-3-11-生成-ServiceAccount（简称-SA）签名密钥对" class="headerlink" title="3.3.11 生成 ServiceAccount（简称 SA）签名密钥对"></a>3.3.11 生成 ServiceAccount（简称 SA）签名密钥对</h4><pre><code class="highlight bash"><span class="comment"># 生成文件 /etc/kubernetes/pki/sa.key —— ServiceAccount 私钥文件</span>openssl genrsa -out /etc/kubernetes/pki/sa.key 2048<span class="comment"># 生成文件 /etc/kubernetes/pki/sa.pub —— ServiceAccount 公钥文件</span>openssl rsa -<span class="keyword">in</span> /etc/kubernetes/pki/sa.key -pubout -out /etc/kubernetes/pki/sa.pub</code></pre><h2 id="4-分发证书到其它节点"><a href="#4-分发证书到其它节点" class="headerlink" title="4. 分发证书到其它节点"></a>4. 分发证书到其它节点</h2><h3 id="4-1-分发到-master-节点"><a href="#4-1-分发到-master-节点" class="headerlink" title="4.1 分发到 master 节点"></a>4.1 分发到 master 节点</h3><p><strong>k8s-master01</strong></p><pre><code class="highlight bash"><span class="comment"># 将生成的 ETCD 证书复制到其他节点</span>hosts=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir -p /etc/kubernetes/pki/&quot;</span>  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/pki/* <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/pki/;  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/admin.kubeconfig <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/controller-manager.kubeconfig <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/scheduler.kubeconfig <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/kube-proxy.kubeconfig <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/<span class="keyword">done</span></code></pre><h3 id="4-2-分发到-node-节点"><a href="#4-2-分发到-node-节点" class="headerlink" title="4.2 分发到 node 节点"></a>4.2 分发到 node 节点</h3><p><strong>k8s-master01</strong></p><pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir -p /etc/kubernetes/pki/&quot;</span>  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/pki/kube-proxy* <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/pki/;  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/kube-proxy.kubeconfig <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/kubernetes/<span class="keyword">done</span></code></pre><h2 id="5-查看证书"><a href="#5-查看证书" class="headerlink" title="5. 查看证书"></a>5. 查看证书</h2><h3 id="5-1-master-节点"><a href="#5-1-master-节点" class="headerlink" title="5.1 master 节点"></a>5.1 master 节点</h3><pre><code class="highlight bash">$ ll /etc/kubernetes/pki/total 140-rw-r--r--. 1 root root  225 Oct 16 23:22 admin-csr.json-rw-------. 1 root root 1679 Oct 16 23:25 admin-key.pem-rw-r--r--. 1 root root 1025 Oct 16 23:25 admin.csr-rw-r--r--. 1 root root 1432 Oct 16 23:25 admin.pem-rw-r--r--. 1 root root  230 Oct 11 20:11 apiserver-csr.json-rw-------. 1 root root 1675 Oct 11 20:17 apiserver-key.pem-rw-r--r--. 1 root root 1565 Oct 11 20:17 apiserver.csr-rw-r--r--. 1 root root 1948 Oct 11 20:17 apiserver.pem-rw-r--r--. 1 root root  294 Oct 11 19:58 ca-config.json-rw-r--r--. 1 root root  258 Oct 11 20:04 ca-csr.json-rw-------. 1 root root 1679 Oct 11 20:04 ca-key.pem-rw-r--r--. 1 root root 1062 Oct 11 20:04 ca.csr-rw-r--r--. 1 root root 1342 Oct 11 20:04 ca.pem-rw-------. 1 root root 1675 Oct 16 22:19 controller-manager-key.pem-rw-r--r--. 1 root root 1082 Oct 16 22:19 controller-manager.csr-rw-r--r--. 1 root root 1489 Oct 16 22:19 controller-manager.pem-rw-r--r--. 1 root root  118 Oct 11 20:23 front-proxy-ca-csr.json-rw-------. 1 root root 1679 Oct 16 21:19 front-proxy-ca-key.pem-rw-r--r--. 1 root root  940 Oct 16 21:19 front-proxy-ca.csr-rw-r--r--. 1 root root 1094 Oct 16 21:19 front-proxy-ca.pem-rw-r--r--. 1 root root   87 Oct 16 21:22 front-proxy-client-csr.json-rw-------. 1 root root 1679 Oct 16 21:25 front-proxy-client-key.pem-rw-r--r--. 1 root root  903 Oct 16 21:25 front-proxy-client.csr-rw-r--r--. 1 root root 1188 Oct 16 21:25 front-proxy-client.pem-rw-r--r--. 1 root root  240 Oct 16 23:31 kube-proxy-csr.json-rw-------. 1 root root 1675 Oct 16 23:31 kube-proxy-key.pem-rw-r--r--. 1 root root 1045 Oct 16 23:31 kube-proxy.csr-rw-r--r--. 1 root root 1456 Oct 16 23:31 kube-proxy.pem-rw-r--r--. 1 root root  266 Oct 16 22:11 manager-csr.json-rw-------. 1 root root 1704 Oct 16 23:34 sa.key-rw-r--r--. 1 root root  451 Oct 16 23:34 sa.pub-rw-r--r--. 1 root root  248 Oct 16 23:07 scheduler-csr.json-rw-------. 1 root root 1679 Oct 16 23:08 scheduler-key.pem-rw-r--r--. 1 root root 1058 Oct 16 23:08 scheduler.csr-rw-r--r--. 1 root root 1464 Oct 16 23:08 scheduler.pem$ ll /etc/kubernetes/total 36-rw-------. 1 root root 6341 Oct 16 23:26 admin.kubeconfig-rw-------. 1 root root 6469 Oct 16 22:30 controller-manager.kubeconfig-rw-------. 1 root root 6345 Oct 16 23:32 kube-proxy.kubeconfigdrwxr-xr-x. 2 root root 4096 Oct 16 23:34 pki-rw-------. 1 root root 6401 Oct 16 23:14 scheduler.kubeconfig</code></pre><h3 id="5-2-node-节点"><a href="#5-2-node-节点" class="headerlink" title="5.2 node 节点"></a>5.2 node 节点</h3><pre><code class="highlight bash">$ ll /etc/kubernetes/pki/total 16-rw-r--r--. 1 root root  240 Oct 16 23:52 kube-proxy-csr.json-rw-------. 1 root root 1675 Oct 16 23:52 kube-proxy-key.pem-rw-r--r--. 1 root root 1045 Oct 16 23:52 kube-proxy.csr-rw-r--r--. 1 root root 1456 Oct 16 23:52 kube-proxy.pem$ ll /etc/kubernetes/total 8-rw-------. 1 root root 6345 Oct 16 23:52 kube-proxy.kubeconfigdrwxr-xr-x. 2 root root  103 Oct 16 23:52 pki</code></pre><h1 id="五、K8S-系统组件配置"><a href="#五、K8S-系统组件配置" class="headerlink" title="五、K8S 系统组件配置"></a>五、K8S 系统组件配置</h1><h2 id="1-ETCD-配置"><a href="#1-ETCD-配置" class="headerlink" title="1. ETCD 配置"></a>1. ETCD 配置</h2><p>etcd 配置大致相同，注意修改每个 Master 节点的 etcd 配置的主机名和IP地址</p><p>官方文档：<a href="https://etcd.io/docs/v3.5/op-guide/configuration/">https://etcd.io/docs/v3.5/op-guide/configuration/</a></p><p>从 Github 获取配置文件示例 ：<a href="https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample">https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample</a></p><p>配置项解读：</p><blockquote><ul><li>name：指定了当前节点的名称，用于集群中区分不同的节点。</li><li>data-dir：指定了 etcd 数据的存储目录。</li><li>wal-dir：指定了 etcd 数据写入磁盘的目录。</li><li>snapshot-count：指定了触发快照的事务数量。</li><li>heartbeat-interval：指定了 etcd 集群中节点之间的心跳间隔。</li><li>election-timeout：指定了选举超时时间。</li><li>quota-backend-bytes：指定了存储的限额，0 表示无限制。</li><li>listen-peer-urls：指定了节点之间通信的 URL，使用 HTTPS 协议。</li><li>listen-client-urls：指定了客户端访问 etcd 集群的 URL，同时提供了本地访问的 URL。</li><li>max-snapshots：指定了快照保留的数量。</li><li>max-wals：指定了日志保留的数量。</li><li>initial-advertise-peer-urls：指定了节点之间通信的初始 URL。</li><li>advertise-client-urls：指定了客户端访问 etcd 集群的初始 URL。</li><li>discovery：定义了 etcd 集群发现相关的选项。</li><li>initial-cluster：指定了 etcd 集群的初始成员。</li><li>initial-cluster-token：指定了集群的 token。</li><li>initial-cluster-state：指定了集群的初始状态。</li><li>strict-reconfig-check：指定了严格的重新配置检查选项。</li><li>enable-v2：启用了 v2 API。</li><li>enable-pprof：启用了性能分析。</li><li>proxy：设置了代理模式。</li><li>client-transport-security：客户端的传输安全配置。</li><li>peer-transport-security：节点之间的传输安全配置。</li><li>debug：是否启用调试模式。</li><li>log-package-levels：日志的输出级别。</li><li>log-outputs：指定了日志的输出类型。</li><li>force-new-cluster：是否强制创建一个新的集群。</li></ul></blockquote><h3 id="1-1-Master01-节点"><a href="#1-1-Master01-节点" class="headerlink" title="1.1 Master01 节点"></a>1.1 Master01 节点</h3><p>如果要用 IPv6 那么把 IPv4 地址修改为 IPv6 即可</p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/etcd/etcd.config.yml &lt;&lt; <span class="string">EOF </span><span class="string">name: &#x27;k8s-master01&#x27;</span><span class="string">data-dir: /data/etcd</span><span class="string">wal-dir: /data/etcd/wal</span><span class="string">snapshot-count: 5000</span><span class="string">heartbeat-interval: 100</span><span class="string">election-timeout: 1000</span><span class="string">quota-backend-bytes: 0</span><span class="string">listen-peer-urls: &#x27;https://10.20.1.101:2380&#x27;</span><span class="string">listen-client-urls: &#x27;https://10.20.1.101:2379,http://127.0.0.1:2379&#x27;</span><span class="string">max-snapshots: 3</span><span class="string">max-wals: 5</span><span class="string">cors:</span><span class="string">initial-advertise-peer-urls: &#x27;https://10.20.1.101:2380&#x27;</span><span class="string">advertise-client-urls: &#x27;https://10.20.1.101:2379&#x27;</span><span class="string">discovery:</span><span class="string">discovery-fallback: &#x27;proxy&#x27;</span><span class="string">discovery-proxy:</span><span class="string">discovery-srv:</span><span class="string">initial-cluster: &#x27;k8s-master01=https://10.20.1.101:2380,k8s-master02=https://10.20.1.102:2380,k8s-master03=https://10.20.1.103:2380&#x27;</span><span class="string">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><span class="string">initial-cluster-state: &#x27;new&#x27;</span><span class="string">strict-reconfig-check: false</span><span class="string">enable-v2: true</span><span class="string">enable-pprof: true</span><span class="string">proxy: &#x27;off&#x27;</span><span class="string">proxy-failure-wait: 5000</span><span class="string">proxy-refresh-interval: 30000</span><span class="string">proxy-dial-timeout: 1000</span><span class="string">proxy-write-timeout: 5000</span><span class="string">proxy-read-timeout: 0</span><span class="string">client-transport-security:</span><span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><span class="string">  client-cert-auth: true</span><span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><span class="string">  auto-tls: true</span><span class="string">peer-transport-security:</span><span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><span class="string">  peer-client-cert-auth: true</span><span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><span class="string">  auto-tls: true</span><span class="string">debug: false</span><span class="string">log-package-levels:</span><span class="string">log-outputs: [default]</span><span class="string">force-new-cluster: false</span><span class="string">EOF</span></code></pre><h3 id="1-2-Master02-节点"><a href="#1-2-Master02-节点" class="headerlink" title="1.2 Master02 节点"></a>1.2 Master02 节点</h3><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/etcd/etcd.config.yml &lt;&lt; <span class="string">EOF </span><span class="string">name: &#x27;k8s-master02&#x27;</span><span class="string">data-dir: /data/etcd</span><span class="string">wal-dir: /data/etcd/wal</span><span class="string">snapshot-count: 5000</span><span class="string">heartbeat-interval: 100</span><span class="string">election-timeout: 1000</span><span class="string">quota-backend-bytes: 0</span><span class="string">listen-peer-urls: &#x27;https://10.20.1.102:2380&#x27;</span><span class="string">listen-client-urls: &#x27;https://10.20.1.102:2379,http://127.0.0.1:2379&#x27;</span><span class="string">max-snapshots: 3</span><span class="string">max-wals: 5</span><span class="string">cors:</span><span class="string">initial-advertise-peer-urls: &#x27;https://10.20.1.102:2380&#x27;</span><span class="string">advertise-client-urls: &#x27;https://10.20.1.102:2379&#x27;</span><span class="string">discovery:</span><span class="string">discovery-fallback: &#x27;proxy&#x27;</span><span class="string">discovery-proxy:</span><span class="string">discovery-srv:</span><span class="string">initial-cluster: &#x27;k8s-master01=https://10.20.1.101:2380,k8s-master02=https://10.20.1.102:2380,k8s-master03=https://10.20.1.103:2380&#x27;</span><span class="string">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><span class="string">initial-cluster-state: &#x27;new&#x27;</span><span class="string">strict-reconfig-check: false</span><span class="string">enable-v2: true</span><span class="string">enable-pprof: true</span><span class="string">proxy: &#x27;off&#x27;</span><span class="string">proxy-failure-wait: 5000</span><span class="string">proxy-refresh-interval: 30000</span><span class="string">proxy-dial-timeout: 1000</span><span class="string">proxy-write-timeout: 5000</span><span class="string">proxy-read-timeout: 0</span><span class="string">client-transport-security:</span><span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><span class="string">  client-cert-auth: true</span><span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><span class="string">  auto-tls: true</span><span class="string">peer-transport-security:</span><span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><span class="string">  peer-client-cert-auth: true</span><span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><span class="string">  auto-tls: true</span><span class="string">debug: false</span><span class="string">log-package-levels:</span><span class="string">log-outputs: [default]</span><span class="string">force-new-cluster: false</span><span class="string">EOF</span></code></pre><h3 id="1-3-Master03-节点"><a href="#1-3-Master03-节点" class="headerlink" title="1.3 Master03 节点"></a>1.3 Master03 节点</h3><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/etcd/etcd.config.yml &lt;&lt; <span class="string">EOF </span><span class="string">name: &#x27;k8s-master03&#x27;</span><span class="string">data-dir: /data/etcd</span><span class="string">wal-dir: /data/etcd/wal</span><span class="string">snapshot-count: 5000</span><span class="string">heartbeat-interval: 100</span><span class="string">election-timeout: 1000</span><span class="string">quota-backend-bytes: 0</span><span class="string">listen-peer-urls: &#x27;https://10.20.1.103:2380&#x27;</span><span class="string">listen-client-urls: &#x27;https://10.20.1.103:2379,http://127.0.0.1:2379&#x27;</span><span class="string">max-snapshots: 3</span><span class="string">max-wals: 5</span><span class="string">cors:</span><span class="string">initial-advertise-peer-urls: &#x27;https://10.20.1.103:2380&#x27;</span><span class="string">advertise-client-urls: &#x27;https://10.20.1.103:2379&#x27;</span><span class="string">discovery:</span><span class="string">discovery-fallback: &#x27;proxy&#x27;</span><span class="string">discovery-proxy:</span><span class="string">discovery-srv:</span><span class="string">initial-cluster: &#x27;k8s-master01=https://10.20.1.101:2380,k8s-master02=https://10.20.1.102:2380,k8s-master03=https://10.20.1.103:2380&#x27;</span><span class="string">initial-cluster-token: &#x27;etcd-k8s-cluster&#x27;</span><span class="string">initial-cluster-state: &#x27;new&#x27;</span><span class="string">strict-reconfig-check: false</span><span class="string">enable-v2: true</span><span class="string">enable-pprof: true</span><span class="string">proxy: &#x27;off&#x27;</span><span class="string">proxy-failure-wait: 5000</span><span class="string">proxy-refresh-interval: 30000</span><span class="string">proxy-dial-timeout: 1000</span><span class="string">proxy-write-timeout: 5000</span><span class="string">proxy-read-timeout: 0</span><span class="string">client-transport-security:</span><span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><span class="string">  client-cert-auth: true</span><span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><span class="string">  auto-tls: true</span><span class="string">peer-transport-security:</span><span class="string">  cert-file: &#x27;/etc/kubernetes/pki/etcd/etcd.pem&#x27;</span><span class="string">  key-file: &#x27;/etc/kubernetes/pki/etcd/etcd-key.pem&#x27;</span><span class="string">  peer-client-cert-auth: true</span><span class="string">  trusted-ca-file: &#x27;/etc/kubernetes/pki/etcd/etcd-ca.pem&#x27;</span><span class="string">  auto-tls: true</span><span class="string">debug: false</span><span class="string">log-package-levels:</span><span class="string">log-outputs: [default]</span><span class="string">force-new-cluster: false</span><span class="string">EOF</span></code></pre><h3 id="1-4-创建-ETCD-Service"><a href="#1-4-创建-ETCD-Service" class="headerlink" title="1.4 创建 ETCD Service"></a>1.4 创建 ETCD Service</h3><p><strong>master 01</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; <span class="string">EOF</span><span class="string"></span><span class="string">[Unit]</span><span class="string">Description=Etcd Service</span><span class="string">Documentation=https://coreos.com/etcd/docs/latest/</span><span class="string">After=network.target</span><span class="string"></span><span class="string">[Service]</span><span class="string">Type=notify</span><span class="string">ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yml</span><span class="string">Restart=on-failure</span><span class="string">RestartSec=10</span><span class="string">LimitNOFILE=65536</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string">Alias=etcd3.service</span><span class="string"></span><span class="string">EOF</span></code></pre><blockquote><p><strong>命令解析：</strong></p><p>该文件定义了 etcd 服务在 Linux 系统上的运行方式，使用 systemd 管理 etcd 进程的启动、停止、自动重启等行为。此配置是为 Kubernetes 高可用集群中的 etcd 节点（例如 k8s-master03）设计的，结合了 &#x2F;etc&#x2F;etcd&#x2F;etcd.config.yml 配置文件运行 etcd。</p><ul><li><p>After&#x3D;network.target：定义服务在哪些 systemd 目标或单元启动后启动。network.target 表示网络服务可用。 影响：确保 etcd 在网络初始化后启动，因为 etcd 需要监听网络端口（2379&#x2F;2380）进行客户端和节点间通信。如果网络不可用，etcd 可能启动失败</p></li><li><p>Type&#x3D;notify：默认值：simple 描述：定义服务进程的类型。notify 表示主进程通过 sd_notify(3) 向 systemd 发送启动完成信号（etcd 支持此机制）。 影响：notify 允许 systemd 等待 etcd 完成初始化（如绑定端口、加入集群）后再标记服务为“运行”。</p></li><li><p>ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;etcd –config-file&#x3D;&#x2F;etc&#x2F;etcd&#x2F;etcd.config.yml</p><p>服务启动时执行的命令及其参数。运行 etcd 二进制，指定配置文件路径</p></li><li><p>Restart&#x3D;on-failure：控制服务失败时的重启行为。on-failure 表示在进程异常退出（非零退出码）、超时或被信号终止时自动重启。</p></li><li><p>RestartSec&#x3D;10：重启前的等待时间（秒）</p></li><li><p>LimitNOFILE&#x3D;65536：设置进程的最大文件描述符数量（软限制和硬限制）。 影响：etcd 需处理大量网络连接（如 Kubernetes API 请求），默认值可能不足导致 “too many open files” 错误。65536 适合高负载集群，需确保系统级限制</p></li><li><p>WantedBy&#x3D;multi-user.target：指定服务在哪个 systemd 目标启用。multi-user.target 表示多用户模式（非图形界面，通常为服务器默认运行级别）</p></li><li><p>Alias&#x3D;etcd3.service：为服务创建别名，允许通过别名（如 systemctl start etcd3.service）操作服务</p></li></ul></blockquote><p><strong>同步到其它Master节点</strong></p><pre><code class="highlight bash"><span class="comment"># 将生成的 ETCD Service复制到其他节点</span>hosts=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/etcd.service <span class="variable">$user</span>@<span class="variable">$host</span>:/usr/lib/systemd/system/;<span class="keyword">done</span></code></pre><h3 id="1-5-启动-ETCD-Service"><a href="#1-5-启动-ETCD-Service" class="headerlink" title="1.5 启动 ETCD Service"></a>1.5 启动 ETCD Service</h3><pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master01 k8s-master02 k8s-master03&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   <span class="built_in">echo</span> <span class="string">&quot;创建 etcd 证书目录&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir -p /etc/kubernetes/pki/etcd&quot;</span>  <span class="built_in">echo</span> <span class="string">&quot;创建软连接&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;ln -s /etc/etcd/ssl/* /etc/kubernetes/pki/etcd/&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now etcd.service&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl status etcd.service&quot;</span><span class="keyword">done</span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/18/20251018-150523.png" alt="查看ETCD Service启动状态"></p><h3 id="1-6-检查-ETCD-集群的健康状态"><a href="#1-6-检查-ETCD-集群的健康状态" class="headerlink" title="1.6 检查 ETCD 集群的健康状态"></a>1.6 检查 ETCD 集群的健康状态</h3><p><strong>master01 、master02、master03</strong></p><pre><code class="highlight bash"><span class="built_in">export</span> ETCDCTL_API=3etcdctl --endpoints=<span class="string">&quot;10.20.1.101:2379,10.20.1.102:2379,10.20.1.103:2379&quot;</span> \  --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem \  --cert=/etc/kubernetes/pki/etcd/etcd.pem \  --key=/etc/kubernetes/pki/etcd/etcd-key.pem \  endpoint status --write-out=table</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/18/20251018-151718.png" alt="检查 ETCD 集群的健康状态"></p><blockquote><p><strong>命令解析：</strong></p><p>该命令用于检查 etcd 集群的健康状态，是 Kubernetes 高可用部署中验证 etcd 集群运行情况的关键步骤</p><ul><li><p>export ETCDCTL_API&#x3D;3</p><p>明确设置 ETCDCTL_API&#x3D;3 确保 etcdctl 使用 v3 协议，避免与 v2 兼容性问题</p></li><li><p>etcdctl：是 etcd 提供的命令行工具，用于与 etcd 集群交互（如查询状态、管理成员、执行操作）</p></li><li><p>–endpoints：指定 etcd 集群的客户端访问端点，包含三个节点的 IP 和端口（2379）</p></li><li><p>–cacert：指定 CA 证书路径 &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;etcd-ca.pem</p></li><li><p>–cert：客户端证书路径 &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;etcd.pem</p></li><li><p>–key：客户端私钥路径 &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;etcd-key.pem</p></li></ul></blockquote><h2 id="2-Nginx-配置"><a href="#2-Nginx-配置" class="headerlink" title="2. Nginx 配置"></a>2. Nginx 配置</h2><h3 id="2-1-编译安装"><a href="#2-1-编译安装" class="headerlink" title="2.1 编译安装"></a>2.1 编译安装</h3><p><strong>master 01</strong></p><pre><code class="highlight bash"><span class="comment"># 安装编译环境</span>yum install -y openssl-devel pcre-devel gcc<span class="comment"># 下载解压 nginx 二进制文件</span>wget http://nginx.org/download/nginx-1.25.3.tar.gztar xvf nginx-*.tar.gz<span class="built_in">cd</span> nginx-1.25.3<span class="comment"># 进行编译</span>./configure --prefix=/usr/local/nginx --sbin-path=/bin/ --user=nginx --group=nginx --with-stream --with-http_ssl_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --without-http --without-http_uwsgi_module --without-http_scgi_module --without-http_fastcgi_modulemake &amp;&amp; make install<span class="comment"># 将编译好的 nginx 二进制包，拷贝到其它节点</span>hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   rsync -a --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/local/nginx <span class="variable">$user</span>@<span class="variable">$host</span>:/usr/local/;  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /bin/nginx* <span class="variable">$user</span>@<span class="variable">$host</span>:/bin/;<span class="keyword">done</span><span class="comment"># 验证 </span>$ nginx -vnginx version: nginx/1.25.3</code></pre><h3 id="2-2-nginx-配置文件"><a href="#2-2-nginx-配置文件" class="headerlink" title="2.2 nginx 配置文件"></a>2.2 nginx 配置文件</h3><p><strong>Master 01</strong></p><pre><code class="highlight bash"><span class="comment"># 写入配置文件（在所有主机上执行）</span><span class="built_in">cat</span> &gt; /usr/local/nginx/conf/kube-nginx.conf &lt;&lt;<span class="string">EOF</span><span class="string">worker_processes 1;</span><span class="string">user nobody;</span><span class="string">events &#123;</span><span class="string">    worker_connections  1024;</span><span class="string">&#125;</span><span class="string">stream &#123;</span><span class="string">    upstream backend &#123;</span><span class="string">    least_conn;</span><span class="string">        hash $remote_addr consistent;</span><span class="string">        server 10.20.1.101:6443        max_fails=3 fail_timeout=30s;</span><span class="string">        server 10.20.1.102:6443        max_fails=3 fail_timeout=30s;</span><span class="string">        server 10.20.1.103:6443        max_fails=3 fail_timeout=30s;</span><span class="string">    &#125;</span><span class="string">    server &#123;</span><span class="string">        listen 127.0.0.1:8443;</span><span class="string">        proxy_connect_timeout 1s;</span><span class="string">        proxy_pass backend;</span><span class="string">    &#125;</span><span class="string">&#125;</span><span class="string">EOF</span><span class="comment"># 将kube-nginx.conf，拷贝到其它 Master 节点</span>hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   rsync -a --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/local/nginx/conf/kube-nginx.conf <span class="variable">$user</span>@<span class="variable">$host</span>:/usr/local/nginx/conf/;<span class="keyword">done</span></code></pre><blockquote><p><strong>命令解析：</strong></p><p>该命令用于创建 Nginx 配置文件 &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;kube-nginx.conf，配置 Nginx 作为 Kubernetes API 服务器的负载均衡器，处理 TCP 流量（端口 6443）</p><ul><li><p>upstream backend</p><p>将本地 8443 端口的请求分发到三个 master 节点的 API 服务器的 6443 端口</p></li><li><p>least_conn;</p><p>选择当前活跃连接数最少的后端服务器进行负载均衡</p></li><li><p>hash $remote_addr consistent;</p><p>基于客户端 IP（$remote_addr）进行一致性哈希，确保同一客户端始终连接到同一后端服务器</p></li><li><p>max_fails&#x3D;3 fail_timeout&#x3D;30s;</p><p>max_fails&#x3D;3（失败 3 次后标记为不可用），fail_timeout&#x3D;30s（标记不可用后 30 秒内不尝试）</p></li><li><p>6443 端口是 Kubernetes API 服务器（kube-apiserver）的默认端口，接受来自客户端（如 kubectl、kubelet、控制器等）的 HTTPS 请求。</p></li><li><p>8443 端口是 kube-apiserver 的代理端口，用于接收请求，并将请求转发到真正的 6443 端口</p></li></ul></blockquote><h3 id="2-3-配置-Nginx-Service"><a href="#2-3-配置-Nginx-Service" class="headerlink" title="2.3 配置 Nginx Service"></a>2.3 配置 Nginx Service</h3><p><strong>Master 01</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/systemd/system/kube-nginx.service &lt;&lt;<span class="string">EOF</span><span class="string">[Unit]</span><span class="string">Description=kube-apiserver nginx proxy</span><span class="string">After=network.target</span><span class="string">After=network-online.target</span><span class="string">Wants=network-online.target</span><span class="string"></span><span class="string">[Service]</span><span class="string">Type=forking</span><span class="string">ExecStartPre=/bin/nginx -c /usr/local/nginx/conf/kube-nginx.conf -p /usr/local/nginx -t</span><span class="string">ExecStart=/bin/nginx -c /usr/local/nginx/conf/kube-nginx.conf -p /usr/local/nginx</span><span class="string">ExecReload=/bin/nginx -c /usr/local/nginx/conf/kube-nginx.conf -p /usr/local/nginx -s reload</span><span class="string">PrivateTmp=true</span><span class="string">Restart=always</span><span class="string">RestartSec=5</span><span class="string">StartLimitInterval=0</span><span class="string">LimitNOFILE=65536</span><span class="string"> </span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string">EOF</span></code></pre><blockquote><p><strong>命令解析：</strong></p><p>创建一个 systemd 单元文件，用于管理系统服务。这个文件定义了一个名为 kube-nginx 的服务，负责运行 Nginx 作为 Kubernetes API 服务器的负载均衡代理</p><p>Nginx 在这里被配置为 TCP 负载均衡器（非 HTTP），运行在每个 master 节点（k8s-master01、k8s-master02、k8s-master03，IP 分别为 192.168.10.11、12、13），监听本地 127.0.0.1:8443 端口，并将请求分发到三个 master 节点的 API 服务器端口 6443。</p><ul><li><p>After&#x3D;network.target ：基本网络接口配置完成</p></li><li><p>After&#x3D;network-online.target ：网络完全在线（可路由外部）</p></li><li><p>Wants&#x3D;network-online.target ：声明弱依赖，建议（但不强制）在 network-online.target 启动后运行服务</p></li><li><p>Type&#x3D;forking：</p><p>forking 表示主进程派生子进程（如 Nginx master 进程派生 worker），systemd 跟踪子进程 PID（从 PID 文件读取）</p></li><li><p>ExecStartPre&#x3D;&#x2F;bin&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;kube-nginx.conf -p &#x2F;usr&#x2F;local&#x2F;nginx -t</p><p>启动前执行的预命令。-t 测试配置文件语法</p></li><li><p>ExecStart&#x3D;&#x2F;bin&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;kube-nginx.conf -p &#x2F;usr&#x2F;local&#x2F;nginx</p><p>启动服务的核心命令，运行 Nginx。 博客上下文：启动 Nginx，加载 kube-nginx.conf，启用 TCP 负载均衡（8443 到 6443）</p></li><li><p>ExecReload&#x3D;&#x2F;bin&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;kube-nginx.conf -p &#x2F;usr&#x2F;local&#x2F;nginx -s reload</p><p>重新加载配置的命令（systemctl reload kube-nginx）。-s reload 发送信号平滑重载</p></li><li><p>PrivateTmp&#x3D;true ：为服务分配私有 &#x2F;tmp 和 &#x2F;var&#x2F;tmp 目录，隔离系统临时文件</p></li><li><p>Restart&#x3D;always ：失败或退出时自动重启。always 表示无论原因都重启</p></li><li><p>RestartSec&#x3D;5 ：重启前等待时间（秒）</p></li><li><p>StartLimitInterval&#x3D;0 ：重启时间窗口（秒），0 表示无限制。</p></li><li><p>LimitNOFILE&#x3D;65536 ：最大文件描述符数，防止 “too many open files” 错误</p></li><li><p>WantedBy&#x3D;multi-user.target : 服务在多用户模式下启用, 确保 Nginx 随系统启动。</p></li></ul></blockquote><h3 id="2-4-设置-Nginx-开机自启"><a href="#2-4-设置-Nginx-开机自启" class="headerlink" title="2.4 设置 Nginx 开机自启"></a>2.4 设置 Nginx 开机自启</h3><pre><code class="highlight bash"><span class="comment"># 刷新系统服务</span>systemctl daemon-reload<span class="comment"># 设置 kube-nginx 开机自启</span>systemctl <span class="built_in">enable</span> --now kube-nginx.service<span class="comment"># 查看 nginx 启动状态</span>systemctl status kube-nginx.service</code></pre><p><strong>将 kube-nginx.service 同步到其它服务器</strong></p><pre><code class="highlight bash"><span class="comment"># 将kube-nginx.service，拷贝到其它 Master 节点,并让Nginx开机自启</span>hosts=<span class="string">&#x27;k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   rsync -a --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/systemd/system/kube-nginx.service <span class="variable">$user</span>@<span class="variable">$host</span>:/etc/systemd/system/;  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now kube-nginx.service&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl status kube-nginx.service&quot;</span><span class="keyword">done</span></code></pre><h2 id="3-kube-apiserver-配置"><a href="#3-kube-apiserver-配置" class="headerlink" title="3. kube-apiserver 配置"></a>3. kube-apiserver 配置</h2><h3 id="3-1-创建必要的目录"><a href="#3-1-创建必要的目录" class="headerlink" title="3.1 创建必要的目录"></a>3.1 创建必要的目录</h3><p><strong>master01</strong></p><pre><code class="highlight bash"><span class="comment"># 所有 k8s 节点创建以下目录</span>hosts=<span class="string">&#x27;k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   ssh root@<span class="variable">$host</span> <span class="string">&quot;mkdir -p /etc/kubernetes/manifests/ /etc/systemd/system/kubelet.service.d /var/lib/kubelet /var/log/kubernetes&quot;</span><span class="keyword">done</span></code></pre><h3 id="3-2-配置-kube-apiserver-service"><a href="#3-2-配置-kube-apiserver-service" class="headerlink" title="3.2 配置 kube-apiserver.service"></a>3.2 配置 kube-apiserver.service</h3><p>官方文档：<a href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/">https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/</a></p><p><strong>master01</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; <span class="string">EOF</span><span class="string"></span><span class="string">[Unit]</span><span class="string">Description=Kubernetes API Server</span><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span><span class="string">After=network.target</span><span class="string"></span><span class="string">[Service]</span><span class="string">ExecStart=/usr/local/bin/kube-apiserver \\</span><span class="string">      --v=2  \\</span><span class="string">      --allow-privileged=true  \\</span><span class="string">      --bind-address=0.0.0.0  \\</span><span class="string">      --secure-port=6443  \\</span><span class="string">      --advertise-address=10.20.1.101 \\</span><span class="string">      --service-cluster-ip-range=10.96.0.0/12,fd00:1111::/112  \\</span><span class="string">      --service-node-port-range=30000-32767  \\</span><span class="string">      --etcd-servers=https://10.20.1.101:2379,https://10.20.1.102:2379,https://10.20.1.103:2379 \\</span><span class="string">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \\</span><span class="string">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \\</span><span class="string">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \\</span><span class="string">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \\</span><span class="string">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \\</span><span class="string">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \\</span><span class="string">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \\</span><span class="string">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \\</span><span class="string">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \\</span><span class="string">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \\</span><span class="string">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \\</span><span class="string">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \\</span><span class="string">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><span class="string">      --authorization-mode=Node,RBAC  \\</span><span class="string">      --enable-bootstrap-token-auth=true  \\</span><span class="string">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \\</span><span class="string">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \\</span><span class="string">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \\</span><span class="string">      --requestheader-allowed-names=aggregator  \\</span><span class="string">      --requestheader-group-headers=X-Remote-Group  \\</span><span class="string">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \\</span><span class="string">      --requestheader-username-headers=X-Remote-User \\</span><span class="string">      --enable-aggregator-routing=true</span><span class="string">Restart=on-failure</span><span class="string">RestartSec=10s</span><span class="string">LimitNOFILE=65535</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string"></span><span class="string">EOF</span></code></pre><p><strong>master02</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; <span class="string">EOF</span><span class="string"></span><span class="string">[Unit]</span><span class="string">Description=Kubernetes API Server</span><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span><span class="string">After=network.target</span><span class="string"></span><span class="string">[Service]</span><span class="string">ExecStart=/usr/local/bin/kube-apiserver \\</span><span class="string">      --v=2  \\</span><span class="string">      --allow-privileged=true  \\</span><span class="string">      --bind-address=0.0.0.0  \\</span><span class="string">      --secure-port=6443  \\</span><span class="string">      --advertise-address=10.20.1.102 \\</span><span class="string">      --service-cluster-ip-range=10.96.0.0/12,fd00:1111::/112  \\</span><span class="string">      --service-node-port-range=30000-32767  \\</span><span class="string">      --etcd-servers=https://10.20.1.101:2379,https://10.20.1.102:2379,https://10.20.1.103:2379 \\</span><span class="string">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \\</span><span class="string">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \\</span><span class="string">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \\</span><span class="string">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \\</span><span class="string">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \\</span><span class="string">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \\</span><span class="string">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \\</span><span class="string">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \\</span><span class="string">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \\</span><span class="string">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \\</span><span class="string">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \\</span><span class="string">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \\</span><span class="string">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><span class="string">      --authorization-mode=Node,RBAC  \\</span><span class="string">      --enable-bootstrap-token-auth=true  \\</span><span class="string">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \\</span><span class="string">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \\</span><span class="string">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \\</span><span class="string">      --requestheader-allowed-names=aggregator  \\</span><span class="string">      --requestheader-group-headers=X-Remote-Group  \\</span><span class="string">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \\</span><span class="string">      --requestheader-username-headers=X-Remote-User \\</span><span class="string">      --enable-aggregator-routing=true</span><span class="string">Restart=on-failure</span><span class="string">RestartSec=10s</span><span class="string">LimitNOFILE=65535</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string"></span><span class="string">EOF</span></code></pre><p><strong>master03</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; <span class="string">EOF</span><span class="string"></span><span class="string">[Unit]</span><span class="string">Description=Kubernetes API Server</span><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span><span class="string">After=network.target</span><span class="string"></span><span class="string">[Service]</span><span class="string">ExecStart=/usr/local/bin/kube-apiserver \\</span><span class="string">      --v=2  \\</span><span class="string">      --allow-privileged=true  \\</span><span class="string">      --bind-address=0.0.0.0  \\</span><span class="string">      --secure-port=6443  \\</span><span class="string">      --advertise-address=10.20.1.103 \\</span><span class="string">      --service-cluster-ip-range=10.96.0.0/12,fd00:1111::/112  \\</span><span class="string">      --service-node-port-range=30000-32767  \\</span><span class="string">      --etcd-servers=https://10.20.1.101:2379,https://10.20.1.102:2379,https://10.20.1.103:2379 \\</span><span class="string">      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \\</span><span class="string">      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \\</span><span class="string">      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \\</span><span class="string">      --client-ca-file=/etc/kubernetes/pki/ca.pem  \\</span><span class="string">      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \\</span><span class="string">      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \\</span><span class="string">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \\</span><span class="string">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \\</span><span class="string">      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \\</span><span class="string">      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \\</span><span class="string">      --service-account-issuer=https://kubernetes.default.svc.cluster.local \\</span><span class="string">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \\</span><span class="string">      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \</span><span class="string">      --authorization-mode=Node,RBAC  \\</span><span class="string">      --enable-bootstrap-token-auth=true  \\</span><span class="string">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \\</span><span class="string">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \\</span><span class="string">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \\</span><span class="string">      --requestheader-allowed-names=aggregator  \\</span><span class="string">      --requestheader-group-headers=X-Remote-Group  \\</span><span class="string">      --requestheader-extra-headers-prefix=X-Remote-Extra-  \\</span><span class="string">      --requestheader-username-headers=X-Remote-User \\</span><span class="string">      --enable-aggregator-routing=true</span><span class="string">Restart=on-failure</span><span class="string">RestartSec=10s</span><span class="string">LimitNOFILE=65535</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string"></span><span class="string">EOF</span></code></pre><h3 id="3-3-启动-kube-apiserver"><a href="#3-3-启动-kube-apiserver" class="headerlink" title="3.3 启动 kube-apiserver"></a>3.3 启动 kube-apiserver</h3><pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master01 k8s-master02 k8s-master03&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now kube-apiserver.service&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl status kube-apiserver.service&quot;</span><span class="keyword">done</span></code></pre><blockquote><p><strong>kube-apiserver.service 文件解析：</strong></p><p> 该配置文件创建 systemd 服务文件，运行 kube-apiserver（Kubernetes 控制平面的核心组件），监听 6443 端口，处理集群 API 请求</p><ul><li><p>–v&#x3D;2</p><p>设置日志级别为 2（中等详细，调试用）</p><p>生产环境可降为 –v&#x3D;1 减少日志，或增至 –v&#x3D;4 排查问题</p></li><li><p>–allow-privileged&#x3D;true</p><p>API 服务器监听所有网络接口（0.0.0.0）上的 6443 端口</p><p>允许外部和内部客户端（如 kubectl、Nginx 负载均衡器）访问</p><p>若仅限本地访问，可设为 –bind-address&#x3D;127.0.0.1，但高可用集群通常需要 0.0.0.0</p></li><li><p>–secure-port&#x3D;6443</p><p>API 服务器监听的 HTTPS 端口（6443）</p><p>提供安全的 API 访问，配合 TLS 证书</p><p>6443 是 Kubernetes 默认端口，Nginx 负载均衡器代理到此端口。</p></li><li><p>–advertise-address&#x3D;</p><p>API 服务器向集群其他组件通告的 IP 地址。</p><p>指定当前节点的 IP（k8s-master01），用于节点间通信和客户端连接。</p></li><li><p>–service-cluster-ip-range&#x3D;10.96.0.0&#x2F;12,fd00:1111::&#x2F;112 \</p><p>定义 Service 的 Cluster IP 地址范围，支持双栈（IPv4 和 IPv6）。</p><ul><li>10.96.0.0&#x2F;12：IPv4 地址池（10.96.0.0 - 10.111.255.255，约 104 万个地址）。</li><li>fd00:1111::&#x2F;112：IPv6 唯一本地地址（ULA），提供 65,536 个地址。</li></ul><p>作用：为 Service（ClusterIP 类型）分配虚拟 IP，供服务发现和负载均衡。</p></li><li><p>–service-node-port-range&#x3D;30000-32767 \</p><p>NodePort 类型 Service 的端口范围。</p><p>限制 NodePort 分配的端口（默认 30000-32767），用于外部访问。</p></li><li><p>–etcd-servers&#x3D;</p><p>指定 etcd 集群的 HTTPS 端点（三个主节点，2379 端口）。</p></li><li><p>–service-account-issuer&#x3D;<a href="https://kubernetes.default.svc.cluster.local/">https://kubernetes.default.svc.cluster.local</a> \</p><p>ServiceAccount token 的发行者标识</p></li><li><p>–kubelet-preferred-address-types&#x3D;InternalIP,ExternalIP,Hostname \</p><p>API 服务器连接 kubelet 时优先使用的地址类型。</p><p>按顺序尝试 InternalIP、ExternalIP、Hostname。</p><p>适合 Calico 网络，优先内部 IP（10.20.1.x）。</p></li><li><p>–enable-admission-plugins&#x3D;NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota \</p><p>启用准入控制插件</p><ul><li>NamespaceLifecycle：管理命名空间生命周期。</li><li>LimitRanger：限制资源使用。</li><li>ServiceAccount：自动注入 ServiceAccount token。</li><li>DefaultStorageClass：为 PVC 设置默认存储类。</li><li>DefaultTolerationSeconds：设置默认容忍时间。</li><li>NodeRestriction：限制 kubelet 权限。</li><li>ResourceQuota：强制资源配额。</li></ul></li><li><p>–authorization-mode&#x3D;Node,RBAC \</p><p>启用 Node 和 RBAC 授权模式。Node 授权 kubelet 请求，RBAC 管理用户和角色权限。</p></li><li><p>–enable-bootstrap-token-auth&#x3D;true \</p><p>启用引导令牌认证，允许新节点通过 token 加入集群。</p></li><li><p>–requestheader-allowed-names&#x3D;aggregator \</p><p>允许的聚合器客户端名称。</p></li><li><p>–requestheader-group-headers&#x3D;X-Remote-Group \</p><p>HTTP 头中传递组信息的字段。</p></li><li><p>–requestheader-extra-headers-prefix&#x3D;X-Remote-Extra- \</p><p>额外信息的 HTTP 头前缀。</p></li><li><p>–requestheader-username-headers&#x3D;X-Remote-User \</p><p>HTTP 头中传递用户名的字段。</p></li><li><p>–enable-aggregator-routing&#x3D;true</p><p>启用 API 聚合器路由</p></li><li><p>Restart&#x3D;on-failure</p><p>服务失败时重启</p></li><li><p>RestartSec&#x3D;10s</p><p>重启前等待 10 秒</p></li><li><p>LimitNOFILE&#x3D;65535</p><p>最大文件描述符数，支持高并发连接，匹配 Nginx 的 65536</p></li></ul></blockquote><h2 id="4-kube-controller-manager-配置"><a href="#4-kube-controller-manager-配置" class="headerlink" title="4. kube-controller-manager 配置"></a>4. kube-controller-manager 配置</h2><h3 id="4-1-配置-kube-controller-manager-service"><a href="#4-1-配置-kube-controller-manager-service" class="headerlink" title="4.1 配置 kube-controller-manager.service"></a>4.1 配置 kube-controller-manager.service</h3><p>官方文档：<a href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-controller-manager/">https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-controller-manager/</a></p><ul><li>所有master节点配置，且配置相同</li><li>172.16.0.0&#x2F;12 为 pod 网段，按需求设置你自己的网段</li></ul><p><strong>master01</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; <span class="string">EOF</span><span class="string"></span><span class="string">[Unit]</span><span class="string">Description=Kubernetes Controller Manager</span><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span><span class="string">After=network.target</span><span class="string"></span><span class="string">[Service]</span><span class="string">ExecStart=/usr/local/bin/kube-controller-manager \\</span><span class="string">      --v=2 \\</span><span class="string">      --bind-address=0.0.0.0 \\</span><span class="string">      --root-ca-file=/etc/kubernetes/pki/ca.pem \\</span><span class="string">      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \\</span><span class="string">      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \\</span><span class="string">      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \\</span><span class="string">      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \\</span><span class="string">      --leader-elect=true \\</span><span class="string">      --use-service-account-credentials=true \\</span><span class="string">      --node-monitor-grace-period=40s \\</span><span class="string">      --node-monitor-period=5s \\</span><span class="string">      --controllers=*,bootstrapsigner,tokencleaner \\</span><span class="string">      --allocate-node-cidrs=true \\</span><span class="string">      --service-cluster-ip-range=10.96.0.0/12,fd00:1111::/112 \\</span><span class="string">      --cluster-cidr=172.16.0.0/12,fc00:2222::/112 \\</span><span class="string">      --node-cidr-mask-size-ipv4=24 \\</span><span class="string">      --node-cidr-mask-size-ipv6=120 \\</span><span class="string">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem</span><span class="string"></span><span class="string">Restart=always</span><span class="string">RestartSec=10s</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string"></span><span class="string">EOF</span></code></pre><blockquote><p><strong>配置解析：</strong></p><p>kube-controller-manager  是 Kubernetes 控制平面的核心组件之一，负责运行控制器以维护集群状态（如 ReplicaSet、Deployment 控制器）。</p><ul><li><p>ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kube-controller-manager \</p><p>指定启动命令，运行 kube-controller-manager 可执行文件（位于 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;），后续参数以 \ 分行。</p></li><li><p>–v&#x3D;2 \</p><p>设置日志级别为 2（中等详细，适合调试）</p><p>生产环境可设为 –v&#x3D;1 减少日志，或增至 –v&#x3D;4 排查复杂问题。</p></li><li><p>–bind-address&#x3D;0.0.0.0 \</p><p>Controller Manager 监听所有网络接口（0.0.0.0）上的端口（默认 10257，HTTPS）。允许外部访问健康检查或指标端点（如 &#x2F;healthz、&#x2F;metrics）。</p></li><li><p>–root-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.pem \</p><p>Kubernetes CA 证书路径，用于验证客户端和服务端证书。</p></li><li><p>–cluster-signing-cert-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.pem \</p><p>用于签署集群内证书的 CA 证书。Controller Manager 使用该 CA 为 CSR（证书签名请求）签名（如 kubelet 证书）。</p></li><li><p>–cluster-signing-key-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca-key.pem \</p><p>CA 证书的私钥。与 –cluster-signing-cert-file 配对，用于签署证书。</p></li><li><p>–service-account-private-key-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;sa.key \</p><p>服务账户（ServiceAccount）token 的签名私钥。生成 ServiceAccount token，供 Pod 认证。</p></li><li><p>–kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;controller-manager.kubeconfig \</p><p>Controller Manager 的 kubeconfig 文件路径，定义 API 服务器连接信息和认证凭据。</p><p>允许 Controller Manager 通过 kubeconfig 访问 API 服务器（6443 端口）。</p></li><li><p>–leader-elect&#x3D;true \</p><p>启用领导者选举，在高可用集群中，确保多个主节点的 Controller Manager 实例中只有一个活跃（其他为热备），避免冲突。</p></li><li><p>–use-service-account-credentials&#x3D;true \</p><p>为每个控制器使用独立的 ServiceAccount 凭据。增强安全性，限制控制器权限（而非使用默认高权限凭据）。</p></li><li><p>–node-monitor-grace-period&#x3D;40s \</p><p>节点控制器标记节点为 NotReady 前的宽限时间。若节点 40 秒未响应（无心跳），标记为不可用。</p></li><li><p>–node-monitor-period&#x3D;5s \</p><p>节点控制器检查节点状态的周期。每 5 秒检查节点健康状态。</p></li><li><p>–controllers&#x3D;*,bootstrapsigner,tokencleaner \</p><p>指定启用的控制器列表。</p><p>*：启用所有默认控制器（如 ReplicaSet、Deployment、Node 控制器）。</p><p>bootstrapsigner：签署引导令牌的 CSR。</p><p>tokencleaner：清理过期引导令牌。</p></li><li><p>–allocate-node-cidrs&#x3D;true \</p><p>启用节点 CIDR 分配。Controller Manager 为每个节点分配 Pod CIDR（由 –cluster-cidr 定义）</p></li><li><p>–service-cluster-ip-range&#x3D;10.96.0.0&#x2F;12,fd00:1111::&#x2F;112 \</p><p>Service 的 Cluster IP 地址范围（IPv4 和 IPv6）。</p><p>定义 Service 的虚拟 IP 池，与 kube-apiserver 的 –service-cluster-ip-range 一致。</p></li><li><p>–node-cidr-mask-size-ipv4&#x3D;24 \</p><p>每个节点的 IPv4 Pod CIDR 子网掩码大小，每个节点分配 &#x2F;24 子网（256 个 IP），从 172.16.0.0&#x2F;12 中划分。</p></li><li><p>–node-cidr-mask-size-ipv6&#x3D;120 \</p><p>每个节点的 IPv6 Pod CIDR 子网掩码大小。</p><p>每个节点分配 &#x2F;120 子网（256 个 IP），从 fc00:2222::&#x2F;112 中划分。</p></li><li><p>–requestheader-client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.pem \</p><p>API 聚合器的 CA 证书。验证聚合器客户端（如扩展 API 服务器），与 kube-apiserver 一致。</p></li><li><p>Restart&#x3D;always</p><p>服务无论何种原因退出都重启。确保 Controller Manager 高可用。</p></li><li><p>RestartSec&#x3D;10s</p><p>重启前等待 10 秒。</p></li></ul></blockquote><p><strong>配置分发到其它Master节点</strong></p><pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   rsync -a --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/kube-controller-manager.service <span class="variable">$user</span>@<span class="variable">$host</span>:/usr/lib/systemd/system/;<span class="keyword">done</span></code></pre><h3 id="4-2-启动-kube-controller-manager"><a href="#4-2-启动-kube-controller-manager" class="headerlink" title="4.2 启动 kube-controller-manager"></a>4.2 启动 kube-controller-manager</h3><pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master01 k8s-master02 k8s-master03&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now kube-controller-manager.service&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl status kube-controller-manager.service&quot;</span><span class="keyword">done</span></code></pre><h2 id="5-kube-scheduler-配置"><a href="#5-kube-scheduler-配置" class="headerlink" title="5. kube-scheduler 配置"></a>5. kube-scheduler 配置</h2><p>所有 master 节点配置，且配置相同</p><h3 id="5-1-kube-scheduler-service"><a href="#5-1-kube-scheduler-service" class="headerlink" title="5.1 kube-scheduler.service"></a>5.1 kube-scheduler.service</h3><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; <span class="string">EOF</span><span class="string"></span><span class="string">[Unit]</span><span class="string">Description=Kubernetes Scheduler</span><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span><span class="string">After=network.target</span><span class="string"></span><span class="string">[Service]</span><span class="string">ExecStart=/usr/local/bin/kube-scheduler \\</span><span class="string">      --v=2 \\</span><span class="string">      --bind-address=0.0.0.0 \\</span><span class="string">      --leader-elect=true \\</span><span class="string">      --kubeconfig=/etc/kubernetes/scheduler.kubeconfig</span><span class="string"></span><span class="string">Restart=always</span><span class="string">RestartSec=10s</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string"></span><span class="string">EOF</span></code></pre><blockquote><p><strong>配置解析：</strong></p><p>kube-scheduler 与 API 服务器（6443 端口）交互，通过 kubeconfig 文件访问集群状态，决定 Pod 分配。</p><ul><li><p>ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kube-scheduler \</p><p>指定启动命令，运行 kube-scheduler 可执行文件（位于 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;），后续参数以 \ 分行。</p><p>启动 Scheduler，负责根据节点资源、策略和约束（如亲和性、污点）将 Pod 调度到节点。</p></li><li><p>–v&#x3D;2 \</p><p>设置日志级别为 2（中等详细，适合调试）。</p><p>生产环境可设为 –v&#x3D;1 减少日志，或增至 –v&#x3D;4 排查复杂问题。</p></li><li><p>–bind-address&#x3D;0.0.0.0 \</p><p>Scheduler 监听所有网络接口（0.0.0.0）上的端口（默认 10259，HTTPS）。</p><p>允许外部访问健康检查或指标端点（如 &#x2F;healthz、&#x2F;metrics），常用于监控（如 Prometheus）。</p></li><li><p>–leader-elect&#x3D;true \</p><p>启用领导者选举。</p><p>在高可用集群中，确保多个主节点的 Scheduler 实例中只有一个活跃（其他为热备），避免调度冲突。</p></li><li><p>–kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;scheduler.kubeconfig \</p><p>Scheduler 的 kubeconfig 文件路径，定义 API 服务器连接信息和认证凭据。</p></li><li><p>Restart&#x3D;always</p><p>服务无论何种原因退出都重启。</p></li><li><p>RestartSec&#x3D;10s</p><p>重启前等待 10 秒。</p></li></ul></blockquote><p><strong>配置同步到其它 master 节点</strong></p><pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master02 k8s-master03&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   rsync -a --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/kube-scheduler.service <span class="variable">$user</span>@<span class="variable">$host</span>:/usr/lib/systemd/system/;<span class="keyword">done</span></code></pre><h3 id="5-2-启动-kube-scheduler"><a href="#5-2-启动-kube-scheduler" class="headerlink" title="5.2 启动 kube-scheduler"></a>5.2 启动 kube-scheduler</h3><pre><code class="highlight bash">hosts=<span class="string">&#x27;k8s-master01 k8s-master02 k8s-master03&#x27;</span>user=root<span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$hosts</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$host</span>;   ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl enable --now kube-scheduler.service&quot;</span>  ssh root@<span class="variable">$host</span> <span class="string">&quot;systemctl status kube-scheduler.service&quot;</span><span class="keyword">done</span></code></pre><h1 id="六、TLS-Bootstrapping-配置"><a href="#六、TLS-Bootstrapping-配置" class="headerlink" title="六、TLS Bootstrapping 配置"></a>六、TLS Bootstrapping 配置</h1><p>官方文档：<a href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/">https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/</a></p><h2 id="1-生成-bootstrap-的-token"><a href="#1-生成-bootstrap-的-token" class="headerlink" title="1. 生成 bootstrap 的 token"></a>1. 生成 bootstrap 的 token</h2><p><strong>master01</strong></p><pre><code class="highlight bash">TOKEN_ID=$(openssl rand -hex 3)TOKEN_SECRET=$(openssl rand -hex 8)BOOTSTRAP_TOKEN=<span class="variable">$&#123;TOKEN_ID&#125;</span>.<span class="variable">$&#123;TOKEN_SECRET&#125;</span> $ <span class="built_in">echo</span> <span class="variable">$BOOTSTRAP_TOKEN</span>25062c.208e46b2a427f63a</code></pre><blockquote><p><strong>命令解析：</strong></p><p>生成一个 Kubernetes 引导令牌（Bootstrap Token），格式为 .，用于节点（主节点或工作节点）通过 kubeadm join 加入集群时进行身份验证</p></blockquote><h2 id="2-配置-bootstrap-kubelet-kubeconfig"><a href="#2-配置-bootstrap-kubelet-kubeconfig" class="headerlink" title="2. 配置 bootstrap-kubelet.kubeconfig"></a>2. 配置 bootstrap-kubelet.kubeconfig</h2><p><strong>master01</strong></p><pre><code class="highlight bash"><span class="comment"># 在指定的 kubeconfig 文件（/etc/kubernetes/bootstrap-kubelet.kubeconfig）中配置一个名为 kubernetes 的集群条目，定义如何连接到 Kubernetes API 服务器，包括 CA 证书和服务器地址</span>kubectl config set-cluster kubernetes     \--certificate-authority=/etc/kubernetes/pki/ca.pem     \--embed-certs=<span class="literal">true</span>     --server=https://127.0.0.1:8443     \--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig<span class="comment"># 在指定的 kubeconfig 文件中创建或更新一个名为 tls-bootstrap-token-user 的用户凭据条目，配置引导令牌（25062c.208e46b2a427f63a），用于 kubelet 在节点引导过程中通过 Nginx 负载均衡器（127.0.0.1:8443）访问 API 服务器</span>kubectl config set-credentials tls-bootstrap-token-user     \--token=25062c.208e46b2a427f63a \--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig<span class="comment"># 在 kubeconfig 文件中配置上下文（context），将集群和用户凭据关联起来，供 kubelet 在节点引导过程中使用以访问 Kubernetes API 服务器</span>kubectl config set-context tls-bootstrap-token-user@kubernetes     \--cluster=kubernetes     \--user=tls-bootstrap-token-user     \--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig<span class="comment"># 在 kubeconfig 文件中设置默认上下文，指定 kubelet 使用特定的上下文（tls-bootstrap-token-user@kubernetes）来访问 Kubernetes API 服务器，从而完成节点引导和注册。</span>kubectl config use-context tls-bootstrap-token-user@kubernetes     \--kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig<span class="comment"># token的位置在 bootstrap.secret.yaml，如果修改的话到这个文件修改</span><span class="comment"># 创建 /root/.kube 目录，用于存储 Kubernetes 管理用户的 kubeconfig 文件</span><span class="built_in">mkdir</span> -p /root/.kube<span class="comment"># 将管理员的 kubeconfig 文件（/etc/kubernetes/admin.kubeconfig）复制到 /root/.kube/config，作为 kubectl 的默认配置文件</span><span class="built_in">cp</span> /etc/kubernetes/admin.kubeconfig /root/.kube/config<span class="comment"># 分发 kubelet 配置文件</span>host=(k8s-master02 k8s-master03)user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;mkdir -p /root/.kube&quot;</span>    rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /root/.kube/config <span class="variable">$user</span>@<span class="variable">$i</span>:/root/.kube/;<span class="keyword">done</span></code></pre><h2 id="3-创建-bootstrap-secret-yaml"><a href="#3-创建-bootstrap-secret-yaml" class="headerlink" title="3. 创建 bootstrap-secret.yaml"></a>3. 创建 bootstrap-secret.yaml</h2><p>注意：bootstrap.secret.yaml的token-id、token-secret，需与上命令token保持一致(即 <code>25062c.208e46b2a427f63a</code> )</p><pre><code class="highlight bash"><span class="comment"># 创建目录</span><span class="built_in">mkdir</span> -p /etc/kubernetes/yaml<span class="comment"># 编辑文件</span><span class="built_in">cat</span> &gt; /etc/kubernetes/yaml/bootstrap-secret.yaml  &lt;&lt; <span class="string">EOF</span><span class="string">apiVersion: v1</span><span class="string">kind: Secret</span><span class="string">metadata:</span><span class="string">  name: bootstrap-token-$&#123;TOKEN_ID&#125;</span><span class="string">  namespace: kube-system</span><span class="string">type: bootstrap.kubernetes.io/token</span><span class="string">stringData:</span><span class="string">  description: &quot;The default bootstrap token generated by &#x27;kubelet &#x27;.&quot;</span><span class="string">  token-id: $&#123;TOKEN_ID&#125;</span><span class="string">  token-secret: $&#123;TOKEN_SECRET&#125;</span><span class="string">  usage-bootstrap-authentication: &quot;true&quot;</span><span class="string">  usage-bootstrap-signing: &quot;true&quot;</span><span class="string">  auth-extra-groups:  system:bootstrappers:default-node-token,system:bootstrappers:worker,system:bootstrappers:ingress</span><span class="string">EOF</span><span class="comment"># 执行资源清单 </span>$ kubectl create -f /etc/kubernetes/yaml/bootstrap-secret.yamlsecret/bootstrap-token-25062c created<span class="comment"># 查看结果</span>$ kubectl get secret -n kube-systemNAME                     TYPE                            DATA   AGEbootstrap-token-25062c   bootstrap.kubernetes.io/token   6      10s</code></pre><h2 id="4-创建-kubelet-bootstrap-rbac-yaml"><a href="#4-创建-kubelet-bootstrap-rbac-yaml" class="headerlink" title="4. 创建 kubelet-bootstrap-rbac.yaml"></a>4. 创建 kubelet-bootstrap-rbac.yaml</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/yaml/kubelet-bootstrap-rbac.yaml &lt;&lt; <span class="string">EOF</span><span class="string">apiVersion: rbac.authorization.k8s.io/v1</span><span class="string">kind: ClusterRoleBinding</span><span class="string">metadata:</span><span class="string">  name: kubelet-bootstrap</span><span class="string">roleRef:</span><span class="string">  apiGroup: rbac.authorization.k8s.io</span><span class="string">  kind: ClusterRole</span><span class="string">  name: system:node-bootstrapper</span><span class="string">subjects:</span><span class="string">- apiGroup: rbac.authorization.k8s.io</span><span class="string">  kind: Group</span><span class="string">  name: system:bootstrappers:default-node-token</span><span class="string">---</span><span class="string">apiVersion: rbac.authorization.k8s.io/v1</span><span class="string">kind: ClusterRoleBinding</span><span class="string">metadata:</span><span class="string">  name: node-autoapprove-bootstrap</span><span class="string">roleRef:</span><span class="string">  apiGroup: rbac.authorization.k8s.io</span><span class="string">  kind: ClusterRole</span><span class="string">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><span class="string">subjects:</span><span class="string">- apiGroup: rbac.authorization.k8s.io</span><span class="string">  kind: Group</span><span class="string">  name: system:bootstrappers:default-node-token</span><span class="string">---</span><span class="string">apiVersion: rbac.authorization.k8s.io/v1</span><span class="string">kind: ClusterRoleBinding</span><span class="string">metadata:</span><span class="string">  name: node-autoapprove-certificate-rotation</span><span class="string">roleRef:</span><span class="string">  apiGroup: rbac.authorization.k8s.io</span><span class="string">  kind: ClusterRole</span><span class="string">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><span class="string">subjects:</span><span class="string">- apiGroup: rbac.authorization.k8s.io</span><span class="string">  kind: Group</span><span class="string">  name: system:nodes</span><span class="string">---</span><span class="string">apiVersion: rbac.authorization.k8s.io/v1</span><span class="string">kind: ClusterRole</span><span class="string">metadata:</span><span class="string">  annotations:</span><span class="string">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><span class="string">  labels:</span><span class="string">    kubernetes.io/bootstrapping: rbac-defaults</span><span class="string">  name: system:kube-apiserver-to-kubelet</span><span class="string">rules:</span><span class="string">  - apiGroups:</span><span class="string">      - &quot;&quot;</span><span class="string">    resources:</span><span class="string">      - nodes/proxy</span><span class="string">      - nodes/stats</span><span class="string">      - nodes/log</span><span class="string">      - nodes/spec</span><span class="string">      - nodes/metrics</span><span class="string">    verbs:</span><span class="string">      - &quot;*&quot;</span><span class="string">---</span><span class="string">apiVersion: rbac.authorization.k8s.io/v1</span><span class="string">kind: ClusterRoleBinding</span><span class="string">metadata:</span><span class="string">  name: system:kube-apiserver</span><span class="string">  namespace: &quot;&quot;</span><span class="string">roleRef:</span><span class="string">  apiGroup: rbac.authorization.k8s.io</span><span class="string">  kind: ClusterRole</span><span class="string">  name: system:kube-apiserver-to-kubelet</span><span class="string">subjects:</span><span class="string">  - apiGroup: rbac.authorization.k8s.io</span><span class="string">    kind: User</span><span class="string">    name: kube-apiserver</span><span class="string">EOF</span><span class="comment"># 执行清单</span>kubectl create -f /etc/kubernetes/yaml/kubelet-bootstrap-rbac.yaml</code></pre><h2 id="5-分发配置文件"><a href="#5-分发配置文件" class="headerlink" title="5. 分发配置文件"></a>5. 分发配置文件</h2><pre><code class="highlight bash">host=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)user=root<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>    rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/&#123;bootstrap-kubelet,kube-proxy&#125;.kubeconfig <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/;<span class="keyword">done</span></code></pre><p><strong>注：若kubectl get node 为空，那应该就是 bootstrap-kubelet.kubeconfig 中的 token 对不上, 修改后重启kubelet</strong></p><h2 id="6-查看集群状态"><a href="#6-查看集群状态" class="headerlink" title="6. 查看集群状态"></a>6. 查看集群状态</h2><pre><code class="highlight bash">[root@k8s-master01 ~]$ kubectl get csWarning: v1 ComponentStatus is deprecated <span class="keyword">in</span> v1.19+NAME                 STATUS    MESSAGE   ERRORscheduler            Healthy   ok        etcd-0               Healthy   ok        controller-manager   Healthy   ok</code></pre><h1 id="七、Node-配置"><a href="#七、Node-配置" class="headerlink" title="七、Node 配置"></a>七、Node 配置</h1><h2 id="1-复制相关证书至-node-节点"><a href="#1-复制相关证书至-node-节点" class="headerlink" title="1. 复制相关证书至 node 节点"></a>1. 复制相关证书至 node 节点</h2><pre><code class="highlight bash">user=roothost=(k8s-master02 k8s-master03 k8s-node01 k8s-node02)<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;sudo mkdir -p /etc/kubernetes/pki/&quot;</span>;  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/pki/&#123;ca.pem,ca-key.pem,front-proxy-ca.pem&#125; <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/pki/;  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/&#123;bootstrap-kubelet.kubeconfig,kube-proxy.kubeconfig&#125; <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/pki/;<span class="keyword">done</span></code></pre><h2 id="2-配置-kubelet（所有节点）"><a href="#2-配置-kubelet（所有节点）" class="headerlink" title="2. 配置 kubelet（所有节点）"></a>2. 配置 kubelet（所有节点）</h2><h3 id="2-1-编辑-kubelet-service"><a href="#2-1-编辑-kubelet-service" class="headerlink" title="2.1 编辑 kubelet.service"></a>2.1 编辑 kubelet.service</h3><p><strong>Master01</strong></p><pre><code class="highlight bash"><span class="comment"># 当使用 docker 作为 Runtime</span><span class="comment"># IPv4示例</span><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; <span class="string">EOF</span><span class="string"></span><span class="string">[Unit]</span><span class="string">Description=Kubernetes Kubelet</span><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span><span class="string">After=network-online.target firewalld.service cri-docker.service docker.socket containerd.service</span><span class="string">Wants=network-online.target</span><span class="string">Requires=docker.socket containerd.service</span><span class="string"></span><span class="string">[Service]</span><span class="string">ExecStart=/usr/local/bin/kubelet \\</span><span class="string">    --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig  \\</span><span class="string">    --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\</span><span class="string">    --config=/etc/kubernetes/kubelet-conf.yml \\</span><span class="string">    --container-runtime-endpoint=unix:///run/cri-dockerd.sock  \\</span><span class="string">    --node-labels=node.kubernetes.io/node= </span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string">EOF</span><span class="comment"># IPv6示例</span><span class="comment"># 若不使用IPv6那么忽略此项即可</span><span class="comment"># 下方 --node-ip 更换为每个节点的IP即可</span><span class="comment"># cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF</span><span class="comment"># [Unit]</span><span class="comment"># Description=Kubernetes Kubelet</span><span class="comment"># Documentation=https://github.com/kubernetes/kubernetes</span><span class="comment"># After=network-online.target firewalld.service cri-docker.service docker.socket # containerd.service</span><span class="comment"># Wants=network-online.target</span><span class="comment"># Requires=docker.socket containerd.service</span><span class="comment"># [Service]</span><span class="comment"># ExecStart=/usr/local/bin/kubelet \\</span><span class="comment">#     --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig  \\</span><span class="comment">#     --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\</span><span class="comment">#     --config=/etc/kubernetes/kubelet-conf.yml \\</span><span class="comment">#     --container-runtime-endpoint=unix:///run/cri-dockerd.sock  \\</span><span class="comment">#     --node-labels=node.kubernetes.io/node=   \\</span><span class="comment">#     --node-ip=192.168.1.31,2408:822a:245:8c01::fab</span><span class="comment"># [Install]</span><span class="comment"># WantedBy=multi-user.target</span><span class="comment"># EOF</span></code></pre><ul><li>注意node-labels&#x3D;node.kubernetes.io&#x2F;node&#x3D;<code>&#39;&#39;</code> ubuntu为<code>&#39;&#39;</code> centos为空</li></ul><blockquote><p><strong>命令解析：</strong></p><ul><li>–bootstrap-kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;bootstrap-kubelet.kubeconfig：引导 kubeconfig 文件路径。用于 TLS Bootstrapping（节点自动加入集群的机制）。kubelet 使用此文件向 API Server 请求证书，首次启动时使用</li><li>–kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;kubelet.kubeconfig：最终的 kubeconfig 文件路径。引导成功后，kubelet 会切换到这个文件，用于与 Kubernetes API Server 通信。</li><li>–config&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;kubelet-conf.yml：kubelet 的 YAML 配置文件路径（包含详细配置，如 cgroup 驱动、Pod 限制等）。这个文件在稍后定义。</li><li>–container-runtime-endpoint&#x3D;unix:&#x2F;&#x2F;&#x2F;run&#x2F;cri-dockerd.sock：容器运行时端点。指定使用 cri-dockerd 的 Unix socket（因为使用 Docker + cri-dockerd 作为 CRI 兼容运行时，而不是直接用 containerd 或 CRI-O）。</li><li>–node-labels&#x3D;node.kubernetes.io&#x2F;node&#x3D;：节点标签。为空值（可以自定义标签，如用于节点分组）。这里的 &#x3D; 后无内容，表示一个空标签</li></ul></blockquote><h3 id="2-2-编辑-kubelet-conf-yml"><a href="#2-2-编辑-kubelet-conf-yml" class="headerlink" title="2.2 编辑 kubelet-conf.yml"></a>2.2 编辑 kubelet-conf.yml</h3><p>官方文档：<a href="https://kubernetes.io/zh-cn/docs/reference/config-api/kubelet-config.v1beta1/">https://kubernetes.io/zh-cn/docs/reference/config-api/kubelet-config.v1beta1/</a></p><p><strong>Master01</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/kubelet-conf.yml &lt;&lt;<span class="string">EOF</span><span class="string">apiVersion: kubelet.config.k8s.io/v1beta1</span><span class="string">kind: KubeletConfiguration</span><span class="string">address: 0.0.0.0</span><span class="string">port: 10250</span><span class="string">readOnlyPort: 10255</span><span class="string">authentication:</span><span class="string">  anonymous:</span><span class="string">    enabled: false</span><span class="string">  webhook:</span><span class="string">    cacheTTL: 2m0s</span><span class="string">    enabled: true</span><span class="string">  x509:</span><span class="string">    clientCAFile: /etc/kubernetes/pki/ca.pem</span><span class="string">authorization:</span><span class="string">  mode: Webhook</span><span class="string">  webhook:</span><span class="string">    cacheAuthorizedTTL: 5m0s</span><span class="string">    cacheUnauthorizedTTL: 30s</span><span class="string">cgroupDriver: systemd</span><span class="string">cgroupsPerQOS: true</span><span class="string">clusterDNS:</span><span class="string">- 10.96.0.10</span><span class="string">clusterDomain: cluster.local</span><span class="string">containerLogMaxFiles: 5</span><span class="string">containerLogMaxSize: 10Mi</span><span class="string">contentType: application/vnd.kubernetes.protobuf</span><span class="string">cpuCFSQuota: true</span><span class="string">cpuManagerPolicy: none</span><span class="string">cpuManagerReconcilePeriod: 10s</span><span class="string">enableControllerAttachDetach: true</span><span class="string">enableDebuggingHandlers: true</span><span class="string">enforceNodeAllocatable:</span><span class="string">- pods</span><span class="string">eventBurst: 10</span><span class="string">eventRecordQPS: 5</span><span class="string">evictionHard:</span><span class="string">  imagefs.available: 15%</span><span class="string">  memory.available: 100Mi</span><span class="string">  nodefs.available: 10%</span><span class="string">  nodefs.inodesFree: 5%</span><span class="string">evictionPressureTransitionPeriod: 5m0s</span><span class="string">failSwapOn: true</span><span class="string">fileCheckFrequency: 20s</span><span class="string">hairpinMode: promiscuous-bridge</span><span class="string">healthzBindAddress: 127.0.0.1</span><span class="string">healthzPort: 10248</span><span class="string">httpCheckFrequency: 20s</span><span class="string">imageGCHighThresholdPercent: 85</span><span class="string">imageGCLowThresholdPercent: 80</span><span class="string">imageMinimumGCAge: 2m0s</span><span class="string">iptablesDropBit: 15</span><span class="string">iptablesMasqueradeBit: 14</span><span class="string">kubeAPIBurst: 10</span><span class="string">kubeAPIQPS: 5</span><span class="string">makeIPTablesUtilChains: true</span><span class="string">maxOpenFiles: 1000000</span><span class="string">maxPods: 110</span><span class="string">nodeStatusUpdateFrequency: 10s</span><span class="string">oomScoreAdj: -999</span><span class="string">podPidsLimit: -1</span><span class="string">registryBurst: 10</span><span class="string">registryPullQPS: 5</span><span class="string">resolvConf: /etc/resolv.conf</span><span class="string">rotateCertificates: true</span><span class="string">runtimeRequestTimeout: 2m0s</span><span class="string">serializeImagePulls: true</span><span class="string">staticPodPath: /etc/kubernetes/manifests</span><span class="string">streamingConnectionIdleTimeout: 4h0m0s</span><span class="string">syncFrequency: 1m0s</span><span class="string">volumeStatsAggPeriod: 1m0s</span><span class="string">EOF</span></code></pre><blockquote><p><strong>命令解析：</strong></p><p>创建 Kubernetes 的 kubelet 配置文件 &#x2F;etc&#x2F;kubernetes&#x2F;kubelet-conf.yml。该文件是 kubelet 的主要配置文件，定义了 kubelet 的运行行为、资源管理、网络配置等关键参数。kubelet 是 Kubernetes 节点上的核心组件，负责管理 Pod、容器生命周期、节点资源等。</p><p><strong>apiVersion</strong>: 指定配置文件使用的 Kubernetes API 版本。这里是 kubelet.config.k8s.io&#x2F;v1beta1，表示 kubelet 配置的 v1beta1 版本。</p><p><strong>kind</strong>: 指定配置类型为 KubeletConfiguration，这是 kubelet 的专用配置类型。</p><p><strong>address</strong>: kubelet 的监听地址。0.0.0.0 表示监听所有网络接口，允许外部访问（如 API Server 或 kubectl）。</p><p><strong>port</strong>: kubelet 的主端口，用于处理 HTTPS 请求（如状态查询、命令执行）。默认值为 10250。</p><p><strong>readOnlyPort</strong>: 只读端口，提供无认证的只读访问（如健康检查或状态查询）。默认值为 10255。<strong>注意</strong>：在高安全性环境中，建议禁用只读端口（设置为 0）以防止未经授权的访问。</p><p><strong>authentication</strong>: 定义 kubelet 的认证机制。</p><ul><li><strong>anonymous.enabled</strong>: 是否允许匿名访问。false 表示禁用匿名访问，增强安全性。</li><li><strong>webhook.enabled</strong>: 是否启用 Webhook 认证。true 表示 kubelet 通过向 API Server 发送 Webhook 请求验证客户端身份。</li><li><strong>webhook.cacheTTL</strong>: Webhook 认证结果的缓存时间，设置为 2m0s（2 分钟），减少重复验证开销。</li><li><strong>x509.clientCAFile</strong>: 指定用于验证客户端证书的 CA 文件路径（&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.pem）。客户端（如 API Server）必须提供由该 CA 签发的证书。</li></ul><p><strong>authorization</strong>: 定义 kubelet 的授权机制。</p><ul><li><strong>mode: Webhook</strong>: 使用 Webhook 模式向 API Server 请求授权决定（基于 RBAC 或其他授权策略）。</li><li><strong>webhook.cacheAuthorizedTTL</strong>: 已授权请求的缓存时间，5m0s（5 分钟）。</li><li><strong>webhook.cacheUnauthorizedTTL</strong>: 未授权请求的缓存时间，30s（30 秒）。较短的未授权缓存时间确保快速更新拒绝策略。</li></ul><p><strong>cgroupDriver</strong>: 指定 kubelet 使用的 cgroup 驱动程序。systemd 表示使用 systemd 管理 cgroup，与 Docker 的 systemd cgroup 驱动一致（配置了 Docker 的 daemon.json 使用 native.cgroupdriver&#x3D;systemd）。</p><p><strong>cgroupsPerQOS</strong>: 是否为不同 QoS（服务质量）级别的 Pod 创建单独的 cgroup。true 启用此功能，确保 Guaranteed、Burstable 和 BestEffort Pod 的资源隔离。</p><p><strong>clusterDNS</strong>: 指定集群内 DNS 服务的 IP 地址。10.96.0.10 是 CoreDNS 的服务 IP（与安装 CoreDNS 时配置的 clusterIP 一致）。</p><p><strong>clusterDomain</strong>: 指定集群的 DNS 域名后缀。cluster.local 是默认值，用于解析服务名称（如 my-service.default.svc.cluster.local）。</p><p><strong>containerLogMaxFiles</strong>: 每个容器的最大日志文件数（轮转日志）。5 表示保留最多 5 个日志文件。</p><p><strong>containerLogMaxSize</strong>: 每个日志文件的最大大小。10Mi 表示 10MB，超过后会触发日志轮转。</p><p><strong>contentType</strong>: 指定 kubelet 与 API Server 通信时使用的内容类型。application&#x2F;vnd.kubernetes.protobuf 表示使用 Protobuf 格式（比 JSON 更高效）。</p><p><strong>cpuCFSQuota</strong>: 是否为容器启用 CPU CFS（Completely Fair Scheduler）配额。true 表示限制容器 CPU 使用量，基于 Pod 的 QoS 设置。</p><p><strong>cpuManagerPolicy</strong>: CPU 分配策略。none 表示不使用 CPU 管理器（不分配专用 CPU 核心，Pod 共享 CPU 资源）。</p><p><strong>cpuManagerReconcilePeriod</strong>: CPU 管理器的协调周期。10s 表示每 10 秒检查并调整 CPU 分配（尽管策略为 none，此参数仍需设置）。</p><p><strong>enableControllerAttachDetach</strong>: 是否允许控制器管理卷的挂载和卸载。true 表示由 kubelet 和控制器协同处理卷操作。</p><p><strong>enableDebuggingHandlers</strong>: 是否启用调试端点（如 &#x2F;debug&#x2F;pprof）。true 允许访问调试信息，便于性能分析。</p><p><strong>enforceNodeAllocatable</strong>: 指定强制限制的资源类型。pods 表示对 Pod 分配的资源进行限制，确保节点保留系统和 kubelet 所需的资源（如内存、CPU）。</p><p><strong>eventBurst</strong>: 事件处理的突发容量。10 表示允许短时间内处理最多 10 个事件。</p><p><strong>eventRecordQPS</strong>: 每秒记录的事件数。5 表示平均每秒记录 5 个事件，控制事件报告频率以避免 API Server 过载。</p><p><strong>evictionHard</strong>: 定义硬性驱逐阈值，当资源低于以下值时，kubelet 会驱逐 Pod 以回收资源：</p><ul><li><strong>imagefs.available</strong>: 镜像文件系统可用空间低于 15% 时触发驱逐。</li><li><strong>memory.available</strong>: 可用内存低于 100Mi（100MB）时触发驱逐。</li><li><strong>nodefs.available</strong>: 节点文件系统可用空间低于 10% 时触发驱逐。</li><li><strong>nodefs.inodesFree</strong>: 节点文件系统可用 inode 低于 5% 时触发驱逐。</li></ul><p><strong>evictionPressureTransitionPeriod</strong>: 驱逐压力过渡期。5m0s 表示在资源压力缓解后，等待 5 分钟才停止驱逐。</p><p><strong>failSwapOn</strong>: 是否允许在启用 swap 分区时启动 kubelet。true 表示如果 swap 启用，kubelet 将启动失败（当前已禁用 swap）。</p><p><strong>fileCheckFrequency</strong>: 检查文件变更的频率。20s 表示每 20 秒检查一次（如 Pod 配置文件）。</p><p><strong>hairpinMode</strong>: 指定 hairpin 流量（Pod 访问自身服务 IP）的处理方式。promiscuous-bridge 表示使用网桥的混杂模式，适用于 Calico 等 CNI 插件。</p><p><strong>healthzBindAddress</strong>: 健康检查监听地址。127.0.0.1 表示仅本地可访问，增强安全性。</p><p><strong>healthzPort</strong>: 健康检查端口。10248 是默认值，用于 &#x2F;healthz 端点。</p><p><strong>httpCheckFrequency</strong>: HTTP 健康检查频率。20s 表示每 20 秒检查一次。</p><p><strong>imageGCHighThresholdPercent</strong>: 镜像垃圾回收的上限阈值。磁盘使用率达到 85% 时触发回收。</p><p><strong>imageGCLowThresholdPercent</strong>: 镜像垃圾回收的下限阈值。回收后磁盘使用率低于 80% 时停止。</p><p><strong>imageMinimumGCAge</strong>: 镜像的最小保留时间。2m0s 表示镜像至少保留 2 分钟，防止频繁回收。</p><p><strong>iptablesDropBit</strong>: 用于标记丢弃数据包的 iptables 位。15 是默认值。</p><p><strong>iptablesMasqueradeBit</strong>: 用于 SNAT（源地址转换）的 iptables 位。14 是默认值。</p><p><strong>makeIPTablesUtilChains</strong>: 是否创建 iptables 工具链。true 表示 kubelet 自动管理 iptables 规则。</p><p><strong>kubeAPIBurst</strong>: 与 API Server 通信的突发请求数。10 表示短时间内最多发送 10 个请求。</p><p><strong>kubeAPIQPS</strong>: 与 API Server 通信的每秒请求数。5 表示平均每秒 5 个请求，控制负载。</p><p><strong>maxOpenFiles</strong>: 最大打开文件数。1000000 允许 kubelet 处理大量文件描述符。</p><p><strong>maxPods</strong>: 节点上最大 Pod 数。110 是默认值，限制节点负载。</p><p><strong>podPidsLimit</strong>: 每个 Pod 的最大 PID 数。-1 表示无限制。</p><p><strong>nodeStatusUpdateFrequency</strong>: 节点状态更新频率。10s 表示每 10 秒向 API Server 报告节点状态。</p><p><strong>oomScoreAdj</strong>: kubelet 进程的 OOM（内存不足）优先级。-999 表示低优先级，降低被杀死概率。</p><p><strong>registryBurst</strong>: 从镜像仓库拉取镜像的突发请求数。10 表示最多 10 个并发请求。</p><p><strong>registryPullQPS</strong>: 镜像拉取的每秒请求数。5 表示平均每秒 5 个请求。</p><p><strong>resolvConf</strong>: DNS 解析配置文件路径。&#x2F;etc&#x2F;resolv.conf 是系统默认值。</p><p><strong>rotateCertificates</strong>: 是否启用证书轮换。true 表示自动更新过期证书。</p><p><strong>runtimeRequestTimeout</strong>: 容器运行时请求超时时间。2m0s 表示 2 分钟。</p><p><strong>serializeImagePulls</strong>: 是否串行拉取镜像。true 表示一次拉取一个镜像，降低资源争用。</p><p><strong>staticPodPath</strong>: 静态 Pod 的清单目录。&#x2F;etc&#x2F;kubernetes&#x2F;manifests 用于存放静态 Pod 的 YAML 文件。</p><p><strong>streamingConnectionIdleTimeout</strong>: 流式连接（如 kubectl exec）的空闲超时。4h0m0s 表示 4 小时。</p><p><strong>syncFrequency</strong>: Pod 同步频率。1m0s 表示每分钟同步一次 Pod 状态。</p><p><strong>volumeStatsAggPeriod</strong>: 卷统计聚合周期。1m0s 表示每分钟收集一次卷使用数据。</p></blockquote><h3 id="2-3-同步文件到其它节点"><a href="#2-3-同步文件到其它节点" class="headerlink" title="2.3 同步文件到其它节点"></a>2.3 同步文件到其它节点</h3><pre><code class="highlight bash">user=roothost=(k8s-master02 k8s-master03 k8s-node01 k8s-node02)<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$i</span>  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/kubelet.service <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/lib/systemd/system/;  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/kubelet-conf.yml <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/;<span class="keyword">done</span></code></pre><h3 id="2-4-所有节点启动-kubelet"><a href="#2-4-所有节点启动-kubelet" class="headerlink" title="2.4 所有节点启动 kubelet"></a>2.4 所有节点启动 kubelet</h3><pre><code class="highlight bash">user=roothost=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>;  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl enable --now kubelet&quot;</span>;  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl status kubelet&quot;</span>;<span class="keyword">done</span></code></pre><h3 id="2-5-测试"><a href="#2-5-测试" class="headerlink" title="2.5 测试"></a>2.5 测试</h3><pre><code class="highlight bash">[root@k8s-master01 ~]$ kubectl get nodesNAME           STATUS     ROLES    AGE     VERSIONk8s-master01   NotReady   &lt;none&gt;   20m     v1.29.2k8s-master02   NotReady   &lt;none&gt;   13m     v1.29.2k8s-master03   NotReady   &lt;none&gt;   13m     v1.29.2k8s-node01     NotReady   &lt;none&gt;   7m53s   v1.29.2k8s-node02     NotReady   &lt;none&gt;   7m52s   v1.29.2</code></pre><h2 id="3-kube-proxy-配置（所有节点）"><a href="#3-kube-proxy-配置（所有节点）" class="headerlink" title="3. kube-proxy 配置（所有节点）"></a>3. kube-proxy 配置（所有节点）</h2><h3 id="3-1-同步-kube-proxy-kubeconfig"><a href="#3-1-同步-kube-proxy-kubeconfig" class="headerlink" title="3.1 同步 kube-proxy.kubeconfig"></a>3.1 同步 kube-proxy.kubeconfig</h3><p><strong>master01</strong></p><p>将 kube-proxy.kube.config 文件同步到其它所有节点</p><pre><code class="highlight bash">user=roothost=(k8s-master02 k8s-master03 k8s-node01 k8s-node02)<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$i</span>  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/kube-proxy.kubeconfig <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/;<span class="keyword">done</span></code></pre><h3 id="3-2-编辑-kube-proxy-service"><a href="#3-2-编辑-kube-proxy-service" class="headerlink" title="3.2 编辑 kube-proxy.service"></a>3.2 编辑 kube-proxy.service</h3><p><strong>Master01</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-proxy.service &lt;&lt; <span class="string">EOF</span><span class="string">[Unit]</span><span class="string">Description=Kubernetes Kube Proxy</span><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span><span class="string">After=network.target</span><span class="string"></span><span class="string">[Service]</span><span class="string">ExecStart=/usr/local/bin/kube-proxy \\</span><span class="string">  --config=/etc/kubernetes/kube-proxy.yaml \\</span><span class="string">  --cluster-cidr=172.16.0.0/12,fc00:2222::/112 \\</span><span class="string">  --v=2</span><span class="string">Restart=always</span><span class="string">RestartSec=10s</span><span class="string"></span><span class="string">[Install]</span><span class="string">WantedBy=multi-user.target</span><span class="string"></span><span class="string">EOF</span></code></pre><blockquote><p><strong>命令解析：</strong></p><p>kube-proxy是Kubernetes的核心组件之一，负责处理Service和Pod的网络代理（如负载均衡、NAT等），确保集群内的网络通信正常工作。</p><p>适用节点：所有Kubernetes节点（Master和Node），因为kube-proxy需要在每个节点上运行，以处理本地Pod的网络流量。</p><ul><li><p>ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kube-proxy</p><p>执行命令：指定服务的启动命令，即运行&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kube-proxy二进制文件</p></li><li><p>–config&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;kube-proxy.yaml</p><p>配置参数：指定kube-proxy的配置文件路径。这个YAML文件（教程中稍后定义）包含详细配置，如代理模式（IPVS）、绑定地址、连接跟踪等。使用配置文件可以分离配置，便于维护和统一所有节点。</p></li><li><p>–cluster-cidr&#x3D;172.16.0.0&#x2F;12,fc00:2222::&#x2F;112</p><p>172.16.0.0&#x2F;12：IPv4 Pod CIDR（私有地址段，范围从172.16.0.0到172.31.255.255，可容纳大量Pod）。</p><p>fc00:2222::&#x2F;112：IPv6 Pod CIDR（ULA私有地址，支持双栈网络）。</p></li></ul></blockquote><h3 id="3-3-编辑-kube-proxy-yaml"><a href="#3-3-编辑-kube-proxy-yaml" class="headerlink" title="3.3 编辑 kube-proxy.yaml"></a>3.3 编辑 kube-proxy.yaml</h3><p><strong>官方文档：</strong><a href="https://kubernetes.io/zh-cn/docs/reference/config-api/kube-proxy-config.v1alpha1/">https://kubernetes.io/zh-cn/docs/reference/config-api/kube-proxy-config.v1alpha1/</a></p><pre><code class="highlight bash"><span class="built_in">cat</span> &gt; /etc/kubernetes/kube-proxy.yaml &lt;&lt; <span class="string">EOF</span><span class="string">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><span class="string">bindAddress: 0.0.0.0</span><span class="string">clientConnection:</span><span class="string">  acceptContentTypes: &quot;&quot;</span><span class="string">  burst: 10</span><span class="string">  contentType: application/vnd.kubernetes.protobuf</span><span class="string">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><span class="string">  qps: 5</span><span class="string">clusterCIDR: 172.16.0.0/12,fc00:2222::/112</span><span class="string">configSyncPeriod: 15m0s</span><span class="string">conntrack:</span><span class="string">  max: null</span><span class="string">  maxPerCore: 32768</span><span class="string">  min: 131072</span><span class="string">  tcpCloseWaitTimeout: 1h0m0s</span><span class="string">  tcpEstablishedTimeout: 24h0m0s</span><span class="string">enableProfiling: false</span><span class="string">healthzBindAddress: 0.0.0.0:10256</span><span class="string">hostnameOverride: &quot;&quot;</span><span class="string">iptables:</span><span class="string">  masqueradeAll: false</span><span class="string">  masqueradeBit: 14</span><span class="string">  minSyncPeriod: 0s</span><span class="string">  syncPeriod: 30s</span><span class="string">ipvs:</span><span class="string">  masqueradeAll: true</span><span class="string">  minSyncPeriod: 5s</span><span class="string">  scheduler: &quot;rr&quot;</span><span class="string">  syncPeriod: 30s</span><span class="string">kind: KubeProxyConfiguration</span><span class="string">metricsBindAddress: 127.0.0.1:10249</span><span class="string">mode: &quot;ipvs&quot;</span><span class="string">nodePortAddresses: null</span><span class="string">oomScoreAdj: -999</span><span class="string">portRange: &quot;&quot;</span><span class="string">udpIdleTimeout: 250ms</span><span class="string">EOF</span></code></pre><blockquote><p><strong>命令解析：</strong></p><p>kube-proxy 的配置文件，定义了 Kubernetes 集群中 kube-proxy 组件的行为。kube-proxy 运行在每个节点上，负责处理 Service 和 Pod 的网络代理（如负载均衡、NAT），支持 Kubernetes 的网络功能。</p><ul><li><p>apiVersion: kubeproxy.config.k8s.io&#x2F;v1alpha1</p><p>指定配置文件的 API 版本，告诉 Kubernetes 使用 kubeproxy.config.k8s.io&#x2F;v1alpha1 版本的 KubeProxyConfiguration 资源格式来解析此文件</p></li><li><p>bindAddress: 0.0.0.0</p><p>监听所有网络接口（IPv4 和 IPv6），允许 kube-proxy 接受来自任何网络接口的请求。0.0.0.0 确保 kube-proxy 能处理两种协议的流量</p></li><li><p>clientConnection: 定义 kube-proxy 与 Kubernetes API 服务器的通信参数</p><ul><li>acceptContentTypes: “” :指定 kube-proxy 接受的 API 响应内容类型,空字符串表示接受默认类型（通常由 contentType 定义）</li><li>burst: 10 允许的突发请求数（QPS 的上限）,控制 kube-proxy 向 API 服务器发送请求的速率</li><li>contentType: application&#x2F;vnd.kubernetes.protobuf   与 API 服务器通信时使用的内容类型,比 JSON（application&#x2F;json）更高效，减少网络带宽</li><li>kubeconfig: &#x2F;etc&#x2F;kubernetes&#x2F;kube-proxy.kubeconfig   访问 API 服务器的 kubeconfig 文件路径</li><li>qps: 5  每秒向 API 服务器发送的请求数,限制 kube-proxy 的 API 请求速率，qps: 5 表示每秒最多 5 个请求，配合 burst 控制突发</li></ul></li><li><p>clusterCIDR: 172.16.0.0&#x2F;12,fc00:2222::&#x2F;112  定义集群的 Pod IP 地址范围（Pod CIDR）,与 Calico 的 CALICO_IPV4POOL_CIDR 和 CALICO_IPV6POOL_CIDR 一致（calico.yaml 或 calico-ipv6.yaml）</p></li><li><p>configSyncPeriod: 15m0s   kube-proxy 同步配置的间隔时间,每 15 分钟，kube-proxy 从 API 服务器重新获取 Service 和 Endpoint 配置，更新本地代理规则</p></li><li><p>conntrack:  配置连接跟踪（Connection Tracking），用于 NAT 和负载均衡</p><ul><li>max: null  系统中连接跟踪表的最大条目数,null 表示使用系统默认值（通常由内核参数 net.nf_conntrack_max 决定）</li><li>maxPerCore: 32768  每个 CPU 核心的连接跟踪条目上限</li><li>min: 131072  连接跟踪表的最小条目数</li><li>tcpCloseWaitTimeout: 1h0m0s  TCP 连接在 CLOSE_WAIT 状态的超时时间,连接关闭后，等待 1 小时释放资源，防止短时间内频繁释放导致性能问题</li><li>tcpEstablishedTimeout: 24h0m0s  已建立的 TCP 连接的超时时间, 保持长连接（如数据库连接）24 小时，减少重新建立开销</li></ul></li><li><p>enableProfiling: false  是否启用 kube-proxy 的性能分析（profiling）,false 禁用 profiling，降低资源消耗</p></li><li><p>healthzBindAddress: 0.0.0.0:10256  健康检查监听地址和端口,kube-proxy 在 0.0.0.0:10256 提供 &#x2F;healthz 端点，供 kubelet 或外部工具检查状态</p></li><li><p>hostnameOverride: “”  覆盖 kube-proxy 报告的节点主机名,空字符串表示使用节点默认主机名（由 uname -n 或 kubelet 提供）</p></li><li><p>iptables:  配置 iptables 代理模式（尽管当前使用 IPVS，此配置仍保留）</p><ul><li>masqueradeAll: false  是否对所有出站流量执行 NAT 伪装（SNAT），false 表示仅对 Service 相关的流量执行 NAT，减少开销</li><li>masqueradeBit: 14   iptables 伪装时使用的标记位，默认值 14 用于标记 NAT 流量，防止冲突</li><li>minSyncPeriod: 0s  iptables 规则同步的最小间隔，0s 表示无最小间隔，允许快速同步</li><li>syncPeriod: 30s   iptables 规则同步的周期，每 30 秒同步 iptables 规则，确保与 API 服务器一致</li></ul></li><li><p>ipvs:  配置 IPVS 代理模式（本文明确使用 mode: “ipvs”）</p><ul><li>masqueradeAll: true  是否对所有出站流量执行 NAT 伪装。true 表示对所有 Pod 流量执行 SNAT，适合 IPVS 模式，确保外部访问（如 NodePort）正确。</li><li>minSyncPeriod: 5s  IPVS 规则同步的最小间隔。确保至少 5 秒同步一次，防止频繁更新导致性能问题。</li><li>scheduler: “rr”   IPVS 负载均衡调度算法。rr（Round Robin，轮询）平均分配 Service 流量到后端 Pod</li><li>syncPeriod: 30s  IPVS 规则同步周期。每 30 秒同步 IPVS 规则，确保与 API 服务器一致。</li></ul></li><li><p>kind: KubeProxyConfiguration  指定资源的类型，声明这是 kube-proxy 的配置文件</p></li><li><p>metricsBindAddress: 127.0.0.1:10249  指标（metrics）监听地址和端口，kube-proxy 在 127.0.0.1:10249 提供 Prometheus 格式的指标，供监控系统（如 Prometheus）采集</p></li><li><p>mode: “ipvs”  kube-proxy 的代理模式， ipvs 模式使用 Linux IPVS（IP Virtual Server）实现高效负载均衡。</p></li><li><p>nodePortAddresses: null  NodePort 服务的监听地址。null 表示监听所有接口（0.0.0.0）</p></li><li><p>oomScoreAdj: -999   调整 kube-proxy 进程的 OOM（Out of Memory）优先级，-999 降低被 OOM Killer 杀死的概率，优先级接近系统关键进程。</p></li><li><p>portRange: “”  分配 NodePort 的端口范围。空字符串使用默认范围（30000-32767）。</p></li><li><p>udpIdleTimeout: 250ms  UDP 连接的空闲超时时间。250 毫秒后关闭空闲 UDP 连接，释放资源。</p></li></ul></blockquote><h3 id="3-4-启动-kube-proxy"><a href="#3-4-启动-kube-proxy" class="headerlink" title="3.4 启动 kube-proxy"></a>3.4 启动 kube-proxy</h3><pre><code class="highlight bash">systemctl daemon-reloadsystemctl <span class="built_in">enable</span> --now kube-proxy.servicesystemctl status kube-proxy.service</code></pre><h3 id="3-5-同步-kube-proxy-到其它节点"><a href="#3-5-同步-kube-proxy-到其它节点" class="headerlink" title="3.5 同步 kube-proxy 到其它节点"></a>3.5 同步 kube-proxy 到其它节点</h3><pre><code class="highlight bash">user=roothost=(k8s-master02 k8s-master03 k8s-node01 k8s-node02)<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$i</span>  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /usr/lib/systemd/system/kube-proxy.service <span class="variable">$user</span>@<span class="variable">$i</span>:/usr/lib/systemd/system/;  rsync --rsync-path=<span class="string">&quot;sudo rsync&quot;</span> /etc/kubernetes/kube-proxy.yaml <span class="variable">$user</span>@<span class="variable">$i</span>:/etc/kubernetes/;  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl daemon-reload&quot;</span>;  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl enable --now kube-proxy.service&quot;</span>;  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;systemctl status kube-proxy.service&quot;</span>;<span class="keyword">done</span></code></pre><h1 id="八、安装-calico-网络插件"><a href="#八、安装-calico-网络插件" class="headerlink" title="八、安装 calico 网络插件"></a>八、安装 calico 网络插件</h1><h2 id="1-下载-calico-资源清单"><a href="#1-下载-calico-资源清单" class="headerlink" title="1. 下载 calico 资源清单"></a>1. 下载 calico 资源清单</h2><p><strong>Master01</strong></p><pre><code class="highlight bash"><span class="comment"># 创建calico目录，进入目录</span>$ <span class="built_in">mkdir</span> -p /etc/calico/$ <span class="built_in">cd</span> /etc/calico/<span class="comment"># 下载calico资源清单</span>wget https://raw.githubusercontent.com/projectcalico/calico/refs/tags/v3.28.0/manifests/calico-typha.yaml</code></pre><h2 id="2-编辑-calico-资源清单-IPV4"><a href="#2-编辑-calico-资源清单-IPV4" class="headerlink" title="2. 编辑 calico 资源清单-IPV4"></a>2. 编辑 calico 资源清单-IPV4</h2><p><strong>Master01</strong></p><pre><code class="highlight bash"><span class="comment"># 复制资源清单，用于IPV4网络</span>$ <span class="built_in">cp</span> /etc/calico/calico-typha.yaml /etc/calico/calico.yaml<span class="comment"># IPV4环境</span>vim calico.yaml<span class="comment"># calico-config ConfigMap处</span><span class="string">&quot;ipam&quot;</span>: &#123;    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;calico-ipam&quot;</span>,&#125;,- name: IP  value: <span class="string">&quot;autodetect&quot;</span>- name: CALICO_IPV4POOL_CIDR  value: <span class="string">&quot;172.16.0.0/12&quot;</span></code></pre><h2 id="3-编辑-calico-资源清单-IPV6"><a href="#3-编辑-calico-资源清单-IPV6" class="headerlink" title="3. 编辑 calico 资源清单-IPV6"></a>3. 编辑 calico 资源清单-IPV6</h2><p><strong>Master01</strong></p><pre><code class="highlight bash"><span class="comment"># 复制资源清单，用于IPV4网络</span>$ <span class="built_in">cp</span> /etc/calico/calico-typha.yaml /etc/calico/calico-ipv6.yaml<span class="comment"># IPV6环境</span>vim calico-ipv6.yaml<span class="comment"># calico-config ConfigMap处</span>    <span class="string">&quot;ipam&quot;</span>: &#123;        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;calico-ipam&quot;</span>,        <span class="string">&quot;assign_ipv4&quot;</span>: <span class="string">&quot;true&quot;</span>,        <span class="string">&quot;assign_ipv6&quot;</span>: <span class="string">&quot;true&quot;</span>    &#125;,    - name: IP      value: <span class="string">&quot;autodetect&quot;</span>    - name: IP6      value: <span class="string">&quot;autodetect&quot;</span>    - name: CALICO_IPV4POOL_CIDR      value: <span class="string">&quot;172.16.0.0/12&quot;</span>    - name: CALICO_IPV6POOL_CIDR      value: <span class="string">&quot;fc00:2222::/112&quot;</span>    - name: FELIX_IPV6SUPPORT      value: <span class="string">&quot;true&quot;</span></code></pre><h2 id="4-执行-calico-资源清单"><a href="#4-执行-calico-资源清单" class="headerlink" title="4. 执行 calico 资源清单"></a>4. 执行 calico 资源清单</h2><pre><code class="highlight bash"><span class="comment"># 本地没有公网 IPv6 使用 calico.yaml（在master01节点执行即可）</span>kubectl apply -f calico.yaml<span class="comment"># 本地有公网 IPv6 使用 calico-ipv6.yaml </span><span class="comment"># kubectl apply -f calico-ipv6.yaml </span><span class="comment"># 查看结果：</span>[root@k8s-master01 ~]$ kubectl get pods -n kube-system -o wideNAME                                      READY   STATUS    RESTARTS        AGE     IP              NODE           NOMINATED NODE   READINESS GATEScalico-kube-controllers-8d76c5f9b-485zp   1/1     Running   2 (3m35s ago)   5m31s   172.27.14.192   k8s-node02     &lt;none&gt;           &lt;none&gt;calico-node-d6plz                         1/1     Running   1 (3m52s ago)   5m31s   10.20.1.104     k8s-node01     &lt;none&gt;           &lt;none&gt;calico-node-w6fvl                         1/1     Running   0               5m32s   10.20.1.103     k8s-master03   &lt;none&gt;           &lt;none&gt;calico-node-z7zs2                         1/1     Running   0               5m32s   10.20.1.101     k8s-master01   &lt;none&gt;           &lt;none&gt;calico-node-z8v77                         1/1     Running   1 (3m43s ago)   5m32s   10.20.1.102     k8s-master02   &lt;none&gt;           &lt;none&gt;calico-node-zb9bv                         1/1     Running   1 (4m14s ago)   5m31s   10.20.1.105     k8s-node02     &lt;none&gt;           &lt;none&gt;calico-typha-7cdb5b98f7-d47gx             1/1     Running   0               5m31s   10.20.1.104     k8s-node01     &lt;none&gt;           &lt;none&gt;</code></pre><p><strong>注意：</strong>执行资源清单会自动下载 calico 需要的镜像，这些镜像基本都在国外，下载会很慢，甚至下载不下来。</p><p><strong>解决办法1：</strong>使用国内仓库</p><pre><code class="highlight bash"><span class="comment"># 若docker镜像拉不下来，可以使用国内的仓库</span>sed -i <span class="string">&quot;s#docker.io/calico/#m.daocloud.io/docker.io/calico/#g&quot;</span> calico.yaml sed -i <span class="string">&quot;s#docker.io/calico/#m.daocloud.io/docker.io/calico/#g&quot;</span> calico-ipv6.yamlsed -i <span class="string">&quot;s#m.daocloud.io/docker.io/calico/#docker.io/calico/#g&quot;</span> calico.yaml sed -i <span class="string">&quot;s#m.daocloud.io/docker.io/calico/#docker.io/calico/#g&quot;</span> calico-ipv6.yaml</code></pre><p><strong>解决方法2：</strong>使用代理下载</p><p>参考：<a href="https://georgechan95.github.io/blog/b01d5c62.html">https://georgechan95.github.io/blog/b01d5c62.html</a></p><pre><code class="highlight bash"><span class="comment"># 下载镜像</span>docker pull docker.io/calico/cni:v3.28.0docker pull docker.io/calico/node:v3.28.0docker pull docker.io/calico/kube-controllers:v3.28.0docker pull docker.io/calico/typha:v3.28.0<span class="comment"># 打包</span>docker save docker.io/calico/cni:v3.28.0 -o cni-v3.28.0.tardocker save docker.io/calico/node:v3.28.0 -o node-v3.28.0.tardocker save docker.io/calico/kube-controllers:v3.28.0 -o kube-controllers-v3.28.0.tardocker save docker.io/calico/typha:v3.28.0 -o typha-v3.28.0.tar<span class="comment"># 同步到其它节点</span>user=roothost=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)<span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;host[@]&#125;</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> <span class="variable">$i</span>  rsync -av /opt/software/hak8s/images root@<span class="variable">$i</span>:/opt/software/  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;docker load -i /opt/software/images/calico/cni-v3.28.0.tar&quot;</span>;  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;docker load -i /opt/software/images/calico/node-v3.28.0.tar&quot;</span>;  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;docker load -i /opt/software/images/calico/kube-controllers-v3.28.0.tar&quot;</span>;  ssh <span class="variable">$user</span>@<span class="variable">$i</span> <span class="string">&quot;docker load -i /opt/software/images/calico/typha-v3.28.0.tar&quot;</span>;<span class="keyword">done</span></code></pre><h1 id="九、安装-Core-DNS"><a href="#九、安装-Core-DNS" class="headerlink" title="九、安装 Core DNS"></a>九、安装 Core DNS</h1><p><strong>Helm安装脚本：</strong> <a href="https://github.com/helm/helm/blob/main/scripts/get-helm-3">https://github.com/helm/helm/blob/main/scripts/get-helm-3</a></p><h2 id="1-安装Helm（仅master01）"><a href="#1-安装Helm（仅master01）" class="headerlink" title="1. 安装Helm（仅master01）"></a>1. 安装Helm（仅master01）</h2><p>参考：<a href="https://georgechan95.github.io/blog/d8e3c7b3.html">https://georgechan95.github.io/blog/d8e3c7b3.html</a></p><pre><code class="highlight bash"><span class="comment"># 下载 helm 二进制包</span>$ wget https://get.helm.sh/helm-v3.14.3-linux-amd64.tar.gz<span class="comment"># 解压</span>$ tar -zxvf helm-v3.14.3-linux-amd64.tar.gz<span class="comment"># 安装到bin目录</span>$ <span class="built_in">mv</span> linux-amd64/helm /usr/local/bin/helm<span class="comment"># 查看helm版本</span>$ helm versionversion.BuildInfo&#123;Version:<span class="string">&quot;v3.14.3&quot;</span>, GitCommit:<span class="string">&quot;f03cc04caaa8f6d7c3e67cf918929150cf6f3f12&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, GoVersion:<span class="string">&quot;go1.21.7&quot;</span>&#125;</code></pre><h2 id="2-安装-CoreDns"><a href="#2-安装-CoreDns" class="headerlink" title="2. 安装 CoreDns"></a>2. 安装 CoreDns</h2><h3 id="2-1-下载-CoreDns-安装包"><a href="#2-1-下载-CoreDns-安装包" class="headerlink" title="2.1 下载 CoreDns 安装包"></a>2.1 下载 CoreDns 安装包</h3><pre><code class="highlight bash"><span class="comment"># 添加 coredns 仓库</span>helm repo add coredns https://coredns.github.io/helm<span class="comment"># 查看仓库 coredns 版本</span>helm search repo coredns --versions<span class="comment"># 拉取指定版本的 coredns</span>helm pull coredns/coredns --version 1.45.0<span class="comment"># 解压</span>tar -zxvf /opt/software/coredns-1.45.0.tgz -C /opt/module/</code></pre><h3 id="2-2-编辑配置文件"><a href="#2-2-编辑配置文件" class="headerlink" title="2.2 编辑配置文件"></a>2.2 编辑配置文件</h3><pre><code class="highlight bash"><span class="comment"># 修改IP</span>$ <span class="built_in">cat</span> values.yaml | grep clusterIP: -A 13  clusterIP: <span class="string">&quot;10.96.0.10&quot;</span><span class="comment"># clusterIPs: []</span><span class="comment"># loadBalancerIP: &quot;&quot;</span><span class="comment"># loadBalancerClass: &quot;&quot;</span><span class="comment"># externalIPs: []</span><span class="comment"># externalTrafficPolicy: &quot;&quot;</span><span class="comment"># ipFamilyPolicy: &quot;&quot;</span><span class="comment"># trafficDistribution: PreferClose</span>  <span class="comment"># The name of the Service</span>  <span class="comment"># If not set, a name is generated using the fullname template</span>  name: <span class="string">&quot;&quot;</span>  annotations: &#123;&#125;  <span class="comment"># Pod selector</span>  selector: &#123;&#125;</code></pre><h3 id="2-3-安装-CoreDns"><a href="#2-3-安装-CoreDns" class="headerlink" title="2.3 安装 CoreDns"></a>2.3 安装 CoreDns</h3><p><strong>master01</strong></p><pre><code class="highlight bash">$ helm install coredns /opt/module/coredns/ -n kube-systemNAME: corednsLAST DEPLOYED: Fri Oct 24 13:47:48 2025NAMESPACE: kube-systemSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:CoreDNS is now running <span class="keyword">in</span> the cluster as a cluster-service.It can be tested with the following:1. Launch a Pod with DNS tools:kubectl run -it --<span class="built_in">rm</span> --restart=Never --image=infoblox/dnstools:latest dnstools2. Query the DNS server:/ <span class="comment"># host kubernetes</span></code></pre><blockquote><p><strong>注意事项：</strong></p><p>安装 coredns 会自动从外网下载镜像，这里可能会失败。</p><p>方式一：</p><pre><code class="highlight plaintext"># 修改为国内源 docker源可选sed -i &quot;s#coredns/#m.daocloud.io/docker.io/coredns/#g&quot; values.yamlsed -i &quot;s#registry.k8s.io/#m.daocloud.io/registry.k8s.io/#g&quot; values.yaml</code></pre><p>方式二：代理服务器下载</p><pre><code class="highlight plaintext"># 下载docker pull coredns/coredns:1.13.1docker pull registry.k8s.io/cpa/cluster-proportional-autoscaler:v1.9.0# 打包docker save coredns/coredns:1.13.1 -o coredns-1.13.1.tardocker save registry.k8s.io/cpa/cluster-proportional-autoscaler:v1.9.0 -o cluster-proportional-autoscaler-v1.9.0.tar# 发送到集群解压user=roothost=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)for i in $&#123;host[@]&#125;; do  echo $i  rsync -av /opt/software/hak8s/images root@$i:/opt/software/  ssh $user@$i &quot;docker load -i /opt/software/images/coredns/coredns-1.13.1.tar&quot;;  ssh $user@$i &quot;docker load -i /opt/software/images/coredns/cluster-proportional-autoscaler-v1.9.0.tar&quot;;done</code></pre></blockquote><p><strong>验证 CoreDns</strong></p><pre><code class="highlight bash">$ kubectl get pods -n kube-system -o wide | grep corednscoredns-68746bb699-4mrxl                  1/1     Running   0             11m   172.25.244.193   k8s-master01   &lt;none&gt;           &lt;none&gt;$ kubectl get nodesNAME           STATUS   ROLES    AGE   VERSIONk8s-master01   Ready    &lt;none&gt;   41h   v1.29.2k8s-master02   Ready    &lt;none&gt;   41h   v1.29.2k8s-master03   Ready    &lt;none&gt;   41h   v1.29.2k8s-node01     Ready    &lt;none&gt;   41h   v1.29.2k8s-node02     Ready    &lt;none&gt;   41h   v1.29.2</code></pre><h1 id="十、安装-Metrics-Server"><a href="#十、安装-Metrics-Server" class="headerlink" title="十、安装 Metrics Server"></a>十、安装 Metrics Server</h1><p>官方文档：<a href="https://github.com/kubernetes-sigs/metrics-server/releases/tag/v0.7.1">https://github.com/kubernetes-sigs/metrics-server/releases/tag/v0.7.1</a></p><h2 id="1-下载-metrics-server-资源清单"><a href="#1-下载-metrics-server-资源清单" class="headerlink" title="1. 下载 metrics-server 资源清单"></a>1. 下载 metrics-server 资源清单</h2><p><strong>master01</strong></p><pre><code class="highlight bash"><span class="comment"># 创建文件夹</span><span class="built_in">mkdir</span> -p /opt/module/metrics-server<span class="built_in">cd</span> /opt/module/metrics-server<span class="comment"># 下载资源清单</span>wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.7.1/components.yaml</code></pre><h2 id="2-编辑-components-yaml"><a href="#2-编辑-components-yaml" class="headerlink" title="2. 编辑 components.yaml"></a>2. 编辑 components.yaml</h2><pre><code class="highlight bash"><span class="comment"># 修改配置</span>vim components.yaml---<span class="comment"># 1</span>- args:        - --cert-dir=/tmp        - --secure-port=10250        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname        - --kubelet-use-node-status-port        - --metric-resolution=15s        - --kubelet-insecure-tls        - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem        - --requestheader-username-headers=X-Remote-User        - --requestheader-group-headers=X-Remote-Group        - --requestheader-extra-headers-prefix=X-Remote-Extra-<span class="comment"># 2</span>        volumeMounts:        - mountPath: /tmp          name: tmp-dir        - name: ca-ssl          mountPath: /etc/kubernetes/pki<span class="comment"># 3</span>      volumes:      - emptyDir: &#123;&#125;        name: tmp-dir      - name: ca-ssl        hostPath:          path: /etc/kubernetes/pki---</code></pre><h2 id="3-部署-metrics-server"><a href="#3-部署-metrics-server" class="headerlink" title="3. 部署 metrics-server"></a>3. 部署 metrics-server</h2><pre><code class="highlight bash">$ kubectl apply -f /opt/module/metrics-server/components.yaml</code></pre><blockquote><p><strong>注意事项：</strong></p><p>安装 metrics-server 会自动从外网下载镜像，这里可能会失败。</p><p>方式一：</p><pre><code class="highlight plaintext"># 修改为国内源 docker源可选sed -i &quot;s#registry.k8s.io/#m.daocloud.io/registry.k8s.io/#g&quot; *.yaml</code></pre><p>方式二：代理服务器下载</p><pre><code class="highlight plaintext"># 下载docker pull registry.k8s.io/metrics-server/metrics-server:v0.7.1# 打包docker save registry.k8s.io/metrics-server/metrics-server:v0.7.1 -o metrics-server-v0.7.1.tar# 发送到集群解压user=roothost=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)for i in $&#123;host[@]&#125;; do  echo $i  rsync -av /opt/software/hak8s/images root@$i:/opt/software/  ssh $user@$i &quot;docker load -i /opt/software/images/metrics-server/metrics-server-v0.7.1.tar&quot;;done</code></pre></blockquote><p><strong>验证部署</strong></p><pre><code class="highlight bash">$ kubectl get pods -n kube-system | grep metrics-servermetrics-server-6d4cb7955c-688pj           1/1     Running   0             2m10s$ kubectl  top nodeNAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   k8s-master01   77m          3%     2168Mi          61%       k8s-master02   101m         5%     1499Mi          42%       k8s-master03   114m         5%     1594Mi          44%       k8s-node01     46m          2%     960Mi           27%       k8s-node02     48m          2%     924Mi           26%</code></pre><h1 id="十一、安装Dashboard"><a href="#十一、安装Dashboard" class="headerlink" title="十一、安装Dashboard"></a>十一、安装Dashboard</h1><p><strong>仅在 master01 操作</strong></p><h2 id="1-下载并执行-dashboard-资源清单"><a href="#1-下载并执行-dashboard-资源清单" class="headerlink" title="1. 下载并执行 dashboard 资源清单"></a>1. 下载并执行 dashboard 资源清单</h2><pre><code class="highlight bash"><span class="comment"># 下载资源清单</span>wget https://raw.githubusercontent.com/kubernetes/dashboard/refs/tags/v2.7.0/aio/deploy/recommended.yaml<span class="comment"># 修改镜像拉取策略</span>$ vim /opt/module/dashboard/recommended.yamlimagePullPolicy: IfNotPresent<span class="comment"># 执行资源清单</span>$ kubectl apply -f /opt/module/dashboard/recommended.yaml<span class="comment"># 查看 Pod</span>$ kubectl get pod -n kubernetes-dashboard -o wideNAME                                         READY   STATUS    RESTARTS   AGE   IP             NODE           NOMINATED NODE   READINESS GATESdashboard-metrics-scraper-5657497c4c-v5jlt   1/1     Running   0          36s   172.18.195.2   k8s-master03   &lt;none&gt;           &lt;none&gt;kubernetes-dashboard-5b749d9495-ns6q2        1/1     Running   0          43s   172.25.92.71   k8s-master02   &lt;none&gt;           &lt;none&gt;</code></pre><blockquote><p>命令解析：</p><p>需提前下载好镜像文件</p><pre><code class="highlight plaintext">docker pull kubernetesui/dashboard:v2.7.0docker pull kubernetesui/metrics-scraper:v1.0.8docker save kubernetesui/dashboard:v2.7.0 -o dashboard-v2.7.0.tardocker save kubernetesui/metrics-scraper:v1.0.8 -o metrics-scraper-v1.0.8.taruser=roothost=(k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02)for i in $&#123;host[@]&#125;; do  echo $i  rsync -av /opt/software/hak8s/images root@$i:/opt/software/  ssh $user@$i &quot;docker load -i /opt/software/images/dashboard/dashboard-v2.7.0.tar&quot;;  ssh $user@$i &quot;docker load -i /opt/software/images/dashboard/metrics-scraper-v1.0.8.tar&quot;;done</code></pre></blockquote><h2 id="2-创建-ServiceAccount"><a href="#2-创建-ServiceAccount" class="headerlink" title="2. 创建 ServiceAccount"></a>2. 创建 ServiceAccount</h2><pre><code class="highlight bash"><span class="built_in">mkdir</span> -p /opt/module/dashboard/<span class="comment"># 创建 ServiceAccount</span><span class="built_in">cat</span> &gt; /opt/module/dashboard/dashboard-user.yaml &lt;&lt; <span class="string">EOF</span><span class="string">apiVersion: v1</span><span class="string">kind: ServiceAccount</span><span class="string">metadata:</span><span class="string">  name: admin-user</span><span class="string">  namespace: kubernetes-dashboard</span><span class="string">---</span><span class="string">apiVersion: rbac.authorization.k8s.io/v1</span><span class="string">kind: ClusterRoleBinding</span><span class="string">metadata:</span><span class="string">  name: admin-user</span><span class="string">roleRef:</span><span class="string">  apiGroup: rbac.authorization.k8s.io</span><span class="string">  kind: ClusterRole</span><span class="string">  name: cluster-admin</span><span class="string">subjects:</span><span class="string">- kind: ServiceAccount</span><span class="string">  name: admin-user</span><span class="string">  namespace: kubernetes-dashboard</span><span class="string">EOF</span><span class="comment"># 执行资源清单，创建SA</span>kubectl apply -f /opt/module/dashboard/dashboard-user.yaml<span class="comment"># 验证</span>$ kubectl get serviceaccount -A | grep admin-userkubernetes-dashboard   admin-user                             0         57s</code></pre><blockquote><p><strong>命令解析：</strong></p><p>在 Kubernetes 集群中为 Dashboard 创建一个具有管理员权限的 ServiceAccount（服务账户），并通过 ClusterRoleBinding（集群角色绑定）授予其全集群管理权限（cluster-admin）。这是为了方便通过 Token 方式登录 Dashboard 进行集群管理，而非使用默认的有限权限账户。整个过程是标准的 Kubernetes RBAC（基于角色的访问控制）配置，适用于二进制部署的集群。</p></blockquote><h2 id="3-更改-dashboard-的-svc-为-NodePort"><a href="#3-更改-dashboard-的-svc-为-NodePort" class="headerlink" title="3. 更改 dashboard 的 svc 为 NodePort"></a>3. 更改 dashboard 的 svc 为 NodePort</h2><pre><code class="highlight bash">$ kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard...  sessionAffinity: None  <span class="built_in">type</span>: NodePort <span class="comment"># 将Cluster为NodePort</span>status:  loadBalancer: &#123;&#125;  <span class="comment"># 保存后，验证</span>$ kubectl get svc kubernetes-dashboard -n kubernetes-dashboard -o wideNAME                   TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE   SELECTORkubernetes-dashboard   NodePort   10.101.243.82   &lt;none&gt;        443:30892/TCP   91s   k8s-app=kubernetes-dashboard</code></pre><h2 id="4-创建-token-访问"><a href="#4-创建-token-访问" class="headerlink" title="4. 创建 token 访问"></a>4. 创建 token 访问</h2><pre><code class="highlight bash">$ kubectl -n kubernetes-dashboard create token admin-usereyJhbGciOiJSUzI1NiIsImtpZCI6IjVRcWNxMUt1ZzZsN3RoeTBHUzd4VzFGbktIZDBIZUNJazllQVFqdy1aSTgifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNzYxNjU5MTM1LCJpYXQiOjE3NjE2NTU1MzUsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJhZG1pbi11c2VyIiwidWlkIjoiY2ZiNTA5MmYtMGY0My00OTllLTg1MzItOTM0YTljMDY0YTJmIn19LCJuYmYiOjE3NjE2NTU1MzUsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDphZG1pbi11c2VyIn0.oHvY4JRIRoNXr_DK2wnIWEo-yQ6KLAXL4kuAxVfY-BfU6o_kI90MzG1N9t8t4HAplzXQcg_v-m4RsMyu63dy96h49WVj6Zp6WbmI2bUmeg7VgBmm43BReO-lKPdWfqUxEJ2Yt2fLSl4CbNuLyKgNxOUtJT_RDz1l_OBgFx23uNs7QrJ42miuJnkgDSXnS0_2VCyLbGYALSgWSZKXeWdjQUL-k40GghOj5I2-HEGld0j9fcl0ASiFEOuNWstP0PKZoO1qPJNrsVtqHM5PiNbhHzU6b60-sJO9keJY8K0ORdNjbTt857I3NIiAklBXsJY4dT8BOaesefa7TvBMHSFgNQ</code></pre><p>复制生成的token: eyJhbGciOiJSU…..</p><p>浏览器访问宿主机地址：<a href="https://10.20.1.101:30892/#/login">https://10.20.1.101:30892/#/login</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/28/20251028-204641.png" alt="登录 DashBoard"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/10/28/20251028-204754.png" alt="查看Pod"></p><h1 id="十二、安装命令补全"><a href="#十二、安装命令补全" class="headerlink" title="十二、安装命令补全"></a>十二、安装命令补全</h1><p><strong>所有节点</strong></p><pre><code class="highlight bash">yum install bash-completion -y<span class="built_in">source</span> /usr/share/bash-completion/bash_completion<span class="built_in">source</span> &lt;(kubectl completion bash)<span class="built_in">echo</span> <span class="string">&quot;source &lt;(kubectl completion bash)&quot;</span> &gt;&gt; ~/.bashrc</code></pre><h1 id="十三、高可用验证"><a href="#十三、高可用验证" class="headerlink" title="十三、高可用验证"></a>十三、高可用验证</h1><h2 id="1-组件状态验证"><a href="#1-组件状态验证" class="headerlink" title="1. 组件状态验证"></a>1. 组件状态验证</h2><p><strong>验证ETCD状态</strong></p><pre><code class="highlight bash"><span class="comment"># 确认 etcd 高可用</span>$ etcdctl --endpoints=<span class="string">&quot;10.20.1.101:2379,10.20.1.102:2379,10.20.1.103:2379&quot;</span> --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem --cert=/etc/kubernetes/pki/etcd/etcd.pem --key=/etc/kubernetes/pki/etcd/etcd-key.pem  endpoint status --write-out=table+------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+|     ENDPOINT     |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |+------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+| 10.20.1.101:2379 | adb2616df23a8bc4 |  3.5.16 |  7.0 MB |     <span class="literal">false</span> |      <span class="literal">false</span> |        39 |    1893807 |            1893807 |        || 10.20.1.102:2379 | 4039909ce7f85a53 |  3.5.16 |  7.0 MB |     <span class="literal">false</span> |      <span class="literal">false</span> |        39 |    1893807 |            1893807 |        || 10.20.1.103:2379 | eee0233fd4f83d74 |  3.5.16 |  6.7 MB |      <span class="literal">true</span> |      <span class="literal">false</span> |        39 |    1893807 |            1893807 |        |+------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</code></pre><p><strong>集群健康状态</strong></p><pre><code class="highlight bash">[root@k8s-master01 ~]$ kubectl get csWarning: v1 ComponentStatus is deprecated <span class="keyword">in</span> v1.19+NAME                 STATUS    MESSAGE   ERRORscheduler            Healthy   ok        controller-manager   Healthy   ok        etcd-0               Healthy   ok[root@k8s-master01 ~]$ kubectl get nodesNAME           STATUS   ROLES    AGE   VERSIONk8s-master01   Ready    &lt;none&gt;   6d    v1.29.2k8s-master02   Ready    &lt;none&gt;   6d    v1.29.2k8s-master03   Ready    &lt;none&gt;   6d    v1.29.2k8s-node01     Ready    &lt;none&gt;   6d    v1.29.2k8s-node02     Ready    &lt;none&gt;   6d    v1.29.2</code></pre><h2 id="2-使用-dnstools-测试"><a href="#2-使用-dnstools-测试" class="headerlink" title="2. 使用 dnstools 测试"></a>2. 使用 dnstools 测试</h2><pre><code class="highlight bash">$ kubectl run -it --<span class="built_in">rm</span> --restart=Never --image=infoblox/dnstools:v3 dnstoolsdnstools<span class="comment"># host kubernetes</span>kubernetes.default.svc.cluster.local has address 10.96.0.1dnstools<span class="comment"># dig kubernetes.default.svc.cluster.local</span>; &lt;&lt;&gt;&gt; DiG 9.11.3 &lt;&lt;&gt;&gt; kubernetes.default.svc.cluster.local;; global options: +cmd;; Got answer:;; WARNING: .<span class="built_in">local</span> is reserved <span class="keyword">for</span> Multicast DNS;; You are currently testing what happens when an mDNS query is leaked to DNS;; -&gt;&gt;HEADER&lt;&lt;- <span class="string">opcode: QUERY, status: NOERROR, id: 45690</span><span class="string">;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1</span><span class="string">;; WARNING: recursion requested but not available</span><span class="string"></span><span class="string">;; OPT PSEUDOSECTION:</span><span class="string">; EDNS: version: 0, flags:; udp: 4096</span><span class="string">; COOKIE: 39b672283592d58b (echoed)</span><span class="string">;; QUESTION SECTION:</span><span class="string">;kubernetes.default.svc.cluster.local. IN A</span><span class="string"></span><span class="string">;; ANSWER SECTION:</span><span class="string">kubernetes.default.svc.cluster.local. 20 IN A10.96.0.1</span><span class="string"></span><span class="string">;; Query time: 0 msec</span><span class="string">;; SERVER: 10.96.0.10#53(10.96.0.10)</span><span class="string">;; WHEN: Thu Oct 30 06:56:34 UTC 2025</span><span class="string">;; MSG SIZE  rcvd: 129</span></code></pre><h2 id="3-Nginx-部署测试"><a href="#3-Nginx-部署测试" class="headerlink" title="3. Nginx 部署测试"></a>3. Nginx 部署测试</h2><p><strong>资源清单：</strong> nginx-test.yaml</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">3</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.3</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span>    <span class="comment"># 修正：必须是 Pod 实际监听的端口号</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">nodePort:</span> <span class="number">30339</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">myapp</span></code></pre><p><strong>执行资源清单：</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f nginx-test.yaml<span class="comment"># 查看 Service</span>$ kubectl get svc NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGEkubernetes   ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP        8dnginx-svc    NodePort    10.98.200.91   &lt;none&gt;        80:30339/TCP   3h21m<span class="comment"># 查看 Deployment</span>$ kubectl get deploy -o wideNAME    READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES         SELECTORnginx   3/3     3            3           3h21m   nginx        nginx:1.29.3   app=myapp<span class="comment"># 查看Pod</span>$ kubectl get pods -o wideNAME                    READY   STATUS    RESTARTS      AGE     IP               NODE           NOMINATED NODE   READINESS GATESbusybox                 1/1     Running   3 (17m ago)   3h18m   172.25.92.67     k8s-master02   &lt;none&gt;           &lt;none&gt;nginx-6594975dd-fds78   1/1     Running   0             3h21m   172.18.195.2     k8s-master03   &lt;none&gt;           &lt;none&gt;nginx-6594975dd-pvkt8   1/1     Running   0             3h21m   172.27.14.193    k8s-node02     &lt;none&gt;           &lt;none&gt;nginx-6594975dd-v96mx   1/1     Running   0             3h21m   172.25.244.199   k8s-master01   &lt;none&gt;           &lt;none&gt;ubuntu-test             1/1     Running   0             8m54s   172.25.244.204   k8s-master01   &lt;none&gt;           &lt;none&gt;</code></pre><p><strong>网络测试</strong></p><pre><code class="highlight bash">$ kubectl <span class="built_in">exec</span> -it nginx-6594975dd-fds78 -- /bin/bashroot@nginx-6594975dd-fds78:/<span class="comment"># curl -k https://10.96.0.1:443</span>&#123;  <span class="string">&quot;kind&quot;</span>: <span class="string">&quot;Status&quot;</span>,  <span class="string">&quot;apiVersion&quot;</span>: <span class="string">&quot;v1&quot;</span>,  <span class="string">&quot;metadata&quot;</span>: &#123;&#125;,  <span class="string">&quot;status&quot;</span>: <span class="string">&quot;Failure&quot;</span>,  <span class="string">&quot;message&quot;</span>: <span class="string">&quot;forbidden: User \&quot;system:anonymous\&quot; cannot get path \&quot;/\&quot;&quot;</span>,  <span class="string">&quot;reason&quot;</span>: <span class="string">&quot;Forbidden&quot;</span>,  <span class="string">&quot;details&quot;</span>: &#123;&#125;,  <span class="string">&quot;code&quot;</span>: 403&#125;</code></pre><blockquote><p>说明：</p><ul><li>Pod 网络到 <strong>Kubernetes API Server</strong> 是通的。</li><li>返回 403 而不是超时或连接失败，说明请求已经到达 API Server。</li><li>403 的原因是你没有提供认证信息（anonymous user），这是正常的，如果只是测试网络，不需要担心。</li></ul></blockquote><h2 id="4-Ubuntu-镜像部署测试"><a href="#4-Ubuntu-镜像部署测试" class="headerlink" title="4. Ubuntu 镜像部署测试"></a>4. Ubuntu 镜像部署测试</h2><h3 id="3-1-部署-NetworkPolicy"><a href="#3-1-部署-NetworkPolicy" class="headerlink" title="3.1 部署 NetworkPolicy"></a>3.1 部署 NetworkPolicy</h3><p>默认 Kubernates 集群 Pod 不能直连外网，需要网络策略允许，这里部署一个 NetworkPolicy 让Pod 可以访问外网</p><p><strong>网络策略资源清单：</strong> <code>NetworkPolicy.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">allow-coredns-egress</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">k8s-app:</span> <span class="string">coredns</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span>  <span class="attr">egress:</span>  <span class="bullet">-</span> <span class="attr">to:</span>    <span class="bullet">-</span> <span class="attr">ipBlock:</span>        <span class="attr">cidr:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">/0</span>  <span class="comment"># 外部DNS</span>    <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">UDP</span>      <span class="attr">port:</span> <span class="number">53</span>    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">port:</span> <span class="number">53</span>  <span class="bullet">-</span> <span class="attr">to:</span>    <span class="bullet">-</span> <span class="attr">ipBlock:</span>        <span class="attr">cidr:</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span><span class="string">/12</span>  <span class="comment"># 服务CIDR (API ClusterIP)</span>    <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">port:</span> <span class="number">443</span>  <span class="bullet">-</span> <span class="attr">to:</span>    <span class="bullet">-</span> <span class="attr">ipBlock:</span>        <span class="attr">cidr:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.0</span><span class="string">/24</span>  <span class="comment"># Master节点IP范围 (API后端端口)</span>    <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">port:</span> <span class="number">8443</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f NetworkPolicy.yaml</code></pre><h3 id="3-2-部署-Ubuntu-Pod"><a href="#3-2-部署-Ubuntu-Pod" class="headerlink" title="3.2 部署 Ubuntu Pod"></a>3.2 部署 Ubuntu Pod</h3><pre><code class="highlight bash"><span class="comment"># 运行 Ubuntu Pod</span>$ kubectl run -it --<span class="built_in">rm</span> --restart=Never --image=ubuntu:22.04 ubuntu-test -- bash<span class="comment"># 替换阿里云源</span><span class="built_in">cat</span> &gt; /etc/apt/sources.list &lt;&lt; <span class="string">&quot;EOF&quot;</span>deb http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverseEOF<span class="comment"># 下载工具</span>apt update -yapt install -y iputils-ping dnsutils curl netcat</code></pre><p><strong>测试网络1</strong></p><pre><code class="highlight bash">root@ubuntu-test:/<span class="comment"># nslookup kubernetes.default.svc.cluster.local</span>;; Got recursion not available from 10.96.0.10;; Got recursion not available from 10.96.0.10;; Got recursion not available from 10.96.0.10;; Got recursion not available from 10.96.0.10Server:10.96.0.10Address:10.96.0.10<span class="comment">#53</span>Name:kubernetes.default.svc.cluster.localAddress: 10.96.0.1;; Got recursion not available from 10.96.0.10</code></pre><p>结论：DNS 解析成功</p><p><strong>测试网络2</strong></p><pre><code class="highlight bash">root@ubuntu-test:/<span class="comment"># dig kubernetes.default.svc.cluster.local</span>; &lt;&lt;&gt;&gt; DiG 9.18.39-0ubuntu0.22.04.2-Ubuntu &lt;&lt;&gt;&gt; kubernetes.default.svc.cluster.local;; global options: +cmd;; Got answer:;; WARNING: .<span class="built_in">local</span> is reserved <span class="keyword">for</span> Multicast DNS;; You are currently testing what happens when an mDNS query is leaked to DNS;; -&gt;&gt;HEADER&lt;&lt;- <span class="string">opcode: QUERY, status: NOERROR, id: 31061</span><span class="string">;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1</span><span class="string">;; WARNING: recursion requested but not available</span><span class="string"></span><span class="string">;; OPT PSEUDOSECTION:</span><span class="string">; EDNS: version: 0, flags:; udp: 1232</span><span class="string">; COOKIE: 3bdf10d9d00e32a3 (echoed)</span><span class="string">;; QUESTION SECTION:</span><span class="string">;kubernetes.default.svc.cluster.local. IN A</span><span class="string"></span><span class="string">;; ANSWER SECTION:</span><span class="string">kubernetes.default.svc.cluster.local. 30 IN A10.96.0.1</span><span class="string"></span><span class="string">;; Query time: 1 msec</span><span class="string">;; SERVER: 10.96.0.10#53(10.96.0.10) (UDP)</span><span class="string">;; WHEN: Thu Oct 30 06:37:24 UTC 2025</span><span class="string">;; MSG SIZE  rcvd: 129</span></code></pre><p>结论：DNS 解析成功</p><p><strong>其它测试</strong></p><pre><code class="highlight bash"><span class="comment"># TCP 连接 443# # TCP 连接 443</span>root@ubuntu-test:/<span class="comment"># nc -zv 10.96.0.1 443</span>Connection to 10.96.0.1 443 port [tcp/*] succeeded!<span class="comment"># 或 curl</span>root@ubuntu-test:/<span class="comment"># curl -k https://10.96.0.1:443</span>&#123;  <span class="string">&quot;kind&quot;</span>: <span class="string">&quot;Status&quot;</span>,  <span class="string">&quot;apiVersion&quot;</span>: <span class="string">&quot;v1&quot;</span>,  <span class="string">&quot;metadata&quot;</span>: &#123;&#125;,  <span class="string">&quot;status&quot;</span>: <span class="string">&quot;Failure&quot;</span>,  <span class="string">&quot;message&quot;</span>: <span class="string">&quot;forbidden: User \&quot;system:anonymous\&quot; cannot get path \&quot;/\&quot;&quot;</span>,  <span class="string">&quot;reason&quot;</span>: <span class="string">&quot;Forbidden&quot;</span>,  <span class="string">&quot;details&quot;</span>: &#123;&#125;,  <span class="string">&quot;code&quot;</span>: 403&#125;</code></pre><p><strong>参考链接</strong></p><blockquote><p><a href="https://cloudmessage.top/archives/kubernetes-1292calicorockylinux92-gao-ke-yong-dockercri-docker-er-jin-zhi-bu-shu">https://cloudmessage.top/archives/kubernetes-1292calicorockylinux92-gao-ke-yong-dockercri-docker-er-jin-zhi-bu-shu</a></p><p><a href="https://www.sundayhk.com/597.html">https://www.sundayhk.com/597.html</a></p><p><a href="https://github.com/cby-chen/Kubernetes/blob/main/doc/v1.29.2-CentOS-binary-install-IPv6-IPv4-Three-Masters-Two-Slaves-Offline.md">https://github.com/cby-chen/Kubernetes/blob/main/doc/v1.29.2-CentOS-binary-install-IPv6-IPv4-Three-Masters-Two-Slaves-Offline.md</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、系统环境&quot;&gt;&lt;a href=&quot;#一、系统环境&quot; class=&quot;headerlink&quot; title=&quot;一、系统环境&quot;&gt;&lt;/a&gt;一、系统环境&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;操作系统：Rocky Linux 9.3&lt;/li&gt;
&lt;li&gt;内核版本：5.14.0-284.11</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Etcd" scheme="https://georgechan95.github.io/tags/Etcd/"/>
    
  </entry>
  
  <entry>
    <title>024-K8S-Etcd的备份与恢复</title>
    <link href="https://georgechan95.github.io/blog/7a3c8be2.html"/>
    <id>https://georgechan95.github.io/blog/7a3c8be2.html</id>
    <published>2025-09-14T09:30:00.000Z</published>
    <updated>2025-09-17T12:57:01.140Z</updated>
    
    <content type="html"><![CDATA[<p><strong>集群环境</strong></p><p>使用 kubeadmin 安装，Etcd 为单节点</p><table><thead><tr><th>IP</th><th>Hostname</th><th>用途</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td><td>Master节点</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td><td>Node节点</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td><td>Node节点</td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td><td>Node节点</td></tr></tbody></table><h1 id="一、ETCD简介"><a href="#一、ETCD简介" class="headerlink" title="一、ETCD简介"></a>一、ETCD简介</h1><p>ETCD用于共享和配置服务发现的分布式，一致性的KV存储系统。 ETCD是CoreOS公司发起的一个开源项目，授权协议为Apache。</p><p>ETCD 存储 k8s 所有数据信息</p><p>ETCD 是 k8s 集群极为重要的一块服务，存储了集群所有的数据信息。同理，如果发生灾难或者 etcd 的数据丢失，都会影响集群数据的恢复。因此需要对 ETCD 数据进行备份，当集群发生崩溃或数据丢失时，可使用备份的数据对集群进行恢复操作。</p><h1 id="二、使用-etcdctl-实现数据的备份和恢复"><a href="#二、使用-etcdctl-实现数据的备份和恢复" class="headerlink" title="二、使用 etcdctl 实现数据的备份和恢复"></a>二、使用 etcdctl 实现数据的备份和恢复</h1><h2 id="1-kubeadmin-安装方式"><a href="#1-kubeadmin-安装方式" class="headerlink" title="1. kubeadmin 安装方式"></a>1. kubeadmin 安装方式</h2><p>当前集群使用 kubeadmin 安装，Etcd 为单节点服务。</p><h3 id="1-1-拷贝-etcdctl-至-master-节点"><a href="#1-1-拷贝-etcdctl-至-master-节点" class="headerlink" title="1.1 拷贝 etcdctl 至 master 节点"></a>1.1 拷贝 etcdctl 至 master 节点</h3><p>etcdctl 工具服务器默认是没有安装的，需要从容器中拷贝到宿主机上。</p><pre><code class="highlight bash"><span class="comment"># 从容器中拷贝 etcdctl 工具到宿主机</span>$ docker <span class="built_in">cp</span> $(docker ps  |  grep -v etcd-mirror | grep -w etcd | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>):/usr/local/bin/etcdctl /usr/bin/Successfully copied 17.9MB to /usr/bin/<span class="comment"># 验证，查看 etcdctl 版本</span>$ etcdctl versionetcdctl version: 3.5.16API version: 3.5</code></pre><h3 id="1-2-基于-ETCD-v3-接口实现数据备份"><a href="#1-2-基于-ETCD-v3-接口实现数据备份" class="headerlink" title="1.2  基于 ETCD v3 接口实现数据备份"></a>1.2  基于 ETCD v3 接口实现数据备份</h3><pre><code class="highlight bash"><span class="comment"># 备份 etcd 数据至 root 目录下</span>$ ETCDCTL_API=3 etcdctl --endpoints=<span class="string">&quot;https://10.20.1.139:2379&quot;</span>  --cert=<span class="string">&quot;/etc/kubernetes/pki/etcd/server.crt&quot;</span>  --key=<span class="string">&quot;/etc/kubernetes/pki/etcd/server.key&quot;</span>  --cacert=<span class="string">&quot;/etc/kubernetes/pki/etcd/ca.crt&quot;</span>   snapshot save /root/snap-$(<span class="built_in">date</span> +%Y%m%d%H%M).db<span class="comment"># 查看备份的文件</span>$ ll /root/snap-202509141757.db -rw------- 1 root root 9199648 Sep 14 17:57 /root/snap-202509141757.db</code></pre><h3 id="1-3-恢复-etcd-数据"><a href="#1-3-恢复-etcd-数据" class="headerlink" title="1.3 恢复 etcd 数据"></a>1.3 恢复 etcd 数据</h3><p>未防止在数据恢复的过程中存在干扰导致数据恢复失败，在执行恢复操作前，需要先停止 etcd 和 apiServer </p><pre><code class="highlight bash"><span class="comment"># 查看 manifest 目录内容</span>$ ll /etc/kubernetes/manifeststotal 16-rw------- 1 root root 2427 Jul 27 16:32 etcd.yaml-rw------- 1 root root 4006 Aug 11 10:13 kube-apiserver.yaml-rw------- 1 root root 2799 Jul 27 16:32 kube-controller-manager.yaml-rw------- 1 root root 1499 Jul 27 16:32 kube-scheduler.yaml<span class="comment"># 移动 manifest 目录，etcd 和 apiServer 会自动停止运行</span>$ <span class="built_in">mv</span> /etc/kubernetes/manifests /etc/kubernetes/manifests-bak</code></pre><p>在恢复前为了能看到 etcd 的恢复效果，这里先把 etcd 数据库内容移除</p><pre><code class="highlight bash">$ <span class="built_in">mv</span> /data/etcd/ /data/etcd-back &amp;&amp; <span class="built_in">mkdir</span> /data/etcd &amp;&amp; <span class="built_in">chmod</span>  700 /data/etcd<span class="comment"># 默认etcd 目录在 /var/lib/etcd , /data/etcd 目录是在集群初始化时（kubeadm init --config /opt/software/kubeadm-config.yaml --upload-certs）修改的路径</span></code></pre><p>恢复 etcd 数据</p><pre><code class="highlight bash"><span class="comment"># 执行命令，讲备份的etcd 数据还原到集群中</span>$ ETCDCTL_API=3 etcdctl --endpoints=<span class="string">&quot;https://10.20.1.139:2379&quot;</span>  --cert=<span class="string">&quot;/etc/kubernetes/pki/etcd/server.crt&quot;</span>  --key=<span class="string">&quot;/etc/kubernetes/pki/etcd/server.key&quot;</span>  --cacert=<span class="string">&quot;/etc/kubernetes/pki/etcd/ca.crt&quot;</span>   snapshot restore /root/snap-202509141757.db<span class="comment"># 启动 etcd 和 api-server</span>$ <span class="built_in">mv</span> /etc/kubernetes/manifests-bak /etc/kubernetes/manifests</code></pre><p>再次查看集群</p><pre><code class="highlight bash">$ kubectl get pods -ANAMESPACE       NAME                                       READY   STATUS             RESTARTS         AGEingress-nginx   ingress-nginx-controller-79sh6             1/1     Running            0                49dingress-nginx   ingress-nginx-controller-cv9bj             1/1     Running            0                49dingress-nginx   ingress-nginx-controller-sg989             1/1     Running            0                49dkube-system     calico-kube-controllers-76dfd7b977-g9sxh   1/1     Running            7 (4m23s ago)    2d6hkube-system     calico-node-45x9j                          1/1     Running            0                49dkube-system     calico-node-8rmt5                          1/1     Running            0                49dkube-system     calico-node-fzs4f                          1/1     Running            0                49dkube-system     calico-node-zhnlk                          1/1     Running            0                49dkube-system     calico-typha-5b56944f9b-6gd7p              1/1     Running            0                49dkube-system     coredns-5c988c55b8-ckqnf                   1/1     Running            0                2d6hkube-system     coredns-5c988c55b8-ljzxf                   1/1     Running            0                2d6hkube-system     etcd-k8s-master01                          1/1     Running            0                49dkube-system     kube-apiserver-k8s-master01                1/1     Running            0                34dkube-system     kube-controller-manager-k8s-master01       1/1     Running            0                49dkube-system     kube-proxy-9qk4c                           1/1     Running            0                49dkube-system     kube-proxy-bm6rt                           1/1     Running            0                49dkube-system     kube-proxy-dwz4c                           1/1     Running            0                49dkube-system     kube-proxy-vsl77                           1/1     Running            0                49dkube-system     kube-scheduler-k8s-master01                1/1     Running            0                49dkube-system     metrics-server-784f4d97b8-88pfh            1/1     Running            0                2d6hnfs-storage     nfs-client-provisioner-58998fc8b5-dh7w2    0/1     CrashLoopBackOff   54 (5m11s ago)   49dtest-quota      test-deploy-5587d8c7c4-7b6fj               1/1     Running            0                2d7h</code></pre><p>数据都已恢复回来。</p><h2 id="2-二进制集群安装方式"><a href="#2-二进制集群安装方式" class="headerlink" title="2. 二进制集群安装方式"></a>2. 二进制集群安装方式</h2><h3 id="2-1-备份-etcd"><a href="#2-1-备份-etcd" class="headerlink" title="2.1 备份 etcd"></a>2.1 备份 etcd</h3><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y etcd</span></code></pre><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">ETCDCTL_API=3  etcdctl snapshot save snap.20240422.db --cacert=/etc/etcd/ssl/ca.pem --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem --endpoints=<span class="string">&quot;https://192.168.66.11:2379&quot;</span></span></code></pre><h3 id="2-2-etcd-数据库还原"><a href="#2-2-etcd-数据库还原" class="headerlink" title="2.2 etcd 数据库还原"></a>2.2 etcd 数据库还原</h3><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">systemctl stop kube-apiserver</span><span class="meta prompt_">$ </span><span class="language-bash">systemctl stop etcd</span><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> /var/lib/etcd/default.etcd /var/lib/etcd/default.etcd.bak</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看数据库路径</span><span class="meta prompt_"># </span><span class="language-bash">systemctl <span class="built_in">cat</span> etcd.service</span><span class="meta prompt_"> </span><span class="meta prompt_">$ </span><span class="language-bash">ETCDCTL_API=3 etcdctl snapshot restore /data/backup/etcd-snapshot-previous.db --data-dir=/var/lib/etcd/default.etcd</span><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chown</span> -R etcd:etcd /var/lib/etcd</span><span class="meta prompt_">$ </span><span class="language-bash">systemctl start kube-apiserver</span><span class="meta prompt_">$ </span><span class="language-bash">systemctl start etcd.service</span></code></pre><h1 id="三、使用-velero-实现数据的备份和恢复"><a href="#三、使用-velero-实现数据的备份和恢复" class="headerlink" title="三、使用 velero 实现数据的备份和恢复"></a>三、使用 velero 实现数据的备份和恢复</h1><h2 id="1-Velero简介"><a href="#1-Velero简介" class="headerlink" title="1. Velero简介"></a>1. Velero简介</h2><p>Velero 是 vmware 开源的一个云原生的灾难恢复和迁移工具，它本身也是开源的,采用Go语言编写，可以安全的备份、恢复和迁移 Kubernetes 集群资源数据；官网 <a href="https://www.cnblogs.com/qiuhom-1874/p/17670945.html">https://velero.io/</a> 。Velero 是西班牙语意思是帆船，非常符合 Kubernetes 社区的命名风格，Velero 的开发公司 Heptio，已被 VMware 收购。Velero 支持标准的 K8S 集群，既可以是私有云平台也可以是公有云，除了灾备之外它还能做资源移转，支持把容器应用从一个集群迁移到另一个集群。Velero 的工作方式就是把kubernetes 中的数据备份到对象存储以实现高可用和持久化，默认的备份保存时间为720小时，并在需要的时候进行下载和恢复。</p><h2 id="2-Velero-与-etcd-快照备份的区别"><a href="#2-Velero-与-etcd-快照备份的区别" class="headerlink" title="2. Velero 与 etcd 快照备份的区别"></a>2. Velero 与 etcd 快照备份的区别</h2><ul><li><p>etcd 快照是全局完成备份(类似于 MySQL 全部备份),即使需要恢复一个资源对象(类似于只恢复 MySQL 的一个库),但是也需要做全局恢复到备份的状态(类似于 MySQL 的全库恢复),即会影响其它 namespace 中 pod 运行服务(类似于会影响 MySQL 其它数据库的数据)。</p></li><li><p>Velero 可以有针对性的备份,比如按照 namespace 单独备份、只备份单独的资源对象等,在恢复的时候可以根据备份只恢复单独的 namespace 或资源对象，而不影响其它 namespace 中 pod 运行服务。</p></li><li><p>velero 支持 ceph、oss 等对象存储，etcd 快照是一个为本地文件。</p></li><li><p>velero 支持任务计划实现周期备份，但 etcd 快照也可以基于 cronjob 实现。</p></li><li><p>velero 支持对AWS EBS 创建快照及还原</p><p><a href="https://www.qloudx.com/velero-for-kubernetes-backup-restore-stateful-workloads-with-aws-ebs-snapshots/">https://www.qloudx.com/velero-for-kubernetes-backup-restore-stateful-workloads-with-aws-ebs-snapshots/</a><br><a href="https://github.com/vmware-tanzu/velero-plugin-for-aws">https://github.com/vmware-tanzu/velero-plugin-for-aws</a></p></li></ul><h2 id="3-velero-整体架构"><a href="#3-velero-整体架构" class="headerlink" title="3. velero 整体架构"></a>3. velero 整体架构</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/15/20250915-234034.png" alt="velero 整体架构"></p><h2 id="4-velero-备份流程"><a href="#4-velero-备份流程" class="headerlink" title="4. velero 备份流程"></a>4. velero 备份流程</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/15/20250915-234122.png" alt="velero 备份流程"></p><p>Velero 客户端调用 Kubernetes API Server 创建 Backup 任务。Backup 控制器基于watch 机制通过 API Server 获取到备份任务。Backup 控制器开始执行备份动作，其会通过请求 API Server 获取需要备份的数据。Backup 控制器将获取到的数据备份到指定的对象存储 server 端。</p><h2 id="5-案例实操"><a href="#5-案例实操" class="headerlink" title="5. 案例实操"></a>5. 案例实操</h2><h3 id="5-1-安装-minio-服务"><a href="#5-1-安装-minio-服务" class="headerlink" title="5.1 安装 minio 服务"></a>5.1 安装 minio 服务</h3><pre><code class="highlight bash"><span class="comment"># 安装 minio</span>$ docker run --name minio \-p 9000:9000 \-p 9999:9999 \-d --restart=always \-e <span class="string">&quot;MINIO_ROOT_USER=admin&quot;</span> \-e <span class="string">&quot;MINIO_ROOT_PASSWORD=12345678&quot;</span> \-v /data/minio/data:/data \minio/minio:RELEASE.2022-04-12T06-55-35Z server /data \--console-address <span class="string">&#x27;0.0.0.0:9999&#x27;</span></code></pre><h3 id="5-2-登录-minio"><a href="#5-2-登录-minio" class="headerlink" title="5.2 登录 minio"></a>5.2 登录 minio</h3><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/15/20250915-234744.png" alt="登录 minio"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/15/20250915-234814.png" alt="minio 首页"></p><h3 id="5-3-创建-bucket-存储桶"><a href="#5-3-创建-bucket-存储桶" class="headerlink" title="5.3 创建 bucket 存储桶"></a>5.3 创建 bucket 存储桶</h3><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/15/20250915-234917.png" alt="创建 bucket 存储桶"></p><h3 id="5-4-在-master-节点部署-velero"><a href="#5-4-在-master-节点部署-velero" class="headerlink" title="5.4 在 master 节点部署 velero"></a>5.4 在 master 节点部署 velero</h3><p>下载地址：<a href="https://github.com/vmware-tanzu/velero/">https://github.com/vmware-tanzu/velero/</a></p><p>Velero 与 K8S 版本匹配关系：<a href="https://github.com/vmware-tanzu/velero/">https://github.com/vmware-tanzu/velero/</a></p><table><thead><tr><th>Velero version</th><th>Expected Kubernetes version compatibility</th><th>Tested on Kubernetes version</th></tr></thead><tbody><tr><td>1.17</td><td>1.18-latest</td><td>1.31.7, 1.32.3, 1.33.1, and 1.34.0</td></tr><tr><td>1.16</td><td>1.18-latest</td><td>1.31.4, 1.32.3, and 1.33.0</td></tr><tr><td>1.15</td><td>1.18-latest</td><td>1.28.8, 1.29.8, 1.30.4 and 1.31.1</td></tr><tr><td>1.14</td><td>1.18-latest</td><td>1.27.9, 1.28.9, and 1.29.4</td></tr><tr><td>1.13</td><td>1.18-latest</td><td>1.26.5, 1.27.3, 1.27.8, and 1.28.3</td></tr><tr><td>1.12</td><td>1.18-latest</td><td>1.25.7, 1.26.5, 1.26.7, and 1.27.3</td></tr><tr><td>1.11</td><td>1.18-latest</td><td>1.23.10, 1.24.9, 1.25.5, and 1.26.1</td></tr></tbody></table><pre><code class="highlight bash"><span class="comment"># 下载 velero</span>$ wget https://github.com/vmware-tanzu/velero/releases/download/v1.14.1/velero-v1.14.1-linux-amd64.tar.gz<span class="comment"># 解压</span>$ tar -zxvf velero-v1.14.1-linux-amd64.tar.gz<span class="comment"># 查看二进制文件</span>$ <span class="built_in">cd</span> velero-v1.14.1-linux-amd64$ lltotal 99048-rw-r--r-- 1 root root     10255 Aug 22  2024 LICENSEdrwxr-xr-x 4 root root        36 Sep 16 00:00 examples-rwxr-xr-x 1 root root 101412456 Aug 26  2024 velero<span class="comment"># 将 velero 二进制文件移动到 /usr/local/bin/ 目录</span>$ <span class="built_in">mv</span> velero /usr/local/bin/<span class="comment"># 文件提权</span>$ <span class="built_in">chmod</span> +x /usr/local/bin/velero<span class="comment"># 查看 velero 是否安装成功</span>$ velero versionClient:Version: v1.14.1Git commit: 8afe3cea8b7058f7baaf447b9fb407312c40d2da&lt;error getting server version: no matches <span class="keyword">for</span> kind <span class="string">&quot;ServerStatusRequest&quot;</span> <span class="keyword">in</span> version <span class="string">&quot;velero.io/v1&quot;</span>&gt;</code></pre><h3 id="5-5-安装-velero-使用-minio-作为备份存储"><a href="#5-5-安装-velero-使用-minio-作为备份存储" class="headerlink" title="5.5 安装 velero, 使用 minio 作为备份存储"></a>5.5 安装 velero, 使用 minio 作为备份存储</h3><pre><code class="highlight bash"><span class="comment"># 创建目录</span>$ <span class="built_in">mkdir</span> -p /data/velero/<span class="comment"># 编辑 minio 认证凭据文件</span>$ <span class="built_in">cat</span> /data/velero/velero-auth.txt[default]aws_access_key_id = adminaws_secret_access_key = 12345678<span class="comment"># 在集群中安装 Velero，并将其配置为使用一个自建的 MinIO S3 兼容存储服务作为备份仓库，并且使用文件系统备份（FSB）方式来备份持久卷数据</span>$ velero --kubeconfig /root/.kube/config install --use-node-agent --default-volumes-to-fs-backup --provider aws --plugins velero/velero-plugin-for-aws:v1.13.0 --bucket etcd-bak --secret-file /data/velero/velero-auth.txt  --use-volume-snapshots=<span class="literal">false</span> --namespace velero-system --backup-location-config region=minio,s3ForcePathStyle=<span class="string">&#x27;true&#x27;</span>,s3Url=http://10.20.1.139:9000<span class="comment"># 不支持 hostPath 卷</span><span class="comment"># 执行上面的命令，会自动拉取镜像</span><span class="comment"># - docker pull velero/velero:v1.14.1</span><span class="comment"># - docker pull velero/velero-plugin-for-aws:v1.13.0</span><span class="comment"># 查看 velero 部署 Pod</span>$ kubectl get pods -n velero-systemNAME                      READY   STATUS    RESTARTS        AGEnode-agent-87z2k          1/1     Running   1 (89s ago)     11mnode-agent-gqp8t          1/1     Running   4 (2m1s ago)    11mnode-agent-rz9rh          1/1     Running   2 (2m15s ago)   11mvelero-58448bc654-nhcm5   1/1     Running   0               11m<span class="comment"># 查看velero日志</span>$ kubectl logs -f deployment/velero -n velero-system</code></pre><p><strong>命令解析：</strong></p><ul><li><p><code>velero ... install</code></p><p>这是 Velero 客户端的主要命令，用于在集群中部署 Velero 的运维控制面（Deployment、CRD 等）。</p></li><li><p><code>--kubeconfig /root/.kube/config</code></p><p>作用：指定 Kubernetes 集群的认证配置文件路径。</p><p>解释：告诉 velero 命令行工具如何连接到目标 Kubernetes 集群。这里它使用 root 用户下的配置。</p></li><li><p><code>--use-node-agent</code></p><p>作用：启用 Node Agent 模式（也称为“上传者”模型）。</p><p>解释：这是 Velero 新版本中推荐的方式，用于替代旧的 restic 集成。每个节点会运行一个 DaemonSet（node-agent），由它来负责本节点上所有 Pod 卷的文件系统备份&#x2F;恢复操作，效率更高。</p></li><li><p><code>--default-volumes-to-fs-backup</code></p><p>作用：将为所有 Pod 中的所有持久卷启用文件系统备份，无需在备份时额外指定注解。</p><p>解释：这是一个便利选项。如果不加这个参数，你需要给每个包含需要备份的 PVC 的 Pod 打上 backup.velero.io&#x2F;backup-volumes&#x3D;<volume-name> 的注解。加上这个参数后，Velero 默认会尝试备份所有挂载的卷（注：有些卷如 emptyDir 或敏感目录可能仍需排除）。</p></li><li><p><code>--use-volume-snapshots=false</code></p><p>作用：明确禁用卷快照功能。</p><p>解释：因为此命令配置的是使用文件系统备份（–use-node-agent 和 –default-volumes-to-fs-backup），而不是基于云厂商特定存储的原生快照功能，所以需要显式关闭快照功能。这与 –provider aws 并不冲突，因为我们将 AWS S3 插件用于兼容 S3 的对象存储，而不是用于快照。</p></li><li><p><code>--provider aws</code></p><p>作用：指定云提供商为 AWS。</p><p>解释：Velero 需要知道它与哪种云存储交互。虽然这里使用的是 MinIO，但 MinIO 提供了与 AWS S3 兼容的 API，因此可以使用 AWS 提供商插件来连接它。</p></li><li><p><code>--plugins velero/velero-plugin-for-aws:v1.13.0</code></p><p>作用：指定要安装的 Velero 插件镜像。</p><p>解释：为了让 –provider aws 正常工作，需要安装 AWS 插件。这个插件使 Velero 能够与 S3 API（包括 MinIO 提供的 S3 兼容 API）进行通信。</p></li><li><p><code>--bucket velero</code></p><p>作用：指定对象存储中的存储桶（Bucket）名称。</p><p>解释：Velero 将把所有备份数据存储在 MinIO 中名为 velero 的存储桶中。这个存储桶需要提前在 MinIO 中创建好。</p></li><li><p><code>--secret-file /data/velero/velero-auth.txt</code></p><p>作用：提供访问对象存储所需的认证凭据文件。</p><p>解释：该文件通常包含两行：aws_access_key_id 和 aws_secret_access_key。这些是访问 MinIO 服务的用户名和密码（MinIO 使用与 AWS 兼容的认证格式）。</p></li><li><p><code>--backup-location-config region=minio,s3ForcePathStyle=&#39;true&#39;,s3Url=http://10.20.1.139:9000</code></p><p>作用：配置备份存储位置的具体参数。</p><p>解释：这是连接 MinIO 的关键配置：</p><p>​region&#x3D;minio: MinIO 默认区域，可以任意设置，但必须提供，通常设为 minio 或 us-east-1。</p><p>​s3ForcePathStyle&#x3D;’true’: 极其重要。强制使用路径风格的 S3 URL（例如 <a href="http://endpoint/bucket/key%EF%BC%89%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E9%A3%8E%E6%A0%BC%EF%BC%88http://bucket.endpoint/key%EF%BC%89%E3%80%82MinIO">http://endpoint/bucket/key），而不是虚拟主机风格（http://bucket.endpoint/key）。MinIO</a> 通常需要启用这个选项。</p><p>​s3Url&#x3D;<a href="http://10.20.1.139:9000/">http://10.20.1.139:9000</a>: 指定 MinIO 服务的访问地址和端口。Velero 将通过这个 URL 上传和下载备份数据。</p></li><li><p><code>--namespace velero-system</code></p><p>作用：指定 Velero 组件将被安装到哪个 Kubernetes 命名空间中。</p><p>解释：Velero 的所有 Pod（velero 和 node-agent）、Secret、ServiceAccount 等资源都会创建在这个名为 velero-system 的命名空间里。这是一个惯例，与其他系统组件隔离。</p></li></ul><p><strong>查看 Velero 备份存储是否健康可用</strong></p><pre><code class="highlight bash">$ kubectl  get BackupStorageLocation -n velero-system  -o yamlapiVersion: v1items:- apiVersion: velero.io/v1  kind: BackupStorageLocation  metadata:    creationTimestamp: <span class="string">&quot;2025-09-16T01:48:14Z&quot;</span>    generation: 3    labels:      component: velero    name: default    namespace: velero-system    resourceVersion: <span class="string">&quot;9463671&quot;</span>    uid: 1ca0f267-af96-4e08-96f9-b578dd335df3  spec:    config:      region: minio      s3ForcePathStyle: <span class="string">&quot;true&quot;</span>      s3Url: http://10.20.1.139:9000 <span class="comment"># minio 地址</span>    default: <span class="literal">true</span>    objectStorage:      bucket: etcd-bak <span class="comment"># 备份存储的桶</span>    provider: aws  status:    lastSyncedTime: <span class="string">&quot;2025-09-16T01:49:24Z&quot;</span>    lastValidationTime: <span class="string">&quot;2025-09-16T01:49:24Z&quot;</span>    phase: Available <span class="comment"># 可用</span>kind: Listmetadata:  resourceVersion: <span class="string">&quot;&quot;</span></code></pre><h3 id="5-6-演示-Velero-的备份和还原"><a href="#5-6-演示-Velero-的备份和还原" class="headerlink" title="5.6 演示 Velero 的备份和还原"></a>5.6 演示 Velero 的备份和还原</h3><p><strong>资源清单：</strong><code>velero-demo-deploy.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">velero-demo-pvc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">storageClassName:</span> <span class="string">nfs-client</span> <span class="comment"># 指定存储类</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">resources:</span>    <span class="attr">requests:</span>      <span class="attr">storage:</span> <span class="string">1Gi</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">velero-demo</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">velero-demo</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">velero-demo</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">velero-demo</span>        <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>        <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>        <span class="attr">volumeMounts:</span> <span class="comment"># 挂载卷</span>          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">velero-storage</span>            <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html</span> <span class="comment"># 挂载路径</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">velero-storage</span>          <span class="attr">persistentVolumeClaim:</span> <span class="comment"># 挂载PVC</span>            <span class="attr">claimName:</span> <span class="string">velero-demo-pvc</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 查看PVC，已绑定</span>$ kubectl get pvcNAME              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGEvelero-demo-pvc   Bound    pvc-0976d62a-08fe-43fe-8882-3a64379bd4c9   1Gi        RWO            nfs-client     &lt;<span class="built_in">unset</span>&gt;                 12m<span class="comment"># 查看POD运行成功</span>$ kubectl get pods -o wideNAME                          READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESvelero-demo-cbbcc8454-k78rj   1/1     Running   0          12m   171.20.85.204   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 在 nfs 挂载目录写入内容</span>$ <span class="built_in">echo</span> <span class="string">&quot;Hello Velero&quot;</span> &gt;&gt; index.html<span class="comment"># 测试 Nginx 访问</span>$ curl http://171.20.85.204Hello Velero</code></pre><p><strong>执行 Velero 备份命令</strong></p><pre><code class="highlight bash"><span class="comment"># 备份 default 命名空间的数据</span>$ velero backup create default-backup-`<span class="built_in">date</span> +%Y%m%d%H%M%S` --include-namespaces default --kubeconfig=/root/.kube/config --namespace velero-systemBackup request <span class="string">&quot;default-backup-20250916210829&quot;</span> submitted successfully.Run `velero backup describe default-backup-20250916210829` or `velero backup logs default-backup-20250916210829` <span class="keyword">for</span> more details.<span class="comment"># 执行操作成功</span><span class="comment"># --ttl 24h0m0s如果未指定，将应用 30 天的默认 TTL 值</span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/16/20250916-210931.png" alt="数据已备份到 minio 中"></p><p><strong>删除 default 命名空间的数据</strong></p><pre><code class="highlight bash"><span class="comment"># 删除挂载目录的index.html文件</span>$ <span class="built_in">rm</span> -rf index.html<span class="comment"># 删除pvc 和 pod</span>$ kubectl delete -f velero-demo-deploy.yaml persistentvolumeclaim <span class="string">&quot;velero-demo-pvc&quot;</span> deleteddeployment.apps <span class="string">&quot;velero-demo&quot;</span> deleted</code></pre><p><strong>使用 Velero 恢复数据</strong></p><pre><code class="highlight bash"><span class="comment"># 使用 velero 恢复数据</span>$ velero restore create --from-backup default-backup-20250916210829 --<span class="built_in">wait</span> --kubeconfig=/root/.kube/config --namespace velero-systemRestore request <span class="string">&quot;default-backup-20250916210829-20250916211224&quot;</span> submitted successfully.Waiting <span class="keyword">for</span> restore to complete. You may safely press ctrl-c to stop waiting - your restore will <span class="built_in">continue</span> <span class="keyword">in</span> the background.............................................................................................................................................................................................................................................................Restore completed with status: Completed. You may check <span class="keyword">for</span> more information using the commands `velero restore describe default-backup-20250916210829-20250916211224` and `velero restore logs default-backup-20250916210829-20250916211224`.<span class="comment"># 会自动拉取镜像：velero/velero-restore-helper:v1.14.1</span><span class="comment"># 查看Pod</span>$ kubectl get pods -o wide NAME                          READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESvelero-demo-cbbcc8454-k78rj   1/1     Running   0          4m31s   171.20.85.203   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 访问Pod，nginx已恢复</span>$ curl http://171.20.85.203Hello Velero</code></pre><p>默认情况下，Velero 执行非破坏性恢复，这意味着它不会删除目标集群上的任何数据。如果备份中的资源已存在于目标集群中，Velero 将跳过该资源</p><pre><code class="highlight bash">$ velero restore create --from-backup default-backup-20250916210829 --<span class="built_in">wait</span> --kubeconfig=/root/.kube/config --namespace velero-system</code></pre><h2 id="6-velero-常用命令"><a href="#6-velero-常用命令" class="headerlink" title="6. velero 常用命令"></a>6. velero 常用命令</h2><h3 id="6-1-为与标签选择器匹配的任何对象创建备份-：app-velero-demo"><a href="#6-1-为与标签选择器匹配的任何对象创建备份-：app-velero-demo" class="headerlink" title="6.1 为与标签选择器匹配的任何对象创建备份 ：app=velero-demo"></a>6.1 为与标签选择器匹配的任何对象创建备份 ：<code>app=velero-demo</code></h3><pre><code class="highlight bash">$ velero backup create nginx-backup --selector app=nginx<span class="comment"># 示例</span>$ velero backup create backup-`<span class="built_in">date</span> +%Y%m%d%H%M%S` --selector app=velero-demo --include-namespaces default --kubeconfig=/root/.kube/config --namespace velero-system</code></pre><h3 id="6-2-备份除与标签匹配的对象之外的所有对象-：app-velero-demo"><a href="#6-2-备份除与标签匹配的对象之外的所有对象-：app-velero-demo" class="headerlink" title="6.2 备份除与标签匹配的对象之外的所有对象 ：app=velero-demo"></a>6.2 备份除与标签匹配的对象<em>之外的</em>所有对象 ：<code>app=velero-demo</code></h3><pre><code class="highlight bash">$ velero backup create nginx-backup --selector <span class="string">&#x27;app notin (velero-demo)&#x27;</span><span class="comment"># 示例</span>$ velero backup create backup-`<span class="built_in">date</span> +%Y%m%d%H%M%S` --selector <span class="string">&#x27;app notin (velero-demo)&#x27;</span> --include-namespaces default --kubeconfig=/root/.kube/config --namespace velero-system</code></pre><h3 id="6-3-定时备份数据"><a href="#6-3-定时备份数据" class="headerlink" title="6.3 定时备份数据"></a>6.3 定时备份数据</h3><pre><code class="highlight bash"><span class="comment"># 每分钟执行执行一次备份</span>$ velero schedule create schedule-backup --schedule=<span class="string">&quot;* * * * *&quot;</span> --include-namespaces=default --default-volumes-to-fs-backup <span class="comment"># 示例：每天2点执行一次备份</span>$ velero schedule create schedule-backup --schedule=<span class="string">&quot;0 2 * * *&quot;</span> --include-namespaces=default --default-volumes-to-fs-backup --kubeconfig=/root/.kube/config --namespace velero-system<span class="comment"># 查看 velero 定时任务</span>$ velero schedule getNAME              STATUS    CREATED                         SCHEDULE    BACKUP TTL   LAST BACKUP   SELECTOR   PAUSEDschedule-backup   Enabled   2025-09-17 20:15:31 +0800 CST   0 2 * * *   0s           n/a           &lt;none&gt;     <span class="literal">false</span><span class="comment"># 查看定时任务详情</span>$ velero schedule describe schedule-backup -n velero-system<span class="comment"># 暂停定时任务</span>$ velero schedule pause schedule-backup -n velero-system<span class="comment"># 删除定时任务</span>$ velero schedule delete schedule-backup -n velero-systemAre you sure you want to <span class="built_in">continue</span> (Y/N)? YSchedule deleted: schedule-backup<span class="comment"># 或者 --confirm 跳过确认，直接删除</span>$ velero schedule delete schedule-backup -n velero-system --confirm</code></pre><pre><code class="highlight bash"><span class="comment"># 每天备份一次，@daily 相当于 0 * * * *</span>$ velero schedule create nginx-daily --schedule=<span class="string">&quot;@daily&quot;</span> --selector app=nginx</code></pre><h2 id="7-卸载-Velero"><a href="#7-卸载-Velero" class="headerlink" title="7. 卸载 Velero"></a>7. 卸载 Velero</h2><p>如果部署的 velero 有问题，需要重新部署，那么才需要删除 velero。</p><pre><code class="highlight bash"><span class="comment"># 方式一：</span>$ velero --kubeconfig /root/.kube/config uninstall --namespace velero-system<span class="comment"># 方式二：</span><span class="comment"># 删除命名空间（这会删除该命名空间下的所有资源）</span>kubectl --kubeconfig /root/.kube/config delete namespace velero-system<span class="comment"># 删除 CRDs（自定义资源定义）</span>kubectl --kubeconfig /root/.kube/config delete crds \  backups.velero.io \  backupstoragelocations.velero.io \  deletebackuprequests.velero.io \  downloadrequests.velero.io \  podvolumebackups.velero.io \  podvolumerestores.velero.io \  resticrepositories.velero.io \  restores.velero.io \  schedules.velero.io \  serverstatusrequests.velero.io \  volumesnapshotlocations.velero.io</code></pre><h2 id="8-补充"><a href="#8-补充" class="headerlink" title="8.补充"></a>8.补充</h2><h3 id="8-1-常用命令"><a href="#8-1-常用命令" class="headerlink" title="8.1 常用命令"></a>8.1 常用命令</h3><pre><code class="highlight bash"><span class="comment"># 备份存储库是否存在并且准备好</span>$ velero repo getNAME                          STATUS   LAST MAINTENANCEdefault-default-kopia-59zrm   Ready    2025-09-17 20:09:24 +0800 CST<span class="comment"># Velero 备份/恢复中是否存在任何错误</span>$ velero backup describe BACKUP_NAME<span class="comment"># 示例：$ velero backup describe &lt;BACKUP_NAME&gt; -n velero-system</span>$ velero backup logs BACKUP_NAME$ velero restore describe RESTORE_NAME$ velero restore logs RESTORE_NAME<span class="comment"># Pod 卷备份/恢复的状态如何</span>$ kubectl -n velero get podvolumebackups -l velero.io/backup-name=BACKUP_NAME -o yaml$ kubectl -n velero get podvolumerestores -l velero.io/restore-name=RESTORE_NAME -o yaml<span class="comment"># 示例：$ kubectl -n velero get podvolumebackups -l velero.io/backup-name=default-backup-20250916210829 -o yaml -n velero-system</span></code></pre><h3 id="8-2-安全的还原"><a href="#8-2-安全的还原" class="headerlink" title="8.2 安全的还原"></a>8.2 安全的还原</h3><pre><code class="highlight bash"><span class="comment"># 修改 velero-system 命名空间中名为 default 的 BackupStorageLocation 资源，将其 accessMode 设置为 ReadOnly。</span><span class="comment"># 效果：Velero 将无法向该存储位置写入新备份（例如，新的备份任务会失败），但可以读取现有备份以进行恢复操作。以防止意外修改或覆盖备份数据</span>$ kubectl patch backupstoragelocation default --namespace velero-system --<span class="built_in">type</span> merge --patch <span class="string">&#x27;&#123;&quot;spec&quot;:&#123;&quot;accessMode&quot;:&quot;ReadOnly&quot;&#125;&#125;&#x27;</span><span class="comment"># 修改 velero-system 命名空间中名为 default 的 BackupStorageLocation 资源，将其 accessMode 设置为 ReadWrite。</span><span class="comment"># 效果：Velero 恢复完整的读写权限，可以创建新备份、删除备份（根据策略）以及读取备份进行恢复。在生产环境中，ReadWrite 是默认模式</span>$ kubectl patch backupstoragelocation default --namespace velero-system --<span class="built_in">type</span> merge --patch <span class="string">&#x27;&#123;&quot;spec&quot;:&#123;&quot;accessMode&quot;:&quot;ReadWrite&quot;&#125;&#125;&#x27;</span></code></pre><h3 id="8-3-资源过滤"><a href="#8-3-资源过滤" class="headerlink" title="8.3 资源过滤"></a>8.3 资源过滤</h3><h4 id="–include-namespaces"><a href="#–include-namespaces" class="headerlink" title="–include-namespaces"></a>–include-namespaces</h4><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">备份命名空间及其对象</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --include-namespaces &lt;namespace&gt;</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">恢复两个命名空间及其对象</span><span class="meta prompt_">$ </span><span class="language-bash">velero restore create &lt;backup-name&gt; --include-namespaces &lt;namespace1&gt;,&lt;namespace2&gt;</span></code></pre><h4 id="–include-resources"><a href="#–include-resources" class="headerlink" title="–include-resources"></a>–include-resources</h4><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">备份集群中的所有 deployment</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --include-resources deployments</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">恢复集群中的所有 deployment 和 configmap</span><span class="meta prompt_">$ </span><span class="language-bash">velero restore create &lt;backup-name&gt; --include-resources deployments,configmaps</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">备份指定命名空间中的 deployment</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --include-resources deployments --include-namespaces &lt;namespace&gt;</span></code></pre><h4 id="–include-cluster-resources"><a href="#–include-cluster-resources" class="headerlink" title="–include-cluster-resources"></a>–include-cluster-resources</h4><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">备份整个集群，包括集群范围的资源</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt;</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">仅恢复集群中的命名空间资源</span><span class="meta prompt_">$ </span><span class="language-bash">velero restore create &lt;backup-name&gt; --include-cluster-resources=<span class="literal">false</span></span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">备份命名空间并包含集群范围的资源</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --include-namespaces &lt;namespace&gt; --include-cluster-resources=<span class="literal">true</span></span></code></pre><h4 id="–selector，该选项不能与-selector-一起使用"><a href="#–selector，该选项不能与-selector-一起使用" class="headerlink" title="–selector，该选项不能与 --selector  一起使用"></a>–selector，该选项不能与 <code>--selector</code>  一起使用</h4><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">包含与标签选择器匹配的资源</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --selector &lt;key&gt;=&lt;value&gt;</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">包含与选择器不匹配的资源</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --selector <span class="string">&quot;&lt;key&gt; notin (&lt;value&gt;)&quot;</span></span></code></pre><h4 id="–or-selector"><a href="#–or-selector" class="headerlink" title="–or-selector"></a>–or-selector</h4><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">包含与任一标签选择器匹配的资源，foo=bar 或者 baz=qux</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create backup1 --or-selector <span class="string">&quot;foo=bar or baz=qux&quot;</span></span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">包括标记为 environment=production 或 environment=prod ，<span class="built_in">env</span>=prod 或 <span class="built_in">env</span>=production 的资源</span> <span class="meta prompt_">$ </span><span class="language-bash">velero restore create restore-prod --from-backup=prod-backup --or-selector <span class="string">&quot;env in (prod,production) or environment in (prod, production)&quot;</span></span></code></pre><h4 id="–include-cluster-scoped-resources"><a href="#–include-cluster-scoped-resources" class="headerlink" title="–include-cluster-scoped-resources"></a>–include-cluster-scoped-resources</h4><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">备份集群中的所有 StorageClasses 和 ClusterRoles</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --include-cluster-scoped-resources=<span class="string">&quot;storageclasses,clusterroles&quot;</span></span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">备份集群中所有集群范围的资源</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --include-cluster-scoped-resources=<span class="string">&quot;*&quot;</span></span></code></pre><h4 id="–include-namespace-scoped-resources，格式为-resources-group"><a href="#–include-namespace-scoped-resources，格式为-resources-group" class="headerlink" title="–include-namespace-scoped-resources，格式为 resources.group"></a>–include-namespace-scoped-resources，格式为 resources.group</h4><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">备份集群中的所有 Deployment 和 ConfigMap</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --include-namespace-scoped-resources=<span class="string">&quot;deployments.apps,configmaps&quot;</span></span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">备份集群中所有命名空间资源</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --include-namespace-scoped-resources=<span class="string">&quot;*&quot;</span></span></code></pre><h4 id="–exclude-namespaces"><a href="#–exclude-namespaces" class="headerlink" title="–exclude-namespaces"></a>–exclude-namespaces</h4><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">从集群备份中排除 kube-system</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --exclude-namespaces kube-system</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">在恢复期间排除两个命名空间</span><span class="meta prompt_">$ </span><span class="language-bash">velero restore create &lt;backup-name&gt; --exclude-namespaces &lt;namespace1&gt;,&lt;namespace2&gt;</span></code></pre><h4 id="–exclude-resources"><a href="#–exclude-resources" class="headerlink" title="–exclude-resources"></a>–exclude-resources</h4><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">从备份中排除 secrets</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --exclude-resources secrets</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">排除 secret 和 rolebindings</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --exclude-resources secrets,rolebindings</span></code></pre><h4 id="velero-io-exclude-from-backup-true"><a href="#velero-io-exclude-from-backup-true" class="headerlink" title="velero.io&#x2F;exclude-from-backup&#x3D;true"></a>velero.io&#x2F;exclude-from-backup&#x3D;true</h4><p>具有该标签的资源<code>velero.io/exclude-from-backup=true</code>不会包含在备份中，即使它包含匹配的选择器标签也是如此</p><h4 id="–exclude-cluster-scoped-resources"><a href="#–exclude-cluster-scoped-resources" class="headerlink" title="–exclude-cluster-scoped-resources"></a>–exclude-cluster-scoped-resources</h4><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">从备份中排除 StorageClasses 和 ClusterRoles</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --exclude-cluster-scoped-resources=<span class="string">&quot;storageclasses,clusterroles&quot;</span></span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">从备份中排除所有集群范围的资源</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --exclude-cluster-scoped-resources=<span class="string">&quot;*&quot;</span></span></code></pre><h4 id="–exclude-namespace-scoped-resources，格式为-resources-group"><a href="#–exclude-namespace-scoped-resources，格式为-resources-group" class="headerlink" title="–exclude-namespace-scoped-resources，格式为 resources.group"></a>–exclude-namespace-scoped-resources，格式为 resources.group</h4><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">从备份中排除所有 Deployment 和 ConfigMap</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --exclude-namespace-scoped-resources=<span class="string">&quot;deployments.apps,configmaps&quot;</span></span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">从备份中排除所有命名空间资源</span><span class="meta prompt_">$ </span><span class="language-bash">velero backup create &lt;backup-name&gt; --exclude-namespace-scoped-resources=<span class="string">&quot;*&quot;</span></span></code></pre><h4 id="Velero-提供资源策略来过滤资源以进行备份或恢复。目前仅支持通过资源策略跳过备份卷"><a href="#Velero-提供资源策略来过滤资源以进行备份或恢复。目前仅支持通过资源策略跳过备份卷" class="headerlink" title="Velero 提供资源策略来过滤资源以进行备份或恢复。目前仅支持通过资源策略跳过备份卷"></a>Velero 提供资源策略来过滤资源以进行备份或恢复。目前仅支持通过资源策略跳过备份卷</h4><p>① 创建资源策略配置映射</p><p>用户需要从定义资源策略的 YAML 文件在 Velero 安装命名空间中创建一个配置映射。创建命令如下所示：</p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create cm &lt;configmap-name&gt; --from-file &lt;yaml-file&gt; -n velero</span></code></pre><p>② 创建对已定义资源策略的备份引用</p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">velero backup create --resource-policies-configmap &lt;configmap-name&gt;</span></code></pre><p>③ YAML 模板</p><pre><code class="highlight yaml"><span class="comment"># currently only supports v1 version</span><span class="attr">version:</span> <span class="string">v1</span><span class="attr">volumePolicies:</span><span class="comment"># each policy consists of a list of conditions and an action</span><span class="comment"># we could have lots of policies, but if the resource matched the first policy, the latters will be ignored</span><span class="comment"># each key in the object is one condition, and one policy will apply to resources that meet ALL conditions</span><span class="comment"># <span class="doctag">NOTE:</span> capacity or storageClass is suited for [Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes), and pod [Volume](https://kubernetes.io/docs/concepts/storage/volumes) not support it.</span><span class="bullet">-</span> <span class="attr">conditions:</span>    <span class="comment"># capacity condition matches the volumes whose capacity falls into the range</span>    <span class="attr">capacity:</span> <span class="string">&quot;10,100Gi&quot;</span>    <span class="comment"># pv matches specific csi driver</span>    <span class="attr">csi:</span>      <span class="attr">driver:</span> <span class="string">aws.ebs.csi.driver</span>    <span class="comment"># pv matches one of the storage class list</span>    <span class="attr">storageClass:</span>      <span class="bullet">-</span> <span class="string">gp2</span>      <span class="bullet">-</span> <span class="string">standard</span>  <span class="attr">action:</span>    <span class="attr">type:</span> <span class="string">skip</span><span class="bullet">-</span> <span class="attr">conditions:</span>    <span class="attr">capacity:</span> <span class="string">&quot;0,100Gi&quot;</span>    <span class="comment"># nfs volume source with specific server and path (nfs could be empty or only config server or path)</span>    <span class="attr">nfs:</span>      <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.200</span><span class="number">.90</span>      <span class="attr">path:</span> <span class="string">/mnt/data</span>  <span class="attr">action:</span>    <span class="attr">type:</span> <span class="string">skip</span><span class="bullet">-</span> <span class="attr">conditions:</span>    <span class="attr">nfs:</span>      <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.200</span><span class="number">.90</span>  <span class="attr">action:</span>    <span class="attr">type:</span> <span class="string">skip</span><span class="bullet">-</span> <span class="attr">conditions:</span>    <span class="comment"># nfs could be empty which matches any nfs volume source</span>    <span class="attr">nfs:</span> &#123;&#125;  <span class="attr">action:</span>    <span class="attr">type:</span> <span class="string">skip</span><span class="bullet">-</span> <span class="attr">conditions:</span>    <span class="comment"># csi could be empty which matches any csi volume source</span>    <span class="attr">csi:</span> &#123;&#125;  <span class="attr">action:</span>    <span class="attr">type:</span> <span class="string">skip</span><span class="bullet">-</span> <span class="attr">conditions:</span>    <span class="attr">volumeTypes:</span>      <span class="bullet">-</span> <span class="string">emptyDir</span>      <span class="bullet">-</span> <span class="string">downwardAPI</span>      <span class="bullet">-</span> <span class="string">configmap</span>      <span class="bullet">-</span> <span class="string">cinder</span>  <span class="attr">action:</span>    <span class="attr">type:</span> <span class="string">skip</span></code></pre><h4 id="并行文件上传"><a href="#并行文件上传" class="headerlink" title="并行文件上传"></a>并行文件上传</h4><pre><code class="highlight bash">$ velero backup create &lt;BACKUP_NAME&gt; --include-namespaces &lt;NAMESPACE&gt; --parallel-files-upload &lt;NUM&gt; --<span class="built_in">wait</span></code></pre><p><strong>参考链接</strong></p><blockquote><p><a href="https://www.cnblogs.com/xiaozhi1223/p/16570606.html">https://www.cnblogs.com/xiaozhi1223/p/16570606.html</a></p><p><a href="https://www.cnblogs.com/qiuhom-1874/p/17670945.html">https://www.cnblogs.com/qiuhom-1874/p/17670945.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;集群环境&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 kubeadmin 安装，Etcd 为单节点&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;Hostname&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Etcd" scheme="https://georgechan95.github.io/tags/Etcd/"/>
    
    <category term="Velero" scheme="https://georgechan95.github.io/tags/Velero/"/>
    
  </entry>
  
  <entry>
    <title>023-K8S-Cordon和Drain的使用</title>
    <link href="https://georgechan95.github.io/blog/847bacfd.html"/>
    <id>https://georgechan95.github.io/blog/847bacfd.html</id>
    <published>2025-09-12T12:11:00.000Z</published>
    <updated>2025-09-12T04:34:08.340Z</updated>
    
    <content type="html"><![CDATA[<p><strong>集群环境</strong></p><table><thead><tr><th>IP</th><th>Hostname</th><th>用途</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td><td>Master节点</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td><td>Node节点</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td><td>Node节点</td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td><td>Node节点</td></tr></tbody></table><h1 id="一、Cordon"><a href="#一、Cordon" class="headerlink" title="一、Cordon"></a>一、Cordon</h1><p><strong><code>kubectl cordon</code></strong> 命令用于将节点标记为不可调度。这意味着 Kubernetes 调度器不会将任何新的 Pod 调度到该节点上。但是，已经在该节点上运行的 Pod 不会受到影响，它们将继续运行。在 <code>kubectl cordon</code> 节点后删除节点上已有 Pod，Kubernetes 会自动将新的 Pod 调度到其他可用节点上，从而实现 Pod 的迁移。但是，请务必注意控制器、资源限制、节点亲和性&#x2F;反亲和性以及 Taints 和 Tolerations 等因素，以确保 Pod 能够成功迁移。</p><h2 id="1-使用场景"><a href="#1-使用场景" class="headerlink" title="1. 使用场景"></a>1. 使用场景</h2><ul><li><strong>节点维护：</strong> 在对节点进行维护（例如，硬件更换、内核更新、资源调整）之前，可以使用 <code>cordon</code> 命令来防止新的 Pod 调度到该节点上。</li><li><strong>资源调整：</strong>在调整节点的计算资源时，可以先使用 <code>cordon</code> 命令，以避免资源竞争。</li><li><strong>工作负载重新分配：</strong>在需要将工作负载重新分配到其他节点时，可以使用 <code>cordon</code> 命令来阻止新的 Pod 调度到目标节点上。</li></ul><h2 id="2-如何使用"><a href="#2-如何使用" class="headerlink" title="2. 如何使用"></a>2. 如何使用</h2><ul><li><p>将节点设置成不可调度</p><pre><code class="highlight bash">$ kubectl cordon &lt;node_name&gt; [options]<span class="comment"># 具体选项参考官网：https://kubernetes.io/zh-cn/docs/reference/kubectl/generated/kubectl_cordon/</span></code></pre><p>将 <code>&lt;node-name&gt;</code> 替换为要 cordon 的节点的名称。</p></li><li><p>检查节点状态</p><p>使用以下命令检查节点的状态，确认节点是否已被 cordon：</p><pre><code class="highlight bash">kubectl get nodes &lt;node-name&gt;</code></pre><p>在输出中，STATUS 列将显示 Ready,SchedulingDisabled，表示节点已被 cordon。</p></li><li><p>解除节点的不可调度状态</p><p>完成维护或调整后，可以使用以下命令将节点标记为可调度：</p><pre><code class="highlight bash">kubectl uncordon &lt;node-name&gt;</code></pre><p>撤销状态后，新的Pod可以调度到该节点上。</p></li></ul><h2 id="3-案例实操"><a href="#3-案例实操" class="headerlink" title="3. 案例实操"></a>3. 案例实操</h2><ul><li><p>当前集群节点状态</p><pre><code class="highlight bash">$ kubectl get nodes -o wideNAME           STATUS   ROLES           AGE   VERSION    INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                      KERNEL-VERSION                CONTAINER-RUNTIMEk8s-master01   Ready    control-plane   46d   v1.29.15   10.20.1.139   &lt;none&gt;        Rocky Linux 9.3 (Blue Onyx)   5.14.0-362.8.1.el9_3.x86_64   docker://28.0.4k8s-node01     Ready    &lt;none&gt;          46d   v1.29.15   10.20.1.140   &lt;none&gt;        Rocky Linux 9.3 (Blue Onyx)   5.14.0-362.8.1.el9_3.x86_64   docker://28.0.4k8s-node02     Ready    &lt;none&gt;          46d   v1.29.15   10.20.1.141   &lt;none&gt;        Rocky Linux 9.3 (Blue Onyx)   5.14.0-362.8.1.el9_3.x86_64   docker://28.0.4k8s-node03     Ready    &lt;none&gt;          46d   v1.29.15   10.20.1.142   &lt;none&gt;        Rocky Linux 9.3 (Blue Onyx)   5.14.0-362.8.1.el9_3.x86_64   docker://28.3.1</code></pre></li><li><p>给节点设置 cordon</p><pre><code class="highlight bash"><span class="comment"># 给 node01 节点设置 cordon </span>$ kubectl cordon k8s-node01node/k8s-node01 cordoned<span class="comment"># 再次查看节点状态，发现 node01 被打上了 SchedulingDisabled 标签</span>$ kubectl get nodesNAME           STATUS                     ROLES           AGE   VERSIONk8s-master01   Ready                      control-plane   46d   v1.29.15k8s-node01     Ready,SchedulingDisabled   &lt;none&gt;          46d   v1.29.15k8s-node02     Ready                      &lt;none&gt;          46d   v1.29.15k8s-node03     Ready                      &lt;none&gt;          46d   v1.29.15</code></pre></li><li><p>创建 Pod</p><p>资源清单：<code>cordon-deployment.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">myapp</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span> <span class="comment"># 默认副本数量为1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span></code></pre><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f cordon-deployment.yamldeployment.apps/myapp created<span class="comment"># 查看 Pod， 被调度到 node02 节点上</span>$ kubectl get pods -o wideNAME                     READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESmyapp-85497bd9fb-hdvdn   1/1     Running   0          25s   171.20.58.223   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre></li><li><p>增加 Pod 副本数</p><pre><code class="highlight bash"><span class="comment"># Pod 设置10个副本</span>$ kubectl scale deployment myapp --replicas=10deployment.apps/myapp scaled<span class="comment"># 查看 Pod, 发现10个副本都被分布在 node02 和 node03 节点上，没有被调度到 node01 节点上</span>$ kubectl get pods -o wideNAME                     READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATESmyapp-85497bd9fb-8kzkf   1/1     Running   0          2m52s   171.20.58.225    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-9vm9s   1/1     Running   0          2m52s   171.20.58.224    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-gtc22   1/1     Running   0          2m52s   171.20.58.227    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-hdvdn   1/1     Running   0          4m4s    171.20.58.223    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-j2tkd   1/1     Running   0          2m52s   171.20.58.228    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-kg9qf   1/1     Running   0          2m52s   171.20.135.147   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-mh9dx   1/1     Running   0          2m53s   171.20.135.145   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-qvrgl   1/1     Running   0          2m52s   171.20.58.226    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-tbcrv   1/1     Running   0          2m52s   171.20.135.149   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-wgpwc   1/1     Running   0          2m52s   171.20.135.146   k8s-node03   &lt;none&gt;           &lt;none&gt;</code></pre></li><li><p>节点设置 uncordon</p><pre><code class="highlight bash"><span class="comment"># 给 node01 节点设置 uncordon </span>$ kubectl uncordon k8s-node01node/k8s-node01 uncordoned<span class="comment"># 再次查看 Node 状态，发现 node01 节点的 SchedulingDisabled 已经去除了</span>$ kubectl get nodesNAME           STATUS   ROLES           AGE   VERSIONk8s-master01   Ready    control-plane   46d   v1.29.15k8s-node01     Ready    &lt;none&gt;          46d   v1.29.15k8s-node02     Ready    &lt;none&gt;          46d   v1.29.15k8s-node03     Ready    &lt;none&gt;          46d   v1.29.15</code></pre></li><li><p>再次增加 Pod 副本数</p><pre><code class="highlight bash"><span class="comment"># 将 Pod 的副本数从 10 增加到 20</span>$ kubectl scale deployment myapp --replicas=20deployment.apps/myapp scaled<span class="comment"># 再次查看 Pod， 发现可以被调度到 node01 节点了</span>$ kubectl get pods -o wideNAME                     READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATESmyapp-85497bd9fb-6wjg6   1/1     Running   0          36s     171.20.135.151   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-8kzkf   1/1     Running   0          6m45s   171.20.58.225    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-97lnr   1/1     Running   0          36s     171.20.58.229    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-9vm9s   1/1     Running   0          6m45s   171.20.58.224    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-d2s9d   1/1     Running   0          36s     171.20.85.195    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-f8jqn   1/1     Running   0          36s     171.20.85.254    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-gbg7t   1/1     Running   0          36s     171.20.85.251    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-gtc22   1/1     Running   0          6m45s   171.20.58.227    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-hdvdn   1/1     Running   0          7m57s   171.20.58.223    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-j2tkd   1/1     Running   0          6m45s   171.20.58.228    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-kg9qf   1/1     Running   0          6m45s   171.20.135.147   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-m7zhs   1/1     Running   0          37s     171.20.85.252    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-mh9dx   1/1     Running   0          6m46s   171.20.135.145   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-nx2nb   1/1     Running   0          36s     171.20.135.150   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-q4z5x   1/1     Running   0          36s     171.20.85.255    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-qvrgl   1/1     Running   0          6m45s   171.20.58.226    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-tbcrv   1/1     Running   0          6m45s   171.20.135.149   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-wgpwc   1/1     Running   0          6m45s   171.20.135.146   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-x9vdq   1/1     Running   0          36s     171.20.85.253    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-xc7q7   1/1     Running   0          36s     171.20.85.198    k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre></li></ul><h1 id="二、Drain"><a href="#二、Drain" class="headerlink" title="二、Drain"></a>二、Drain</h1><p><strong><code>kubectl drain</code></strong> 命令用于安全地将节点上的所有 Pod 驱逐到其他节点。在驱逐 Pod 之前，<code>drain</code> 命令会先 cordon 节点，以防止新的 Pod 调度到该节点上。</p><h2 id="1-使用场景-1"><a href="#1-使用场景-1" class="headerlink" title="1. 使用场景"></a>1. 使用场景</h2><ul><li><strong>节点维护：</strong>在需要关闭或删除节点之前，可以使用 <code>drain</code> 命令将节点上的所有 Pod 驱逐到其他节点，以确保应用程序的可用性。</li><li><strong>节点缩容：</strong>在需要缩减集群规模时，可以使用 <code>drain</code> 命令将要移除的节点上的 Pod 驱逐到其他节点。</li></ul><h2 id="2-如何使用-1"><a href="#2-如何使用-1" class="headerlink" title="2. 如何使用"></a>2. 如何使用</h2><ul><li><p>给节点设置 Drain </p><pre><code class="highlight bash">kubectl drain &lt;node-name&gt; --ignore-daemonsets --force</code></pre><ul><li><p><code>--ignore-daemonsets</code>：忽略 DaemonSet 管理的 Pod。DaemonSet 通常提供节点本地服务，即使节点被标记为不可调度，也应该在节点上运行。</p></li><li><p><code>--force</code>：强制驱逐 Pod，即使它们没有被 ReplicationController、Job 或 DaemonSet 管理。</p></li></ul></li><li><p>处理 Grace Period</p><p>如果 Pod 有较长的 grace period，<code>drain</code> 命令可能需要较长时间才能完成。可以使用 <code>--grace-period</code> 标志来覆盖 Pod 的终止宽限期，并强制立即驱逐：</p><pre><code class="highlight bash">kubectl drain &lt;node-name&gt; --grace-period 0 --force --ignore-daemonsets</code></pre><p>请谨慎使用此选项，因为强制停止 Pod 可能会导致数据丢失或应用程序错误。</p></li></ul><h2 id="3-案例实操-1"><a href="#3-案例实操-1" class="headerlink" title="3. 案例实操"></a>3. 案例实操</h2><ul><li><p>查看当前集群 Pod 运行情况</p><pre><code class="highlight bash">$ kubectl get pods -o wideNAME                     READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATESmyapp-85497bd9fb-6wjg6   1/1     Running   0          36s     171.20.135.151   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-8kzkf   1/1     Running   0          6m45s   171.20.58.225    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-97lnr   1/1     Running   0          36s     171.20.58.229    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-9vm9s   1/1     Running   0          6m45s   171.20.58.224    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-d2s9d   1/1     Running   0          36s     171.20.85.195    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-f8jqn   1/1     Running   0          36s     171.20.85.254    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-gbg7t   1/1     Running   0          36s     171.20.85.251    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-gtc22   1/1     Running   0          6m45s   171.20.58.227    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-hdvdn   1/1     Running   0          7m57s   171.20.58.223    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-j2tkd   1/1     Running   0          6m45s   171.20.58.228    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-kg9qf   1/1     Running   0          6m45s   171.20.135.147   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-m7zhs   1/1     Running   0          37s     171.20.85.252    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-mh9dx   1/1     Running   0          6m46s   171.20.135.145   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-nx2nb   1/1     Running   0          36s     171.20.135.150   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-q4z5x   1/1     Running   0          36s     171.20.85.255    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-qvrgl   1/1     Running   0          6m45s   171.20.58.226    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-tbcrv   1/1     Running   0          6m45s   171.20.135.149   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-wgpwc   1/1     Running   0          6m45s   171.20.135.146   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-x9vdq   1/1     Running   0          36s     171.20.85.253    k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-xc7q7   1/1     Running   0          36s     171.20.85.198    k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre></li><li><p>给 node01 节点设置 Drain</p><pre><code class="highlight bash">$ kubectl drain k8s-node01 --ignore-daemonsets --forcenode/k8s-node01 cordoned<span class="comment"># 查看节点状态， node01 被打上了 SchedulingDisabled 标签</span>$ kubectl get nodes NAME           STATUS                     ROLES           AGE   VERSIONk8s-master01   Ready                      control-plane   46d   v1.29.15k8s-node01     Ready,SchedulingDisabled   &lt;none&gt;          46d   v1.29.15k8s-node02     Ready                      &lt;none&gt;          46d   v1.29.15k8s-node03     Ready                      &lt;none&gt;          46d   v1.29.15</code></pre></li><li><p>查看 node01 节点的 Pod</p><pre><code class="highlight bash"><span class="comment"># 所有pod都被调度到 node02和node03节点了</span>$ kubectl get pods -o wideNAME                     READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATESmyapp-85497bd9fb-4cx54   1/1     Running   0          6m37s   171.20.58.233    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-6wjg6   1/1     Running   0          79m     171.20.135.151   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-8kzkf   1/1     Running   0          85m     171.20.58.225    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-97lnr   1/1     Running   0          79m     171.20.58.229    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-9vm9s   1/1     Running   0          85m     171.20.58.224    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-cv4xb   1/1     Running   0          6m38s   171.20.135.153   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-gtc22   1/1     Running   0          85m     171.20.58.227    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-hdvdn   1/1     Running   0          86m     171.20.58.223    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-j2tkd   1/1     Running   0          85m     171.20.58.228    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-kg9qf   1/1     Running   0          85m     171.20.135.147   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-mh9dx   1/1     Running   0          85m     171.20.135.145   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-nx2nb   1/1     Running   0          79m     171.20.135.150   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-qvrgl   1/1     Running   0          85m     171.20.58.226    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-rtcjg   1/1     Running   0          6m37s   171.20.135.154   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-rwvr7   1/1     Running   0          6m39s   171.20.135.152   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-sj22k   1/1     Running   0          6m37s   171.20.135.155   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-tbcrv   1/1     Running   0          85m     171.20.135.149   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-wgpwc   1/1     Running   0          85m     171.20.135.146   k8s-node03   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-x98hg   1/1     Running   0          6m38s   171.20.58.231    k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-85497bd9fb-z886v   1/1     Running   0          6m38s   171.20.58.232    k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre></li><li><p>取消 node01 节点的不可调度标签</p><pre><code class="highlight bash">$ kubectl uncordon k8s-node01node/k8s-node01 uncordoned</code></pre></li></ul><h2 id="4-drain-特别说明"><a href="#4-drain-特别说明" class="headerlink" title="4. drain - 特别说明"></a>4. drain - 特别说明</h2><p>kubectl drain 操作会将相应节点上的旧 Pod 删除，并在可调度节点上面起一个对应的 Pod。当旧 Pod 没有被正常删除的情况下，新 Pod 不会起来。例如：旧 Pod 一直处于 Terminating 状态。</p><p>对应的解决方式是通过重启相应节点的 kubelet，或者强制删除该 Pod 。</p><pre><code class="highlight bash"><span class="comment"># 重启发生`Terminating`节点的kubelet</span>systemctl restart kubelet<span class="comment"># 强制删除`Terminating`状态的Pod</span>kubectl delete pod &lt;PodName&gt; --namespace=&lt;Namespace&gt; --force --grace-period=0</code></pre><h2 id="5-恢复被勿驱逐的节点"><a href="#5-恢复被勿驱逐的节点" class="headerlink" title="5. 恢复被勿驱逐的节点"></a>5. 恢复被勿驱逐的节点</h2><p>如果在执行 drain 命令时，勿将不该驱逐的 Pod 驱逐出去，例如如下情况</p><pre><code class="highlight bash"><span class="comment"># 1.执行 drain 命令，驱逐 node01 节点上的Pod，由于node01部署了 metrics-server，因此发生报错，提示需要添加参数 --delete-emptydir-data</span>$ kubectl drain k8s-node01 --ignore-daemonsets --forcenode/k8s-node01 cordonederror: unable to drain node <span class="string">&quot;k8s-node01&quot;</span> due to error:cannot delete Pods with <span class="built_in">local</span> storage (use --delete-emptydir-data to override): kube-system/metrics-server-56cfc8b678-zvqpz, continuing <span class="built_in">command</span>...There are pending nodes to be drained: k8s-node01cannot delete Pods with <span class="built_in">local</span> storage (use --delete-emptydir-data to override): kube-system/metrics-server-56cfc8b678-zvqpz<span class="comment"># 查看 metrics-server</span>$ kubectl get pod -n kube-system  -o wide -w | grep metrics-servermetrics-server-56cfc8b678-zvqpz            1/1     Running   2 (2d1h ago)     2d1h   171.20.85.237   k8s-node01     &lt;none&gt;           &lt;none&gt;<span class="comment"># 2. 再次执行 drain 命令，node01 上的 Pod都被驱逐了，但也让 calico、etrics-server等组件也被驱逐了</span>$ kubectl drain k8s-node01 --ignore-daemonsets --force --delete-emptydir-datanode/k8s-node01 already cordonedWarning: ignoring DaemonSet-managed Pods: ingress-nginx/ingress-nginx-controller-cv9bj, kube-system/calico-node-45x9j, kube-system/kube-proxy-9qk4cevicting pod test-quota/test-deploy-5587d8c7c4-mptk4evicting pod default/myapp-85497bd9fb-m7zhsevicting pod default/myapp-85497bd9fb-gbg7tevicting pod default/myapp-85497bd9fb-xc7q7evicting pod default/myapp-85497bd9fb-q4z5xevicting pod default/myapp-85497bd9fb-f8jqnevicting pod kube-system/coredns-5f98f8d567-cv75devicting pod kube-system/calico-kube-controllers-558d465845-78g6devicting pod kube-system/metrics-server-56cfc8b678-zvqpzevicting pod default/myapp-85497bd9fb-d2s9devicting pod default/myapp-85497bd9fb-x9vdqI0912 11:08:35.913958  761187 request.go:697] Waited <span class="keyword">for</span> 1.021455195s due to client-side throttling, not priority and fairness, request: GET:https://10.20.1.139:6443/api/v1/namespaces/kube-system/pods/metrics-server-56cfc8b678-zvqpzI0912 11:08:46.113856  761187 request.go:697] Waited <span class="keyword">for</span> 1.222486642s due to client-side throttling, not priority and fairness, request: GET:https://10.20.1.139:6443/api/v1/namespaces/kube-system/pods/calico-kube-controllers-558d465845-78g6dI0912 11:08:56.114006  761187 request.go:697] Waited <span class="keyword">for</span> 1.222272943s due to client-side throttling, not priority and fairness, request: GET:https://10.20.1.139:6443/api/v1/namespaces/default/pods/myapp-85497bd9fb-d2s9dpod/myapp-85497bd9fb-gbg7t evictedpod/myapp-85497bd9fb-d2s9d evictedpod/myapp-85497bd9fb-m7zhs evictedpod/test-deploy-5587d8c7c4-mptk4 evictedI0912 11:09:06.914431  761187 request.go:697] Waited <span class="keyword">for</span> 1.022353159s due to client-side throttling, not priority and fairness, request: GET:https://10.20.1.139:6443/api/v1/namespaces/kube-system/pods/coredns-5f98f8d567-cv75dpod/myapp-85497bd9fb-f8jqn evictedpod/myapp-85497bd9fb-xc7q7 evictedpod/calico-kube-controllers-558d465845-78g6d evictedpod/coredns-5f98f8d567-cv75d evictedpod/metrics-server-56cfc8b678-zvqpz evictedpod/myapp-85497bd9fb-x9vdq evictedpod/myapp-85497bd9fb-q4z5x evictednode/k8s-node01 drained</code></pre><p>如何让 calico 、metrics-server 等组件重新调度到node01 节点</p><pre><code class="highlight bash"><span class="comment"># 删除 node01 节点的 SchedulingDisabled 标签</span>$ kubectl uncordon k8s-node01node/k8s-node01 uncordoned<span class="comment"># 滚动更新pod，重新调度</span>$ kubectl rollout restart deployment -n kube-system corednsdeployment.apps/coredns restarted$ kubectl rollout restart deployment -n kube-system metrics-serverdeployment.apps/metrics-server restarted$ kubectl rollout restart deployment -n kube-system calico-kube-controllersdeployment.apps/calico-kube-controllers restarted<span class="comment"># 再次查看 Pod</span>$ kubectl get pods -n kube-system -o wideNAME                                       READY   STATUS        RESTARTS        AGE     IP               NODE           NOMINATED NODE   READINESS GATEScalico-kube-controllers-558d465845-f2mhr   1/1     Running       0               7m46s   171.20.32.129    k8s-master01   &lt;none&gt;           &lt;none&gt;calico-node-45x9j                          1/1     Running       0               46d     10.20.1.140      k8s-node01     &lt;none&gt;           &lt;none&gt;calico-node-8rmt5                          1/1     Running       0               46d     10.20.1.139      k8s-master01   &lt;none&gt;           &lt;none&gt;calico-node-fzs4f                          1/1     Running       0               46d     10.20.1.142      k8s-node03     &lt;none&gt;           &lt;none&gt;calico-node-zhnlk                          1/1     Running       0               46d     10.20.1.141      k8s-node02     &lt;none&gt;           &lt;none&gt;calico-typha-5b56944f9b-6gd7p              1/1     Running       0               46d     10.20.1.141      k8s-node02     &lt;none&gt;           &lt;none&gt;coredns-5c988c55b8-ckqnf                   1/1     Running       0               30s     171.20.85.196    k8s-node01     &lt;none&gt;           &lt;none&gt;coredns-5c988c55b8-ljzxf                   0/1     Running       0               27s     171.20.135.156   k8s-node03     &lt;none&gt;           &lt;none&gt;coredns-5f98f8d567-72vc7                   1/1     Terminating   0               46d     171.20.58.192    k8s-node02     &lt;none&gt;           &lt;none&gt;etcd-k8s-master01                          1/1     Running       1               46d     10.20.1.139      k8s-master01   &lt;none&gt;           &lt;none&gt;kube-apiserver-k8s-master01                1/1     Running       4 (2d15h ago)   32d     10.20.1.139      k8s-master01   &lt;none&gt;           &lt;none&gt;kube-controller-manager-k8s-master01       1/1     Running       39              46d     10.20.1.139      k8s-master01   &lt;none&gt;           &lt;none&gt;kube-proxy-9qk4c                           1/1     Running       0               46d     10.20.1.140      k8s-node01     &lt;none&gt;           &lt;none&gt;kube-proxy-bm6rt                           1/1     Running       0               46d     10.20.1.142      k8s-node03     &lt;none&gt;           &lt;none&gt;kube-proxy-dwz4c                           1/1     Running       0               46d     10.20.1.139      k8s-master01   &lt;none&gt;           &lt;none&gt;kube-proxy-vsl77                           1/1     Running       0               46d     10.20.1.141      k8s-node02     &lt;none&gt;           &lt;none&gt;kube-scheduler-k8s-master01                1/1     Running       37 (24h ago)    46d     10.20.1.139      k8s-master01   &lt;none&gt;           &lt;none&gt;metrics-server-56cfc8b678-znl7h            1/1     Running       1 (7m4s ago)    7m46s   171.20.58.230    k8s-node02     &lt;none&gt;           &lt;none&gt;</code></pre><h2 id="6-Taints-和-Drain-的区别"><a href="#6-Taints-和-Drain-的区别" class="headerlink" title="6. Taints 和 Drain 的区别"></a>6. Taints 和 Drain 的区别</h2><p>在 Kubernetes 中，<strong>Taints（污点）</strong> 和 <strong>Drain（清空节点）</strong> 都是用于管理节点调度和 Pod 驱逐的机制，但它们的作用、实现方式和应用场景有显著区别。Taints 是一种更细粒度的调度控制工具，而 Drain 是一个高层的操作命令，用于节点维护。下面我从定义、功能、实现、场景等方面进行详细比较。</p><h3 id="6-1-基本定义"><a href="#6-1-基本定义" class="headerlink" title="6.1 基本定义"></a>6.1 基本定义</h3><ul><li><p><strong>Taints（污点）</strong>：是一种节点属性，用于“排斥”某些 Pod 调度到该节点。只有 Pod 配置了匹配的 <strong>Tolerations（容忍）</strong> 才能调度到带有该 Taint 的节点。Taints 可以有三种效果（Effect）：</p><ul><li><p>NoSchedule：阻止新 Pod 调度到节点（不影响现有 Pod）。</p></li><li><p>PreferNoSchedule：优先避免调度新 Pod（但可能调度）。</p></li><li><p>NoExecute：阻止新 Pod 调度，并驱逐现有 Pod（如果 Pod 无匹配 Toleration）。</p></li></ul></li><li><p><strong>Drain（清空节点）</strong>：是一个 kubectl drain 命令，用于安全地从节点上驱逐所有（或指定）Pod，并标记节点为不可调度（相当于 Cordon）。它不是一个独立机制，而是结合了 Cordon 和 Eviction 的过程。</p></li></ul><h3 id="6-2-功能比较"><a href="#6-2-功能比较" class="headerlink" title="6.2 功能比较"></a>6.2 功能比较</h3><table><thead><tr><th>方面</th><th>Taints (污点)</th><th>Drain (清空节点)</th></tr></thead><tbody><tr><td><strong>主要作用</strong></td><td>控制 Pod 调度和驱逐，通过节点“污点”排斥不匹配 Pod。</td><td>安全驱逐节点上 Pod，并防止新 Pod 调度，用于节点维护。</td></tr><tr><td><strong>对新 Pod</strong></td><td>通过 NoSchedule 效果阻止调度（需 Pod 有 Toleration 才能调度）。</td><td>标记节点为 unschedulable，阻止所有新 Pod 调度（忽略 DaemonSet）。</td></tr><tr><td><strong>对现有 Pod</strong></td><td>通过 NoExecute 效果驱逐不匹配 Pod（渐进式）。</td><td>强制驱逐所有非 DaemonSet Pod（可配置忽略 PDB、local storage 等）。</td></tr><tr><td><strong>自动性</strong></td><td>手动添加&#x2F;移除 Taint；节点控制器可自动添加（如 out-of-disk）。</td><td>手动执行命令；自动添加 unschedulable Taint。</td></tr><tr><td><strong>影响范围</strong></td><td>细粒度：可针对特定节点组（如专用硬件节点）隔离 Pod。</td><td>全局：针对整个节点清空，DaemonSet Pod 被忽略（会重建）。</td></tr><tr><td><strong>恢复方式</strong></td><td>kubectl taint nodes <node> key:NoSchedule- 移除 Taint。</td><td>kubectl uncordon <node> 移除 unschedulable 标记。</td></tr><tr><td><strong>示例命令</strong></td><td>kubectl taint nodes node1 key&#x3D;value:NoSchedule</td><td>kubectl drain node1 –ignore-daemonsets</td></tr></tbody></table><h3 id="6-3-实现机制的区别"><a href="#6-3-实现机制的区别" class="headerlink" title="6.3 实现机制的区别"></a>6.3 实现机制的区别</h3><ul><li><p><strong>Taints 的实现</strong>：</p><ul><li>Taints 存储在节点的 spec.taints 字段中，与 Pod 的 Tolerations 匹配。</li><li>Kubernetes 调度器（Scheduler）在调度 Pod 时检查 Taints 和 Tolerations。</li><li>例如，添加 Taint 后，只有有 Toleration 的 Pod（如 DaemonSet）才能运行。节点控制器会自动添加特定 Taint（如 node.kubernetes.io&#x2F;not-ready:NoExecute）来处理故障节点。</li><li>它更灵活，支持自定义键值对（如 dedicated&#x3D;frontend:NoSchedule），用于节点亲和性反向控制。</li></ul></li><li><p><strong>Drain 的实现</strong>：</p><ul><li>Drain 内部会先执行 cordon（标记节点 unschedulable），相当于添加一个隐式的 Taint node.kubernetes.io&#x2F;unschedulable:NoSchedule。</li><li>然后逐个驱逐 Pod（evict），尊重 PodDisruptionBudget (PDB)，忽略 DaemonSet。</li><li>完成后，节点被“清空”，但 DaemonSet Pod 仍运行（因为它们忽略 unschedulable Taint）。</li><li>Drain 不是直接使用 Taints，而是结合了 Taints 的效果（unschedulable Taint） + 手动驱逐逻辑。</li></ul><p><strong>关键点</strong>：Drain 会自动使用 Taint 来实现部分功能，但 Taints 可以独立使用，而不一定涉及驱逐。</p></li></ul><h3 id="6-4-使用场景"><a href="#6-4-使用场景" class="headerlink" title="6.4 使用场景"></a>6.4 使用场景</h3><ul><li><strong>Taints 适合：</strong><ul><li>专用节点隔离：如将 GPU 节点 Taint 为 gpu&#x3D;true:NoSchedule，只允许有 GPU Toleration 的 Pod 调度。</li><li>故障处理：自动驱逐 Pod 到健康节点（NoExecute 效果）。</li><li>高级调度：结合 Node Affinity，实现复杂亲和规则。</li></ul></li><li><strong>Drain 适合：</strong><ul><li>节点维护：如升级 kubelet、重启节点前清空 Pod，确保 Pod 迁移到其他节点。</li><li>临时不可用：快速标记节点维护中，防止新 Pod 调度。</li></ul></li><li><strong>两者结合</strong>：在 Drain 过程中，Kubernetes 会添加 node.kubernetes.io&#x2F;unschedulable Taint 来阻止调度。如果你想在 Drain 后进一步隔离，可以添加自定义 Taint。</li></ul><h3 id="6-5-注意事项"><a href="#6-5-注意事项" class="headerlink" title="6.5 注意事项"></a>6.5 注意事项</h3><ul><li><strong>兼容性</strong>：DaemonSet Pod 通常有内置 Toleration，能忽略 unschedulable Taint，因此 Drain 不会移除它们。</li><li><strong>潜在问题</strong>：如果 Pod 有本地存储（如 emptyDir），Drain 可能失败，需要 –delete-emptydir-data 参数。</li><li><strong>最佳实践</strong>：Drain 前备份 Pod 配置；使用 Taints 时，确保关键 Pod（如系统组件）有对应 Toleration。</li></ul><p><strong>参考链接</strong></p><blockquote><p><a href="https://kubernetes.io/zh-cn/docs/reference/kubectl/generated/kubectl_cordon/">https://kubernetes.io/zh-cn/docs/reference/kubectl/generated/kubectl_cordon/</a></p><p><a href="https://chegva.com/6300.html">https://chegva.com/6300.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;集群环境&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;Hostname&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;10.20.1.139&lt;/td&gt;
</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>003-PyCharm下载和安装</title>
    <link href="https://georgechan95.github.io/blog/2cd8097a.html"/>
    <id>https://georgechan95.github.io/blog/2cd8097a.html</id>
    <published>2025-09-10T04:17:00.000Z</published>
    <updated>2025-09-10T05:21:50.199Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、下载-PyCharm"><a href="#一、下载-PyCharm" class="headerlink" title="一、下载 PyCharm"></a>一、下载 PyCharm</h1><h2 id="1-访问-jetbrains-官网"><a href="#1-访问-jetbrains-官网" class="headerlink" title="1. 访问 jetbrains 官网"></a>1. 访问 jetbrains 官网</h2><p><a href="https://www.jetbrains.com/">https://www.jetbrains.com/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-121952.png" alt="jetbrains 官网"></p><h2 id="2-进入到下载页面"><a href="#2-进入到下载页面" class="headerlink" title="2. 进入到下载页面"></a>2. 进入到下载页面</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-122121.png" alt="进入到PyCharm下载页面"></p><h2 id="3-下载"><a href="#3-下载" class="headerlink" title="3. 下载"></a>3. 下载</h2><h3 id="3-1-下载最新版"><a href="#3-1-下载最新版" class="headerlink" title="3.1 下载最新版"></a>3.1 下载最新版</h3><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-122429.png" alt="最新版下载页"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-122250.png" alt="选择适合当前操作系统的PyCharm"></p><p><strong>点击 <code>Download</code> 即可下载最新版 PyCharm</strong></p><h3 id="3-2-下载历史版本"><a href="#3-2-下载历史版本" class="headerlink" title="3.2 下载历史版本"></a>3.2 下载历史版本</h3><p>在下载页选择 <code>Other versions</code> ，进入历史版本下载页</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-122543.png" alt="进入历史版本下载页"></p><p>也可以直接访问历史版本下载页Url ： <a href="https://www.jetbrains.com/pycharm/download/other.html">https://www.jetbrains.com/pycharm/download/other.html</a></p><p>选择要下载的 PyCharm 版本，点击即可下载</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-122736.png" alt="image-20250910122735864"></p><h1 id="二、安装-PyCharm"><a href="#二、安装-PyCharm" class="headerlink" title="二、安装 PyCharm"></a>二、安装 PyCharm</h1><h2 id="1-双击-exe-安装包"><a href="#1-双击-exe-安装包" class="headerlink" title="1. 双击 exe 安装包"></a>1. 双击 exe 安装包</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-123130.png" alt="双击 exe 安装包"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-123240.png" alt="点击 Next"></p><h2 id="2-选择安装位置"><a href="#2-选择安装位置" class="headerlink" title="2. 选择安装位置"></a>2. 选择安装位置</h2><p>选择安装位置，点击 <code>Next</code></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-123459.png" alt="选择安装位置"></p><h2 id="3-勾选设置选项"><a href="#3-勾选设置选项" class="headerlink" title="3. 勾选设置选项"></a>3. 勾选设置选项</h2><p>勾选：安装后在桌面创建图标，点击 <code>Next</code></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-123847.png" alt="安装后在桌面创建图标"></p><h2 id="4-点击安装"><a href="#4-点击安装" class="headerlink" title="4. 点击安装"></a>4. 点击安装</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-123854.png" alt="点击 Install"></p><h2 id="5-安装完成"><a href="#5-安装完成" class="headerlink" title="5. 安装完成"></a>5. 安装完成</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-124025.png" alt="安装完成，点击 Finish"></p><h2 id="6-验证"><a href="#6-验证" class="headerlink" title="6. 验证"></a>6. 验证</h2><p>回到桌面，找到 PyCharm 图标，双击打开。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-124206.png" alt="双击打开 PyCharm"></p><p><strong>不导入配置</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-124312.png" alt="不导入配置，点击 OK"></p><h1 id="三、激活-PyCharm"><a href="#三、激活-PyCharm" class="headerlink" title="三、激活 PyCharm"></a>三、激活 PyCharm</h1><p>如果安装的 PyCharm 是非社区版，打开则需要激活，如下：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-124625.png" alt="待激活PyCharm"></p><p><strong>！！！！！！ 仅作学习 ,有条件请支持正版</strong> </p><p>激活方式，参考：<a href="https://www.exception.site/article/1660">https://www.exception.site/article/1660</a></p><p>补丁下载：</p><pre><code class="highlight plaintext">补丁网盘链接:链接：https://pan.baidu.com/s/1eU7uYJ_DDMMYeFvn8HCJbg?pwd=euoa 提取码：euoa备用链接:链接：https://pan.baidu.com/s/1CRKqy66EhuunYaIeLtuNCQ?pwd=eohl 提取码：eohl无限速蓝奏云网盘链接：https://wwz.lanzoul.com/iU4pm1d7fwxc</code></pre><h2 id="1-解压激活包"><a href="#1-解压激活包" class="headerlink" title="1. 解压激活包"></a>1. 解压激活包</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-130559.png" alt="解压激活包"></p><h2 id="2-复制激活包"><a href="#2-复制激活包" class="headerlink" title="2. 复制激活包"></a>2. 复制激活包</h2><p>进入解压目录，找到 <code>jetbra</code> 目录</p><p><code>JetBrains  2024 最新全家桶激活</code> \ <code>方式3：永久激活补丁+脚本（适合最新版本，可显示到2025年）</code> \ <code>jetbra</code></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-130959.png" alt="jetbra 目录"></p><p>将整个 <code>jetbra</code> 目录复制到电脑的某个路径下，不要动。</p><p>这里将 <code>jetbra</code> 目录复制到  E:\software\JetBrains</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-131117.png" alt="将 `jetbra` 目录复制到  E:\software\JetBrains"></p><h2 id="3-执行激活脚本"><a href="#3-执行激活脚本" class="headerlink" title="3. 执行激活脚本"></a>3. 执行激活脚本</h2><p>进入 jetbra -&gt; scripts 目录，双击 <code>install-current-user.vbs</code> 脚本，激活PyCharm</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-130022.png" alt="执行激活脚本"></p><p>等待一会，直到出现弹框，显示 ： Done</p><h2 id="4-输入激活码"><a href="#4-输入激活码" class="headerlink" title="4. 输入激活码"></a>4. 输入激活码</h2><p>重新打开 PyCharm，输入激活码</p><pre><code class="highlight plaintext">EUWT4EE9X2-eyJsaWNlbnNlSWQiOiJFVVdUNEVFOVgyIiwibGljZW5zZWVOYW1lIjoic2lnbnVwIHNjb290ZXIiLCJhc3NpZ25lZU5hbWUiOiIiLCJhc3NpZ25lZUVtYWlsIjoiIiwibGljZW5zZVJlc3RyaWN0aW9uIjoiIiwiY2hlY2tDb25jdXJyZW50VXNlIjpmYWxzZSwicHJvZHVjdHMiOlt7ImNvZGUiOiJQU0kiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBDIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjpmYWxzZX0seyJjb2RlIjoiUFBDIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQV1MiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBDV01QIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfV0sIm1ldGFkYXRhIjoiMDEyMDIyMDkwMlBTQU4wMDAwMDUiLCJoYXNoIjoiVFJJQUw6MzUzOTQ0NTE3IiwiZ3JhY2VQZXJpb2REYXlzIjo3LCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-FT9l1nyyF9EyNmlelrLP9rGtugZ6sEs3CkYIKqGgSi608LIamge623nLLjI8f6O4EdbCfjJcPXLxklUe1O/5ASO3JnbPFUBYUEebCWZPgPfIdjw7hfA1PsGUdw1SBvh4BEWCMVVJWVtc9ktE+gQ8ldugYjXs0s34xaWjjfolJn2V4f4lnnCv0pikF7Ig/Bsyd/8bsySBJ54Uy9dkEsBUFJzqYSfR7Z/xsrACGFgq96ZsifnAnnOvfGbRX8Q8IIu0zDbNh7smxOwrz2odmL72UaU51A5YaOcPSXRM9uyqCnSp/ENLzkQa/B9RNO+VA7kCsj3MlJWJp5Sotn5spyV+gA==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-125955.png" alt="点击 Activate"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-125909.png" alt="点击 Continue"></p><h2 id="5-激活完成"><a href="#5-激活完成" class="headerlink" title="5. 激活完成"></a>5. 激活完成</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/10/20250910-131534.png" alt="激活完成"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、下载-PyCharm&quot;&gt;&lt;a href=&quot;#一、下载-PyCharm&quot; class=&quot;headerlink&quot; title=&quot;一、下载 PyCharm&quot;&gt;&lt;/a&gt;一、下载 PyCharm&lt;/h1&gt;&lt;h2 id=&quot;1-访问-jetbrains-官网&quot;&gt;&lt;a hre</summary>
      
    
    
    
    <category term="Python" scheme="https://georgechan95.github.io/categories/Python/"/>
    
    <category term="PyCharm" scheme="https://georgechan95.github.io/categories/Python/PyCharm/"/>
    
    
    <category term="Python" scheme="https://georgechan95.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>022-K8S-资源限制</title>
    <link href="https://georgechan95.github.io/blog/6617f273.html"/>
    <id>https://georgechan95.github.io/blog/6617f273.html</id>
    <published>2025-09-09T13:03:00.000Z</published>
    <updated>2025-09-11T13:51:29.469Z</updated>
    
    <content type="html"><![CDATA[<p><strong>集群环境</strong></p><table><thead><tr><th>IP</th><th>Hostname</th><th>用途</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td><td>Master节点</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td><td>Node节点</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td><td>Node节点</td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td><td>Node节点</td></tr></tbody></table><h1 id="一、资源限制-概念"><a href="#一、资源限制-概念" class="headerlink" title="一、资源限制 - 概念"></a>一、资源限制 - 概念</h1><p><em>备注：CPU单位换算：100m CPU，100 milliCPU 和 0.1 CPU 都相同；精度不能超过 1m。1000m CPU &#x3D; 1 CPU。</em></p><p><strong>官方文档</strong></p><ul><li><a href="https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/assign-cpu-resource/">https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/assign-cpu-resource/</a></li><li><a href="https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/assign-memory-resource/">https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/assign-memory-resource/</a></li></ul><p>Kubernetes 对资源的限制实际上是通过 cgroup 来控制的，cgroup 是容器的一组用来控制内核如何运行进程的相关属性集合。针对内存、CPU和各种设备都有对应的 cgroup。</p><p>默认情况下，Pod 运行没有 CPU 和内存的限额。这意味着系统中的任何 Pod 将能够像执行 Pod 所在节点机器一样，可以消耗足够多的 CPU 和内存。一般会针对某些应用的 Pod 资源进行资源限制，这个资源限制是通过 resources 的 requests【要分配的资源】和 limits【最大使用资源】来实现的。</p><h1 id="二、资源限制-特性"><a href="#二、资源限制-特性" class="headerlink" title="二、资源限制 - 特性"></a>二、资源限制 - 特性</h1><ul><li>调度器在调度时并不关注各类资源在当前时刻的实际使用量，而只关心节点上部署的所有 Pod 的资源申请量之和</li><li>在容器内看到的始终是节点的内存，而不是容器本身的内存</li><li>在容器内看到的始终是节点所有的 CPU 核，而不是仅仅只是容器可用的</li></ul><h1 id="三、资源限制-HPA"><a href="#三、资源限制-HPA" class="headerlink" title="三、资源限制 - HPA"></a>三、资源限制 - HPA</h1><h2 id="1-资源限制-案例解析"><a href="#1-资源限制-案例解析" class="headerlink" title="1. 资源限制 - 案例解析"></a>1. 资源限制 - 案例解析</h2><p>资源清单：<code>resource-limited-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">resource-limited-pod</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span>      <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>      <span class="comment"># 定义容器的资源请求和限制，控制 CPU 和内存的使用</span>      <span class="attr">resources:</span>        <span class="attr">requests:</span> <span class="comment"># 定义容器的资源请求，即容器启动时需要的最小资源量</span>          <span class="comment"># 容器启动时需要的最小内存量</span>          <span class="attr">memory:</span> <span class="string">&quot;64Mi&quot;</span>          <span class="comment"># 容器启动时需要的最小CPU量（250毫核， 0.25核心）</span>          <span class="attr">cpu:</span> <span class="string">&quot;250m&quot;</span>        <span class="attr">limits:</span> <span class="comment"># 定义容器的资源限制，即容器可以使用的最大资源量</span>          <span class="comment"># 容器可以使用的最大内存量</span>          <span class="attr">memory:</span> <span class="string">&quot;128Mi&quot;</span>          <span class="comment"># 容器可以使用的最大CPU量（500毫核， 0.5核心）</span>          <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span></code></pre><h2 id="2-资源限制-案例实操"><a href="#2-资源限制-案例实操" class="headerlink" title="2. 资源限制 - 案例实操"></a>2. 资源限制 - 案例实操</h2><h3 id="2-1-部署-metrics-server"><a href="#2-1-部署-metrics-server" class="headerlink" title="2.1 部署 metrics.server"></a>2.1 部署 metrics.server</h3><p>Metrics-Server 是集群核心监控数据的聚合器。通俗地说，它存储了集群中各节点的监控数据，并且提供了 API 以供分析和使用。</p><p>HPA 需要 Metrics Server 提供 CPU 指标, Pod 的扩缩容也都是基于指标的变化动态进行的。</p><p><strong>部署 metrics.server</strong></p><p><strong>参考：</strong><a href="https://georgechan95.github.io/blog/e62b8338.html">015-K8S-Prometheus部署及监控告警</a> 第十一段</p><p>**Github: ** <a href="https://github.com/kubernetes-sigs/metrics-server">https://github.com/kubernetes-sigs/metrics-server</a></p><p>metrics.server 部署资源清单：<code>components.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>    <span class="attr">rbac.authorization.k8s.io/aggregate-to-admin:</span> <span class="string">&quot;true&quot;</span>    <span class="attr">rbac.authorization.k8s.io/aggregate-to-edit:</span> <span class="string">&quot;true&quot;</span>    <span class="attr">rbac.authorization.k8s.io/aggregate-to-view:</span> <span class="string">&quot;true&quot;</span>  <span class="attr">name:</span> <span class="string">system:aggregated-metrics-reader</span><span class="attr">rules:</span><span class="bullet">-</span> <span class="attr">apiGroups:</span>  <span class="bullet">-</span> <span class="string">metrics.k8s.io</span>  <span class="attr">resources:</span>  <span class="bullet">-</span> <span class="string">pods</span>  <span class="bullet">-</span> <span class="string">nodes</span>  <span class="attr">verbs:</span>  <span class="bullet">-</span> <span class="string">get</span>  <span class="bullet">-</span> <span class="string">list</span>  <span class="bullet">-</span> <span class="string">watch</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">system:metrics-server</span><span class="attr">rules:</span><span class="bullet">-</span> <span class="attr">apiGroups:</span>  <span class="bullet">-</span> <span class="string">&quot;&quot;</span>  <span class="attr">resources:</span>  <span class="bullet">-</span> <span class="string">nodes/metrics</span>  <span class="attr">verbs:</span>  <span class="bullet">-</span> <span class="string">get</span><span class="bullet">-</span> <span class="attr">apiGroups:</span>  <span class="bullet">-</span> <span class="string">&quot;&quot;</span>  <span class="attr">resources:</span>  <span class="bullet">-</span> <span class="string">pods</span>  <span class="bullet">-</span> <span class="string">nodes</span>  <span class="attr">verbs:</span>  <span class="bullet">-</span> <span class="string">get</span>  <span class="bullet">-</span> <span class="string">list</span>  <span class="bullet">-</span> <span class="string">watch</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server-auth-reader</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="attr">roleRef:</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">Role</span>  <span class="attr">name:</span> <span class="string">extension-apiserver-authentication-reader</span><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server:system:auth-delegator</span><span class="attr">roleRef:</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">name:</span> <span class="string">system:auth-delegator</span><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">system:metrics-server</span><span class="attr">roleRef:</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">name:</span> <span class="string">system:metrics-server</span><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="attr">spec:</span>  <span class="attr">ports:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https</span>    <span class="attr">port:</span> <span class="number">443</span>    <span class="attr">protocol:</span> <span class="string">TCP</span>    <span class="attr">targetPort:</span> <span class="string">https</span>  <span class="attr">selector:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">strategy:</span>    <span class="attr">rollingUpdate:</span>      <span class="attr">maxUnavailable:</span> <span class="number">0</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>      <span class="bullet">-</span> <span class="attr">args:</span>        <span class="bullet">-</span> <span class="string">--cert-dir=/tmp</span>        <span class="bullet">-</span> <span class="string">--secure-port=10250</span>        <span class="bullet">-</span> <span class="string">--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span>        <span class="bullet">-</span> <span class="string">--kubelet-use-node-status-port</span>        <span class="bullet">-</span> <span class="string">--kubelet-insecure-tls</span>  <span class="comment"># 跳过 Kubelet TLS 验证</span>        <span class="bullet">-</span> <span class="string">--metric-resolution=15s</span>        <span class="attr">image:</span> <span class="string">registry.k8s.io/metrics-server/metrics-server:v0.7.0</span>        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>        <span class="attr">livenessProbe:</span>          <span class="attr">failureThreshold:</span> <span class="number">3</span>          <span class="attr">httpGet:</span>            <span class="attr">path:</span> <span class="string">/livez</span>            <span class="attr">port:</span> <span class="string">https</span>            <span class="attr">scheme:</span> <span class="string">HTTPS</span>          <span class="attr">periodSeconds:</span> <span class="number">10</span>        <span class="attr">name:</span> <span class="string">metrics-server</span>        <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">10250</span>          <span class="attr">name:</span> <span class="string">https</span>          <span class="attr">protocol:</span> <span class="string">TCP</span>        <span class="attr">readinessProbe:</span>          <span class="attr">failureThreshold:</span> <span class="number">3</span>          <span class="attr">httpGet:</span>            <span class="attr">path:</span> <span class="string">/readyz</span>            <span class="attr">port:</span> <span class="string">https</span>            <span class="attr">scheme:</span> <span class="string">HTTPS</span>          <span class="attr">initialDelaySeconds:</span> <span class="number">20</span>          <span class="attr">periodSeconds:</span> <span class="number">10</span>        <span class="attr">resources:</span>          <span class="attr">requests:</span>            <span class="attr">cpu:</span> <span class="string">100m</span>            <span class="attr">memory:</span> <span class="string">200Mi</span>        <span class="attr">securityContext:</span>          <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span>          <span class="attr">capabilities:</span>            <span class="attr">drop:</span>            <span class="bullet">-</span> <span class="string">ALL</span>          <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span>          <span class="attr">runAsNonRoot:</span> <span class="literal">true</span>          <span class="attr">runAsUser:</span> <span class="number">1000</span>          <span class="attr">seccompProfile:</span>            <span class="attr">type:</span> <span class="string">RuntimeDefault</span>        <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/tmp</span>          <span class="attr">name:</span> <span class="string">tmp-dir</span>      <span class="attr">nodeSelector:</span>        <span class="attr">kubernetes.io/os:</span> <span class="string">linux</span>      <span class="attr">priorityClassName:</span> <span class="string">system-cluster-critical</span>      <span class="attr">serviceAccountName:</span> <span class="string">metrics-server</span>      <span class="attr">volumes:</span>      <span class="bullet">-</span> <span class="attr">emptyDir:</span> &#123;&#125;        <span class="attr">name:</span> <span class="string">tmp-dir</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">apiregistration.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">APIService</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">v1beta1.metrics.k8s.io</span><span class="attr">spec:</span>  <span class="attr">group:</span> <span class="string">metrics.k8s.io</span>  <span class="attr">groupPriorityMinimum:</span> <span class="number">100</span>  <span class="attr">insecureSkipTLSVerify:</span> <span class="literal">true</span>  <span class="attr">service:</span>    <span class="attr">name:</span> <span class="string">metrics-server</span>    <span class="attr">namespace:</span> <span class="string">kube-system</span>  <span class="attr">version:</span> <span class="string">v1beta1</span>  <span class="attr">versionPriority:</span> <span class="number">100</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，部署 metrics-server</span>$ kubectl apply -f components.yaml<span class="comment"># 查看 metrics-server 运行状态，确保处于执行中</span>$ kubectl get pod -n kube-system  -o wide -w | grep metrics-servermetrics-server-56cfc8b678-zvqpz            1/1     Running   2 (56s ago)    2m9s   171.20.85.237   k8s-node01     &lt;none&gt;           &lt;none&gt;</code></pre><h3 id="2-2-演示-hpa-自动扩缩容"><a href="#2-2-演示-hpa-自动扩缩容" class="headerlink" title="2.2 演示 hpa 自动扩缩容"></a>2.2 演示 hpa 自动扩缩容</h3><h4 id="2-2-1-部署-Deployment"><a href="#2-2-1-部署-Deployment" class="headerlink" title="2.2.1 部署 Deployment"></a>2.2.1 部署 Deployment</h4><p>资源清单：<code>hpa-deploy-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">hpa-deploy-demo</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span> <span class="comment"># 默认副本数量为1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">resources:</span> <span class="comment"># 定义容器的资源请求和限制，控制 CPU 和内存的使用</span>            <span class="attr">requests:</span>              <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span>              <span class="attr">cpu:</span> <span class="string">&quot;200m&quot;</span>            <span class="attr">limits:</span>              <span class="attr">memory:</span> <span class="string">&quot;200Mi&quot;</span>              <span class="attr">cpu:</span> <span class="string">&quot;400m&quot;</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">hpa-deploy-demo</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，部署 Deployment 和 Service</span>$ kubectl delete -f hpa-deploy-demo.yaml deployment.apps <span class="string">&quot;hpa-deploy-demo&quot;</span> deletedservice <span class="string">&quot;hpa-deploy-demo&quot;</span> deleted<span class="comment"># 查看Pod，当前仅有一个 Pod 处于运行中，与资源清单中定义Pod副本数一致</span>$ kubectl get podsNAME                               READY   STATUS    RESTARTS   AGEhpa-deploy-demo-5587d8c7c4-k578h   1/1     Running   0          9s<span class="comment"># 查看Service，确定 Service IP</span>$ kubectl get svc NAME              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGEhpa-deploy-demo   ClusterIP   10.109.153.144   &lt;none&gt;        80/TCP    16s</code></pre><h4 id="2-2-2-部署-HPA"><a href="#2-2-2-部署-HPA" class="headerlink" title="2.2.2 部署 HPA"></a>2.2.2 部署 HPA</h4><p><strong>创建 HPA</strong></p><pre><code class="highlight bash"><span class="comment"># 创建一个或更新一个 HPA 资源，自动根据 CPU 使用率（目标值为 10%）调整 hpa-deploy-demo 这个 Deployment 的 Pod 副本数，副本数范围在 2 到 10 之间</span>$ kubectl autoscale deployment hpa-deploy-demo --cpu-percent=10 --min=2 --max=10horizontalpodautoscaler.autoscaling/hpa-deploy-demo autoscaled<span class="comment"># 查看HPA，过一会 Deployment 副本数由 1 变成 2，表示 HPA生效了</span>$ kubectl get hpa hpa-deploy-demoNAME              REFERENCE                    TARGETS   MINPODS   MAXPODS   REPLICAS   AGEhpa-deploy-demo   Deployment/hpa-deploy-demo   0%/10%    2         10        2          3s</code></pre><p><strong>测试自动扩缩容</strong></p><pre><code class="highlight bash"><span class="comment"># 多打开几个终端，连续访问 Service，观察 HPA 是否自动根据CPU负载，对 Deployment 进行了扩容</span>$ <span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span> wget -q -O- http://10.109.153.144; <span class="keyword">done</span><span class="comment"># 观察HPA运行状态（随着访问量的增加 Pod 扩容，随着访问量减少 Pod 缩容）</span>$ kubectl get hpa -wNAME              REFERENCE                    TARGETS         MINPODS   MAXPODS   REPLICAS   AGEhpa-deploy-demo   Deployment/hpa-deploy-demo   &lt;unknown&gt;/10%   2         10        0          3shpa-deploy-demo   Deployment/hpa-deploy-demo   16%/10%         2         10        2          13shpa-deploy-demo   Deployment/hpa-deploy-demo   17%/10%         2         10        4          28shpa-deploy-demo   Deployment/hpa-deploy-demo   14%/10%         2         10        4          44shpa-deploy-demo   Deployment/hpa-deploy-demo   11%/10%         2         10        4          59shpa-deploy-demo   Deployment/hpa-deploy-demo   7%/10%          2         10        4          75shpa-deploy-demo   Deployment/hpa-deploy-demo   0%/10%          2         10        4          90shpa-deploy-demo   Deployment/hpa-deploy-demo   0%/10%          2         10        4          6m4shpa-deploy-demo   Deployment/hpa-deploy-demo   0%/10%          2         10        3          6m20shpa-deploy-demo   Deployment/hpa-deploy-demo   0%/10%          2         10        2          6m35s</code></pre><h3 id="2-3-HPA资源清单"><a href="#2-3-HPA资源清单" class="headerlink" title="2.3 HPA资源清单"></a>2.3 HPA资源清单</h3><pre><code class="highlight bash">kubectl autoscale deployment hpa-deploy-demo --cpu-percent=10 --min=2 --max=10</code></pre><p>上面的HPA创建命令可以转换成资源清单如下：</p><p><code>horizontal-pod-autoscaler.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">autoscaling/v2</span><span class="attr">kind:</span> <span class="string">HorizontalPodAutoscaler</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">hpa-deploy-demo</span><span class="attr">spec:</span>  <span class="attr">scaleTargetRef:</span>    <span class="attr">apiVersion:</span> <span class="string">apps/v1</span>    <span class="attr">kind:</span> <span class="string">Deployment</span>    <span class="attr">name:</span> <span class="string">hpa-deploy-demo</span> <span class="comment"># 关联的Deployment名称</span>  <span class="attr">minReplicas:</span> <span class="number">2</span> <span class="comment"># 最小副本数量</span>  <span class="attr">maxReplicas:</span> <span class="number">10</span> <span class="comment"># 最大副本数量</span>  <span class="attr">metrics:</span>    <span class="bullet">-</span> <span class="attr">type:</span> <span class="string">Resource</span> <span class="comment"># 指标类型为资源指标</span>      <span class="attr">resource:</span>        <span class="attr">name:</span> <span class="string">cpu</span> <span class="comment"># 资源指标名称为CPU</span>        <span class="attr">target:</span>          <span class="attr">type:</span> <span class="string">Utilization</span> <span class="comment"># 指标类型为利用率</span>          <span class="attr">averageUtilization:</span> <span class="number">10</span> <span class="comment"># 目标利用率为10%</span></code></pre><h3 id="2-4-HPA-操作"><a href="#2-4-HPA-操作" class="headerlink" title="2.4 HPA 操作"></a>2.4 HPA 操作</h3><pre><code class="highlight bash"><span class="comment"># 查看 HPA</span>kubectl get hpa<span class="comment"># 指定 Deployment 查看 HPA，并动态监控</span>kubectl get hpa hpa-deploy-demo --watch<span class="comment"># 删除指定的 HPA</span>kubectl delete hpa hpa-deploy-demo</code></pre><h1 id="四、服务质量等级（QoS）"><a href="#四、服务质量等级（QoS）" class="headerlink" title="四、服务质量等级（QoS）"></a>四、服务质量等级（QoS）</h1><h2 id="1-什么是-QoS"><a href="#1-什么是-QoS" class="headerlink" title="1. 什么是 QoS"></a>1. 什么是 QoS</h2><p>QoS（Quality of Service）即服务质量等级，是 Kubernetes 中作用于 Pod 的重要配置机制。当 Kubernetes 创建 Pod 时，会根据容器的资源配置自动为其分配相应的 QoS 等级，这直接影响 Pod 的调度优先级和资源回收策略。</p><h2 id="2-QoS-等级分类"><a href="#2-QoS-等级分类" class="headerlink" title="2. QoS 等级分类"></a>2. QoS 等级分类</h2><p>Kubernetes 中的 QoS 等级分为三种：</p><h3 id="2-1-Guaranteed（保证级）-优先级最高"><a href="#2-1-Guaranteed（保证级）-优先级最高" class="headerlink" title="2.1 Guaranteed（保证级）-  优先级最高"></a>2.1 Guaranteed（保证级）-  优先级最高</h3><p><strong>特征</strong>：Pod 中的每个容器都必须同时设置 CPU 和内存的 <code>limits</code> 和 <code>requests</code>，且对应的值必须相等。</p><p><strong>适用场景</strong>：关键业务应用，需要稳定的资源保证。</p><p><strong>配置示例</strong>：</p><pre><code class="highlight yaml"><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span>      <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>      <span class="attr">resources:</span> <span class="comment"># 定义容器的资源请求和限制，控制 CPU 和内存的使用</span>        <span class="attr">requests:</span>          <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span>          <span class="attr">cpu:</span> <span class="string">&quot;200m&quot;</span>        <span class="attr">limits:</span>          <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span>          <span class="attr">cpu:</span> <span class="string">&quot;200m&quot;</span></code></pre><p><strong>如果容器的资源 requests 没有显式设置，默认与 limits 相同</strong></p><h3 id="2-2-Burstable（突发级）-优先级中等"><a href="#2-2-Burstable（突发级）-优先级中等" class="headerlink" title="2.2 Burstable（突发级）-  优先级中等"></a>2.2 Burstable（突发级）-  优先级中等</h3><p><strong>特征</strong>：Pod 中至少有一个容器设置了内存或 CPU 的 <code>requests</code> 或 <code>limits</code>，但不满足 Guaranteed 等级的要求。</p><p><strong>适用场景</strong>：一般业务应用，允许资源使用量在一定范围内波动。</p><p><strong>配置示例</strong>：</p><pre><code class="highlight yaml"><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span>      <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>      <span class="attr">resources:</span> <span class="comment"># 定义容器的资源请求和限制，控制 CPU 和内存的使用</span>        <span class="attr">requests:</span>          <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span>        <span class="attr">limits:</span>          <span class="attr">memory:</span> <span class="string">&quot;200Mi&quot;</span></code></pre><h3 id="2-3-BestEffort（尽力而为级）-优先级最低"><a href="#2-3-BestEffort（尽力而为级）-优先级最低" class="headerlink" title="2.3 BestEffort（尽力而为级）-   优先级最低"></a>2.3 BestEffort（尽力而为级）-   优先级最低</h3><p><strong>特征</strong>：Pod 中的所有容器都没有设置任何内存或 CPU 的 <code>limits</code> 和 <code>requests</code>。</p><p><strong>适用场景</strong>：非关键应用，对资源要求不高，可以容忍被优先回收。</p><p><strong>配置示例</strong>：</p><pre><code class="highlight yaml"><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span>      <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>      <span class="attr">resources:</span> &#123;&#125;</code></pre><h2 id="3-QoS-的作用机制"><a href="#3-QoS-的作用机制" class="headerlink" title="3. QoS 的作用机制"></a>3. QoS 的作用机制</h2><h3 id="3-1-调度优先级"><a href="#3-1-调度优先级" class="headerlink" title="3.1 调度优先级"></a>3.1 调度优先级</h3><ul><li><strong>Guaranteed</strong>：最高优先级，优先分配到资源充足的节点</li><li><strong>Burstable</strong>：中等优先级，在满足基本资源需求的前提下调度</li><li><strong>BestEffort</strong>：最低优先级，通常调度到剩余资源较多的节点</li></ul><h3 id="3-2-资源回收策略"><a href="#3-2-资源回收策略" class="headerlink" title="3.2 资源回收策略"></a>3.2 资源回收策略</h3><p>当节点资源不足时，Kubernetes 会按照以下顺序回收 Pod：</p><ol><li>首先回收 <strong>BestEffort</strong> 级别的 Pod</li><li>其次回收超出 <code>requests</code> 资源使用量的 <strong>Burstable</strong> 级别 Pod</li><li>最后回收 <strong>Guaranteed</strong> 级别的 Pod（仅在系统组件需要资源时）</li></ol><h2 id="4-查看-Pod-的-QoS-等级"><a href="#4-查看-Pod-的-QoS-等级" class="headerlink" title="4. 查看 Pod 的 QoS 等级"></a>4. 查看 Pod 的 QoS 等级</h2><p>使用以下命令可以查看 Pod 的 QoS 等级：</p><pre><code class="highlight bash">kubectl get pod &lt;pod-name&gt; -o yaml | grep qosClass</code></pre><p>或者使用 <code>describe</code> 命令：</p><pre><code class="highlight bash">kubectl describe pod &lt;pod-name&gt; | grep QoS</code></pre><h1 id="五、LimitRange"><a href="#五、LimitRange" class="headerlink" title="五、LimitRange"></a>五、LimitRange</h1><h2 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h2><p><code>LimitRange</code> 是一种用于限制容器资源使用的配置对象。它允许集群管理员定义资源的最小和最大限制，并确保容器在这些限制范围内使用资源。</p><p>通过使用 <code>LimitRange</code>，可以避免容器使用过多或过少的资源，保护集群免受资源耗尽和应用程序崩溃的影响。</p><p>默认情况下， Kubernetes 集群上的容器运行使用的计算资源没有限制。 使用 Kubernetes 资源配额， 管理员（也称为 集群操作者）可以在一个指定的命名空间内限制集群资源的使用与创建。 在命名空间中，一个 Pod 最多能够使用命名空间的资源配额所定义的 CPU 和内存用量。 作为集群操作者或命名空间级的管理员，你可能也会担心如何确保一个 Pod 不会垄断命名空间内所有可用的资源。</p><p>LimitRange 是限制命名空间内可为每个适用的对象类别 （例如 Pod 或 PersistentVolumeClaim） 指定的资源分配量（限制和请求）的策略对象。</p><p>一个 LimitRange（限制范围） 对象提供的限制能够做到：</p><ul><li>在一个命名空间中实施对每个 Pod 或 Container 最小和最大的资源使用量的限制。</li><li>在一个命名空间中实施对每个 PersistentVolumeClaim 能申请的最小和最大的存储空间大小的限制。</li><li>在一个命名空间中实施对一种资源的申请值和限制值的比值的控制。</li><li>设置一个命名空间中对计算资源的默认申请&#x2F;限制值，并且自动的在运行时注入到多个 Container 中。</li></ul><p><strong>当某命名空间中有一个 LimitRange 对象时，将在该命名空间中实施 LimitRange 限制。</strong></p><h2 id="2-案例"><a href="#2-案例" class="headerlink" title="2. 案例"></a>2. 案例</h2><h3 id="2-1-创建-LimitRange"><a href="#2-1-创建-LimitRange" class="headerlink" title="2.1 创建 LimitRange"></a>2.1 创建 LimitRange</h3><p>资源清单：<code>limit-range.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">LimitRange</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">limit-range-demo</span>  <span class="comment"># 限制范围的名称</span>  <span class="attr">namespace:</span> <span class="string">default</span>      <span class="comment"># 限制范围的命名空间</span><span class="attr">spec:</span>  <span class="attr">limits:</span>    <span class="bullet">-</span> <span class="attr">type:</span> <span class="string">Pod</span>        <span class="comment"># 限制Pod的资源</span>      <span class="attr">max:</span>                <span class="comment"># 定义了 Pod 中所有容器的资源请求（requests）和限制（limits）之和的最大值。</span>        <span class="attr">cpu:</span> <span class="string">&quot;1&quot;</span>          <span class="comment"># 该 Pod 使用的 CPU 总和不能超过 1 核。</span>        <span class="attr">memory:</span> <span class="string">&quot;1Gi&quot;</span>     <span class="comment"># 该 Pod 使用的内存总和不能超过 1GiB。</span>      <span class="attr">min:</span>                <span class="comment"># 定义了 Pod 中所有容器的资源请求（requests）之和的最小值</span>        <span class="attr">cpu:</span> <span class="string">&quot;200m&quot;</span>       <span class="comment"># 该 Pod 至少需要请求（requests）200 milliCPU（即 0.2 核）</span>        <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span>   <span class="comment"># 该 Pod 至少需要请求（requests）100 Mebibyte 内存</span>    <span class="bullet">-</span> <span class="attr">type:</span> <span class="string">Container</span>  <span class="comment"># 限制Container的资源</span>      <span class="attr">max:</span>                <span class="comment"># 定义了单个容器可以设置的资源限制（limits）的最大值。</span>        <span class="attr">cpu:</span> <span class="string">500m</span>         <span class="comment"># 任何容器定义的 limits.cpu 都不能超过 500m（0.5核）</span>        <span class="attr">memory:</span> <span class="string">1Gi</span>       <span class="comment"># 任何容器定义的 limits.memory 都不能超过 500MiB</span>      <span class="attr">min:</span>                <span class="comment"># 定义了单个容器可以设置的资源请求（requests）的最小值。</span>        <span class="attr">cpu:</span> <span class="string">100m</span>         <span class="comment"># 任何容器定义的 requests.cpu 都不能低于 100m（0.1 核）</span>        <span class="attr">memory:</span> <span class="string">100Mi</span>     <span class="comment"># 任何容器定义的 requests.memory 都不能低于 100MiB</span>      <span class="attr">defaultRequest:</span>     <span class="comment"># 默认请求值，如果一个容器被创建时没有指定 requests.cpu 或 requests.memory，系统会自动为它设置这些默认值</span>        <span class="attr">cpu:</span> <span class="string">200m</span>        <span class="attr">memory:</span> <span class="string">500Mi</span>      <span class="attr">default:</span>            <span class="comment"># 默认限制值，如果一个容器被创建时没有指定 limits.cpu 或 limits.memory，系统会自动为它设置这些默认值</span>        <span class="attr">cpu:</span> <span class="string">500m</span>        <span class="attr">memory:</span> <span class="string">500Mi</span>      <span class="attr">maxLimitRequestRatio:</span> <span class="comment"># 定义了容器的最大资源限制与请求的比例。</span>        <span class="attr">cpu:</span> <span class="string">&quot;2&quot;</span>            <span class="comment">#  容器的 limits.cpu / requests.cpu 的比值不能大于 2。例如，如果 requests.cpu 是 100m，那么 limits.cpu 最大只能设为 200m</span>        <span class="attr">memory:</span> <span class="string">&quot;4&quot;</span>         <span class="comment"># 容器的 limits.memory / requests.memory 的比值不能大于 4。例如，如果 requests.memory 是 100MiB，那么 limits.memory 最大只能设为 400MiB</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 LimitRange</span>$ kubectl apply -f limit-range.yaml limitrange/limit-range-demo created<span class="comment"># 查看有哪些 LimitRange</span>$ kubectl get LimitRangeNAME               CREATED ATlimit-range-demo   2025-09-11T12:50:58Z<span class="comment"># 查看详情</span>$ kubectl describe LimitRange limit-range-demoName:       limit-range-demoNamespace:  defaultType        Resource  Min    Max   Default Request  Default Limit  Max Limit/Request Ratio----        --------  ---    ---   ---------------  -------------  -----------------------Pod         cpu       200m   1     -                -              -Pod         memory    100Mi  1Gi   -                -              -Container   memory    100Mi  1Gi   500Mi            500Mi          4Container   cpu       100m   500m  200m             500m           2</code></pre><h3 id="2-2-创建-Pod"><a href="#2-2-创建-Pod" class="headerlink" title="2.2 创建 Pod"></a>2.2 创建 Pod</h3><h4 id="2-2-1-不符合-LimitRange-要求的-Pod"><a href="#2-2-1-不符合-LimitRange-要求的-Pod" class="headerlink" title="2.2.1 不符合 LimitRange 要求的 Pod"></a>2.2.1 不符合 LimitRange 要求的 Pod</h4><p>资源清单：<code>error-limit-deploy.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">error-limited-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span>      <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>      <span class="comment"># 最大内存与最小内存的比值不能超过 4，这里超过了，因此资源清单执行失败</span>      <span class="attr">resources:</span>        <span class="attr">requests:</span> <span class="comment"># 定义容器的资源请求，即容器启动时需要的最小资源量</span>          <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span>          <span class="attr">cpu:</span> <span class="string">&quot;250m&quot;</span>        <span class="attr">limits:</span> <span class="comment"># 定义容器的资源限制，即容器可以使用的最大资源量</span>          <span class="attr">memory:</span> <span class="string">&quot;500Mi&quot;</span>          <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f error-limit-deploy.yaml Error from server (Forbidden): error when creating <span class="string">&quot;error-limit-deploy.yaml&quot;</span>: pods <span class="string">&quot;error-limited-deploy&quot;</span> is forbidden: memory max <span class="built_in">limit</span> to request ratio per Container is 4, but provided ratio is 5.000000</code></pre><p>最大内存与最小内存的比值不能超过 4，这里是5，超过了，因此 Pod 创建失败。</p><h4 id="2-2-2-符合-LimitRange-要求的-Pod"><a href="#2-2-2-符合-LimitRange-要求的-Pod" class="headerlink" title="2.2.2 符合 LimitRange 要求的 Pod"></a>2.2.2 符合 LimitRange 要求的 Pod</h4><p>资源清单：<code>right-limit-deploy.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">error-limited-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span>      <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>      <span class="comment"># 最大内存与最小内存的比值不能超过 4，这里超过了，因此资源清单执行失败</span>      <span class="attr">resources:</span>        <span class="attr">requests:</span> <span class="comment"># 定义容器的资源请求，即容器启动时需要的最小资源量</span>          <span class="attr">memory:</span> <span class="string">&quot;200Mi&quot;</span>          <span class="attr">cpu:</span> <span class="string">&quot;200m&quot;</span>        <span class="attr">limits:</span> <span class="comment"># 定义容器的资源限制，即容器可以使用的最大资源量</span>          <span class="attr">memory:</span> <span class="string">&quot;500Mi&quot;</span>          <span class="attr">cpu:</span> <span class="string">&quot;400m&quot;</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f right-limit-deploy.yaml pod/error-limited-deploy created$ kubectl get pods NAME                   READY   STATUS    RESTARTS   AGEerror-limited-deploy   1/1     Running   0          94s</code></pre><h1 id="六、ResourceQuota"><a href="#六、ResourceQuota" class="headerlink" title="六、ResourceQuota"></a>六、ResourceQuota</h1><h2 id="1-概念-1"><a href="#1-概念-1" class="headerlink" title="1. 概念"></a>1. 概念</h2><p><code>ResourceQuota</code> 是一种用于限制命名空间内资源使用的对象。它允许集群管理员对命名空间中的资源使用进行配额管理，确保不同的团队或项目之间资源的公平分配和有效利用。</p><p>使用 <code>ResourceQuota</code>，可以限制命名空间中的CPU、内存和其他资源的总量，防止资源滥用和浪费。</p><p>资源配额，通过 ResourceQuota 对象来定义，对每个命名空间的资源消耗总量提供限制。 它可以限制命名空间中某种类型的对象的总数目上限，也可以限制命名空间中的 Pod 可以使用的计算资源的总上限。</p><p>资源配额的工作方式如下：</p><ul><li>不同的团队可以在不同的命名空间下工作。这可以通过 RBAC 强制执行。</li><li>集群管理员可以为每个命名空间创建一个或多个 ResourceQuota 对象。</li><li>当用户在命名空间下创建资源（如 Pod、Service 等）时，Kubernetes 的配额系统会跟踪集群的资源使用情况， 以确保使用的资源用量不超过 ResourceQuota 中定义的硬性资源限额。</li><li>如果资源创建或者更新请求违反了配额约束，那么该请求会报错（HTTP 403 FORBIDDEN）， 并在消息中给出有可能违反的约束。</li><li>如果命名空间下的计算资源 （如 cpu 和 memory）的配额被启用， 则用户必须为这些资源设定请求值（request）和约束值（limit），否则配额系统将拒绝 Pod 的创建。 提示: 可使用 LimitRanger 准入控制器来为没有设置计算资源需求的 Pod 设置默认值。</li></ul><p>简而言之，<code>ResourceQuota</code> 配额就是用来设置一个命名空间最多能创建多少个对象，比如能创建多少svc，能创建多少pod&#x2F;deploy。</p><h2 id="2-案例-1"><a href="#2-案例-1" class="headerlink" title="2. 案例"></a>2. 案例</h2><h3 id="2-1-创建-ResourceQuota"><a href="#2-1-创建-ResourceQuota" class="headerlink" title="2.1 创建 ResourceQuota"></a>2.1 创建 ResourceQuota</h3><p><strong>资源清单：</strong> <code>resource-quota.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ResourceQuota</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-resource-quota</span>  <span class="attr">namespace:</span> <span class="string">test-quota</span><span class="attr">spec:</span>  <span class="attr">hard:</span> <span class="comment"># 强制性的资源上限</span>    <span class="attr">requests.cpu:</span> <span class="string">&quot;20&quot;</span>            <span class="comment"># 该命名空间中所有 Pod 的 spec.containers[].resources.requests.cpu 之和不能超过 20 个 CPU 核心</span>    <span class="attr">requests.memory:</span> <span class="string">100Gi</span>        <span class="comment"># 该命名空间中所有 Pod 的 spec.containers[].resources.requests.memory 之和不能超过 100 Gibibyte</span>    <span class="attr">limits.cpu:</span> <span class="string">&quot;40&quot;</span>              <span class="comment"># 该命名空间中所有 Pod 的 spec.containers[].resources.limits.cpu 之和不能超过 40 个 CPU 核心</span>    <span class="attr">limits.memory:</span> <span class="string">200Gi</span>          <span class="comment"># 该命名空间中所有 Pod 的 spec.containers[].resources.limits.memory 之和不能超过 200 Gibibyte</span>    <span class="attr">pods:</span> <span class="string">&quot;1&quot;</span>                     <span class="comment"># 在该命名空间中最多只能创建 1 个 Pod</span>    <span class="attr">configmaps:</span> <span class="string">&quot;10&quot;</span>              <span class="comment"># 最多只能创建 10 个 ConfigMap</span>    <span class="attr">persistentvolumeclaims:</span> <span class="string">&quot;4&quot;</span>   <span class="comment"># 最多只能创建 4 个 PersistentVolumeClaim (PVC)</span>    <span class="attr">replicationcontrollers:</span> <span class="string">&quot;20&quot;</span>  <span class="comment"># 最多只能创建 20 个 ReplicationController（一种老的 Pod 控制器）</span>    <span class="attr">secrets:</span> <span class="string">&quot;10&quot;</span>                 <span class="comment"># 最多只能创建 10 个 Secret</span>    <span class="attr">services:</span> <span class="string">&quot;10&quot;</span>                <span class="comment"># 最多只能创建 10 个 Service</span>    <span class="attr">services.loadbalancers:</span> <span class="string">&quot;2&quot;</span>   <span class="comment"># 在所有的 Service 中，类型为 LoadBalancer 的不能超过 2 个</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 创建名称空间</span>$ kubectl create ns test-quotanamespace/test-quota created<span class="comment"># 执行资源清单，创建 ResourceQuota</span>$ kubectl apply -f resource-quota.yaml resourcequota/my-resource-quota created<span class="comment"># 查看 quota 配置详情</span>$ kubectl describe ResourceQuota -n test-quotaName:                   my-resource-quotaNamespace:              test-quotaResource                Used  Hard--------                ----  ----configmaps              1     10limits.cpu              0     40limits.memory           0     200Gipersistentvolumeclaims  0     4pods                    0     1replicationcontrollers  0     20requests.cpu            0     20requests.memory         0     100Gisecrets                 0     10services                0     10services.loadbalancers  0     2</code></pre><h3 id="2-2-创建-Pod-1"><a href="#2-2-创建-Pod-1" class="headerlink" title="2.2 创建 Pod"></a>2.2 创建 Pod</h3><p>资源清单：<code>test-deploy.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">test-deploy</span>  <span class="attr">namespace:</span> <span class="string">test-quota</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span> <span class="comment"># 默认副本数量为1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">resources:</span> <span class="comment"># 定义容器的资源请求和限制，控制 CPU 和内存的使用</span>            <span class="attr">requests:</span>              <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span>              <span class="attr">cpu:</span> <span class="string">&quot;200m&quot;</span>            <span class="attr">limits:</span>              <span class="attr">memory:</span> <span class="string">&quot;200Mi&quot;</span>              <span class="attr">cpu:</span> <span class="string">&quot;400m&quot;</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单创建 Pod</span>$ kubectl apply -f test-deploy.yaml deployment.apps/test-deploy created<span class="comment"># 查看Pod，当前只有一个</span>$ kubectl get pods -n test-quotaNAME                           READY   STATUS    RESTARTS   AGEtest-deploy-5587d8c7c4-mptk4   1/1     Running   0          12s<span class="comment"># 给 Pod 扩容，由于在 ResourceQuota 中限制只能有1个 Pod，因此扩容会失败</span>$ kubectl scale deployment test-deploy --replicas=3 -n test-quotadeployment.apps/test-deploy scaled<span class="comment"># 监控pod，发现一直只有一个副本</span>$ kubectl get pods -n test-quota -wNAME                           READY   STATUS    RESTARTS   AGEtest-deploy-5587d8c7c4-mptk4   1/1     Running   0          79s</code></pre><p><strong>参考链接</strong></p><blockquote><p><a href="https://jimmysong.io/book/kubernetes-handbook/cluster/qos/">https://jimmysong.io/book/kubernetes-handbook/cluster/qos/</a></p><p><a href="https://www.cnblogs.com/renshengdezheli/p/17528247.html">https://www.cnblogs.com/renshengdezheli/p/17528247.html</a></p><p><a href="https://www.cnblogs.com/zhanglianghhh/p/14259632.html">https://www.cnblogs.com/zhanglianghhh/p/14259632.html</a></p><p><a href="https://juejin.cn/post/6974203884369608734">https://juejin.cn/post/6974203884369608734</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;集群环境&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;Hostname&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;10.20.1.139&lt;/td&gt;
</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>002-安装Python开发环境</title>
    <link href="https://georgechan95.github.io/blog/7591dd09.html"/>
    <id>https://georgechan95.github.io/blog/7591dd09.html</id>
    <published>2025-09-08T12:22:00.000Z</published>
    <updated>2025-09-08T12:30:31.296Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、下载Python开发环境"><a href="#一、下载Python开发环境" class="headerlink" title="一、下载Python开发环境"></a>一、下载Python开发环境</h1><ul><li>官网：<a href="https://www.python.org/">https://www.python.org/</a></li><li>文档下载地址：<a href="https://www.python.org/doc/">https://www.python.org/doc/</a></li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/07/20250907-104643.png" alt="Python官网"></p><p>下载地址： <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></p><p>历史版本下载：<a href="https://www.python.org/downloads/windows/">https://www.python.org/downloads/windows/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/07/20250907-104733.png" alt="找到下载的Python版本"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/07/20250907-104943.png" alt="选择Window64位安装包"></p><h1 id="二、安装Python开发环境"><a href="#二、安装Python开发环境" class="headerlink" title="二、安装Python开发环境"></a>二、安装Python开发环境</h1><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201043.png" alt="选择自定义安装"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201244.png" alt="默认勾选全部选项，然后Next"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201528.png" alt="自定义安装路径，并为所有用户安装"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201506.png" alt="安装进行中"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201750.png" alt="安装完成"></p><h1 id="三、验证Python开发环境是否安装成功"><a href="#三、验证Python开发环境是否安装成功" class="headerlink" title="三、验证Python开发环境是否安装成功"></a>三、验证Python开发环境是否安装成功</h1><p>打开命令行，输入命令：</p><pre><code class="highlight powershell">C:\Users\kd&gt;pythonPython <span class="number">3.12</span>.<span class="number">0</span> (tags/v3.<span class="number">12.0</span>:<span class="number">0</span>fb18b0, Oct  <span class="number">2</span> <span class="number">2023</span>, <span class="number">13</span>:<span class="number">03</span>:<span class="number">39</span>) [<span class="type">MSC</span> <span class="type">v.1935</span> <span class="number">64</span> <span class="type">bit</span> (<span class="type">AMD64</span>)] on win32<span class="built_in">Type</span> <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> or <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.&gt;&gt;&gt;</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201910.png" alt="image-20250908201909767"></p><p>成功打印了 Python 版本号，开发环境安装成功！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、下载Python开发环境&quot;&gt;&lt;a href=&quot;#一、下载Python开发环境&quot; class=&quot;headerlink&quot; title=&quot;一、下载Python开发环境&quot;&gt;&lt;/a&gt;一、下载Python开发环境&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;官网：&lt;a href=&quot;http</summary>
      
    
    
    
    <category term="Python" scheme="https://georgechan95.github.io/categories/Python/"/>
    
    
    <category term="Python" scheme="https://georgechan95.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>001-Python语言概述</title>
    <link href="https://georgechan95.github.io/blog/95026633.html"/>
    <id>https://georgechan95.github.io/blog/95026633.html</id>
    <published>2025-09-07T02:44:00.000Z</published>
    <updated>2025-09-08T12:30:31.294Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、Python-简介"><a href="#一、Python-简介" class="headerlink" title="一、Python 简介"></a>一、Python 简介</h1><p><em>Python 是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言。</em></p><p><em>Python 的设计具有很强的可读性，相比其他语言经常使用英文关键字，其他语言的一些标点符号，它具有比其他语言更有特色语法结构。</em></p><ul><li><strong>Python 是一种解释型语言：</strong> 这意味着开发过程中没有了编译这个环节。类似于PHP和Perl语言。</li><li><strong>Python 是交互式语言：</strong> 这意味着，您可以在一个 Python 提示符 <strong>&gt;&gt;&gt;</strong> 后直接执行代码。</li><li><strong>Python 是面向对象语言:</strong> 这意味着Python支持面向对象的风格或代码封装在对象的编程技术。</li><li><strong>Python 是初学者的语言：</strong>Python 对初级程序员而言，是一种伟大的语言，它支持广泛的应用程序开发，从简单的文字处理到 WWW 浏览器再到游戏。</li></ul><h1 id="二、Python-发展历史"><a href="#二、Python-发展历史" class="headerlink" title="二、Python 发展历史"></a>二、Python 发展历史</h1><p>Python 是由 Guido van Rossum 在八十年代末和九十年代初，在荷兰国家数学和计算机科学研究所设计出来的。</p><p>Python 本身也是由诸多其他语言发展而来的,这包括 ABC、Modula-3、C、C++、Algol-68、SmallTalk、Unix shell 和其他的脚本语言等等。</p><p>像 Perl 语言一样，Python 源代码同样遵循 GPL(GNU General Public License)协议。</p><p>现在 Python 是由一个核心开发团队在维护，Guido van Rossum 仍然占据着至关重要的作用，指导其进展。</p><p>Python 2.7 被确定为最后一个 Python 2.x 版本，它除了支持 Python 2.x 语法外，还支持部分 Python 3.1 语法。</p><h1 id="三、Python-特点"><a href="#三、Python-特点" class="headerlink" title="三、Python 特点"></a>三、Python 特点</h1><ul><li><strong>1.易于学习：</strong>Python 有相对较少的关键字，结构简单，和一个明确定义的语法，学习起来更加简单。</li><li><strong>2.易于阅读：</strong>Python 代码定义的更清晰。</li><li><strong>3.易于维护：</strong>Python的 成功在于它的源代码是相当容易维护的。</li><li><strong>4.一个广泛的标准库：</strong>Python 的最大的优势之一是丰富的库，跨平台的，在 UNIX、Windows 和 Mac 兼容很好。</li><li><strong>5.互动模式：</strong>互动模式的支持，您可以从终端输入执行代码并获得结果的语言，互动的测试和调试代码片段。</li><li><strong>6.可移植：</strong>基于其开放源代码的特性，Python 已经被移植（也就是使其工作）到许多平台。</li><li><strong>7.可扩展：</strong>如果你需要一段运行很快的关键代码，或者是想要编写一些不愿开放的算法，你可以使用 C 或 C++ 完成那部分程序，然后从你的 Python 程序中调用。</li><li><strong>8.数据库：</strong>Python 提供所有主要的商业数据库的接口。</li><li><strong>9.GUI 编程：</strong>Python 支持 GUI 可以创建和移植到许多系统调用。</li><li><strong>10.可嵌入:</strong> 你可以将 Python 嵌入到 C&#x2F;C++ 程序，让你的程序的用户获得”脚本化”的能力。</li></ul><p><strong>参考链接</strong></p><blockquote><p><a href="https://www.runoob.com/python/python-intro.html">https://www.runoob.com/python/python-intro.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、Python-简介&quot;&gt;&lt;a href=&quot;#一、Python-简介&quot; class=&quot;headerlink&quot; title=&quot;一、Python 简介&quot;&gt;&lt;/a&gt;一、Python 简介&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Python 是一个高层次的结合了解释性、编译性、互动性和面</summary>
      
    
    
    
    <category term="Python" scheme="https://georgechan95.github.io/categories/Python/"/>
    
    
    <category term="Python" scheme="https://georgechan95.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>021-K8S-安全参数</title>
    <link href="https://georgechan95.github.io/blog/e2c03adc.html"/>
    <id>https://georgechan95.github.io/blog/e2c03adc.html</id>
    <published>2025-08-23T06:43:00.000Z</published>
    <updated>2025-09-06T08:19:42.939Z</updated>
    
    <content type="html"><![CDATA[<p><strong>集群环境</strong></p><table><thead><tr><th>IP</th><th>Hostname</th><th>用途</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td><td>Master节点</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td><td>Node节点</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td><td>Node节点</td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td><td>Node节点</td></tr></tbody></table><h1 id="一、配置容器级别的安全控制"><a href="#一、配置容器级别的安全控制" class="headerlink" title="一、配置容器级别的安全控制"></a>一、配置容器级别的安全控制</h1><h2 id="1-共享主机网络"><a href="#1-共享主机网络" class="headerlink" title="1. 共享主机网络"></a>1. 共享主机网络</h2><p>通常情况下，Pod中的容器会使用 Kubernetes 网络插件提供的网络，这些插件确保了 Pod 之间的网络通信。然而，有时候可能需要 Pod 直接使用主机（节点）的网络，直接使用主机的IP地址和端口，可以通过在 Pod 的配置中设置 <code>hostNetwork: true</code> 来实现。</p><p>直接使用主机网络可以减少网络转发的开销，提高网络性能，但同时也需要注意Pod直接使用主机端口可能会存在部分冲突。</p><h3 id="1-1-案例"><a href="#1-1-案例" class="headerlink" title="1.1 案例"></a>1.1 案例</h3><p>资源清单：<code>host-network.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">nodeName:</span> <span class="string">k8s-master01</span> <span class="comment"># 选择 Pod 运行的节点的名字</span>      <span class="attr">hostNetwork:</span> <span class="literal">true</span> <span class="comment"># 主机共享网络</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f host-network.yaml<span class="comment"># 查看Pod详情</span>$ kubectl get pods -o wideNAME                     READY   STATUS    RESTARTS   AGE   IP            NODE           NOMINATED NODE   READINESS GATESnginx-76985c7d59-pzlpk   1/1     Running   0          11s   10.20.1.139   k8s-master01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 使用物理机IP访问Nginx</span>$ curl http://10.20.1.139:80&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="1-2-hostNetwork-使用注意事项"><a href="#1-2-hostNetwork-使用注意事项" class="headerlink" title="1.2 hostNetwork 使用注意事项"></a>1.2 hostNetwork 使用注意事项</h3><p>Pod 直接使用主机的网络会占用宿主机的端口，Pod 的 IP 就是宿主机的 IP，使用时需要考虑是否与主机上的端口冲突，因此一般情况下除非某个特定应用必须占用宿主机上的特定端口，否则不建议使用主机网络。</p><p>由于Pod使用主机网络，访问Pod需要直接通过节点端口，因此要 <strong>注意放通节点安全组端口</strong> ，否则会出现访问不通的情况。</p><p>另外由于占用主机端口，使用 Deployment 部署 hostNetwork 类型 Pod 时，要注意 <strong>Pod的副本数不要超过节点数量</strong> ，否则会导致一个节点上调度了多个Pod，Pod 启动时端口冲突无法创建。例如上面例子中的 nginx，如果服务数为 2，并部署在只有1个节点的集群上，就会有一个Pod无法创建，查询Pod日志会发现是由于端口占用导致 nginx 无法启动。</p><p><strong>请避免在同一个节点上调度多个使用主机网络的 Pod，否则在创建 ClusterIP 类型的 Service 访问 Pod 时，会出现访问 ClusterIP 不通的情况。</strong></p><h2 id="2-共享主机端口"><a href="#2-共享主机端口" class="headerlink" title="2. 共享主机端口"></a>2. 共享主机端口</h2><p>在 Kubernetes 中，hostPort 是一种用于将主机上的特定端口映射到运行在 Pod 内部容器的端口的配置选项。通过使用 hostPort，你可以在主机上暴露容器的服务，从而允许外部网络通过主机的 IP 地址和指定的端口访问容器内的应用程序。</p><h3 id="2-1-案例"><a href="#2-1-案例" class="headerlink" title="2.1 案例"></a>2.1 案例</h3><p>资源清单：<code>host-port.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">hostPort:</span> <span class="number">8080</span> <span class="comment"># 主机端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f host-port.yaml deployment.apps/nginx created<span class="comment"># 查看Pod运行情况</span>$ kubectl get pods -o wideNAME                    READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnginx-585b8dd6d-9tzl6   1/1     Running   0          8s    171.20.85.209   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 通过Pod运行节点的物理机IP和映射端口 8080 访问Nginx</span>$ curl 10.20.1.140:8080&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="2-2-hostPort-与-NodePort-的区别"><a href="#2-2-hostPort-与-NodePort-的区别" class="headerlink" title="2.2 hostPort 与 NodePort 的区别"></a>2.2 hostPort 与 NodePort 的区别</h3><p>hostPort 与 NodePort 的区别是，NodePort 服务默认是把请求转发到随机的一个运行的 Pod 上，而 hostPort 是直接转发到本 Node 上的指定 Pod。</p><table><thead><tr><th>特性</th><th>nodePort（Service）</th><th>hostPort（Pod）</th></tr></thead><tbody><tr><td>作用范围</td><td>集群所有节点</td><td>单个Pod所在节点</td></tr><tr><td>端口范围</td><td>默认30000-32767（可配置）</td><td>任意可用端口</td></tr><tr><td>安全性</td><td>推荐生产环境使用</td><td>存在端口冲突风险</td></tr><tr><td>负载均衡</td><td>自动负载均衡</td><td>需手动实现负载均衡</td></tr></tbody></table><h3 id="2-3-注意事项"><a href="#2-3-注意事项" class="headerlink" title="2.3 注意事项"></a>2.3 注意事项</h3><p>一个 Node 只能启动一个 hostPort，所以最初是用于把守护进程集（DaemonSets）部署到每个 Node (确保一个 Node 只有一个 hostPort )。如下图所示，3个 Node 上部署4个带 hostPort 的 Pod，会有一个不成功。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/23/20250823-162900.png" alt="每个Node节点只能运行一个 hostPort"></p><p>即便是3个 Node 上部署3个带 hostPort 的 Pod 滚动升级时也会有问题，所以使用 hostPort 的服务在升级的时候一定要保障先停掉旧版本的 Pod 实例再启动新版本的 Pod 实例。</p><h2 id="3-共享主机IPC和PID"><a href="#3-共享主机IPC和PID" class="headerlink" title="3. 共享主机IPC和PID"></a>3. 共享主机IPC和PID</h2><ul><li><p>PID</p><ul><li><p>当 Pod 的 hostPID 设置为 true 时，Pod 内的容器将与宿主机共享相同的 PID 命名空间。这意味着容器可以看到宿主机上运行的所有进程（通过 ps 命令等），并且可以与宿主机的进程进行交互（例如发送信号）。</p></li><li><p>使用场景：常用于需要监控或管理宿主机进程的场景，例如运行监控代理或安全工具。</p></li></ul></li><li><p>IPC</p><ul><li>当 Pod 的 hostIPC 设置为 true 时，Pod 内的容器将与宿主机共享相同的 IPC（进程间通信）命名空间，允许容器使用宿主机的 IPC 机制。这意味着容器内的进程可以直接访问宿主机的 IPC 资源（例如宿主机的共享内存、消息队列等），也可以与宿主机上的进程或其他共享同一 IPC 命名空间的容器进程进行通信。</li></ul></li></ul><h3 id="3-1-案例"><a href="#3-1-案例" class="headerlink" title="3.1 案例"></a>3.1 案例</h3><p>资源清单：<code>host-ipc-pid.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-ipc-pid</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx-ipc-pid</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx-ipc-pid</span>    <span class="attr">spec:</span>      <span class="attr">hostIPC:</span> <span class="literal">true</span> <span class="comment"># 主机共享 IPC 命名空间</span>      <span class="attr">hostPID:</span> <span class="literal">true</span> <span class="comment"># 主机共享 PID 命名空间</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Deployment</span>$ kubectl apply -f host-ipc-pid.yaml<span class="comment"># 查看Pod运行详情</span>$ kubectl get pods -o wideNAME                            READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnginx-ipc-pid-d9f877dbd-hq2vp   1/1     Running   0          14s   171.20.85.210   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 进入容器</span>$ kubectl <span class="built_in">exec</span> -it nginx-ipc-pid-d9f877dbd-hq2vp -- /bin/bash<span class="comment"># 在容器内查看进程，可以看到，把系统进程也一并打印出来了</span>root@nginx-ipc-pid-d9f877dbd-hq2vp:/<span class="comment"># ls -l /proc/</span>total 0drwxrwxrwt  2 root  root    40 Sep  6 02:19 acpi-r--r--r--  1 root  root     0 Sep  6 02:38 bootconfig-r--r--r--  1 root  root     0 Sep  6 02:38 buddyinfodr-xr-xr-x  4 root  root     0 Sep  6 02:19 bus-r--r--r--  1 root  root     0 Sep  6 02:38 cgroups-r--r--r--  1 root  root     0 Sep  6 02:38 cmdline-r--r--r--  1 root  root     0 Sep  6 02:38 consoles-r--r--r--  1 root  root     0 Sep  6 02:38 cpuinfo-r--r--r--  1 root  root     0 Sep  6 02:38 crypto-r--r--r--  1 root  root     0 Sep  6 02:38 devices-r--r--r--  1 root  root     0 Sep  6 02:38 diskstats-r--r--r--  1 root  root     0 Sep  6 02:38 dmadr-xr-xr-x  4 root  root     0 Sep  6 02:38 driverdr-xr-xr-x  3 root  root     0 Sep  6 02:38 dynamic_debug-r--r--r--  1 root  root     0 Sep  6 02:38 execdomains-r--r--r--  1 root  root     0 Sep  6 02:38 fb-r--r--r--  1 root  root     0 Sep  6 02:19 filesystemsdr-xr-xr-x  4 root  root     0 Sep  6 02:19 fs-r--r--r--  1 root  root     0 Sep  6 02:38 interrupts-r--r--r--  1 root  root     0 Sep  6 02:38 iomem-r--r--r--  1 root  root     0 Sep  6 02:38 ioportsdr-xr-xr-x 35 root  root     0 Sep  6 02:19 irq-r--r--r--  1 root  root     0 Sep  6 02:38 kallsymscrw-rw-rw-  1 root  root  1, 3 Sep  6 02:19 kcore-r--r--r--  1 root  root     0 Sep  6 02:38 key-userscrw-rw-rw-  1 root  root  1, 3 Sep  6 02:19 keys-r--------  1 root  root     0 Sep  6 02:38 kmsg-r--------  1 root  root     0 Sep  6 02:38 kpagecgroup-r--------  1 root  root     0 Sep  6 02:38 kpagecount-r--------  1 root  root     0 Sep  6 02:38 kpageflags-r--r--r--  1 root  root     0 Sep  6 02:38 loadavg-r--r--r--  1 root  root     0 Sep  6 02:38 locks-r--r--r--  1 root  root     0 Sep  6 02:38 mdstat-r--r--r--  1 root  root     0 Sep  6 02:38 meminfo-r--r--r--  1 root  root     0 Sep  6 02:38 misc-r--r--r--  1 root  root     0 Sep  6 02:38 moduleslrwxrwxrwx  1 root  root    11 Sep  6 02:38 mounts -&gt; self/mounts-rw-r--r--  1 root  root     0 Sep  6 02:38 mtrrlrwxrwxrwx  1 root  root     8 Sep  6 02:19 net -&gt; self/net-r--------  1 root  root     0 Sep  6 02:38 pagetypeinfo-r--r--r--  1 root  root     0 Sep  6 02:38 partitions-r--r--r--  1 root  root     0 Sep  6 02:38 schedstatdrwxrwxrwt  2 root  root    40 Sep  6 02:19 scsilrwxrwxrwx  1 root  root     0 Sep  6 02:19 self -&gt; 3214631-r--------  1 root  root     0 Sep  6 02:38 slabinfo-r--r--r--  1 root  root     0 Sep  6 02:38 softirqs-r--r--r--  1 root  root     0 Sep  6 02:38 <span class="built_in">stat</span>-r--r--r--  1 root  root     0 Sep  6 02:38 swapsdr-xr-xr-x  1 root  root     0 Sep  6 02:19 sys--w-------  1 root  root     0 Sep  6 02:19 sysrq-triggerdr-xr-xr-x  5 root  root     0 Sep  6 02:38 sysvipclrwxrwxrwx  1 root  root     0 Sep  6 02:19 thread-self -&gt; 3214631/task/3214631crw-rw-rw-  1 root  root  1, 3 Sep  6 02:19 timer_listdr-xr-xr-x  6 root  root     0 Sep  6 02:38 <span class="built_in">tty</span>-r--r--r--  1 root  root     0 Sep  6 02:38 <span class="built_in">uptime</span>-r--r--r--  1 root  root     0 Sep  6 02:38 version-r--------  1 root  root     0 Sep  6 02:38 vmallocinfo-r--r--r--  1 root  root     0 Sep  6 02:38 vmstat-r--r--r--  1 root  root     0 Sep  6 02:38 zoneinfo</code></pre><h3 id="3-2-Linux-Namespace-中的-IPC-是什么-？"><a href="#3-2-Linux-Namespace-中的-IPC-是什么-？" class="headerlink" title="3.2 Linux Namespace 中的 IPC 是什么 ？"></a>3.2 Linux Namespace 中的 IPC 是什么 ？</h3><ul><li>参考：<a href="https://www.cnblogs.com/Skybiubiu/p/17315019.html">https://www.cnblogs.com/Skybiubiu/p/17315019.html</a></li></ul><p>IPC (Inter-Process Communication) Namespace 是 Linux 容器隔离的一种命名空间，用于隔离进程间通信（IPC）资源，包括 System V IPC 和 POSIX IPC。</p><p>在 Linux 中，进程间通信机制可以使用不同的 IPC 方法。这些方法包括管道、套接字、消息队列、信号量和共享内存等。这些 IPC 机制可以在系统全局范围内使用，也可以在特定的命名空间内使用。</p><p>当一个容器启动时，如果该容器运行在它自己的 IPC Namespace 中，那么将为该容器分配一个独立的 IPC 句柄。这意味着该容器内部的进程和外部的进程将无法相互通信。</p><p>IPC Namespace 具有以下两个主要特性：</p><ul><li>隔离：IPC Namespace 可以将特定容器中的进程隔离并限制进程之间在 IPC 资源上的共享。这样就可以避免其他容器或主机干扰到该容器中的进程，或者该容器中的进程干扰到其他容器或主机。</li><li>共享：如果多个容器运行在同一个 IPC Namespace 中，它们将共享容器之间的 IPC 资源，这使得在同一 IPC Namespace 中的容器之间通信变得更加容易和高效。</li></ul><p>总的来说，IPC Namespace 可以有效地保护容器内的进程，避免不必要的干扰。同时，在多个容器需要通信时，将它们加入同一个 IPC Namespace 可以更好地共享资源，从而实现更好的协作和协同工作。</p><h1 id="二、配置pod的安全上下文"><a href="#二、配置pod的安全上下文" class="headerlink" title="二、配置pod的安全上下文"></a>二、配置pod的安全上下文</h1><p>针对于container级别的控制</p><h2 id="1-指定运行容器的用户"><a href="#1-指定运行容器的用户" class="headerlink" title="1. 指定运行容器的用户"></a>1. 指定运行容器的用户</h2><p>资源清单：<code>user-id-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">alpine-user-id</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">alpine-user-id</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">alpine-user-id</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alpine</span>          <span class="attr">image:</span> <span class="string">alpine:3.22.1</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">command:</span>  <span class="comment"># 容器启动命令</span>            <span class="bullet">-</span> <span class="string">/bin/sleep</span>            <span class="bullet">-</span> <span class="string">&quot;3600&quot;</span>          <span class="attr">securityContext:</span>            <span class="attr">runAsUser:</span> <span class="number">405</span> <span class="comment"># 运行用户 ID</span></code></pre><p><strong>运行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f user-id-pod.yaml<span class="comment"># 查看Pod</span>$ kubectl get podsNAME                              READY   STATUS    RESTARTS   AGEalpine-user-id-687f8f598b-dcj8f   1/1     Running   0          5m15s<span class="comment"># 进入容器，查看当前用户ID</span>$ kubectl <span class="built_in">exec</span> -it alpine-user-id-687f8f598b-dcj8f -- /bin/sh/ $ <span class="built_in">id</span>uid=405(guest) gid=100(<span class="built_in">users</span>) <span class="built_in">groups</span>=100(<span class="built_in">users</span>)</code></pre><h2 id="2-阻止容器以root用户运行"><a href="#2-阻止容器以root用户运行" class="headerlink" title="2. 阻止容器以root用户运行"></a>2. 阻止容器以root用户运行</h2><p>有的应用在容器中设置了运行用户，然后可能会有黑客上传一个以root用户运行的镜像到我们的镜像仓库。然后在容器中利用root用户<br>的权限，这样是很危险的，所以我们可以禁用容器中的root用户，让他不能以root用户启动容器</p><h3 id="2-1-创建一个非-Root-运行的-Nginx-镜像"><a href="#2-1-创建一个非-Root-运行的-Nginx-镜像" class="headerlink" title="2.1 创建一个非 Root 运行的 Nginx 镜像"></a>2.1 创建一个非 Root 运行的 Nginx 镜像</h3><p><strong>Dockerfile</strong></p><pre><code class="highlight dockerfile"><span class="keyword">FROM</span> nginx:<span class="number">1.29</span>.<span class="number">0</span>  <span class="comment"># 修改 Nginx 配置：移除 &#x27;user&#x27; 指令（避免权限警告），并将默认监听端口改为 8080</span><span class="keyword">RUN</span><span class="language-bash"> sed -i <span class="string">&#x27;/^user /d&#x27;</span> /etc/nginx/nginx.conf &amp;&amp; \</span><span class="language-bash">    sed -i <span class="string">&#x27;s/listen       80;/listen       8080;/&#x27;</span> /etc/nginx/conf.d/default.conf</span><span class="comment"># 创建必要的临时目录和 PID 文件，并调整权限给 nginx 用户</span><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> -p /var/cache/nginx/client_temp /var/cache/nginx/proxy_temp /var/cache/nginx/fastcgi_temp /var/cache/nginx/uwsgi_temp /var/cache/nginx/scgi_temp &amp;&amp; \</span><span class="language-bash">    <span class="built_in">chown</span> -R nginx:nginx /var/cache/nginx /var/log/nginx /etc/nginx/conf.d /var/run &amp;&amp; \</span><span class="language-bash">    <span class="built_in">chmod</span> -R 755 /var/cache/nginx /var/log/nginx /etc/nginx/conf.d /var/run &amp;&amp; \</span><span class="language-bash">    <span class="built_in">touch</span> /var/run/nginx.pid &amp;&amp; \</span><span class="language-bash">    <span class="built_in">chown</span> -R nginx:nginx /var/run/nginx.pid</span><span class="comment"># 切换到非 root 用户（使用镜像内置的 nginx 用户）</span><span class="keyword">USER</span> nginx<span class="comment"># 暴露端口（非特权端口）</span><span class="keyword">EXPOSE</span> <span class="number">8080</span><span class="comment"># 启动命令</span><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;nginx&quot;</span>, <span class="string">&quot;-g&quot;</span>, <span class="string">&quot;daemon off;&quot;</span>]</span></code></pre><p><strong>构建镜像</strong></p><pre><code class="highlight bash">docker build -t nginx-nonroot:1.0 .</code></pre><p><strong>测试镜像</strong></p><pre><code class="highlight bash"><span class="comment"># 运行 nginx-nonroot 容器</span>$ docker run -d -p 8080:8080 nginx-nonroot:1.0<span class="comment"># 访问 nginx-nonroot</span>$ curl http://localhost:8080&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;<span class="comment"># 查看当前nginx容器，启动命令的用户</span>nginx@b094f1470b19:/$ <span class="built_in">id</span>uid=101(nginx) gid=101(nginx) <span class="built_in">groups</span>=101(nginx)<span class="comment"># 查看Nginx容器内的所有用户，可以看到 101 对应的就是用户 nginx，也是 Dockerfile 中指定的用户</span>nginx@b094f1470b19:/$ <span class="built_in">cat</span> /etc/passwdroot:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologin<span class="built_in">sync</span>:x:4:65534:<span class="built_in">sync</span>:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologinmail:x:8:8:mail:/var/mail:/usr/sbin/nologinnews:x:9:9:news:/var/spool/news:/usr/sbin/nologinuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologinproxy:x:13:13:proxy:/bin:/usr/sbin/nologinwww-data:x:33:33:www-data:/var/www:/usr/sbin/nologinbackup:x:34:34:backup:/var/backups:/usr/sbin/nologinlist:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologinirc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin_apt:x:42:65534::/nonexistent:/usr/sbin/nologinnobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologinnginx:x:101:101:nginx user:/nonexistent:/bin/false</code></pre><h3 id="2-2-Pod-以非-root-用户运行"><a href="#2-2-Pod-以非-root-用户运行" class="headerlink" title="2.2 Pod 以非 root 用户运行"></a>2.2 Pod 以非 root 用户运行</h3><p>资源清单：<code>non-root-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">non-root-pod</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">non-root-pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">non-root-pod</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-nonroot</span>          <span class="attr">image:</span> <span class="string">nginx-nonroot:1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">runAsNonRoot:</span> <span class="literal">true</span> <span class="comment"># 以非root用户运行</span>            <span class="attr">runAsUser:</span> <span class="number">101</span> <span class="comment"># 运行用户 ID, 以非root用户运行，最好指定运行的用户id</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f non-root-pod.yaml<span class="comment"># 查看Pod详情</span>$ kubectl get pods -o wideNAME                            READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnon-root-pod-589bdf555b-c6925   1/1     Running   0          57s   171.20.85.214   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 进入Pod容器，查看当前容器运行的 User id</span>$ kubectl <span class="built_in">exec</span> -it non-root-pod-589bdf555b-c6925 -- /bin/bashnginx@non-root-pod-589bdf555b-c6925:/$ <span class="built_in">id</span>uid=101(nginx) gid=101(nginx) <span class="built_in">groups</span>=101(nginx)</code></pre><h3 id="2-3-使用特权模式启动容器"><a href="#2-3-使用特权模式启动容器" class="headerlink" title="2.3 使用特权模式启动容器"></a>2.3 使用特权模式启动容器</h3><p>使得容器内的进程以 root 用户运行，并具有宿主机的几乎所有权限（如访问所有设备、挂载文件系统、修改内核参数等）。</p><p>容器内的 root 用户几乎等同于宿主机的 root，具有访问宿主机设备（&#x2F;dev）、文件系统、内核功能等的权限。</p><p>注意：privileged: true 仅影响容器，而非整个 Pod。如果 Pod 有多个容器，需要为每个需要特权的容器单独设置。</p><p><strong>资源清单：</strong> <code>privileged-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">privileged-pod</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">privileged-pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">privileged-pod</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-privileged</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">true</span> <span class="comment"># 启用特权模式</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f privileged-pod.yaml<span class="comment"># 查看Pod详情</span>$ kubectl get pods -o wideNAME                              READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESprivileged-pod-86bdcd8565-lx5ff   1/1     Running   0          74s   171.20.85.216   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 进入Pod</span>$ kubectl <span class="built_in">exec</span> -it privileged-pod-86bdcd8565-lx5ff -- /bin/bash<span class="comment"># 查看运行容器的用户id</span>root@privileged-pod-86bdcd8565-lx5ff:/<span class="comment"># id</span>uid=0(root) gid=0(root) <span class="built_in">groups</span>=0(root)<span class="comment"># 查看 /dev 目录，容器内可以查看到宿主机所有的挂载设备</span>root@privileged-pod-86bdcd8565-lx5ff:/<span class="comment"># ls /dev</span>autofs dm-1   hidraw0 mcelog  ppp sda1   snd    tty0   tty15  tty21  tty28tty34  tty40  tty47  tty53  tty6   tty9     uinput vcs1  vcsa1  vcsu1  vga_arbiterbsg dma_heap  hpet mem ptmx sda2   sr0    tty1   tty16  tty22  tty29tty35  tty41  tty48  tty54  tty60  ttyS0    urandom vcs2  vcsa2  vcsu2  vhcibus dri   hwrng mqueue  pts sda3   stderr    tty10  tty17  tty23  tty3tty36  tty42  tty49  tty55  tty61  ttyS1    usbmon0 vcs3  vcsa3  vcsu3  vhost-netcore fb0   input net random  sg0   stdin    tty11  tty18  tty24  tty30tty37  tty43  tty5   tty56  tty62  ttyS2    usbmon1 vcs4  vcsa4  vcsu4  vhost-vsockcpu fd   kmsg null rfkill  sg1   stdout    tty12  tty19  tty25  tty31tty38  tty44  tty50  tty57  tty63  ttyS3    usbmon2 vcs5  vcsa5  vcsu5  vmcicpu_dma_latency  full   loop-control  nvram rtc0 shm   termination-log  tty13  tty2   tty26  tty32tty39  tty45  tty51  tty58  tty7   udmabuf  userfaultfd  vcs6  vcsa6  vcsu6  zerodm-0 fuse   mapper port sda snapshot  <span class="built_in">tty</span>    tty14  tty20  tty27  tty33tty4   tty46  tty52  tty59  tty8   uhid     vcs vcsa  vcsu   vfio</code></pre><h3 id="2-4-为容器-添加-禁用-linux-内核的功能"><a href="#2-4-为容器-添加-禁用-linux-内核的功能" class="headerlink" title="2.4 为容器 添加&#x2F;禁用 linux 内核的功能"></a>2.4 为容器 添加&#x2F;禁用 linux 内核的功能</h3><p>使用特权模式启动的容器被赋予了过大的权限，我们可以根据需求给予容器所需的 linux 内核的能力。</p><p>在 Kubernetes 中，可以通过配置 Pod 的 securityContext 来为容器添加或禁用 Linux 内核功能（Capabilities）。Linux Capabilities 是 Linux 内核提供的一种机制，将 root 用户的权限细分为多个独立的功能，允许以更精细的方式控制容器进程的权限，而不是简单地以 root 或非 root 用户运行。这种方式可以增强安全性，遵循最小权限原则。</p><p><strong>什么是 Linux Capabilities</strong></p><p>Linux Capabilities 是 Linux 内核将特权操作拆分成多个独立权限的机制，例如：</p><ul><li>CAP_SYS_ADMIN：允许执行高权限操作（如挂载文件系统、修改系统配置）。</li><li>CAP_NET_ADMIN：允许配置网络（如修改网络接口、设置防火墙规则）。</li><li>CAP_SYS_PTRACE：允许跟踪其他进程（结合 hostPID: true 可用于调试宿主机进程）。</li><li>CAP_CHOWN：允许更改文件的所有者。</li><li>完整 Capabilities 列表见 <a href="http://man7.org/linux/man-pages/man7/capabilities.7.html">Linux man page</a>。</li></ul><p>默认情况下：</p><ul><li>容器以非特权模式运行时，只有部分 Capabilities（例如 CAP_CHOWN、CAP_SETUID 等）。</li><li>特权模式（privileged: true）授予容器所有 Capabilities，等同于宿主机 root。</li><li>通过 securityContext.capabilities，可以显式添加（add）或禁用（drop）特定 Capabilities。</li></ul><p><strong>资源清单：</strong> <code>capabilities-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">capabilities-pod</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">capabilities-pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">capabilities-pod</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-capabilities</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">false</span> <span class="comment"># 禁用特权模式</span>            <span class="attr">capabilities:</span>              <span class="attr">add:</span>                <span class="bullet">-</span> <span class="string">NET_ADMIN</span> <span class="comment"># 添加网络管理能力</span>                <span class="bullet">-</span> <span class="string">SYS_PTRACE</span> <span class="comment"># 添加跟踪进程的能力（适用于 hostPID: true）</span>              <span class="attr">drop:</span><span class="comment">#                - CHOWN # 禁用更改文件所有者的能力（Nginx启动需要修改文件所有者，因此不能禁用）</span>                <span class="bullet">-</span> <span class="string">SYS_ADMIN</span> <span class="comment"># 禁用高危的系统管理能力</span></code></pre><p>注意：在linux中内核功能通常以CAP_开头，这里需要省略掉</p><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f capabilities-pod.yaml<span class="comment"># 查看Pod</span>$ kubectl get pods -wNAME                                READY   STATUS              RESTARTS   AGEcapabilities-pod-787896d744-p6ptf   0/1     ContainerCreating   0          12scapabilities-pod-787896d744-p6ptf   1/1     Running             0          13s</code></pre><h3 id="2-5-阻止对容器根文件系统的写入"><a href="#2-5-阻止对容器根文件系统的写入" class="headerlink" title="2.5 阻止对容器根文件系统的写入"></a>2.5 阻止对容器根文件系统的写入</h3><p><strong>资源清单：</strong><code>read-only-root-filesystem-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">read-only-root-filesystem-pod</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">read-only-root-filesystem-pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">read-only-root-filesystem-pod</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alpine</span>          <span class="attr">image:</span> <span class="string">alpine:3.22.1</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span> <span class="comment"># 只读根文件系统</span>          <span class="attr">command:</span>  <span class="comment"># 容器启动命令</span>            <span class="bullet">-</span> <span class="string">/bin/sleep</span>            <span class="bullet">-</span> <span class="string">&quot;3600&quot;</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">read-only-root-filesystem-pod</span> <span class="comment"># # 挂载了一个可写的 emptyDir 卷到 /volume 路径，允许容器写入数据</span>              <span class="attr">mountPath:</span> <span class="string">/volume</span>              <span class="attr">readOnly:</span> <span class="literal">false</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">read-only-root-filesystem-pod</span> <span class="comment"># 定义一个 emptyDir 卷，是一种临时存储卷，卷在 Pod 创建时分配，初始为空，生命周期与 Pod 绑定（Pod 删除时卷被销毁）</span>          <span class="attr">emptyDir:</span> &#123;&#125;</code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f read-only-root-filesystem-pod.yaml<span class="comment"># 查看Pod</span>$ kubectl get pods NAME                                             READY   STATUS    RESTARTS   AGEread-only-root-filesystem-pod-77bc855c7f-t9nsh   1/1     Running   0          39s<span class="comment"># 进入Pod容器</span>$ kubectl <span class="built_in">exec</span> -it read-only-root-filesystem-pod-77bc855c7f-t9nsh -- /bin/sh<span class="comment"># 在根路径下创建文件失败，因为 Pod 禁止了根路径下的文件写入</span>/ <span class="comment"># touch a.txt</span><span class="built_in">touch</span>: a.txt: Read-only file system<span class="comment"># 在挂载路径下创建文件</span>/ <span class="comment"># touch /volume/a.txt</span></code></pre><p><strong>readOnlyRootFilesystem: true</strong></p><p><strong>作用</strong>：将容器根文件系统（&#x2F;, 包括 &#x2F;etc、&#x2F;usr 等）设为只读。</p><p><strong>详情</strong>：</p><ul><li>容器无法在根文件系统上写入文件（如修改 &#x2F;etc&#x2F;passwd 或创建 &#x2F;tmp&#x2F;testfile），增强安全性。</li><li>防止恶意或意外修改关键文件，降低容器被攻击的风险。</li><li>影响：<ul><li>某些应用（如需要写日志或缓存到根文件系统的）可能失败，除非提供可写路径（如通过卷）。</li><li>在 alpine 镜像中，&#x2F;bin&#x2F;sleep 不需要写根文件系统，因此运行正常。</li></ul></li><li><strong>注意</strong>：与之前的 nginx:1.29.0 配置不同，Nginx 默认需要写日志（&#x2F;var&#x2F;log&#x2F;nginx）和缓存（&#x2F;var&#x2F;cache&#x2F;nginx），启用 readOnlyRootFilesystem: true 可能导致 Nginx 失败，除非将这些路径挂载到可写卷。</li></ul><p>如果想将此配置应用于 nginx:1.29.0，需添加多个可写卷：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-readonly</span><span class="attr">spec:</span>  <span class="attr">containers:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>    <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>    <span class="attr">securityContext:</span>      <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span>    <span class="attr">volumeMounts:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span>      <span class="attr">mountPath:</span> <span class="string">/var/log/nginx</span>      <span class="attr">readOnly:</span> <span class="literal">false</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cache-volume</span>      <span class="attr">mountPath:</span> <span class="string">/var/cache/nginx</span>      <span class="attr">readOnly:</span> <span class="literal">false</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run-volume</span>      <span class="attr">mountPath:</span> <span class="string">/var/run</span>      <span class="attr">readOnly:</span> <span class="literal">false</span>  <span class="attr">volumes:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span>    <span class="attr">emptyDir:</span> &#123;&#125;  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cache-volume</span>    <span class="attr">emptyDir:</span> &#123;&#125;  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run-volume</span>    <span class="attr">emptyDir:</span> &#123;&#125;</code></pre><h3 id="2-6-容器使用不同用户运行时共享存储卷"><a href="#2-6-容器使用不同用户运行时共享存储卷" class="headerlink" title="2.6  容器使用不同用户运行时共享存储卷"></a>2.6  容器使用不同用户运行时共享存储卷</h3><p>当一个 pod 中的两个容器都使用 root 用户运行时，他们之前可以互相读取对方的挂载卷。但是，当我们为每个容器配置其他的启动用户时，<br>可以会出现一些访问权限的问题。<br>在 kubernetes 中，可以为 pod 中的容器指定一个 supplemental 组，以允许他们无论通过哪个用户启动容器都可以共享文件。</p><pre><code class="highlight yaml"><span class="attr">spec:</span>  <span class="attr">securityContext:</span>    <span class="comment"># 用户组id设置为555，则创建存储卷时存储卷属于用户ID为555的用户组</span>    <span class="attr">fsGroup:</span> <span class="number">555</span>    <span class="comment"># 定义了某个用户所关联的额外的用户组</span>    <span class="attr">supplementalGroups:</span>      <span class="bullet">-</span> <span class="number">666</span>      <span class="bullet">-</span> <span class="number">777</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-A</span>      <span class="attr">image:</span> <span class="string">test-container</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">securityContext:</span>        <span class="attr">runAsUser:</span> <span class="number">01</span>      <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/volume</span>          <span class="attr">name:</span> <span class="string">test-volume</span>          <span class="attr">readOnly:</span> <span class="literal">false</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-B</span>      <span class="attr">image:</span> <span class="string">test-container</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">securityContext:</span>        <span class="attr">runAsUser:</span> <span class="number">02</span>      <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/volume</span>          <span class="attr">name:</span> <span class="string">test-volume</span>          <span class="attr">readOnly:</span> <span class="literal">false</span>  <span class="attr">volumes:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-volume</span>      <span class="attr">emptyDir:</span> &#123;&#125;</code></pre><p>在pod级别指定 fsGroup 与 supplementalGroups 属性，然后分别指定两个容器的启动用户为 01、02。然后在启动容器，在容器中执行<code>id</code>命令<br>可以查看容器的用户和用户组，然后就可以看到两个容器虽然用户不同，但是都属于“555、666、777”这三个组中。</p><h1 id="三、Pod-Security-Admission"><a href="#三、Pod-Security-Admission" class="headerlink" title="三、Pod Security Admission"></a>三、Pod Security Admission</h1><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h2 id="1-PodSecurityPolicy-概念（过时）"><a href="#1-PodSecurityPolicy-概念（过时）" class="headerlink" title="1. PodSecurityPolicy 概念（过时）"></a>1. PodSecurityPolicy 概念（过时）</h2><p>PodSecurityPolicy 在 kubernetes 中简称为 psp，主要定义了用户能否在 pod 中使用各种安全相关的特性。</p><p>当有人调用 api server创建pod时，PodSecurityPolicy 会拿到这个 pod 的信息与自己个规则做比较。如果符合规则，就运行其存入 etcd；否则会被拒绝。<br>因为是在创建 pod 时校验的，所以修改 psp，不会对已创建的 pod 采取措施。也可以设置默认值，就是用 psp 中配置的默认值替换掉 pod 中的值。</p><p>Pod Security Policy 是一个赋予集群管理员控制 Pod 安全规范的内置准入控制器，可以让管理人员控制Pod实例安全的诸多方面，例如禁止采用root权限、防止容器逃逸等等。Pod Security Policy 定义了一组 Pod 运行时必须遵循的条件及相关字段的默认值，Pod 必须满足这些条件才能被成功创建，Pod Security Policy 对象 Spec 包含以下字段也即是 Pod Security Policy 能够控制的方面：</p><table><thead><tr><th>控制的角度</th><th>字段名称</th></tr></thead><tbody><tr><td>运行特权容器</td><td>privileged</td></tr><tr><td>使用宿主名字空间</td><td>hostPID,hostIPC</td></tr><tr><td>使用宿主的网络和端口</td><td>hostNetwork, hostPorts</td></tr><tr><td>控制卷类型的使用</td><td>volumes</td></tr><tr><td>使用宿主文件系统</td><td>allowedHostPaths</td></tr><tr><td>允许使用特定的 FlexVolume 驱动</td><td>allowedFlexVolumes</td></tr><tr><td>分配拥有 Pod 卷的 FSGroup 账号</td><td>fsGroup</td></tr><tr><td>以只读方式访问根文件系统</td><td>readOnlyRootFilesystem</td></tr><tr><td>设置容器的用户和组 ID</td><td>runAsUser, runAsGroup, supplementalGroups</td></tr><tr><td>限制 root 账号特权级提升</td><td>allowPrivilegeEscalation, defaultAllowPrivilegeEscalation</td></tr><tr><td>Linux 功能（Capabilities）</td><td>defaultAddCapabilities, requiredDropCapabilities, allowedCapabilities</td></tr><tr><td>设置容器的 SELinux 上下文</td><td>seLinux</td></tr><tr><td>指定容器可以挂载的 proc 类型</td><td>allowedProcMountTypes</td></tr><tr><td>指定容器使用的 AppArmor 模版</td><td>annotations</td></tr><tr><td>指定容器使用的 seccomp 模版</td><td>annotations</td></tr><tr><td>指定容器使用的 sysctl 模版</td><td>forbiddenSysctls,allowedUnsafeSysctls</td></tr></tbody></table><p>其中AppArmor 和seccomp 需要通过给PodSecurityPolicy对象添加注解的方式设定：</p><pre><code class="highlight yaml"><span class="attr">seccomp.security.alpha.kubernetes.io/allowedProfileNames:</span> <span class="string">&#x27;docker/default&#x27;</span><span class="attr">seccomp.security.alpha.kubernetes.io/defaultProfileNames:</span> <span class="string">&#x27;docker/default&#x27;</span><span class="attr">apparmor.security.beta.kubernetes.io/allowedProfileNames:</span> <span class="string">&#x27;runtime/default&#x27;</span> <span class="attr">apparmor.security.beta.kubernetes.io/defaultProfileNames:</span> <span class="string">&#x27;runtime/default&#x27;</span></code></pre><p>Pod Security Policy是集群级别的资源，它的使用流程：</p><p><img src="https://img2022.cnblogs.com/blog/1669826/202204/1669826-20220406164525862-2082600217.png" alt="Pod Security Policy 使用流程"></p><p>由于需要创建 ClusterRole&#x2F;Role 和 ClusterRoleBinding&#x2F;RoleBinding 绑定服务账号来使用 PSP,这使得我们不能很容易的看出究竟使用了哪些 PSP,更难看出 Pod 的创建被哪些安全规则限制。</p><h2 id="2-关于-Pod-Security-Admission"><a href="#2-关于-Pod-Security-Admission" class="headerlink" title="2. 关于 Pod Security Admission"></a>2. 关于 Pod Security Admission</h2><p>通过对 PodSecurityPolicy 使用，应该也会发现它的问题，例如没有 dry-run 和审计模式、不方便开启和关闭等，并且使用起来也不那么清晰。种种缺陷造成的结果是 PodSecurityPolicy 在 Kubernetes v1.21 被标记为弃用，并且将在 v1.25中被移除，在 kubernets v1.22 中则增加了新特性 Pod Security Admission。</p><p>pod security admission 是 kubernetes 内置的一种准入控制器，在 kubernetes v1.23 版本中这一特性门是默认开启的，在v1.22中需要通过 kube-apiserver 参数 <code>--feature-gates=&quot;...,PodSecurity=true&quot;</code> 开启。在低于v1.22的 kuberntes 版本中也可以自行安装 Pod Security Admission Webhook。</p><p>Pod Security Admission 机制在易用性和灵活性上都有了很大提升，从使用角度有以下三点显著不同：</p><ul><li>可以在集群中默认开启，只要不设置约束条件就不会触发对 pod 的校验</li><li>只在命名空间级别生效，可以为不同命名空间通过添加标签的方式设置不同的安全限制</li><li>根据实践预设了三种安全等级，不需要由用户单独去设置每一项安全条件</li></ul><p>为了广泛的覆盖安全应用场景， Pod Security Standards渐进式的定义了三种不同的Pod安全标准策略：</p><table><thead><tr><th>Profile</th><th>描述</th></tr></thead><tbody><tr><td><strong>Privileged</strong></td><td>不受限制的策略，提供最大可能范围的权限许可。此策略允许已知的特权提升。</td></tr><tr><td><strong>Baseline</strong></td><td>限制性最弱的策略，禁止已知的策略提升。允许使用默认的（规定最少）Pod 配置。</td></tr><tr><td><strong>Restricted</strong></td><td>限制性非常强的策略，遵循当前的保护 Pod 的最佳实践。</td></tr></tbody></table><p>详细内容参见 <a href="https://kubernetes.io/docs/concepts/security/pod-security-standards">Pod Security Standards</a>。</p><h2 id="3-Pod-Security-Standards-实施方法"><a href="#3-Pod-Security-Standards-实施方法" class="headerlink" title="3. Pod Security Standards 实施方法"></a>3. Pod Security Standards 实施方法</h2><p>在kubernetes集群中开启了pod security admission特性门之后，就可以通过给namespace设置label的方式来实施Pod Security Standards。其中有三种设定模式可选用：</p><table><thead><tr><th align="left">Mode</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left"><strong>enforce</strong></td><td align="left">违反安全标准策略的 Pod 将被拒绝。</td></tr><tr><td align="left"><strong>audit</strong></td><td align="left">违反安全标准策略触发向审计日志中记录的事件添加审计注释，但其他行为被允许。</td></tr><tr><td align="left"><strong>warn</strong></td><td align="left">违反安全标准策略将触发面向用户的警告，但其他行为被允许。</td></tr></tbody></table><p>label设置模板解释：</p><pre><code class="highlight bash"><span class="comment"># 设定模式及安全标准策略等级</span><span class="comment"># MODE必须是 `enforce`, `audit`或`warn`其中之一。</span><span class="comment"># LEVEL必须是`privileged`, `baseline`或 `restricted`其中之一</span>pod-security.kubernetes.io/&lt;MODE&gt;: &lt;LEVEL&gt;<span class="comment"># 此选项是非必填的，用来锁定使用哪个版本的的安全标准</span><span class="comment"># MODE必须是 `enforce`, `audit`或`warn`其中之一。</span><span class="comment"># VERSION必须是一个有效的kubernetes minor version(例如v1.23)，或者 `latest`</span>pod-security.kubernetes.io/&lt;MODE&gt;-version: &lt;VERSION&gt;</code></pre><p>一个 namesapce 可以设定任意种模式或者不同的模式设定不同的安全标准策略。</p><p>通过准入控制器配置文件，可以为pod security admission设置默认配置：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apiserver.config.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">AdmissionConfiguration</span> <span class="comment"># 准入控制</span><span class="attr">plugins:</span><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PodSecurity</span>  <span class="attr">configuration:</span>    <span class="attr">apiVersion:</span> <span class="string">pod-security.admission.config.k8s.io/v1beta1</span>    <span class="attr">kind:</span> <span class="string">PodSecurityConfiguration</span>    <span class="comment"># Defaults applied when a mode label is not set.</span>    <span class="comment">#</span>    <span class="comment"># Level label values must be one of:</span>    <span class="comment"># - &quot;privileged&quot; (default)</span>    <span class="comment"># - &quot;baseline&quot;</span>    <span class="comment"># - &quot;restricted&quot;</span>    <span class="comment">#</span>    <span class="comment"># Version label values must be one of:</span>    <span class="comment"># - &quot;latest&quot; (default) </span>    <span class="comment"># - specific version like &quot;v1.23&quot;</span>    <span class="attr">defaults:</span> <span class="comment"># 默认执行最宽松的检验策略</span>      <span class="attr">enforce:</span> <span class="string">&quot;privileged&quot;</span>      <span class="attr">enforce-version:</span> <span class="string">&quot;latest&quot;</span> <span class="comment"># latest 表示使用最新的 PSS 版本（基于集群版本，例如 Kubernetes 1.25 可能是 v1.25）</span>      <span class="attr">audit:</span> <span class="string">&quot;privileged&quot;</span>      <span class="attr">audit-version:</span> <span class="string">&quot;latest&quot;</span>      <span class="attr">warn:</span> <span class="string">&quot;privileged&quot;</span>      <span class="attr">warn-version:</span> <span class="string">&quot;latest&quot;</span>    <span class="attr">exemptions:</span>      <span class="comment"># 指定免除检查的认证用户名，空数组表示没有用户豁免，所有用户创建的 Pod 都受策略约束。</span>      <span class="attr">usernames:</span> []      <span class="comment"># 指定免除检查的 RuntimeClass 名称。空数组表示没有 RuntimeClass 豁免，适用于所有运行时（如 containerd、CRI-O）</span>      <span class="attr">runtimeClassNames:</span> []      <span class="comment"># 指定免除检查的命名空间</span>      <span class="attr">namespaces:</span> []</code></pre><p>pod security admission 可以从 username，runtimeClassName，namespace 三个维度对pod进行安全标准检查的豁免。</p><h2 id="4-Pod-Security-Standards实施演示"><a href="#4-Pod-Security-Standards实施演示" class="headerlink" title="4. Pod Security Standards实施演示"></a>4. Pod Security Standards实施演示</h2><ul><li>环境: kubernetes v1.29</li></ul><p>运行时的容器面临很多攻击风险，例如容器逃逸，从容器发起资源耗尽型攻击。</p><h3 id="4-1-Baseline策略"><a href="#4-1-Baseline策略" class="headerlink" title="4.1 Baseline策略"></a>4.1 Baseline策略</h3><p>Baseline策略目标是应用于常见的容器化应用，禁止已知的特权提升，在官方的介绍中此策略针对的是应用运维人员和非关键性应用开发人员，在该策略中包括：</p><p>必须禁止共享宿主机命名空间、禁止容器特权、 限制Linux能力、禁止hostPath卷、限制宿主机端口、设定AppArmor、SElinux、Seccomp、Sysctls等。</p><p><strong>下面演示设定Baseline策略。</strong></p><p>违反Baseline策略存在的风险：</p><ul><li>特权容器可以看到宿主机设备</li><li>挂载procfs后可以看到宿主机进程，打破进程隔离</li><li>可以打破网络隔离</li><li>挂载运行时socket后可以不受限制的与运行时通信</li></ul><p>等等以上风险都可能导致容器逃逸。</p><ol><li><p>创建名为my-baseline-namespace的namespace，并设定enforce和warn两种模式都对应Baseline等级的Pod安全标准策略：</p><p>资源清单：<code>my-baseline-namespace.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span> <span class="comment"># 命名空间的 API 版本（固定为 v1）</span><span class="attr">kind:</span> <span class="string">Namespace</span> <span class="comment"># 资源类型：命名空间（用于隔离集群资源）</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-baseline-namespace</span> <span class="comment"># 命名空间名称，Pod 将在此命名空间内运行</span>  <span class="attr">labels:</span> <span class="comment"># 核心：通过标签配置 Pod 安全策略（PSA 规则）</span>    <span class="comment"># 强制实施 Baseline 级别的安全标准，所有在该命名空间创建的 Pod 必须符合此标准，否则会被拒绝创建。</span>    <span class="comment"># Baseline 标准核心约束（Kubernetes 官方定义）：</span>      <span class="comment"># - 禁止特权容器（privileged: true）。</span>      <span class="comment"># - 禁止已知的特权升级路径（如 allowPrivilegeEscalation: true 且 runAsUser: 0）。</span>      <span class="comment"># - 允许默认的（相对宽松的）Pod 配置（如允许使用主机网络 hostNetwork、主机 PID hostPID、主机 IPC hostIPC 等，这也是与更严格的 Restricted 级别的主要区别）</span>    <span class="attr">pod-security.kubernetes.io/enforce:</span> <span class="string">baseline</span>    <span class="comment"># 指定 enforce 规则所使用的 Kubernetes 版本（此处为 v1.29）， 这确保了 PSA 规则仅在指定的 Kubernetes 版本下生效，避免与未来版本的 Kubernetes 发生冲突。</span>    <span class="attr">pod-security.kubernetes.io/enforce-version:</span> <span class="string">v1.29</span>    <span class="comment"># 当 Pod 不符合 Baseline 标准时，不阻止创建，但会生成警告信息（通过 API 响应或事件日志）。</span>    <span class="attr">pod-security.kubernetes.io/warn:</span> <span class="string">baseline</span>    <span class="comment"># 指定 warn 规则所使用的 Kubernetes 版本，与 enforce-version 保持一致（v1.29），确保警告规则与强制规则基于相同的标准定义</span>    <span class="attr">pod-security.kubernetes.io/warn-version:</span> <span class="string">v1.29</span><span class="comment"># 当同时指定 enforce: baseline 和 warn: baseline 时，Pod 创建流程如下：</span><span class="comment"># - 先检查 enforce 规则：</span><span class="comment">#   若 Pod 完全符合 baseline 标准 → 允许创建，进入下一步。</span><span class="comment">#   若 Pod 违反 baseline 核心约束（如特权容器、特权升级等）→ 直接拒绝创建，流程终止。</span><span class="comment"># - 再检查 warn 规则（仅当 enforce 允许创建时）：</span><span class="comment">#   若 Pod 存在潜在风险（如使用了不推荐但未被 enforce 禁止的配置）→ 生成警告信息（如 Warning: Pod violates PodSecurity &quot;baseline:v1.29&quot;）。</span><span class="comment">#   若 Pod 完全符合 baseline 标准 → 无警告，Pod 正常运行。</span></code></pre><p><strong>执行资源清单：</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f my-baseline-namespace.yaml <span class="comment"># 查看名称空间</span>$ kubectl get nsNAME                    STATUS   AGEkube-node-lease         Active   40dkube-public             Active   40dkube-system             Active   40dmy-baseline-namespace   Active   4snetwork                 Active   37d</code></pre></li><li><p>创建pod</p><ul><li><p>创建一个违反baseline策略的pod</p><p>资源清单：<code>fail-hostnamespaces.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">my-baseline-namespace</span>  <span class="attr">name:</span> <span class="string">fail-hostnamespaces</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">fail-hostnamespaces</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">fail-hostnamespaces</span>    <span class="attr">spec:</span>      <span class="attr">hostPID:</span> <span class="literal">true</span> <span class="comment"># 与主机共享PID</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">true</span> <span class="comment"># 启用特权模式</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 提示 容器创建异常</span>$ kubectl apply -f fail-hostnamespaces.yaml Warning: would violate PodSecurity <span class="string">&quot;baseline:v1.29&quot;</span>: host namespaces (hostPID=<span class="literal">true</span>), privileged (container <span class="string">&quot;nginx&quot;</span> must not <span class="built_in">set</span> securityContext.privileged=<span class="literal">true</span>)deployment.apps/fail-hostnamespaces created<span class="comment"># 只有Deploy，Pod创建失败</span>$ kubectl get deployment -n my-baseline-namespaceNAME                  READY   UP-TO-DATE   AVAILABLE   AGEfail-hostnamespaces   0/1     0            0           16s</code></pre></li><li><p>创建不违反 baseline 策略的 pod，设定 Pod 的 hostPID&#x3D;false，securityContext.privileged&#x3D;false</p><p>资源清单：<code>success-hostnamespaces.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">my-baseline-namespace</span>  <span class="attr">name:</span> <span class="string">success-hostnamespaces</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">fail-hostnamespaces</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">fail-hostnamespaces</span>    <span class="attr">spec:</span>      <span class="attr">hostPID:</span> <span class="literal">false</span> <span class="comment"># 不与主机共享PID</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">false</span> <span class="comment"># 禁用特权模式</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 创建Pod</span>$ kubectl apply -f success-hostnamespaces.yaml<span class="comment"># Pod成功启动</span>$ kubectl get pods -n my-baseline-namespaceNAME                                      READY   STATUS    RESTARTS   AGEsuccess-hostnamespaces-759ccb9dcd-x9cp6   1/1     Running   0          12s</code></pre></li></ul></li></ol><h3 id="4-2-Restricted策略"><a href="#4-2-Restricted策略" class="headerlink" title="4.2 Restricted策略"></a>4.2 Restricted策略</h3><p>Restricted 策略目标是实施当前保护 Pod 的最佳实践，在官方介绍中此策略主要针对运维人员和安全性很重要的应用开发人员，以及不太被信任的用户。该策略包含所有的 baseline 策略的内容，额外增加： 限制可以通过 PersistentVolumes 定义的非核心卷类型、禁止（通过 SetUID 或 SetGID 文件模式）获得特权提升、必须要求容器以非 root 用户运行、Containers 不可以将 runAsUser 设置为 0、 容器组必须弃用 ALL capabilities 并且只允许添加 NET_BIND_SERVICE 能力。</p><p>restricted 策略进一步的限制在容器内获取 root 权限，linux内核功能。例如针对 kubernetes 网络的中间人攻击需要拥有Linux系统的 CAP_NET_RAW 权限来发送ARP包。</p><ol><li><p>创建名为 my-restricted-namespace 的 namespace，并设定 enforce 和 warn 两种模式都对应 Restricted 等级的 Pod 安全标准策略：</p><p>资源清单：<code>my-restricted-namespace.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span> <span class="comment"># 命名空间的 API 版本（固定为 v1）</span><span class="attr">kind:</span> <span class="string">Namespace</span> <span class="comment"># 资源类型：命名空间（用于隔离集群资源）</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-restricted-namespace</span> <span class="comment"># 命名空间名称，Pod 将在此命名空间内运行</span>  <span class="attr">labels:</span> <span class="comment"># 核心：通过标签配置 Pod 安全策略（PSA 规则）</span>    <span class="comment"># 强制实施 Baseline 级别的安全标准，所有在该命名空间创建的 Pod 必须符合此标准，否则会被拒绝创建。</span>    <span class="attr">pod-security.kubernetes.io/enforce:</span> <span class="string">restricted</span>    <span class="comment"># 指定 enforce 规则所使用的 Kubernetes 版本（此处为 v1.29）， 这确保了 PSA 规则仅在指定的 Kubernetes 版本下生效，避免与未来版本的 Kubernetes 发生冲突。</span>    <span class="attr">pod-security.kubernetes.io/enforce-version:</span> <span class="string">v1.29</span>    <span class="comment"># 当 Pod 不符合 Restricted 标准时，不阻止创建，但会生成警告信息（通过 API 响应或事件日志）。</span>    <span class="attr">pod-security.kubernetes.io/warn:</span> <span class="string">restricted</span>    <span class="comment"># 指定 warn 规则所使用的 Kubernetes 版本，与 enforce-version 保持一致（v1.29），确保警告规则与强制规则基于相同的标准定义</span>    <span class="attr">pod-security.kubernetes.io/warn-version:</span> <span class="string">v1.29</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 创建名称空间</span>$ kubectl apply -f my-restricted-namespace.yaml namespace/my-restricted-namespace created<span class="comment"># 查看</span>$ kubectl get ns | grep restrictedmy-restricted-namespace   Active   12s</code></pre></li><li><p>创建pod</p><ul><li><p>创建一个违反 Restricted 策略的 pod</p><p>资源清单：<code>fail-restricted-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">my-restricted-namespace</span>  <span class="attr">name:</span> <span class="string">fail-restricted</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">fail-restricted</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">fail-restricted</span>    <span class="attr">spec:</span>      <span class="attr">hostPID:</span> <span class="literal">true</span> <span class="comment"># 与主机共享PID</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alpine</span>          <span class="attr">image:</span> <span class="string">alpine:3.22.1</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">command:</span> <span class="comment"># 容器启动命令</span>            <span class="bullet">-</span> <span class="string">/bin/sleep</span>            <span class="bullet">-</span> <span class="string">&quot;3600&quot;</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">true</span> <span class="comment"># 启用特权模式</span></code></pre><p>执行资源清单</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，提示异常</span>$ kubectl apply -f fail-restricted-pod.yaml Warning: would violate PodSecurity <span class="string">&quot;restricted:v1.29&quot;</span>: host namespaces (hostPID=<span class="literal">true</span>), privileged (container <span class="string">&quot;alpine&quot;</span> must not <span class="built_in">set</span> securityContext.privileged=<span class="literal">true</span>), allowPrivilegeEscalation != <span class="literal">false</span> (container <span class="string">&quot;alpine&quot;</span> must <span class="built_in">set</span> securityContext.allowPrivilegeEscalation=<span class="literal">false</span>), unrestricted capabilities (container <span class="string">&quot;alpine&quot;</span> must <span class="built_in">set</span> securityContext.capabilities.drop=[<span class="string">&quot;ALL&quot;</span>]), runAsNonRoot != <span class="literal">true</span> (pod or container <span class="string">&quot;alpine&quot;</span> must <span class="built_in">set</span> securityContext.runAsNonRoot=<span class="literal">true</span>), seccompProfile (pod or container <span class="string">&quot;alpine&quot;</span> must <span class="built_in">set</span> securityContext.seccompProfile.<span class="built_in">type</span> to <span class="string">&quot;RuntimeDefault&quot;</span> or <span class="string">&quot;Localhost&quot;</span>)deployment.apps/fail-restricted created<span class="comment"># 查看 Deploy，Pod未启动</span>$ kubectl get deployment -n my-restricted-namespaceNAME              READY   UP-TO-DATE   AVAILABLE   AGEfail-restricted   0/1     0            0           53s$ kubectl get pods -n my-restricted-namespaceNo resources found <span class="keyword">in</span> my-restricted-namespace namespace.</code></pre></li><li><p>创建不违反 Restricted 策略的 pod，设定 Pod 的 securityContext.runAsNonRoot&#x3D;true，Drop 所有 linux 能力。</p><p>资源清单：<code>success-restricted-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">my-restricted-namespace</span>  <span class="attr">name:</span> <span class="string">success-restricted</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">success-restricted</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">success-restricted</span>    <span class="attr">spec:</span>      <span class="attr">hostPID:</span> <span class="literal">false</span> <span class="comment"># 不与主机共享PID</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-nonroot</span>          <span class="attr">image:</span> <span class="string">nginx-nonroot:1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="comment"># 容器级别的安全上下文</span>          <span class="attr">securityContext:</span>            <span class="comment"># 以非root启动</span>            <span class="attr">runAsNonRoot:</span> <span class="literal">true</span>            <span class="comment"># 运行容器的用户ID</span>            <span class="attr">runAsUser:</span> <span class="number">101</span>            <span class="comment"># 不允许权限提升</span>            <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span>            <span class="comment"># 禁用所有能力</span>            <span class="attr">capabilities:</span>              <span class="attr">drop:</span>                <span class="bullet">-</span> <span class="string">ALL</span>      <span class="comment"># Pod级别的安全上下文</span>      <span class="attr">securityContext:</span>        <span class="comment"># 不允许以root启动</span>        <span class="attr">runAsNonRoot:</span> <span class="literal">true</span>        <span class="comment"># 不允许使用默认的seccomp profile</span>        <span class="attr">seccompProfile:</span>          <span class="attr">type:</span> <span class="string">RuntimeDefault</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f success-restricted-pod.yaml deployment.apps/success-restricted created<span class="comment"># 查看Pod 已成功运行</span>$ kubectl get deployment -n my-restricted-namespaceNAME                 READY   UP-TO-DATE   AVAILABLE   AGEsuccess-restricted   1/1     1            1           28s</code></pre></li></ul></li></ol><h1 id="四、pod-security-admission当前局限性"><a href="#四、pod-security-admission当前局限性" class="headerlink" title="四、pod security admission当前局限性"></a>四、pod security admission当前局限性</h1><p>如果你的集群中已经配置PodSecurityPolicy，考虑把它们迁移到pod security admission是需要一定的工作量的。</p><p>首先需要考虑当前的pod security admission是否适合你的集群，目前它旨在满足开箱即用的最常见的安全需求，与PSP相比它存在以下差异：</p><ul><li>pod security admission 只是对 pod 进行安全标准的检查，不支持对 pod 进行修改，不能为 pod 设置默认的安全配置。</li><li>pod security admission 只支持官方定义的三种安全标准策略，不支持灵活的自定义安全标准策略。这使得不能完全将 PSP 规则迁移到 pod security admission，需要进行具体的安全规则考量。</li><li>pod security admission 不像 PSP 一样可以与具体的用户进行绑定，只支持豁免特定的用户或者 RuntimeClass 及 namespace。</li></ul><p><strong>参考链接</strong></p><blockquote><p><a href="https://support.huaweicloud.com/usermanual-cce/cce_10_0402.html">https://support.huaweicloud.com/usermanual-cce/cce_10_0402.html</a></p><p><a href="https://www.cnblogs.com/zhangmingcheng/p/17640118.html">https://www.cnblogs.com/zhangmingcheng/p/17640118.html</a></p><p><a href="https://www.cnblogs.com/bocloud/p/16107335.html">https://www.cnblogs.com/bocloud/p/16107335.html</a></p><p><a href="https://waynerv.com/posts/enable-pod-security-policy-for-cluster/">https://waynerv.com/posts/enable-pod-security-policy-for-cluster/</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;集群环境&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;Hostname&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;10.20.1.139&lt;/td&gt;
</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>020-K8S-审计</title>
    <link href="https://georgechan95.github.io/blog/88f4f580.html"/>
    <id>https://georgechan95.github.io/blog/88f4f580.html</id>
    <published>2025-08-10T06:43:00.000Z</published>
    <updated>2025-08-11T02:54:19.657Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h1><p>Kubernetes 审计（Auditing） 功能提供了与安全相关的、按时间顺序排列的记录集， 记录每个用户、使用 Kubernetes API 的应用以及控制面自身引发的活动（所有访问kube-apiserver服务的客户端）。</p><p>审计功能使得集群管理员能够回答以下问题：</p><ul><li>发生了什么？</li><li>什么时候发生的？</li><li>谁触发的？</li><li>活动发生在哪个（些）对象上？</li><li>在哪观察到的？</li><li>它从哪触发的？</li><li>活动的后续处理行为是什么？</li></ul><p>这对平台管理者来说十分重要，能够回答一些在故障时候出现的问题。哪个用户，从哪个ip上，发起了什么请求。如删除了一个命名空间，导致这个命名空间下的所有pod被回收，对故障进行复盘。</p><p>Kubernetes 审计功能由 kube-apiserver 服务提供。每个请求在不同执行阶段都会生成审计事件；这些审计事件会根据特定策略被预处理并写入后端。策略确定要记录的内容，当前的后端支持日志文件和 webhook。</p><p>每个请求都可被记录其相关的 <strong>阶段（stage）</strong>。已定义的阶段有：</p><ul><li><code>RequestReceived</code> - 此阶段对应审计处理器接收到请求后，并且在委托给处理器处理之前生成的事件。</li><li><code>ResponseStarted</code> - 在响应消息的头部发送后，响应消息体发送前生成的事件。 只有长时间运行的请求（例如 watch）才会生成这个阶段。</li><li><code>ResponseComplete</code> - 当响应消息体完成并且没有更多数据需要传输的时候。</li><li><code>Panic</code> - 当 panic 发生时生成。</li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-152540.png" alt="审计的4个阶段"></p><p>审计日志记录功能会增加 API server 的内存消耗，因为需要为每个请求存储审计所需的某些上下文。 此外，内存消耗取决于审计日志记录的配置。</p><p>Kubernetes 审计是一种监控和记录 Kubernetes 集群中资源操作的方法，用于确保集群的安全性和符合性。通过审计，管理员可以跟踪对集群资源的访问和修改，以便在发生安全事件时进行调查和响应。Kubernetes 提供了审计日志记录的框架，允许管理员自定义审计策略，以确定哪些资源操作应该被记录。</p><h1 id="二、审计策略简介"><a href="#二、审计策略简介" class="headerlink" title="二、审计策略简介"></a>二、审计策略简介</h1><p>审计策略定义了关于应记录哪些事件以及应包含哪些数据的规则。 审计策略对象结构定义在 <code>audit.k8s.io</code> API 组。 处理事件时，将按顺序与规则列表进行比较。第一个匹配规则设置事件的审计级别（Audit Level），<strong>审计级别（Audit Level）可以理解为记录什么？</strong> 已定义的审计级别有：</p><ul><li>None - 符合这条规则的日志将不会记录。</li><li>Metadata - 记录请求的元数据（请求的用户、时间戳、资源、动词等等）， 但是不记录请求或者响应的消息体。</li><li>Request - 记录事件的元数据和请求的消息体，但是不记录响应的消息体。 这不适用于非资源类型的请求。</li><li>RequestResponse - 记录事件的元数据，请求和响应的消息体。这不适用于非资源类型的请求。</li></ul><p>你可以使用 <code>--audit-policy-file</code> 标志将包含策略的文件传递给 <code>kube-apiserver</code>。 如果不设置该标志，则不记录事件。 注意 <code>rules</code> 字段 <strong>必须</strong> 在审计策略文件中提供。没有（0）规则的策略将被视为非法配置。</p><p>审计策略定义了哪些资源操作应该被审计以及审计记录的格式。在 Kubernetes 中，审计策略通过 Admission Controllers 实现，可以通过 Webhook 的方式进行集成。审计策略可以根据资源的类型、操作的类型和用户身份等信息进行过滤，以满足不同场景下的审计需求。</p><h1 id="三、启用审计"><a href="#三、启用审计" class="headerlink" title="三、启用审计"></a>三、启用审计</h1><h2 id="1-创建审计策略文件"><a href="#1-创建审计策略文件" class="headerlink" title="1. 创建审计策略文件"></a>1. 创建审计策略文件</h2><pre><code class="highlight bash"><span class="comment"># 创建文件夹，用于存放审计日志策略文件，和日志文件</span>$ <span class="built_in">mkdir</span> /etc/kubernetes/audit-policy /etc/kubernetes/audit-logs<span class="comment"># 编辑审计策略（仅是示例）</span>$ <span class="built_in">cat</span> /etc/kubernetes/audit-policy/policy.yamlapiVersion: audit.k8s.io/v1kind: Policyrules:  <span class="comment"># 设置机密资源的审计日志级别为Metadata</span>  - level: Metadata    resources:      - group: <span class="string">&quot;&quot;</span>        resources: [<span class="string">&quot;pods&quot;</span>]    namespaces: [<span class="string">&quot;default&quot;</span>]             <span class="comment"># 默认就是default命名空间</span>  <span class="comment"># 设置节点的审计日志级别为RequestResponse</span>  - level: RequestResponse    userGroups: [<span class="string">&quot;system:nodes&quot;</span>]  <span class="comment"># 对于其他内容，不要记录任何内容</span>  - level: None</code></pre><h2 id="2-添加审计日志"><a href="#2-添加审计日志" class="headerlink" title="2. 添加审计日志"></a>2. 添加审计日志</h2><p>审计日志参数如下：</p><ul><li>–audit-log-path 指定用来写入审计事件的日志文件路径。不指定此标志会禁用日志后端。- 意味着标准化</li><li>–audit-log-maxage 定义保留旧审计日志文件的最大天数</li><li>–audit-log-maxbackup 定义要保留的审计日志文件的最大数量</li><li>–audit-log-maxsize 定义审计日志文件轮转之前的最大大小（兆字节）</li></ul><pre><code class="highlight yaml"><span class="comment"># 修改 kube-apiserver.yaml，添加添加审计日志配置</span><span class="string">$</span> <span class="string">vim</span> <span class="string">/etc/kubernetes/manifests/kube-apiserver.yaml</span><span class="comment"># 配置审计日志参数</span><span class="attr">spec:</span>  <span class="attr">containers:</span>  <span class="bullet">-</span> <span class="attr">command:</span>    <span class="bullet">-</span> <span class="string">--audit-policy-file=/etc/kubernetes/audit-policy/policy.yaml</span><span class="comment"># 审计策略文件</span>    <span class="bullet">-</span> <span class="string">--audit-log-path=/etc/kubernetes/audit-logs/audit.log</span><span class="comment"># 审计日志文件</span>    <span class="bullet">-</span> <span class="string">--audit-log-maxsize=10</span><span class="comment"># 单个日志最大 10MB</span>    <span class="bullet">-</span> <span class="string">--audit-log-maxbackup=20</span><span class="comment"># 最多保留20个日志文件</span><span class="comment"># 挂载存储卷，将审计策略文件和日志文件挂载到容器内的指定路径</span><span class="attr">volumeMounts:</span><span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/kubernetes/audit-policy/policy.yaml</span>  <span class="attr">name:</span> <span class="string">audit-policy</span>  <span class="attr">readOnly:</span> <span class="literal">true</span><span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/kubernetes/audit-logs</span>  <span class="attr">name:</span> <span class="string">audit-logs</span>  <span class="attr">readOnly:</span> <span class="literal">false</span><span class="comment"># 声明挂载卷</span>  <span class="attr">volumes:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">audit-policy</span>    <span class="attr">hostPath:</span>      <span class="attr">path:</span> <span class="string">/etc/kubernetes/audit-policy/policy.yaml</span>      <span class="attr">type:</span> <span class="string">File</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">audit-logs</span>    <span class="attr">hostPath:</span>      <span class="attr">path:</span> <span class="string">/etc/kubernetes/audit-logs</span>      <span class="attr">type:</span> <span class="string">DirectoryOrCreate</span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-155941.png" alt="配置审计日志参数"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-160013.png" alt="挂载存储卷"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-160042.png" alt="声明挂载卷"></p><p>保存 kube-apiserver.yaml 文件后，等待生效（为了保险起见也可以重启 kubelet ）。</p><pre><code class="highlight bash">$ systemctl daemon-reload$ systemctl restart kubelet</code></pre><h2 id="3-查看审计日志"><a href="#3-查看审计日志" class="headerlink" title="3. 查看审计日志"></a>3. 查看审计日志</h2><h3 id="3-1-创建测试-Pod"><a href="#3-1-创建测试-Pod" class="headerlink" title="3.1 创建测试 Pod"></a>3.1 创建测试 Pod</h3><pre><code class="highlight bash">$ kubectl run audit-demo --image=nginx:1.29.0 --image-pull-policy=IfNotPresent</code></pre><h3 id="3-2-查看日志"><a href="#3-2-查看日志" class="headerlink" title="3.2 查看日志"></a>3.2 查看日志</h3><pre><code class="highlight bash">$ <span class="built_in">tail</span> -1000f /etc/kubernetes/audit-logs/audit.log | grep audit-demo -A 10&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;Metadata&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;3943a216-8452-45d9-a127-6ab2e58e4fa0&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;RequestReceived&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/api/v1/namespaces/default/pods/audit-demo&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;get&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:serviceaccount:kube-system:calico-cni-plugin&quot;</span>,<span class="string">&quot;uid&quot;</span>:<span class="string">&quot;3d9a2a4d-8207-4e57-ae9e-23e4e1a943be&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:serviceaccounts&quot;</span>,<span class="string">&quot;system:serviceaccounts:kube-system&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.140&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;calico/v0.0.0 (linux/amd64) kubernetes/<span class="variable">$Format</span>&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;pods&quot;</span>,<span class="string">&quot;namespace&quot;</span>:<span class="string">&quot;default&quot;</span>,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;audit-demo&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.977141Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.977141Z&quot;</span>&#125;&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;Metadata&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;3943a216-8452-45d9-a127-6ab2e58e4fa0&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;ResponseComplete&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/api/v1/namespaces/default/pods/audit-demo&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;get&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:serviceaccount:kube-system:calico-cni-plugin&quot;</span>,<span class="string">&quot;uid&quot;</span>:<span class="string">&quot;3d9a2a4d-8207-4e57-ae9e-23e4e1a943be&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:serviceaccounts&quot;</span>,<span class="string">&quot;system:serviceaccounts:kube-system&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.140&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;calico/v0.0.0 (linux/amd64) kubernetes/<span class="variable">$Format</span>&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;pods&quot;</span>,<span class="string">&quot;namespace&quot;</span>:<span class="string">&quot;default&quot;</span>,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;audit-demo&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;responseStatus&quot;</span>:&#123;<span class="string">&quot;metadata&quot;</span>:&#123;&#125;,<span class="string">&quot;code&quot;</span>:200&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.977141Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.979410Z&quot;</span>,<span class="string">&quot;annotations&quot;</span>:&#123;<span class="string">&quot;authorization.k8s.io/decision&quot;</span>:<span class="string">&quot;allow&quot;</span>,<span class="string">&quot;authorization.k8s.io/reason&quot;</span>:<span class="string">&quot;RBAC: allowed by ClusterRoleBinding \&quot;calico-cni-plugin\&quot; of ClusterRole \&quot;calico-cni-plugin\&quot; to ServiceAccount \&quot;calico-cni-plugin/kube-system\&quot;&quot;</span>&#125;&#125;&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;Metadata&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;8c1f6ae3-edb9-41cf-a73a-633ad406d270&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;RequestReceived&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/api/v1/namespaces/default/pods/audit-demo&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;get&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:serviceaccount:kube-system:calico-cni-plugin&quot;</span>,<span class="string">&quot;uid&quot;</span>:<span class="string">&quot;3d9a2a4d-8207-4e57-ae9e-23e4e1a943be&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:serviceaccounts&quot;</span>,<span class="string">&quot;system:serviceaccounts:kube-system&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.140&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;calico/v0.0.0 (linux/amd64) kubernetes/<span class="variable">$Format</span>&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;pods&quot;</span>,<span class="string">&quot;namespace&quot;</span>:<span class="string">&quot;default&quot;</span>,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;audit-demo&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.984952Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.984952Z&quot;</span>&#125;</code></pre><h3 id="3-3-日志解析"><a href="#3-3-日志解析" class="headerlink" title="3.3 日志解析"></a>3.3 日志解析</h3><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-161933.png" alt="审计日志解析"></p><h1 id="四、审计策略案例实践"><a href="#四、审计策略案例实践" class="headerlink" title="四、审计策略案例实践"></a>四、审计策略案例实践</h1><pre><code class="highlight bash"><span class="comment"># 创建命名空间</span>$ kubectl create ns auditnamespace/audit created$ kubectl get ns | grep auditaudit             Active   11m</code></pre><h2 id="1-只记录-audit-命名空间里的日志"><a href="#1-只记录-audit-命名空间里的日志" class="headerlink" title="1. 只记录 audit 命名空间里的日志"></a>1. 只记录 audit 命名空间里的日志</h2><p>修改审计策略，现在配置只记录某个命名空间里的审计日志，namespaces: [“audit”] 表示只记录 audit 命名空间里的日志。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">omitStages:</span>                     <span class="comment"># 记录审计阶段为：ResponseStarted</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span>             <span class="comment"># 设置机密资源的审计日志级别为Metadata</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]       <span class="comment"># 只记录该命名空间的日志</span></code></pre><p>重启 kubelet , 让策略生效</p><pre><code class="highlight bash">$ systemctl daemon-reload &amp;&amp; systemctl restart kubelet</code></pre><p>清空 <code>audit.log</code></p><pre><code class="highlight bash">$ &gt; /etc/kubernetes/audit-logs/audit.log</code></pre><p>查看审计日志，只记录了audit 命名空间的操作，default 命名空间的操作没有记录。</p><pre><code class="highlight bash">$ <span class="built_in">tail</span> -100f /etc/kubernetes/audit-logs/audit.log&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;RequestResponse&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;2205c680-4877-4498-b40f-459b2779afa8&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;ResponseComplete&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/apis/node.k8s.io/v1/runtimeclasses?allowWatchBookmarks=true\u0026resourceVersion=2798746\u0026timeout=9m18s\u0026timeoutSeconds=558\u0026watch=true&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;watch&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:node:k8s-master01&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:nodes&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.139&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;kubelet/v1.29.15 (linux/amd64) kubernetes/0d0f172&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;runtimeclasses&quot;</span>,<span class="string">&quot;apiGroup&quot;</span>:<span class="string">&quot;node.k8s.io&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;responseStatus&quot;</span>:&#123;<span class="string">&quot;metadata&quot;</span>:&#123;&#125;,<span class="string">&quot;code&quot;</span>:200&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:06:30.212676Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:08:29.706126Z&quot;</span>,<span class="string">&quot;annotations&quot;</span>:&#123;<span class="string">&quot;authorization.k8s.io/decision&quot;</span>:<span class="string">&quot;allow&quot;</span>,<span class="string">&quot;authorization.k8s.io/reason&quot;</span>:<span class="string">&quot;&quot;</span>&#125;&#125;&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;RequestResponse&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;4a54a59a-fa98-43e7-a004-f14b9d4bd6eb&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;ResponseComplete&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/api/v1/nodes?allowWatchBookmarks=true\u0026fieldSelector=metadata.name%3Dk8s-master01\u0026resourceVersion=2798755\u0026timeout=6m45s\u0026timeoutSeconds=405\u0026watch=true&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;watch&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:node:k8s-master01&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:nodes&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.139&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;kubelet/v1.29.15 (linux/amd64) kubernetes/0d0f172&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;nodes&quot;</span>,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;k8s-master01&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;responseStatus&quot;</span>:&#123;<span class="string">&quot;metadata&quot;</span>:&#123;&#125;,<span class="string">&quot;code&quot;</span>:200&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:06:31.945964Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:08:29.706028Z&quot;</span>,<span class="string">&quot;annotations&quot;</span>:&#123;<span class="string">&quot;authorization.k8s.io/decision&quot;</span>:<span class="string">&quot;allow&quot;</span>,<span class="string">&quot;authorization.k8s.io/reason&quot;</span>:<span class="string">&quot;&quot;</span>&#125;&#125;&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;RequestResponse&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;9dcf6bb7-51f5-45d0-a7b6-f352e455c736&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;ResponseComplete&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/api/v1/services?allowWatchBookmarks=true\u0026resourceVersion=2798746\u0026timeout=8m41s\u0026timeoutSeconds=521\u0026watch=true&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;watch&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:node:k8s-master01&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:nodes&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.139&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;kubelet/v1.29.15 (linux/amd64) kubernetes/0d0f172&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;services&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;responseStatus&quot;</span>:&#123;<span class="string">&quot;metadata&quot;</span>:&#123;&#125;,<span class="string">&quot;code&quot;</span>:200&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:06:29.952827Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:08:29.706023Z&quot;</span>,<span class="string">&quot;annotations&quot;</span>:&#123;<span class="string">&quot;authorization.k8s.io/decision&quot;</span>:<span class="string">&quot;allow&quot;</span>,<span class="string">&quot;authorization.k8s.io/reason&quot;</span>:<span class="string">&quot;&quot;</span>&#125;&#125;</code></pre><h2 id="2-只记录-audit-命名空间的-pods-操作日志"><a href="#2-只记录-audit-命名空间的-pods-操作日志" class="headerlink" title="2. 只记录 audit 命名空间的 pods 操作日志"></a>2. 只记录 audit 命名空间的 pods 操作日志</h2><p>修改审计策略，该审计策略表示只记录 audit 命名空间的 pods 操作</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span>     <span class="comment"># 只记录audit命名空间的pods操作日志</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">omitStages:</span>                     <span class="comment"># 记录审计阶段为：ResponseStarted</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span>             <span class="comment"># 设置机密资源的审计日志级别为Metadata</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>        <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]       <span class="comment"># 只记录该命名空间的日志</span></code></pre><h2 id="3-只记录-audit-命名空间的-pods-services-deployments-操作日志"><a href="#3-只记录-audit-命名空间的-pods-services-deployments-操作日志" class="headerlink" title="3. 只记录 audit 命名空间的 pods,services,deployments 操作日志"></a>3. 只记录 audit 命名空间的 pods,services,deployments 操作日志</h2><p>编辑审计策略文件，表示只记录 audit 命名空间的 pods,services,deployments 操作，因为 deployments 的 apiVersion 的父级为 apps，所以需要 group: “apps” 。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span>     <span class="comment"># 只记录audit命名空间的pods,services,deployments操作日志</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">omitStages:</span>                     <span class="comment"># 记录审计阶段为：ResponseStarted</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span>             <span class="comment"># 设置机密资源的审计日志级别为Metadata</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>        <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>,<span class="string">&quot;services&quot;</span>]      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;apps&quot;</span>        <span class="attr">resources:</span> [<span class="string">&quot;deployments&quot;</span>]    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]       <span class="comment"># 只记录该命名空间的日志</span></code></pre><h2 id="4-只记录-audit-命名空间的-pods-操作-审计级别为-RequestResponse"><a href="#4-只记录-audit-命名空间的-pods-操作-审计级别为-RequestResponse" class="headerlink" title="4. 只记录 audit 命名空间的 pods 操作,审计级别为 RequestResponse"></a>4. 只记录 audit 命名空间的 pods 操作,审计级别为 RequestResponse</h2><p>编辑审计策略文件，表示只记录 audit 命名空间的 pods 操作,审计级别为 RequestResponse，记录事件的元数据，请求和响应的消息体。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span>     <span class="comment"># 只记录audit命名空间的pods,services,deployments操作日志</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">omitStages:</span>                     <span class="comment"># 记录审计阶段为：ResponseStarted</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">RequestResponse</span>             <span class="comment"># 设置机密资源的审计日志级别为 RequestResponse</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>        <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]       <span class="comment"># 只记录该命名空间的日志</span></code></pre><h2 id="5-只记录-audit-命名空间下的-dev-用户的-pods-操作，其他用户操作不记录"><a href="#5-只记录-audit-命名空间下的-dev-用户的-pods-操作，其他用户操作不记录" class="headerlink" title="5. 只记录 audit 命名空间下的 dev 用户的 pods 操作，其他用户操作不记录"></a>5. 只记录 audit 命名空间下的 dev 用户的 pods 操作，其他用户操作不记录</h2><p>参考：<a href="https://georgechan95.github.io/blog/424f1119.html">https://georgechan95.github.io/blog/424f1119.html</a></p><p>编辑审计策略文件，设置审计策略：只记录 audit 命名空间下的 george 用户的 pods 操作，其他用户的操作不记录。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span>     <span class="comment"># 只记录audit命名空间的pods,services,deployments操作日志</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">omitStages:</span>                     <span class="comment"># 记录审计阶段为：ResponseStarted</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span>             <span class="comment"># 设置机密资源的审计日志级别为 Metadata</span>    <span class="attr">users:</span> [<span class="string">&quot;george&quot;</span>]           <span class="comment"># 只记录 george 用户的操作</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>        <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]       <span class="comment"># 只记录该命名空间的日志</span></code></pre><h2 id="6-rules-规则是从上往下匹配的，第一条规则已经匹配了，第二条就不匹配了"><a href="#6-rules-规则是从上往下匹配的，第一条规则已经匹配了，第二条就不匹配了" class="headerlink" title="6. rules 规则是从上往下匹配的，第一条规则已经匹配了，第二条就不匹配了"></a>6. rules 规则是从上往下匹配的，第一条规则已经匹配了，第二条就不匹配了</h2><p>编辑审计策略文件，有两条策略，一条是：apiVersion 为 group: “” 的操作不记录日志，另外一条是：只记录 audit 命名空间下 george 用户的 pod 操作。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span> <span class="comment"># This is required.</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="comment"># Don&#x27;t generate audit events for all requests in RequestReceived stage.</span><span class="attr">omitStages:</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="comment"># apiVersion为 group: &quot;&quot; 的操作不记录日志</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">None</span>    <span class="attr">resources:</span>    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>  <span class="comment"># 只记录 audit 命名空间下 george 用户的 pod 操作</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span>    <span class="attr">users:</span> [<span class="string">&quot;george&quot;</span>]    <span class="attr">resources:</span>    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>      <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]</code></pre><p>查看审计日志，可以发现在客户端使用 george 用户查询 pod 和使用管理员用户查看 pod 都没有生成审计日志，rules 规则是从上往下匹配的，第一条规则已经匹配了，第二条就不匹配了。</p><h2 id="7-在-Metadata-级别为所有请求生成日志"><a href="#7-在-Metadata-级别为所有请求生成日志" class="headerlink" title="7. 在 Metadata 级别为所有请求生成日志"></a>7. 在 Metadata 级别为所有请求生成日志</h2><p>编辑审计策略文件，在 Metadata 级别为所有请求生成日志。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1beta1</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">rules:</span><span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span></code></pre><h1 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h1><p>实施审计策略可以帮助管理员监控和记录集群中的资源操作，确保集群的安全性和符合性。通过启用审计 Admission Controller 和配置相应的审计策略，我们可以灵活地控制审计记录的格式和范围。</p><p><strong>参考链接</strong></p><blockquote><p><a href="https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/audit/">https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/audit/</a></p><p><a href="https://kubernetes.io/zh-cn/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Event">https://kubernetes.io/zh-cn/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Event</a></p><p><a href="https://www.cnblogs.com/renshengdezheli/p/18266120">https://www.cnblogs.com/renshengdezheli/p/18266120</a></p><p><a href="https://www.cnblogs.com/tencent-cloud-native/p/14097545.html">https://www.cnblogs.com/tencent-cloud-native/p/14097545.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、概述&quot;&gt;&lt;a href=&quot;#一、概述&quot; class=&quot;headerlink&quot; title=&quot;一、概述&quot;&gt;&lt;/a&gt;一、概述&lt;/h1&gt;&lt;p&gt;Kubernetes 审计（Auditing） 功能提供了与安全相关的、按时间顺序排列的记录集， 记录每个用户、使用 Kub</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>019-K8S-kubectl端口转发</title>
    <link href="https://georgechan95.github.io/blog/9bea6e2e.html"/>
    <id>https://georgechan95.github.io/blog/9bea6e2e.html</id>
    <published>2025-08-04T15:02:00.000Z</published>
    <updated>2025-08-10T04:05:16.107Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h1><p>在 Kubernetes 集群中，所有资源都运行在私有网络空间（通常使用 CNI 插件构建 overlay 网络），这带来了以下调试难题：</p><ul><li>Pod 使用动态 IP 地址（生命周期短暂）</li><li>Service 的 ClusterIP 仅在集群内部可达</li><li>生产环境通常禁用 NodePort 等暴露方式</li></ul><p>针对上述的几种情况，我们就可以使用 <code>kubectl port-forward</code>来满足需求。</p><h2 id="1-port-forward-介绍"><a href="#1-port-forward-介绍" class="headerlink" title="1. port-forward 介绍"></a>1. port-forward 介绍</h2><p><code>kubectl port-forward</code> 是 Kubernetes 命令行工具 kubectl 提供的一个功能，用于在本地主机和 Kubernetes 集群中的 Pod 之间建立端口转发。</p><p>当你运行 kubectl port-forward 命令时，它会将本地主机上的一个端口与 Kubernetes 集群中的一个 Pod 的端口进行绑定。这样，在本地主机上监听的端口上收到的流量将被转发到 Pod 的端口上，反之亦然。</p><p>这个功能在开发和调试应用程序时非常有用。以下是一些 <code>kubectl port-forward</code>的常见用途和好处：</p><ul><li><strong>访问远程 Pod 的本地服务</strong>: 你可以将 Pod 的端口转发到本地主机，从而能够直接访问 Pod 上运行的服务。例如，你可以将一个运行在 Kubernetes 集群中的数据库 Pod 的端口转发到本地，以便在本地开发环境中连接和测试数据库。</li><li><strong>调试和日志记录</strong>: 通过将 Pod 的端口转发到本地，你可以使用本地工具来调试和监视在 Kubernetes 中运行的应用程序。你可以使用本地的调试器、日志记录工具或其他开发工具来检查应用程序的状态、调试问题或查看日志。</li><li><strong>绕过 Kubernetes 服务和负载均衡器</strong>: 有时候，你可能想直接访问运行在 Kubernetes 中的应用程序，而不经过 Kubernetes 的服务发现和负载均衡机制。通过将 Pod 的端口转发到本地，你可以绕过这些机制，直接连接到应用程序。</li></ul><p><strong>端口转发优势</strong></p><table><thead><tr><th><strong>特性</strong></th><th><strong>kubectl port-forward</strong></th><th><strong>NodePort</strong></th><th><strong>Ingress</strong></th></tr></thead><tbody><tr><td>无需修改资源配置</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>临时性访问</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>支持TCP&#x2F;UDP</td><td><strong>TCP</strong></td><td>✓</td><td><strong>HTTP&#x2F;HTTPS only</strong></td></tr><tr><td>网络策略穿透</td><td>✓</td><td>✗</td><td>✗</td></tr></tbody></table><p><strong>注意：<code>kubectl port-forward</code> 目前仅支持 <code>TCP</code> 端口的转发，对 <code>UDP</code> 协议的支持正在 <code>GitHub</code> 的 <code>Issue</code> Port-forward for UDP 中进行跟踪。</strong></p><h2 id="2-安装-socat"><a href="#2-安装-socat" class="headerlink" title="2. 安装 socat"></a>2. 安装 socat</h2><p>kubectl port-forward 命令依赖 socat 来处理本地端口与 Kubernetes Pod 之间的 TCP 连接转发。如果 socat 未安装，命令会无法执行转发操作，导致连接丢失（”lost connection to pod”）。</p><p><strong>Pod 运行的每个节点都需要安装</strong></p><pre><code class="highlight bash"><span class="comment"># Linux（例如 Ubuntu/Debian）：</span>sudo apt updatesudo apt install socat<span class="comment"># Linux（例如 CentOS/RHEL/Fedora）</span>sudo yum install socat<span class="comment"># dnf 系统</span>sudo dnf install socat<span class="comment"># macOS（使用 Homebrew）</span>brew install socat</code></pre><h1 id="二、kubectl-port-forward-命令概述"><a href="#二、kubectl-port-forward-命令概述" class="headerlink" title="二、kubectl port-forward 命令概述"></a>二、kubectl port-forward 命令概述</h1><h2 id="1-基本语法"><a href="#1-基本语法" class="headerlink" title="1. 基本语法"></a>1. 基本语法</h2><pre><code class="highlight bash">kubectl port-forward &lt;pod-name&gt; [local-port:]pod-port [-n namespace]  kubectl port-forward deployment/&lt;deployment-name&gt; [local-port:]pod-port [-n namespace]kubectl port-forward replicaset/&lt;replicaset-name&gt; [local-port:]pod-port [-n namespace]kubectl port-forward service/&lt;service-name&gt; [local-port:]pod-port [-n namespace]</code></pre><p><strong>核心参数说明</strong></p><pre><code class="highlight plaintext">-n, --namespace string       指定命名空间（默认default）--address stringArray        绑定地址（默认为127.0.0.1）， 0.0.0.0 表示所有ip都能连接访问--pod-running-timeout duration 等待Pod运行的最长时间</code></pre><h2 id="2-多资源类型支持"><a href="#2-多资源类型支持" class="headerlink" title="2. 多资源类型支持"></a>2. 多资源类型支持</h2><pre><code class="highlight bash"><span class="comment"># Pod 转发（直接访问指定Pod）</span>kubectl port-forward pod/nginx 8080:80 <span class="comment"># Deployment 转发（自动选择最新Pod）</span>kubectl port-forward deployment/nginx 8080:80 <span class="comment"># Service 转发（自动选择后端Pod）</span>kubectl port-forward svc/mysql 3306:3306 <span class="comment"># StatefulSet 转发（指定序号Pod）</span>kubectl port-forward pod/redis-1 6379:6379</code></pre><h2 id="3-高级转发模式"><a href="#3-高级转发模式" class="headerlink" title="3. 高级转发模式"></a>3. 高级转发模式</h2><h3 id="3-1-多端口转发"><a href="#3-1-多端口转发" class="headerlink" title="3.1 多端口转发"></a>3.1 多端口转发</h3><pre><code class="highlight bash">kubectl port-forward pod/nginx 8080:80 8443:443</code></pre><h3 id="3-2-后台运行"><a href="#3-2-后台运行" class="headerlink" title="3.2 后台运行"></a>3.2 后台运行</h3><pre><code class="highlight bash"><span class="comment"># 使用 nohup 防止终端关闭后进程终止</span><span class="built_in">nohup</span> kubectl port-forward pod/nginx 8080:80 &gt; portforward.log 2&gt;&amp;1 &lt; /dev/null &amp;</code></pre><p><strong>命令解析</strong></p><p>这个命令用于在后台运行 Kubernetes 的 kubectl port-forward 操作，将本地端口（8080）上的流量转发到 Kubernetes 中名为 nginx 的 Pod 的端口（80）。它通过 nohup 确保进程在终端关闭后继续运行，将输出重定向到日志文件，并将进程与终端分离。</p><ul><li><p>**<code>nohup</code>**：作用：nohup（no hang-up，意为“无挂起”）是一个 Unix 工具，用于让进程在用户退出终端或关闭会话后继续运行。通常，当终端会话关闭时，进程会收到 SIGHUP（挂起信号）而终止，而 nohup 可以防止进程因收到此信号而停止。</p></li><li><p>**<code>&gt; portforward.log</code>**：作用：将命令的标准输出（stdout）重定向到文件 portforward.log 中。</p><ul><li>kubectl port-forward 的输出（例如连接信息或日志）会被写入到当前目录下的 portforward.log 文件，而不是显示在终端上。</li><li>如果 portforward.log 文件已存在，&gt; 会覆盖原有内容（若想追加而不是覆盖，可以用 &gt;&gt;）。</li></ul></li><li><p>**<code>2&gt;&amp;1</code>**：作用：将标准错误（stderr）重定向到标准输出（stdout）。</p><p>在 Unix&#x2F;Linux 中，进程有三个标准文件描述符</p><ul><li>0：标准输入（stdin）</li><li>1：标准输出（stdout）</li><li>2：标准错误（stderr）</li></ul><p>2&gt;&amp;1 表示将标准错误（2）重定向到标准输出（1）的同一个目标。结合前面的 <code>&gt; portforward.log</code>，这意味着标准错误和标准输出都会被写入到 portforward.log 文件中。</p></li><li><p><strong><code>&lt; /dev/null</code></strong> ：将标准输入（stdin）重定向到 &#x2F;dev&#x2F;null。</p><ul><li><code>/dev/null</code> 是一个特殊的 Unix 文件，任何写入其中的数据都会被丢弃，读取时则返回空。</li><li><code>&lt; /dev/null</code> 表示将命令的标准输入设置为 &#x2F;dev&#x2F;null，意味着命令不会从终端读取任何输入。</li></ul></li><li><p><strong><code>&amp;</code></strong> ：将命令放入后台运行</p><ul><li><p><code>&amp;</code> 使整个命令在后台执行，终端会立即返回提示符，允许用户继续执行其他命令。</p></li><li><p>结合 <code>nohup</code>，这确保进程不仅在后台运行，而且在终端关闭后也不会终止。</p></li></ul></li></ul><p><strong>关闭后台进程</strong></p><pre><code class="highlight bash"><span class="comment"># 查找进程</span>ps aux | grep kubectl输出示例：user     12345  0.1  0.2 123456 7890 ?  S    04:00   0:00 kubectl port-forward pod/nginx 8080:80<span class="comment"># 杀死进程</span><span class="built_in">kill</span> -9 &lt;PID&gt;</code></pre><h1 id="三、案例实操"><a href="#三、案例实操" class="headerlink" title="三、案例实操"></a>三、案例实操</h1><h2 id="1-创建-Pod"><a href="#1-创建-Pod" class="headerlink" title="1. 创建 Pod"></a>1. 创建 Pod</h2><pre><code class="highlight bash"><span class="comment"># 创建一个nginx deployment</span>$ kubectl create deployment nginx-deployment --image=nginx:1.29.0 --replicas=3<span class="comment"># 查看Deployment</span>$ kubectl get deployment -o wideNAME               READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTORnginx-deployment   2/3     3            2           14s   nginx        nginx:1.29.0   app=nginx-deployment<span class="comment"># 查看Pod</span>$ kubectl get pods -o wideNAME                               READY   STATUS         RESTARTS   AGE    IP               NODE         NOMINATED NODE   READINESS GATESnginx-deployment-95cff5589-5jldt   1/1     Running        0          108s   171.20.58.206    k8s-node02   &lt;none&gt;           &lt;none&gt;nginx-deployment-95cff5589-b7klr   1/1     Running        0          108s   171.20.85.206    k8s-node01   &lt;none&gt;           &lt;none&gt;nginx-deployment-95cff5589-jctfz   0/1     ErrImagePull   0          108s   171.20.135.129   k8s-node03   &lt;none&gt;           &lt;none&gt;</code></pre><h2 id="2-本地访问pod"><a href="#2-本地访问pod" class="headerlink" title="2. 本地访问pod"></a>2. 本地访问pod</h2><pre><code class="highlight bash"><span class="comment"># 本地访问 Pod 正常</span>$ curl http://171.20.58.206:80&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="3-使用端口转发"><a href="#3-使用端口转发" class="headerlink" title="3. 使用端口转发"></a>3. 使用端口转发</h2><p><strong>仅本地访问</strong></p><pre><code class="highlight bash"><span class="comment"># 前台运行端口转发，此时转发的地址默认是 127.0.0.1，仅本地可以访问</span>$ kubectl port-forward deployment/nginx-deployment 30080:80 -n defaultForwarding from 127.0.0.1:30080 -&gt; 80Forwarding from [::1]:30080 -&gt; 80<span class="comment"># 新开终端，通过转发的端口 30080 访问 pod</span>$ curl 127.0.0.1:30080&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><p><strong>不限制访问IP</strong></p><pre><code class="highlight bash"><span class="comment"># 前台运行端口转发，所有IP可以访问</span>$ kubectl port-forward deployment/nginx-deployment 30080:80 -n default --address=0.0.0.0Forwarding from 0.0.0.0:30080 -&gt; 80</code></pre><p>浏览器，通过转发端口访问 nginx</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-120031.png" alt="浏览器通过转发端口访问"></p><h1 id="四、故障排查与最佳实践"><a href="#四、故障排查与最佳实践" class="headerlink" title="四、故障排查与最佳实践"></a>四、故障排查与最佳实践</h1><h2 id="1-常见错误解决方案"><a href="#1-常见错误解决方案" class="headerlink" title="1. 常见错误解决方案"></a>1. 常见错误解决方案</h2><table><thead><tr><th><strong>错误现象</strong></th><th><strong>可能原因</strong></th><th><strong>解决方案</strong></th></tr></thead><tbody><tr><td><code>unable to do port forwarding: pod not found</code></td><td>Pod未启动</td><td>检查Pod状态：<code>kubectl describe pod/[name]</code></td></tr><tr><td><code>error: listen tcp 127.0.0.1:8080: bind: address already in use</code></td><td>端口冲突</td><td>更换端口或杀死占用进程：<code>lsof -i :8080</code></td></tr><tr><td><code>error: timed out waiting for the condition</code></td><td>Pod启动超时</td><td>增加超时参数：<code>--pod-running-timeout=5m</code></td></tr></tbody></table><h2 id="2-性能优化技巧"><a href="#2-性能优化技巧" class="headerlink" title="2. 性能优化技巧"></a>2. 性能优化技巧</h2><p><strong>批量转发：同时转发多个相关端口</strong></p><pre><code class="highlight bash">kubectl port-forward deployment/nginx-deployment 80:80 443:443</code></pre><p><strong>保持连接：使用工具自动重连</strong></p><pre><code class="highlight bash"><span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span> kubectl port-forward svc/redis 6379:6379; <span class="keyword">done</span></code></pre><p><strong>网络诊断：开启详细日志</strong></p><pre><code class="highlight bash">kubectl port-forward -v=9 pod/nginx 8080:80</code></pre><p><strong>参考链接</strong></p><blockquote><p><a href="https://blog.csdn.net/J56793/article/details/145400712">https://blog.csdn.net/J56793/article/details/145400712</a></p><p><a href="https://feisky.gitbooks.io/kubernetes/content/practice/portforward.html">https://feisky.gitbooks.io/kubernetes/content/practice/portforward.html</a></p><p><a href="https://www.cnblogs.com/waldron/p/17927449.html">https://www.cnblogs.com/waldron/p/17927449.html</a></p><p><a href="https://chanjarster.github.io/post/k8s/kubectl-port-forward/">https://chanjarster.github.io/post/k8s/kubectl-port-forward/</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、概述&quot;&gt;&lt;a href=&quot;#一、概述&quot; class=&quot;headerlink&quot; title=&quot;一、概述&quot;&gt;&lt;/a&gt;一、概述&lt;/h1&gt;&lt;p&gt;在 Kubernetes 集群中，所有资源都运行在私有网络空间（通常使用 CNI 插件构建 overlay 网络），这带来了</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>018-K8S-临时容器</title>
    <link href="https://georgechan95.github.io/blog/af9812e0.html"/>
    <id>https://georgechan95.github.io/blog/af9812e0.html</id>
    <published>2025-08-03T14:01:00.000Z</published>
    <updated>2025-08-05T13:24:18.989Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、了解临时容器"><a href="#一、了解临时容器" class="headerlink" title="一、了解临时容器"></a>一、了解临时容器</h1><p>临时容器：一种特殊的容器，该容器在现有 Pod 中临时运行，以便完成用户发起的操作，例如故障排查。 你会使用临时容器来检查服务，而不是用它来构建应用程序</p><p>Pods 是 Kubernetes 应用程序的基本构建块。由于 pod 是一次性且可替换的，因此一旦 Pod 创建，就无法将容器加入到 Pod 中。取而代之的是，通常使用 Deployments 以受控的方式来删除并替换 Pod。</p><p>有时有必要检查现有 Pod 的状态，例如，对于难以复现的故障进行排查。在这些场景中，可以在现有 Pod 中运行临时容器来检查其状态并运行任意命令。</p><h2 id="1-什么是临时容器？"><a href="#1-什么是临时容器？" class="headerlink" title="1.  什么是临时容器？"></a>1.  什么是临时容器？</h2><p>临时容器与其他容器的不同之处在于，它们缺少对资源或执行的保证，并且永远不会自动重启，因此不适用于构建应用程序。临时容器使用与常规容器相同的 <code>ContainerSpec</code> 段进行描述，但许多字段是不相容且不允许的。</p><ul><li>临时容器没有端口配置，因此像 <code>ports</code>，<code>livenessProbe</code>，<code>readinessProbe</code> 这样的字段是不允许的。</li><li>Pod 资源分配是不可变的，因此 <code>resources</code> 配置是不允许的。</li></ul><p>临时容器是使用 API 中的一种特殊的 <code>ephemeralcontainers</code> 处理器进行创建的， 而不是直接添加到 <code>pod.spec</code> 段，因此无法使用 kubectl edit 来添加一个临时容器。与常规容器一样，将临时容器添加到 Pod 后，将不能更改或删除临时容器</p><h2 id="2-临时容器的用途"><a href="#2-临时容器的用途" class="headerlink" title="2. 临时容器的用途"></a>2. 临时容器的用途</h2><p>当由于容器崩溃或容器镜像不包含调试工具而导致 kubectl exec 无用时， 临时容器对于交互式故障排查很有用。尤其是，Distroless 镜像 允许用户部署最小的容器镜像，从而减少攻击面并减少故障和漏洞的暴露。 由于 distroless 镜像不包含 Shell 或任何的调试工具，因此很难单独使用 kubectl exec 命令进行故障排查。使用临时容器时，启用 进程名字空间共享 很有帮助，可以查看其他容器中的进程</p><p><a href="https://github.com/GoogleContainerTools/distroless">https://github.com/GoogleContainerTools/distroless</a></p><h1 id="二、使用临时容器"><a href="#二、使用临时容器" class="headerlink" title="二、使用临时容器"></a>二、使用临时容器</h1><h2 id="1-给运行中的-Pod-增加临时容器"><a href="#1-给运行中的-Pod-增加临时容器" class="headerlink" title="1. 给运行中的 Pod 增加临时容器"></a>1. 给运行中的 Pod 增加临时容器</h2><p>使用 <code>kubectl debug</code> 命令来给正在运行中的 Pod 增加一个临时容器</p><pre><code class="highlight bash"><span class="comment"># 1.启动一个普通的Pod</span>kubectl run demo --image=nginx:1.29.0 --restart=Never<span class="comment"># 2.给运行中的Pod demo 增加临时容器（不创建新的pod，仅调试运行中的pod）</span>kubectl debug -it demo --image=yauritux/busybox-curl:latest --target=demo --image-pull-policy=IfNotPresent</code></pre><p><strong>命令解析</strong></p><ul><li><p><code>kubectl debug</code> 是 Kubernetes 提供的一个调试工具，用于诊断 Pod 的问题</p></li><li><p><code>-it</code> 表示以交互模式（interactive 和 terminal）运行，允许用户进入调试容器的终端。</p></li><li><p><code>demo</code> 指定了要调试的 Pod 的名称</p></li><li><p><code>yauritux/busybox-curl:latest</code> 指定调试容器使用的镜像，这是带 curl 工具的 busybox</p></li><li><p><code>--target=demo</code> 指定调试的目标是 demo Pod</p></li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/05/20250805-171442.png" alt="创建临时容器"></p><p><strong>查看POD</strong></p><pre><code class="highlight bash"><span class="comment"># 增加临时容器，-it会自动进入pod</span>[root@k8s-master01 ~]$ kubectl debug -it demo --image=yauritux/busybox-curl:latest --target=demo --image-pull-policy=IfNotPresentTargeting container <span class="string">&quot;demo&quot;</span>. If you don<span class="string">&#x27;t see processes from this container it may be because the container runtime doesn&#x27;</span>t support this feature.Defaulting debug container name to debugger-rq9mr.If you don<span class="string">&#x27;t see a command prompt, try pressing enter.</span><span class="string"></span><span class="string"></span><span class="string"># 在pod 内 访问 nginx</span><span class="string">/home # curl localhost</span><span class="string">&lt;!DOCTYPE html&gt;</span><span class="string">&lt;html&gt;</span><span class="string">&lt;body&gt;</span><span class="string">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span><span class="string">&lt;/body&gt;</span><span class="string">&lt;/html&gt;</span><span class="string"></span><span class="string"></span><span class="string"># 新起一个终端，查看 Pod， READY 1/1 可以看出 Pod 内部只有一个容器</span><span class="string">$ kubectl get pods -o wide</span><span class="string">NAME   READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><span class="string">demo   1/1     Running   0          99m   171.20.85.201   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><span class="string"></span><span class="string"></span><span class="string"># 查看 Pod 详情，里面就有临时容器</span><span class="string">$ kubectl get pod demo -o yaml</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">......</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">  # 主容器</span><span class="string">  - image: nginx:1.29.0</span><span class="string">    imagePullPolicy: IfNotPresent</span><span class="string">    ......</span><span class="string">  dnsPolicy: ClusterFirst</span><span class="string">  enableServiceLinks: true</span><span class="string">  ephemeralContainers:</span><span class="string">  - image: yauritux/busybox-curl:latest</span><span class="string">    imagePullPolicy: IfNotPresent</span><span class="string">    name: debugger-4rrx4</span><span class="string">    ......</span><span class="string">  nodeName: k8s-node01</span><span class="string">  preemptionPolicy: PreemptLowerPriority</span><span class="string">  priority: 0</span><span class="string">  restartPolicy: Never</span><span class="string">  ......</span><span class="string">status:</span><span class="string">  conditions:</span><span class="string">  ......</span><span class="string">  ephemeralContainerStatuses:</span><span class="string">  - containerID: docker://ea0f00240984545badc309b3f23617b924200ad9851f979dfdf83d559ad669e2</span><span class="string">    image: yauritux/busybox-curl:latest</span><span class="string">    imageID: docker://sha256:cda3fcfbc75d9cd4624dc403fd5f54f2e49b84874e4cf8d01a56f0e2db6c72e6</span><span class="string">    lastState: &#123;&#125;</span><span class="string">    name: debugger-4rrx4</span><span class="string">    ready: false</span><span class="string">    restartCount: 0</span><span class="string">    state:</span><span class="string">      running:</span><span class="string">        startedAt: &quot;2025-08-05T11:15:27Z&quot;</span><span class="string">  hostIP: 10.20.1.140</span><span class="string">  hostIPs:</span><span class="string">  - ip: 10.20.1.140</span><span class="string">  phase: Running</span><span class="string">  podIP: 171.20.85.202</span><span class="string">  podIPs:</span><span class="string">  - ip: 171.20.85.202</span><span class="string">  qosClass: BestEffort</span><span class="string">  startTime: &quot;2025-08-05T11:14:39Z&quot;</span></code></pre><p><strong>总结：这种方式调试 pod 不会创建新的 pod，只在原有的 pod 中增加临时容器。</strong></p><h2 id="2-通过-Pod-副本调试"><a href="#2-通过-Pod-副本调试" class="headerlink" title="2. 通过 Pod 副本调试"></a>2. 通过 Pod 副本调试</h2><p><strong>在添加新的容器时创建 Pod 副本</strong></p><p>当应用程序正在运行但其表现不符合预期时，你会希望在 Pod 中添加额外的调试工具， 这时添加新容器是很有用的</p><pre><code class="highlight bash"><span class="comment"># 1.启动一个普通的Pod</span>$ kubectl run myapp --image=busybox:1.31.1 --restart=Never -- <span class="built_in">sleep</span> 1d<span class="comment"># 2.建立 myapp 的一个名为 myapp-debug 的副本， 新增了一个用于调试的 Ubuntu 容器</span>$ kubectl debug myapp -it --image=ubuntu:20.04 --share-processes --copy-to=myapp-debug<span class="comment"># 如果你没有使用 --container 指定新的容器名，kubectl debug 会自动生成的。</span><span class="comment"># 默认情况下，-i 标志使 kubectl debug 附加到新容器上。 你可以通过指定 --attach=false 来防止这种情况</span><span class="comment"># --share-processes 允许在此 Pod 中的其他容器中查看该容器的进程。 </span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/05/20250805-204430.png" alt="添加新的容器时创建 Pod 副本"></p><p><strong>查看POD</strong></p><pre><code class="highlight bash"><span class="comment"># 创建新的pod myapp-debug, 使用镜像 ubuntu:20.04, 与 myapp 共享进程</span>$ kubectl debug myapp -it --image=ubuntu:20.04 --share-processes --copy-to=myapp-debugDefaulting debug container name to debugger-8hjcc.If you don<span class="string">&#x27;t see a command prompt, try pressing enter.</span><span class="string"># 查看进程</span><span class="string">root@myapp-debug:/# ps aux  </span><span class="string">USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><span class="string">65535          1  0.0  0.0   1028     4 ?        Ss   12:41   0:00 /pause</span><span class="string">root           7  0.0  0.0   1296     4 ?        Ss   12:42   0:00 sleep 1d # busybox 进程</span><span class="string">root          13  0.0  0.0   4116  3532 pts/0    Ss   12:42   0:00 /bin/bash</span><span class="string">root          24  0.0  0.0   5900  2852 pts/0    R+   12:50   0:00 ps aux</span><span class="string"></span><span class="string"></span><span class="string"># 新起shell终端，查看Pod</span><span class="string"># 新建了一个 pod myapp-debug, READY 2/2 表示里面有两个容器（busybox 和 ubuntu）</span><span class="string">$ kubectl get pods -o wide</span><span class="string">NAME          READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES</span><span class="string">myapp         1/1     Running   0          3m50s   171.20.85.203   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><span class="string">myapp-debug   2/2     Running   0          3m35s   171.20.85.204   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><span class="string"></span><span class="string"></span><span class="string"># 查看新建的 Pod 详情</span><span class="string">$ kubectl get pod myapp-debug -o yaml</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">  ......</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">  # 第一个容器 busybox</span><span class="string">  - args:</span><span class="string">    - sleep</span><span class="string">    - 1d</span><span class="string">    image: busybox:1.31.1</span><span class="string">    imagePullPolicy: IfNotPresent</span><span class="string">    name: myapp</span><span class="string">    resources: &#123;&#125;</span><span class="string">    terminationMessagePath: /dev/termination-log</span><span class="string">    terminationMessagePolicy: File</span><span class="string">    volumeMounts:</span><span class="string">    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount</span><span class="string">      name: kube-api-access-hmf9b</span><span class="string">      readOnly: true</span><span class="string">  # 第二个容器 ubuntu</span><span class="string">  - image: ubuntu:20.04</span><span class="string">    imagePullPolicy: IfNotPresent</span><span class="string">    name: debugger-8hjcc</span><span class="string">    resources: &#123;&#125;</span><span class="string">    stdin: true</span><span class="string">    terminationMessagePath: /dev/termination-log</span><span class="string">    terminationMessagePolicy: File</span><span class="string">    tty: true</span><span class="string">    volumeMounts:</span><span class="string">    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount</span><span class="string">      name: kube-api-access-hmf9b</span><span class="string">      readOnly: true</span><span class="string">  dnsPolicy: ClusterFirst</span><span class="string">  containerStatuses:</span><span class="string">  ......</span></code></pre><h2 id="3-在改变-Pod-命令时创建-Pod-副本"><a href="#3-在改变-Pod-命令时创建-Pod-副本" class="headerlink" title="3. 在改变 Pod 命令时创建 Pod 副本"></a>3. 在改变 Pod 命令时创建 Pod 副本</h2><p>有时更改容器的命令很有用，例如添加调试标志或因为应用崩溃</p><pre><code class="highlight bash"><span class="comment"># 1.启动pod，执行命令 false</span><span class="comment"># false 是 busybox 默认命令之一，执行后容器会退出</span>$ kubectl run --image=busybox:1.31.1 myapp -- <span class="literal">false</span><span class="comment"># 2.使用 kubectl debug 命令创建该 Pod 的一个副本， 在该副本中命令改变为交互式 shell：</span>$ kubectl debug myapp -it --copy-to=myapp-debug --container=myapp -- sh<span class="comment"># 要更改指定容器的命令，你必须用 --container 命令指定容器的名字， 否则 kubectl debug 将建立一个新的容器运行你指定的命令</span><span class="comment"># 默认情况下，标志 -i 使 kubectl debug 附加到容器。 你可通过指定 --attach=false 来防止这种情况</span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/05/20250805-211440.png" alt="改变 Pod 命令时创建 Pod 副本"></p><p><strong>查看Pod</strong></p><pre><code class="highlight bash"><span class="comment"># 使用 kubectl debug 命令创建该 Pod 的一个副本， 在该副本中命令为 sh</span>$ kubectl debug myapp -it --copy-to=myapp-debug --container=myapp -- shIf you don<span class="string">&#x27;t see a command prompt, try pressing enter.</span><span class="string"># 查看进程</span><span class="string">/ # ps aux</span><span class="string">PID   USER     TIME  COMMAND</span><span class="string">    1 root      0:00 sh # 此为pod执行的进程命令：sh</span><span class="string">    7 root      0:00 ps aux</span><span class="string">/ # </span><span class="string"></span><span class="string"></span><span class="string"># 新起shell终端，查看Pod,myapp-debug 为复制的pod，修改了shell，成功运行。</span><span class="string">$ kubectl get pods -o wide</span><span class="string">NAME          READY   STATUS             RESTARTS      AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><span class="string">myapp         0/1     CrashLoopBackOff   2 (16s ago)   41s   171.20.85.205   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><span class="string">myapp-debug   1/1     Running            0             22s   171.20.58.205   k8s-node02   &lt;none&gt;           &lt;none&gt;</span></code></pre><h2 id="4-在同一个节点上创建-pod-进行调试"><a href="#4-在同一个节点上创建-pod-进行调试" class="headerlink" title="4. 在同一个节点上创建 pod 进行调试"></a>4. 在同一个节点上创建 pod 进行调试</h2><p>如果这些方法都不起作用，你可以找到运行 Pod 的节点，然后创建一个 Pod 运行在该节点上。 你可以通过 <code>kubectl debug</code> 在节点上创建一个交互式 Shell</p><pre><code class="highlight bash">kubectl debug node/mynode -it --image=ubuntu<span class="comment"># kubectl debug 基于节点的名字自动生成新的 Pod 的名字</span><span class="comment"># 节点的根文件系统会被挂载在 /host。</span><span class="comment"># 新的调试容器运行在主机 IPC 名字空间、主机网络名字空间以及主机 PID 名字空间内， Pod 没有特权，因此读取某些进程信息可能会失败，并且 chroot /host 也会失败</span><span class="comment"># 如果你需要一个特权 Pod，需要手动创建</span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/05/20250805-212317.png" alt="在同一个节点上创建 pod 进行调试"></p><p><strong>测试</strong></p><pre><code class="highlight bash"><span class="comment"># 会在 Kubernetes 集群的 k8s-node01 节点上启动一个临时的调试容器，使用 ubuntu:20.04 镜像</span>$ kubectl debug node/k8s-node01 -it --image=ubuntu:20.04Creating debugging pod node-debugger-k8s-node01-5zhwj with container debugger on node k8s-node01.If you don<span class="string">&#x27;t see a command prompt, try pressing enter.</span><span class="string"></span><span class="string"># 查看物理机内存</span><span class="string">root@k8s-node01:/# free -m</span><span class="string">              total        used        free      shared  buff/cache   available</span><span class="string">Mem:           7671         864        4760         154        2047        6381</span><span class="string">Swap:             0           0           0</span><span class="string"></span><span class="string"># 查看目录机目录</span><span class="string">root@k8s-node01:/# cd /host/opt/images/</span><span class="string">root@k8s-node01:/host/opt/images# ls</span><span class="string">all-in-one.tar       defaultbackend-amd64-1.5.tar </span></code></pre><p><strong>常用场景</strong></p><p><code>kubectl debug node/</code> 常用于以下场景：</p><ul><li><strong>检查节点文件系统</strong>：<ul><li>检查节点上的日志文件（比如 &#x2F;var&#x2F;log）。</li><li>查看 Kubernetes 相关文件（比如 &#x2F;etc&#x2F;kubernetes 或 &#x2F;var&#x2F;lib&#x2F;kubelet）。</li></ul></li><li><strong>诊断网络问题</strong>：<ul><li>检查节点的网络配置（比如 ifconfig、ip addr）。</li><li>测试网络连通性（比如 ping、curl）。</li></ul></li><li><strong>检查进程或资源</strong>：<ul><li>查看节点上的运行进程（ps aux）。</li><li>检查磁盘使用情况（df -h）或内存状态（free -m）。</li></ul></li><li><strong>调试 Kubernetes 组件</strong>：<ul><li>检查 kubelet、containerd 或 Docker 的状态。</li><li>验证节点的 CRI（容器运行时接口）配置。</li></ul></li></ul><p><strong>参考链接</strong></p><blockquote><p><a href="http://kubernetes.hankbook.cn/pods/ephemeral-containers.html">http://kubernetes.hankbook.cn/pods/ephemeral-containers.html</a></p><p><a href="https://cloudmessage.top/archives/k8s-lin-shi-rong-qi-guan-fang-diao-shi-ji-zhi">https://cloudmessage.top/archives/k8s-lin-shi-rong-qi-guan-fang-diao-shi-ji-zhi</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、了解临时容器&quot;&gt;&lt;a href=&quot;#一、了解临时容器&quot; class=&quot;headerlink&quot; title=&quot;一、了解临时容器&quot;&gt;&lt;/a&gt;一、了解临时容器&lt;/h1&gt;&lt;p&gt;临时容器：一种特殊的容器，该容器在现有 Pod 中临时运行，以便完成用户发起的操作，例如故障</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>017-K8S-网络策略NetworkPolicy</title>
    <link href="https://georgechan95.github.io/blog/99657768.html"/>
    <id>https://georgechan95.github.io/blog/99657768.html</id>
    <published>2025-07-28T13:33:00.000Z</published>
    <updated>2025-08-05T06:53:48.526Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、网络策略-NetworkPolicy-简介"><a href="#一、网络策略-NetworkPolicy-简介" class="headerlink" title="一、网络策略(NetworkPolicy)简介"></a>一、网络策略(NetworkPolicy)简介</h1><h2 id="1-概念解析"><a href="#1-概念解析" class="headerlink" title="1. 概念解析"></a>1. 概念解析</h2><p>如果你希望在 IP 地址或端口层面（OSI 第 3 层或第 4 层）控制网络流量， 则你可以考虑为集群中特定应用使用 Kubernetes 网络策略（NetworkPolicy）</p><p>Kubernetes 网络策略(NetworkPolicy)是一个资源对象，主要用于定义Pod之间的流量控制，其实现了一个基于标签的选择器模型，允许管理员通过网络策略规则限制对Pod的流量访问。</p><p>网络策略(NetworkPolicy)是以Pod为单位进行授权的，因此，只有当所有的Pod都通过了网络策略时，才能够接收到其他Pod发送的流量。这种方式极大提高了网络的安全性。</p><p>Pod 是通过如下三个标识符的组合来辩识是否可以通讯：</p><ul><li>其他被允许的 Pods（例外：Pod 无法阻塞对自身的访问）</li><li>被允许的名字空间</li><li>IP 组块 [ ipBlock ]（例外：与 Pod 运行所在的节点的通信总是被允许的， 无论 Pod 或节点的 IP 地址）</li></ul><h2 id="2-前置条件"><a href="#2-前置条件" class="headerlink" title="2. 前置条件"></a>2. 前置条件</h2><p>网络策略通过 网络插件 来实现。 要使用网络策略，你必须使用支持 NetworkPolicy 的网络解决方案。 创建一个 NetworkPolicy 资源对象而没有控制器来使它生效的话，是没有任何作用的</p><ul><li>Calico （当前使用此网络插件）</li><li>Antrea</li><li>Cilium</li><li>Kube-router</li><li>Romana</li><li>Weave 网络</li></ul><h2 id="3-隔离默认策略"><a href="#3-隔离默认策略" class="headerlink" title="3. 隔离默认策略"></a>3. 隔离默认策略</h2><ul><li>出口的隔离<ul><li>默认情况下，一个 Pod 的出口是非隔离的，即所有外向连接都是被允许的</li></ul></li><li>入口的隔离<ul><li>默认情况下，一个 Pod 对入口是非隔离的，即所有入站连接都是被允许的</li></ul></li></ul><h2 id="4-特别说明"><a href="#4-特别说明" class="headerlink" title="4. 特别说明"></a>4. 特别说明</h2><p>网络策略是相加的，所以不会产生冲突。如果策略适用于 Pod 某一特定方向的流量， Pod 在对应方向所允许的连接是适用的网络策略所允许的集合。 因此，评估的顺序不影响策略的结果。</p><p>要允许从源 Pod 到目的 Pod 的连接，源 Pod 的出口策略和目的 Pod 的入口策略都需要允许连接。 如果任何一方不允许连接，建立连接将会失败。</p><h1 id="二、创建-pod-和-svc"><a href="#二、创建-pod-和-svc" class="headerlink" title="二、创建 pod 和 svc"></a>二、创建 pod 和 svc</h1><p>基于 Nginx 镜像创建Pod，用于后续实验测试。</p><pre><code class="highlight bash"><span class="comment"># 创建工作空间，演示的Pod创建在此工作空间内</span>$ kubectl create ns network<span class="comment"># 切换工作空间到 network， 切换后续所有操作默认再次工作空间内（此操作非必须）</span>$ kubectl config set-context --current --namespace=network<span class="comment"># 查看当前所在工作空间</span>$ kubectl config view --minify<span class="comment"># 创建两个nginx pod用于测试使用</span>kubectl run web1 --image=nginx:1.29.0 --labels=app=web,<span class="built_in">env</span>=prod --image-pull-policy=IfNotPresent -n network --expose --port 80kubectl run web2 --image=nginx:1.29.0 --labels=app=web,<span class="built_in">env</span>=<span class="built_in">test</span> --image-pull-policy=IfNotPresent -n network --expose --port 80<span class="comment"># 查看Pod</span>$ kubectl get pods -o wide -n networkNAME   READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESweb1   1/1     Running   0          65s   171.20.85.196   k8s-node01   &lt;none&gt;           &lt;none&gt;web2   1/1     Running   0          30s   171.20.85.197   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 Service</span>$ kubectl get svc -o wide -n networkNAME   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE   SELECTORweb1   ClusterIP   10.110.3.181    &lt;none&gt;        80/TCP    70s   app=web,<span class="built_in">env</span>=prodweb2   ClusterIP   10.100.184.48   &lt;none&gt;        80/TCP    35s   app=web,<span class="built_in">env</span>=<span class="built_in">test</span><span class="comment"># 修改nginx的首页文件index.html，用于区分两个pod</span>$ kubectl <span class="built_in">exec</span> -it web1 -- sh -c <span class="string">&quot;echo web1 &gt; /usr/share/nginx/html/index.html&quot;</span>$ kubectl <span class="built_in">exec</span> -it web2 -- sh -c <span class="string">&quot;echo web2 &gt; /usr/share/nginx/html/index.html&quot;</span><span class="comment"># 访问Pod，测试首页是否改变</span>$ curl 171.20.85.196web1$ curl 171.20.85.197web2</code></pre><h1 id="三、未添加网络策略，访问Pod"><a href="#三、未添加网络策略，访问Pod" class="headerlink" title="三、未添加网络策略，访问Pod"></a>三、未添加网络策略，访问Pod</h1><p>查看当前命名空间下的 NetworkPolicy，当前没有网络策略。</p><pre><code class="highlight bash">$ kubectl get networkpolicy -n networkNo resources found <span class="keyword">in</span> network namespace.</code></pre><p>新建一个临时 Pod， 用于访问 web1 和 web2。在没有网络策略的情况下，临时 Pod 可以访问 web1 和 web2</p><pre><code class="highlight bash"><span class="comment"># 创建临时Pod，推出容器时自动删除该pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=<span class="built_in">env</span>=prod --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh<span class="comment"># 由于临时 Pod 与 web1 不在同一个 名称空间，因此访问Service需要添加 名称空间</span>/home <span class="comment"># curl web1.network</span>web1/home <span class="comment"># curl web1.network.svc.cluster.local</span>web1/home <span class="comment"># curl web2.network</span>web2</code></pre><p>修改Nginx Pod 的 Service 类型为 LoadBalance ，让浏览器可以访问 Nginx。</p><pre><code class="highlight bash"><span class="comment"># 修改 Service 类型</span>$ kubectl patch svc web1 -n network -p <span class="string">&#x27;&#123;&quot;spec&quot;:&#123;&quot;type&quot;:&quot;LoadBalancer&quot;&#125;&#125;&#x27;</span>$ kubectl patch svc web2 -n network -p <span class="string">&#x27;&#123;&quot;spec&quot;:&#123;&quot;type&quot;:&quot;LoadBalancer&quot;&#125;&#125;&#x27;</span><span class="comment"># 查看 Service</span>$ kubectl get svc -o wideNAME   TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTORweb1   LoadBalancer   10.110.3.181    &lt;pending&gt;     80:31193/TCP   30m   app=web,<span class="built_in">env</span>=prodweb2   LoadBalancer   10.100.184.48   &lt;pending&gt;     80:30826/TCP   29m   app=web,<span class="built_in">env</span>=<span class="built_in">test</span></code></pre><p>测试浏览器访问 Service</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/31/20250731-142153.png" alt="访问web1"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/31/20250731-142217.png" alt="访问web2"></p><p><strong>结论：未添加网络策略，外界可以随意访问 pod。这是不安全的。</strong></p><h1 id="四、Pod-添加网络策略"><a href="#四、Pod-添加网络策略" class="headerlink" title="四、Pod 添加网络策略"></a>四、Pod 添加网络策略</h1><p>网络策略 NetworkPolicy 是一种以应用为中心的结构，允许你设置如何允许 Pod 与网络上的各类网络“实体” 通信。 说白了，网络策略本质上就是建立一个防火墙，控制入站和出站流量。</p><p>网络策略通过 CNI(Containernetworking Interface) 网络插件来实现。 要使用网络策略，你必须使用支持 NetworkPolicy 的网络解决方案。 创建一个 NetworkPolicy 资源对象而没有控制器来使它生效的话，是没有任何作用的。此kubernetes集群使用的网络插件是Calico，Calico支持网络策略，大家熟知的Flannel是不支持网络策略的。</p><p>Pod 有两种隔离: 出口的隔离和入口的隔离，即出站（Egress）和入站（Ingress）。</p><p><strong>为了允许两个 Pods 之间的网络数据流，源端 Pod 上的出站（Egress）规则和 目标端 Pod 上的入站（Ingress）规则都需要允许该流量。 如果源端的出站（Egress）规则或目标端的入站（Ingress）规则拒绝该流量， 则流量将被拒绝。</strong></p><h2 id="1-入站网络策略"><a href="#1-入站网络策略" class="headerlink" title="1. 入站网络策略"></a>1. 入站网络策略</h2><p>下面的 yaml 文件是一个标准的网络策略：</p><ul><li>PodSelector : 指定被此 NetworkPolicy 影响的 Pod。此处匹配 Label 为 “role&#x3D;db” 的 Pod。</li><li>PolicyTypes: 规定所需的网络策略类型。此处包括 Ingress 和 Egress。</li><li>Ingress: 定义允许从指定来源（IP 地址范围、命名空间 或 Pod）和端口接收流量的规则。此处仅允许 TCP 流量访问端口 6379。</li><li>Egress: 定义允许发送到指定目标（IP 地址范围）和端口的流量的规则。此处仅允许 TCP 流量发送到端口 5978 的目标 IP 地址范围为 10.0.0.0&#x2F;24</li></ul><p>资源清单：<code>networkpolicy-example.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span>    <span class="comment"># networking.k8s.io/v1 是 NetworkPolicy 资源的标准 API</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span>                <span class="comment"># 资源所在名称空间，该 NetworkPolicy 只能作用于该名称空间下的Pod</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">role:</span> <span class="string">db</span>                      <span class="comment"># 当前网络策略作用于 network 名称空间下，具有标签 role: db 的 Pod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>                         <span class="comment"># 控制入站流量</span>  <span class="bullet">-</span> <span class="string">Egress</span>                          <span class="comment"># 控制出站流量</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">ipBlock:</span>            <span class="comment">#cidr: 0.0.0.0/0表示允许所有客户端可以访问</span>            <span class="attr">cidr:</span> <span class="number">172.17</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span>     <span class="comment"># 允许来自 IP 范围 172.17.0.0 到 172.17.255.255 的流量</span>            <span class="attr">except:</span>              <span class="bullet">-</span> <span class="number">172.17</span><span class="number">.1</span><span class="number">.0</span><span class="string">/24</span>       <span class="comment"># 排除子范围 172.17.1.0 到 172.17.1.255，即这部分 IP 被禁止。</span>        <span class="bullet">-</span> <span class="attr">namespaceSelector:</span>            <span class="attr">matchLabels:</span>              <span class="attr">project:</span> <span class="string">myproject</span>    <span class="comment"># 允许来自具有标签 project=myproject 的命名空间中的所有 Pod 发起的流量。</span>        <span class="bullet">-</span> <span class="attr">podSelector:</span>            <span class="attr">matchLabels:</span>              <span class="attr">role:</span> <span class="string">frontend</span>        <span class="comment"># 允许 【同一命名】 空间内具有标签 role=frontend 的 Pod 发起的流量。</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">6379</span>                <span class="comment"># 只允许上述来源访问 role=db Pod 的 TCP 6379 端口</span>  <span class="attr">egress:</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">ipBlock:</span>            <span class="attr">cidr:</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">/24</span>       <span class="comment"># 允许 role=db Pod 访问 IP 范围 10.0.0.0 到 10.0.0.255 的目标</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">5978</span>                <span class="comment"># 只允许访问目标的 TCP 5978 端口</span></code></pre><h3 id="1-1-入站网络策略-pod标签选择器"><a href="#1-1-入站网络策略-pod标签选择器" class="headerlink" title="1.1 入站网络策略-pod标签选择器"></a>1.1 入站网络策略-pod标签选择器</h3><p><strong>查看 pod 标签</strong></p><pre><code class="highlight bash"><span class="comment"># 查看pod</span>$ kubectl get pod -o wide -n network --show-labelsNAME   READY   STATUS    RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATES   LABELSweb1   1/1     Running   0          128m   171.20.85.196   k8s-node01   &lt;none&gt;           &lt;none&gt;            app=web,<span class="built_in">env</span>=prodweb2   1/1     Running   0          128m   171.20.85.197   k8s-node01   &lt;none&gt;           &lt;none&gt;            app=web,<span class="built_in">env</span>=<span class="built_in">test</span><span class="comment"># 查看Service</span>$ kubectl get svc -n network -o wideNAME   TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE    SELECTORweb1   LoadBalancer   10.110.3.181    &lt;pending&gt;     80:31193/TCP   146m   app=web,<span class="built_in">env</span>=prodweb2   LoadBalancer   10.100.184.48   &lt;pending&gt;     80:30826/TCP   146m   app=web,<span class="built_in">env</span>=<span class="built_in">test</span></code></pre><h4 id="1-1-1-案例1"><a href="#1-1-1-案例1" class="headerlink" title="1.1.1 案例1"></a>1.1.1 案例1</h4><p>编写网络策略规则，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，仅仅允许当前命名空间(network)内标签为 role&#x3D;podclient 的 pod可以访问 web1的80端口(TCP)。</p><p><strong>资源清单：</strong><code>network-policy-pod-selector.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">podSelector:</span>        <span class="comment"># 仅当前命名空间内，具有标签 role: podclient 的 Pod 可以访问 web1</span>            <span class="attr">matchLabels:</span>              <span class="attr">role:</span> <span class="string">podclient</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">80</span>            <span class="comment"># web1 只开放80端口</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-pod-selector.yaml<span class="comment"># 查看 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       28s</code></pre><p>**测试1：使用浏览器访问 web1 **</p><p>浏览器没有Pod标签，因此访问 web1 失败</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/31/20250731-162205.png" alt="浏览器访问 web1"></p><p><strong>测试2：没有 role&#x3D;podclient 标签的临时pod，访问web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod，不添加标签</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --image-pull-policy=IfNotPresent -n network -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 Service 失败，因为没有 role=podclient 标签，无法通过网络策略</span>/home <span class="comment"># curl web1</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out<span class="comment"># 访问 web2 Service 成功，因为 web2 无网络策略限制</span>/home <span class="comment"># curl web2</span>web2</code></pre><p><strong>测试3：具有 role&#x3D;podclient 标签，但Pod不在 network 名称空间，访问web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 default 名称空间创建临时Pod，添加标签 role=podclient</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=role=podclient --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 Service 失败，虽然pod1具有标签 role=podclient，但由于网络策略限制了与web1必须在同一名称空间，因此访问失败</span>/home <span class="comment"># curl web1.network</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out<span class="comment"># 访问 web2 Service 成功，因为 web2 无网络策略限制</span>/home <span class="comment"># curl web2.network</span>web2</code></pre><p><strong>测试4：具有 role&#x3D;podclient 标签，且Pod在 network 名称空间</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod，添加标签 role=podclient</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=role=podclient --image-pull-policy=IfNotPresent -n network -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 成功</span>/home <span class="comment"># curl web1</span>web1</code></pre><h3 id="1-2-入站网络策略-namespaceSelector命名空间选择器"><a href="#1-2-入站网络策略-namespaceSelector命名空间选择器" class="headerlink" title="1.2 入站网络策略-namespaceSelector命名空间选择器"></a>1.2 入站网络策略-namespaceSelector命名空间选择器</h3><p><strong>查看命名空间的标签</strong></p><pre><code class="highlight bash">$ kubectl get ns --show-labelsNAME              STATUS   AGE     LABELSdefault           Active   4d      kubernetes.io/metadata.name=defaultkube-node-lease   Active   4d      kubernetes.io/metadata.name=kube-node-leasekube-public       Active   4d      kubernetes.io/metadata.name=kube-publickube-system       Active   4d      kubernetes.io/metadata.name=kube-systemnetwork           Active   177m    kubernetes.io/metadata.name=network</code></pre><p><strong>给命名空间打标签</strong></p><p>给 default 命名空间打 name&#x3D;default 标签</p><pre><code class="highlight bash"><span class="comment"># 给 default 命名空间打标签</span>$ kubectl label ns default name=defaultnamespace/default labeled<span class="comment"># 查看命名空间标签</span>$ kubectl get ns --show-labels | grep defaultdefault           Active   4d      kubernetes.io/metadata.name=default,name=default</code></pre><h4 id="1-2-1-案例1"><a href="#1-2-1-案例1" class="headerlink" title="1.2.1 案例1"></a>1.2.1 案例1</h4><p>定义通过 namespaceSelector 命名空间来控制的入站网络策略，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，允许标签为 <code>name: default</code> 的 namespace下的所有 pod 可以访问 web1 的 80 端口(TCP)。</p><p><strong>资源清单：</strong> <code>network-policy-namespace-selector.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">namespaceSelector:</span>            <span class="attr">matchLabels:</span>      <span class="comment"># 具有 name=default 标签的命名空间下所有的pod，可以访问web1的80端口</span>              <span class="attr">name:</span> <span class="string">default</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">80</span>            <span class="comment"># web1 只开放80端口</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-namespace-selector.yaml<span class="comment"># 查看 network 命名空间下的 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       113s</code></pre><p><strong>测试1：在没有 name&#x3D;default 标签的名称空间下创建Pod，访问 web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --image-pull-policy=IfNotPresent -n network -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 失败，network 命名空间没有 name=default 标签，无法通过网络策略</span>/home <span class="comment"># curl web1</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out<span class="comment"># 访问 web2 成功，web2 无网络策略限制</span>/home <span class="comment"># curl web2</span>web2</code></pre><p><strong>测试2： 在具有 name&#x3D;default 标签的名称空间下创建Pod，访问 web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 成功，default 命名空间具有 name=default 标签，通过了网络策略</span>/home <span class="comment"># curl web1.network</span>web1</code></pre><h4 id="1-2-2-案例2"><a href="#1-2-2-案例2" class="headerlink" title="1.2.2 案例2"></a>1.2.2 案例2</h4><p>修改网络策略，设置只允许 default 命名空间里的特定 pod 能访问，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，允许标签为name: default 的 namespace下的标签为 role: podclient 的 pod 可以访问 web1 的80端口(TCP)。</p><p><strong>资源清单：</strong><code>network-policy-namespace-pod-selector.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">namespaceSelector:</span>            <span class="attr">matchLabels:</span>      <span class="comment"># 具有 name=default 标签的命名空间下的pod</span>              <span class="attr">name:</span> <span class="string">default</span>          <span class="attr">podSelector:</span>            <span class="attr">matchLabels:</span>      <span class="comment"># 在具有 name=default 标签的命名空间基础上，还需要具有 role=podclient 标签的pod</span>              <span class="attr">role:</span> <span class="string">podclient</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">80</span>            <span class="comment"># web1 只开放80端口</span></code></pre><p><strong>注意：</strong> podSelector 前面没有 - ，因此 namespaceSelector 和 podSelector 这两个条件是 <strong>并集关系</strong>，需要同时满足。</p><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-namespace-pod-selector.yaml networkpolicy.networking.k8s.io/my-network-policy created<span class="comment"># 查看 network 名称空间下的 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       11s</code></pre><p><strong>测试1：在没有 name&#x3D;default 标签的名称空间下，创建具有标签 role&#x3D;podclient 的 Pod，访问 web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=role=podclient --image-pull-policy=IfNotPresent -n network -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 失败，network 命名空间没有 name=default 标签，无法通过网络策略</span>/home <span class="comment"># curl web1</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out<span class="comment"># 访问 web2 成功，web2 无网络策略限制</span>/home <span class="comment"># curl web2</span>web2</code></pre><p><strong>测试2： 在具有 name&#x3D;default 标签的名称空间下，创建没有标签 role&#x3D;podclient 的 Pod，访问 web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 失败，虽然 default 命名空间具有 name=default 标签，但 pod1 没有标签 role=podclient，无法通过了网络策略</span>/home <span class="comment"># curl web1.network</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out</code></pre><p><strong>测试3： 在具有 name&#x3D;default 标签的名称空间下，创建具有标签 role&#x3D;podclient 的 Pod，访问 web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --image-pull-policy=IfNotPresent --labels=role=podclient -n default -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 成功，pod1 同时满足了在具有 name=default 标签的 default 命名空间下，且具有标签 role=podclient，通过了网络策略</span>/home <span class="comment"># curl web1.network</span>web1</code></pre><h3 id="1-3-入站网络策略-IP地址控制"><a href="#1-3-入站网络策略-IP地址控制" class="headerlink" title="1.3 入站网络策略-IP地址控制"></a>1.3 入站网络策略-IP地址控制</h3><h4 id="1-3-1-案例1"><a href="#1-3-1-案例1" class="headerlink" title="1.3.1 案例1"></a>1.3.1 案例1</h4><p>定义通过IP地址来控制的入站网络策略，如下网络策略的功能为：把名为my-network-policy的网络策略应用到 web1，只允许 171.20.10.0&#x2F;24 这个网段的pod可以访问 web1 的80端口(TCP)。</p><p><strong>资源清单：</strong><code>network-policy-ipBlock.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">ipBlock:</span>            <span class="attr">cidr:</span> <span class="number">171.20</span><span class="number">.10</span><span class="number">.0</span><span class="string">/24</span>    <span class="comment"># 只允许 171.20.10.0/24 这个网段的pod可以访问 web1 的80端口(TCP)</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">80</span>            <span class="comment"># web1 只开放80端口</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-ipBlock.yaml<span class="comment"># 查看 network 名称空间的 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       35s</code></pre><p><strong>测试1：创建Pod，固定IP地址，访问web1</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 Pod Ip地址范围</span>$ calicoctl get ippoolNAME                  CIDR            SELECTOR   default-ipv4-ippool   171.20.0.0/16   all()<span class="comment"># 创建 171.20.10.0/24 这个网段的pod</span>$ kubectl create -f - &lt;&lt;<span class="string">EOF</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">  labels:</span><span class="string">    app: pod</span><span class="string">  annotations:</span><span class="string">    &quot;cni.projectcalico.org/ipAddrs&quot;: &quot;[\&quot;171.20.10.27\&quot;]&quot;</span><span class="string">  name: pod1</span><span class="string">  namespace: default</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">    - image: nginx:1.29.0</span><span class="string">      imagePullPolicy: IfNotPresent</span><span class="string">      name: pod1</span><span class="string">EOF</span><span class="comment"># 创建非 171.20.10.0/24 这个网段的pod</span>$ kubectl create -f - &lt;&lt;<span class="string">EOF</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">  labels:</span><span class="string">    app: pod</span><span class="string">  annotations:</span><span class="string">    &quot;cni.projectcalico.org/ipAddrs&quot;: &quot;[\&quot;171.20.20.57\&quot;]&quot;</span><span class="string">  name: pod2</span><span class="string">  namespace: default</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">    - image: nginx:1.29.0</span><span class="string">      imagePullPolicy: IfNotPresent</span><span class="string">      name: pod2</span><span class="string">EOF</span><span class="comment"># 查看创建 Pod 的IP地址</span>$ kubectl get pods -o wide -n defaultNAME   READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATESpod1   1/1     Running   0          24s   171.20.10.27   k8s-node02   &lt;none&gt;           &lt;none&gt;pod2   1/1     Running   0          16s   171.20.20.57   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># pod1 访问 web1 成功，pod1 ip 为 171.20.10.27，在 171.20.10.0/24 网段内，可通过网络策略</span>$ kubectl <span class="built_in">exec</span> -it pod1 -n default -- sh -c <span class="string">&quot;curl web1.network&quot;</span>web1<span class="comment"># pod2 访问 web1 失败，pod2 ip 为 171.20.20.57，不在 171.20.10.0/24 网段内，无法通过网络策略</span>$ kubectl <span class="built_in">exec</span> -it pod2 -n default -- sh -c <span class="string">&quot;curl web1.network&quot;</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out</code></pre><h4 id="1-3-2-案例2"><a href="#1-3-2-案例2" class="headerlink" title="1.3.2 案例2"></a>1.3.2 案例2</h4><p>修改网络策略，设置只允许 171.20.10.0&#x2F;24 这个网段的进行访问，但是 171.20.10.10 不可以访问，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，只允许 171.20.10.0&#x2F;24 这个网段的 pod 可以访问 web1 的80端口(TCP)，但是 171.20.10.10 这个IP的 pod 不可以访问 web1 的80端口(TCP)</p><p><strong>资源清单：</strong> <code>network-policy-ipBlock-except.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">ipBlock:</span>            <span class="attr">cidr:</span> <span class="number">171.20</span><span class="number">.10</span><span class="number">.0</span><span class="string">/24</span>    <span class="comment"># 只允许 171.20.10.0/24 这个网段的pod可以访问 web1 的80端口(TCP)、</span>            <span class="attr">except:</span>              <span class="bullet">-</span> <span class="number">171.20</span><span class="number">.10</span><span class="number">.10</span><span class="string">/32</span>        <span class="comment"># 排除单个ip</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">80</span>            <span class="comment"># web1 只开放80端口</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-ipBlock-except.yaml<span class="comment"># 查询 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       42s</code></pre><p><strong>测试1：创建Pod，固定IP地址，访问web1</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 Pod Ip地址范围</span>$ calicoctl get ippoolNAME                  CIDR            SELECTOR   default-ipv4-ippool   171.20.0.0/16   all()<span class="comment"># 创建 171.20.10.0/24 这个网段的pod</span>$ kubectl create -f - &lt;&lt;<span class="string">EOF</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">  labels:</span><span class="string">    app: pod</span><span class="string">  annotations:</span><span class="string">    &quot;cni.projectcalico.org/ipAddrs&quot;: &quot;[\&quot;171.20.10.27\&quot;]&quot;</span><span class="string">  name: pod1</span><span class="string">  namespace: default</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">    - image: nginx:1.29.0</span><span class="string">      imagePullPolicy: IfNotPresent</span><span class="string">      name: pod1</span><span class="string">EOF</span><span class="comment"># 创建非 171.20.10.0/24 这个网段的pod</span>$ kubectl create -f - &lt;&lt;<span class="string">EOF</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">  labels:</span><span class="string">    app: pod</span><span class="string">  annotations:</span><span class="string">    &quot;cni.projectcalico.org/ipAddrs&quot;: &quot;[\&quot;171.20.10.10\&quot;]&quot;</span><span class="string">  name: pod2</span><span class="string">  namespace: default</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">    - image: nginx:1.29.0</span><span class="string">      imagePullPolicy: IfNotPresent</span><span class="string">      name: pod2</span><span class="string">EOF</span><span class="comment"># 查看创建 Pod 的IP地址</span>$ kubectl get pods -o wide -n defaultNAME   READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATESpod1   1/1     Running   0          24s   171.20.10.27   k8s-node02   &lt;none&gt;           &lt;none&gt;pod2   1/1     Running   0          16s   171.20.20.10   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># pod1 访问 web1 成功，pod1 ip 为 171.20.10.27，在 171.20.10.0/24 网段内，可通过网络策略</span>$ kubectl <span class="built_in">exec</span> -it pod1 -n default -- sh -c <span class="string">&quot;curl web1.network&quot;</span>web1<span class="comment"># pod2 访问 web1 失败，pod2 ip 为 171.20.10.10，被 NetworkPolicy except 排除在外，无法通过网络策略</span>$ kubectl <span class="built_in">exec</span> -it pod2 -n default -- sh -c <span class="string">&quot;curl web1.network&quot;</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out</code></pre><h2 id="2-出站网络策略"><a href="#2-出站网络策略" class="headerlink" title="2. 出站网络策略"></a>2. 出站网络策略</h2><p><strong>创建 web3</strong></p><pre><code class="highlight bash"><span class="comment"># 创建web3用于测试使用</span>$ kubectl run web3 --image=nginx:1.29.0 --labels=app=web,<span class="built_in">env</span>=dev --image-pull-policy=IfNotPresent -n network --expose --port 80<span class="comment"># 查看Pod</span>$ $ kubectl get pods -o wide -n networkNAME   READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESweb1   1/1     Running   0          6h26m   171.20.85.196   k8s-node01   &lt;none&gt;           &lt;none&gt;web2   1/1     Running   0          6h26m   171.20.85.197   k8s-node01   &lt;none&gt;           &lt;none&gt;web3   1/1     Running   0          5s      171.20.10.0     k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 Service</span>$ $ kubectl get pods -o wide -n network --show-labelsNAME   READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES   LABELSweb1   1/1     Running   0          6h27m   171.20.85.196   k8s-node01   &lt;none&gt;           &lt;none&gt;            app=web,<span class="built_in">env</span>=prodweb2   1/1     Running   0          6h26m   171.20.85.197   k8s-node01   &lt;none&gt;           &lt;none&gt;            app=web,<span class="built_in">env</span>=<span class="built_in">test</span>web3   1/1     Running   0          35s     171.20.10.0     k8s-node02   &lt;none&gt;           &lt;none&gt;            app=web,<span class="built_in">env</span>=dev<span class="comment"># 修改nginx的首页文件index.html，用于区分pod</span>$ kubectl <span class="built_in">exec</span> -it web3 -- sh -c <span class="string">&quot;echo web3 &gt; /usr/share/nginx/html/index.html&quot;</span><span class="comment"># 访问Pod，测试首页是否改变</span>$ curl 171.20.10.0web3</code></pre><h3 id="2-1-出站网络策略-pod标签选择器"><a href="#2-1-出站网络策略-pod标签选择器" class="headerlink" title="2.1 出站网络策略-pod标签选择器"></a>2.1 出站网络策略-pod标签选择器</h3><h4 id="2-1-1-案例1"><a href="#2-1-1-案例1" class="headerlink" title="2.1.1 案例1"></a>2.1.1 案例1</h4><p>定义通过 pod 标签选择器来控制的出站网络策略，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，web1只能访问当前命名空间标签为 test: pod3的pod的80端口(TCP)</p><p><strong>资源清单：</strong><code>network-policy-pod-selector.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span>  <span class="attr">egress:</span>                   <span class="comment"># 出站网络策略</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">podSelector:</span>            <span class="attr">matchLabels:</span>    <span class="comment"># 只能访问标签为 env: dev 的Pod</span>              <span class="attr">env:</span> <span class="string">dev</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>     <span class="comment"># 只能访问端口 80，且协议为TCP</span>          <span class="attr">port:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-pod-selector.yaml<span class="comment"># 查询 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       85s</code></pre><p><strong>测试出站网络策略</strong></p><p>进入 web1 , 访问 web2 和 web3</p><pre><code class="highlight bash"><span class="comment"># web1 直接访问 web3 的ip是成功的，因为满足的出站策略</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl 171.20.10.0&quot;</span>web3<span class="comment"># web1 直接访问 web2 的ip失败了，因为 出站策略里，限制了访问的pod，不包含 pod2</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl 171.20.85.197&quot;</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out<span class="comment"># web1 访问 web3 svc 失败，原因为：如果想通过svc访问 pod,pod 需要去kube-dns那里查询 svc 的IP地址，但是现在 web1 没有 kube-dns 的访问权限</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl web3.network&quot;</span>curl: (6) Could not resolve host: web3.network</code></pre><p>web1 访问 web3 svc 失败，原因为：如果想通过svc访问 pod,pod 需要去kube-dns那里查询 svc 的IP地址，但是现在 web1 没有 kube-dns 的访问权限</p><h3 id="2-2-出站网络策略-pod标签选择器和-namespaceSelector-命名空间选择器"><a href="#2-2-出站网络策略-pod标签选择器和-namespaceSelector-命名空间选择器" class="headerlink" title="2.2 出站网络策略-pod标签选择器和 namespaceSelector 命名空间选择器"></a>2.2 出站网络策略-pod标签选择器和 namespaceSelector 命名空间选择器</h3><h4 id="2-2-1-案例1"><a href="#2-2-1-案例1" class="headerlink" title="2.2.1 案例1"></a>2.2.1 案例1</h4><p>修改网络策略，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，web1 能访问 kube-system 命名空间下的所有 pod 和当前命名空间下标签为 env: dev 的 pod，访问端口为 80 和 53。</p><p><strong>查看命名空间 kube-system 的标签</strong></p><pre><code class="highlight bash">$ kubectl get ns --show-labels | grep kube-systemkube-system       Active   4d4h    kubernetes.io/metadata.name=kube-system</code></pre><p><strong>资源清单：</strong> <code>network-policy-pod-namespace.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span>  <span class="attr">egress:</span>                   <span class="comment"># 出站网络策略</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">namespaceSelector:</span>      <span class="comment"># 标签为 kubernetes.io/metadata.name: kube-system 下的所有pod，web1 都能访问</span>            <span class="attr">matchLabels:</span>              <span class="attr">kubernetes.io/metadata.name:</span> <span class="string">kube-system</span>        <span class="bullet">-</span> <span class="attr">podSelector:</span>            <span class="attr">matchLabels:</span>          <span class="comment"># 并且能访问标签为 env: dev 的Pod（web3）</span>              <span class="attr">env:</span> <span class="string">dev</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>           <span class="comment"># 能访问端口 80，且协议为TCP</span>          <span class="attr">port:</span> <span class="number">80</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">UDP</span>           <span class="comment"># 能访问端口 53，且协议为UDP</span>          <span class="attr">port:</span> <span class="number">53</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-pod-namespace.yaml<span class="comment"># 查询 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       85s</code></pre><p><strong>测试出站网络策略</strong></p><p>进入 web1 , 访问 web2 和 web3</p><pre><code class="highlight bash"><span class="comment"># web1 直接访问 web3 svc成功，因为满足的出站策略，且 web1 具有 kube-dns 访问权限，因此可以解析域名</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl web3.network&quot;</span>web3<span class="comment"># web1 直接访问 web2 的ip失败了，因为 出站策略里，限制了访问的pod，不包含 pod2</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl web2.network&quot;</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out</code></pre><h3 id="2-3-优化出站网络策略"><a href="#2-3-优化出站网络策略" class="headerlink" title="2.3 优化出站网络策略"></a>2.3 优化出站网络策略</h3><p>上面的案例存在问题：web1可以访问标签为 <code>env: dev</code> 的 pod 的 80端口 和 53端口, 而 web3 只有 80端口，53 端口属于 kube-system 名称空间下的 coredns pod.</p><h4 id="2-3-1-案例1"><a href="#2-3-1-案例1" class="headerlink" title="2.3.1 案例1"></a>2.3.1 案例1</h4><p>修改网络策略，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，web1能访问 kube-system 命名空间下的所有 pod 的53端口，web1能访问当前命名空间下标签为 <code>env: dev</code> 的pod的80端口。</p><p><strong>资源清单：</strong><code>network-policy-pod-namespace2.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span>  <span class="attr">egress:</span>                   <span class="comment"># 出站网络策略</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">namespaceSelector:</span>      <span class="comment"># 标签为 kubernetes.io/metadata.name: kube-system 下的所有 pod，web1 都能访问</span>            <span class="attr">matchLabels:</span>              <span class="attr">kubernetes.io/metadata.name:</span> <span class="string">kube-system</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">UDP</span>           <span class="comment"># 能访问端口 53，且协议为UDP</span>          <span class="attr">port:</span> <span class="number">53</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">podSelector:</span>            <span class="attr">matchLabels:</span> <span class="comment"># 并且能访问标签为 env: dev 的Pod（web3）</span>              <span class="attr">env:</span> <span class="string">dev</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="comment"># 能访问端口 80，且协议为TCP</span>          <span class="attr">port:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-pod-namespace2.yaml$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       26m</code></pre><p><strong>测试出站网络策略</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 coredns Pod</span>$ kubectl get pods -n kube-system -o wide | grep corednscoredns-5f98f8d567-72vc7                   1/1     Running   0               4d16h   171.20.58.192   k8s-node02     &lt;none&gt;           &lt;none&gt;coredns-5f98f8d567-cv75d                   1/1     Running   0               4d16h   171.20.85.192   k8s-node01     &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 coredns Service</span>$ kubectl get service -n kube-system -o wide | grep kube-dnskube-dns       ClusterIP   10.96.0.10       &lt;none&gt;        53/UDP,53/TCP,9153/TCP   4d16h   k8s-app=kube-dns<span class="comment"># 测试 pod1 访问 coredns Service 53 端口，成功</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=<span class="built_in">env</span>=prod --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh/home <span class="comment"># telnet kube-dns.kube-system 53</span>Connected to kube-dns.kube-system<span class="comment"># 测试 web1 访问 web3 80 端口，成功</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl web3.network&quot;</span>web3</code></pre><h3 id="2-4-出站网络策略-指定端口范围"><a href="#2-4-出站网络策略-指定端口范围" class="headerlink" title="2.4 出站网络策略-指定端口范围"></a>2.4 出站网络策略-指定端口范围</h3><p>在Kubernetes v1.22 版本，出了个新特性，在编写 NetworkPolicy 时，你可以针对一个端口范围而不是某个固定端口。这一目的可以通过使用 endPort 字段来实现，如下例所示：</p><p><strong>资源清单：</strong> <code>network-policy-ipBlock.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">multi-port-egress</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span>  <span class="attr">egress:</span>                   <span class="comment"># 出站网络策略</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">ipBlock:</span>            <span class="attr">cidr:</span> <span class="number">171.20</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span>    <span class="comment"># 只允许 171.20.0.0/16 这个网段的pod可以访问</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">53</span>                  <span class="comment"># 可以访问 53-80 之间的端口</span>          <span class="attr">endPort:</span> <span class="number">80</span></code></pre><p>上面的规则允许名字空间 network 中所有带有标签 env: prod 的 Pod 使用 TCP 协议 与 171.20.0.0&#x2F;16 范围内的 IP 通信，只要目标端口介于 53 和 80 之间就可以。</p><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f network-policy-ipBlock.yaml</code></pre><p><strong>测试出站网络策略</strong></p><pre><code class="highlight bash"><span class="comment"># 测试 pod1 访问 coredns Service 53 端口，成功</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=<span class="built_in">env</span>=prod --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh/home <span class="comment"># telnet kube-dns.kube-system 53</span>Connected to kube-dns.kube-system<span class="comment"># 测试 web1 访问 web3 80 端口，成功</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl web3.network&quot;</span>web3</code></pre><p><strong>使用endPort字段时存在以下限制</strong>：</p><ul><li>作为一种 Beta 阶段的特性，<strong>端口范围设定默认是被启用的</strong>。要在整个集群 范围内禁止使用 endPort 字段，你需要为 API 服务器设置 -feature-gates&#x3D;NetworkPolicyEndPort&#x3D;false,… 以禁用 NetworkPolicyEndPort 特性。</li><li>endPort 字段必须等于或者大于 port 字段的值。</li><li>port，endPort 两个字段的设置值都只能是数字。</li></ul><p><strong>注意</strong>：你的集群所使用的 CNI 网络插件 必须支持在 NetworkPolicy 规约中使用 endPort 字段。 如果你的网络插件 不支持 endPort 字段，而你指定了一个包含 endPort 字段的 NetworkPolicy， 策略只对单个 port 字段生效。</p><h1 id="五、默认网络策略"><a href="#五、默认网络策略" class="headerlink" title="五、默认网络策略"></a>五、默认网络策略</h1><h2 id="1-默认拒绝所有入站流量"><a href="#1-默认拒绝所有入站流量" class="headerlink" title="1. 默认拒绝所有入站流量"></a>1. 默认拒绝所有入站流量</h2><p>可以通过创建<strong>选择所有容器</strong>但不允许任何进入这些容器的入站流量的 NetworkPolicy 来为命名空间创建 “default” 隔离策略。这样可以确保即使容器没有选择其他任何 NetworkPolicy，也仍然可以被隔离。 此策略不会更改默认的出口隔离行为。</p><p>默认拒绝所有入站流量，网络策略如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">default-deny-ingress</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span> &#123;&#125;<span class="comment"># 空选择器（&#123;&#125;）表示匹配default命名空间下所有Pod</span>  <span class="attr">policyTypes:</span><span class="comment"># 定义入站流量</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="comment"># 没有 ingress 规则，意味着拒绝所有入站流量</span></code></pre><h2 id="2-默认允许所有入站流量"><a href="#2-默认允许所有入站流量" class="headerlink" title="2. 默认允许所有入站流量"></a>2. 默认允许所有入站流量</h2><p>如果要允许所有流量进入某个命名空间中的所有 Pod（即使添加了导致某些 Pod 被视为 “隔离”的策略），则可以创建一个策略来明确允许该名字空间中的所有流量。</p><p>默认允许所有入站流量，网络策略如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">allow-all-ingress</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span> &#123;&#125;<span class="comment"># 空选择器（&#123;&#125;）表示匹配default命名空间下所有Pod</span>  <span class="attr">ingress:</span>  <span class="bullet">-</span> &#123;&#125;<span class="comment"># 空规则（&#123;&#125;）表示允许所有入站流量。</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span><span class="comment"># 控制入站流量（从外部或集群内其他 Pod 访问目标 Pod）</span></code></pre><h2 id="3-默认拒绝所有出站流量"><a href="#3-默认拒绝所有出站流量" class="headerlink" title="3. 默认拒绝所有出站流量"></a>3. 默认拒绝所有出站流量</h2><p>可以通过创建选择所有容器但不允许来自这些容器的任何出站流量的 NetworkPolicy 来为名字空间创建 “default” egress 隔离策略。<br>此策略可以确保即使没有被其他任何 NetworkPolicy 选择的 Pod 也不会被允许流出流量。 此策略不会更改默认的入站流量隔离行为。</p><p>默认拒绝所有出站流量，网络策略如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">default-deny-egress</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span> &#123;&#125;<span class="comment"># 空选择器（&#123;&#125;）表示匹配default命名空间下所有Pod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span><span class="comment"># 控制出站流量（Pod 访问其他 Pod、Service 或外部网络）</span>  <span class="comment"># 没有 egress 规则，意味着拒绝所有出站流量</span></code></pre><h2 id="4-默认允许所有出站流量"><a href="#4-默认允许所有出站流量" class="headerlink" title="4. 默认允许所有出站流量"></a>4. 默认允许所有出站流量</h2><p>如果要允许来自名字空间中所有 Pod 的所有流量（即使添加了导致某些 Pod 被视为“隔离”的策略）， 则可以创建一个策略，该策略明确允许该名字空间中的所有出站流量。</p><p>默认允许所有出站流量，网络策略如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">allow-all-egress</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span> &#123;&#125;<span class="comment"># 空选择器（&#123;&#125;）表示匹配default命名空间下所有Pod</span>  <span class="attr">egress:</span>  <span class="bullet">-</span> &#123;&#125;<span class="comment"># 空规则（&#123;&#125;）表示允许所有出站流量。</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span><span class="comment"># 控制出站流量（Pod 访问其他 Pod、Service 或外部网络）</span></code></pre><h2 id="5-默认拒绝所有入口和所有出站流量"><a href="#5-默认拒绝所有入口和所有出站流量" class="headerlink" title="5. 默认拒绝所有入口和所有出站流量"></a>5. 默认拒绝所有入口和所有出站流量</h2><p>你可以为名字空间创建“默认”策略，以通过在该名字空间中创建以下 NetworkPolicy 来阻止所有入站和出站流量。<br>此策略可以确保即使没有被其他任何 NetworkPolicy 选择的 Pod 也不会被 允许入站或出站流量。</p><p>默认拒绝所有入口和所有出站流量，网络策略如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">default-deny-all</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span> &#123;&#125;<span class="comment"># 空选择器（&#123;&#125;）表示匹配default命名空间下所有Pod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span><span class="comment"># 控制入站流量（从外部或集群内其他 Pod 访问目标 Pod）</span>  <span class="bullet">-</span> <span class="string">Egress</span><span class="comment"># 控制出站流量（Pod 访问其他 Pod、Service 或外部网络）</span>  <span class="comment"># 没有 egress 规则，意味着拒绝所有出站流量</span>  <span class="comment"># 没有 ingress 规则，意味着拒绝所有入站流量</span></code></pre><h1 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h1><p>网络策略(NetworkPolicy)是 Kubernetes 集群中一个非常重要的安全控制措施，可以帮助我们保护 Kubernetes集群的网络安全。</p><p>通过网络策略(NetworkPolicy)示例，展示了如何使用网络策略( NetworkPolicy )来限制Pod之间的流量访问。</p><p>在 Kubernetes 集群中使用网络策略( NetworkPolicy )可以提高网络的安全性，但也需要注意以下几点：</p><ul><li>应该避免创建过于复杂的网络策略(NetworkPolicy)，因为这可能会导致网络通信中断或延迟。</li><li>在创建网络策略(NetworkPolicy)前，需要确保已仔细检查其规则，并确认这些规则符合预期。</li><li>当修改或删除一个网络策略(NetworkPolicy)时，需要确保所有Pod都能够正常通信。</li></ul><p><strong>通过网络策略（至少目前还）无法完成的工作</strong></p><ul><li>强制集群内部流量经过某公用网关（这种场景最好通过服务网格或其他代理来实现）</li><li>与 TLS 相关的场景（考虑使用服务网格或者 Ingress 控制器）</li><li>特定于节点的策略（你可以使用 CIDR 来表达这一需求不过你无法使用节点在 Kubernetes 中的其他标识信息来辩识目标节点）；</li><li>基于名字来选择服务来选择目标 Pod 或名字空间</li><li>基于名字来选择服务来选择目标 Pod 或名字空间</li><li>实现适用于所有名字空间或 Pods 的默认策略（某些第三方 Kubernetes 发行版本或项目可以做到这点）；</li><li>高级的策略查询或者可达性相关工具；</li><li>生成网络安全事件日志的能力（例如，被阻塞或接收的连接请求）；</li><li>显式地拒绝策略的能力（目前，NetworkPolicy 的模型默认采用拒绝操作， 其唯一的能力是添加允许策略）；</li><li>禁止本地回路或指向宿主的网络流量（Pod 目前无法阻塞 localhost 访问， 它们也无法禁止来自所在节点的访问请求）；</li></ul><p><strong>参考链接</strong></p><blockquote><p><a href="https://www.cnblogs.com/renshengdezheli/p/17479289.html">https://www.cnblogs.com/renshengdezheli/p/17479289.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、网络策略-NetworkPolicy-简介&quot;&gt;&lt;a href=&quot;#一、网络策略-NetworkPolicy-简介&quot; class=&quot;headerlink&quot; title=&quot;一、网络策略(NetworkPolicy)简介&quot;&gt;&lt;/a&gt;一、网络策略(NetworkPol</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Pod" scheme="https://georgechan95.github.io/tags/Pod/"/>
    
  </entry>
  
  <entry>
    <title>016-K8S-固定Pod IP地址，基于Calico插件</title>
    <link href="https://georgechan95.github.io/blog/c9536d9e.html"/>
    <id>https://georgechan95.github.io/blog/c9536d9e.html</id>
    <published>2025-07-26T05:35:00.000Z</published>
    <updated>2025-07-28T03:11:50.871Z</updated>
    
    <content type="html"><![CDATA[<p><strong>需求：</strong></p><p>在某种情况下，创建 Pod 时主动给它分配IP地址，并要求即使重启Pod IP地址也不变。</p><p>这里演示 Calico 网络插件环境中，如何给 Pod 分配固定的 IP 地址。</p><h1 id="一、确认环境"><a href="#一、确认环境" class="headerlink" title="一、确认环境"></a>一、确认环境</h1><h2 id="1-修改-calico-配置文件"><a href="#1-修改-calico-配置文件" class="headerlink" title="1. 修改 calico 配置文件"></a>1. 修改 calico 配置文件</h2><p>修改配置文件 <code>vim /etc/cni/net.d/10-calico.conflist</code> ，将 <code>ipam</code> 类型修改为 <code>calico-ipam</code></p><pre><code class="highlight bash">$ vim /etc/cni/net.d/10-calico.conflist<span class="string">&quot;ipam&quot;</span>: &#123;          <span class="string">&quot;type&quot;</span>: <span class="string">&quot;calico-ipam&quot;</span>&#125;</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/26/20250726-135737.png" alt="image-20250726135707385"></p><h2 id="2-安装-calicoctl-工具"><a href="#2-安装-calicoctl-工具" class="headerlink" title="2. 安装 calicoctl 工具"></a>2. 安装 calicoctl 工具</h2><p>二进制方式安装 calicoctl 工具，版本号选择 Calico 相同的版本，这里是 3.26.3</p><h3 id="2-1-安装-calicoctl"><a href="#2-1-安装-calicoctl" class="headerlink" title="2.1 安装 calicoctl"></a>2.1 安装 calicoctl</h3><pre><code class="highlight bash"><span class="comment"># 下载 calicoctl 二进制包</span>$ wget https://github.com/projectcalico/calico/releases/download/v3.26.3/calicoctl-linux-amd64<span class="comment"># 将二进制包放到指定目录</span>$ <span class="built_in">mv</span> calicoctl-linux-amd64 /usr/local/bin/calicoctl<span class="comment"># 授权</span>$ <span class="built_in">chmod</span> +x /usr/local/bin/calicoctl<span class="comment"># 永久设置环境变量</span>calicoctl get ippool --show-ip-allocations</code></pre><h3 id="2-2-配置-calicoctl"><a href="#2-2-配置-calicoctl" class="headerlink" title="2.2 配置 calicoctl"></a>2.2 配置 calicoctl</h3><p>calicoctl 通过读写 calico 的数据存储系统（ datastore ）进行查看或者其他各类管理操作，通常，它需要提供认证信息经由相应的数据存储完成认证。在使用<code>Kubernetes API</code> 数据存储时，需要使用类似 kubectl 的认证信息完成认证。它可以通过环境变量声明的 <code>DATASTORE_TYPE</code> 和 <code>KUBECONFIG</code> 接入集群，例如以下命令格式运行 calicoctl ：</p><pre><code class="highlight bash"><span class="comment"># 临时设置环境变量</span>$ <span class="built_in">export</span> CALICO_DATASTORE_TYPE=kubernetes$ <span class="built_in">export</span> CALICO_KUBECONFIG=~/.kube/config<span class="comment"># 测试</span>$ calicoctl get nodesNAME           k8s-master01   k8s-node01     k8s-node02     k8s-node03</code></pre><p>也可以直接将认证信息等保存于配置文件中，calicoctl 默认加载 <code>/etc/calico/calicoctl.cfg</code> 配置文件读取配置信息，如下所示：</p><pre><code class="highlight bash">$ <span class="built_in">cat</span> /etc/calico/calicoctl.cfg apiVersion: projectcalico.org/v3kind: CalicoAPIConfigmetadata:spec:  datastoreType: <span class="string">&quot;kubernetes&quot;</span>         kubeconfig: <span class="string">&quot;/root/.kube/config&quot;</span></code></pre><h2 id="3-查看-calico-的-CIDR-地址范围"><a href="#3-查看-calico-的-CIDR-地址范围" class="headerlink" title="3. 查看 calico 的 CIDR 地址范围"></a>3. 查看 calico 的 CIDR 地址范围</h2><pre><code class="highlight bash">$ calicoctl get ippoolNAME                  CIDR            SELECTOR   default-ipv4-ippool   171.20.0.0/16   all()</code></pre><h2 id="4-创建-Pod"><a href="#4-创建-Pod" class="headerlink" title="4. 创建 Pod"></a>4. 创建 Pod</h2><p>在 CIDR 地址范围内给 Pod 设定一个 IP 地址。</p><p>IP 地址范围：171.20.0.0 到 171.20.255.255</p><h3 id="4-1-直接创建-Pod"><a href="#4-1-直接创建-Pod" class="headerlink" title="4.1 直接创建 Pod"></a>4.1 直接创建 Pod</h3><p>资源清单1：<code>fixed-pod-ip.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">annotations:</span>    <span class="comment"># 设置Pod固定ip地址</span>    <span class="attr">&quot;cni.projectcalico.org/ipAddrs&quot;:</span> <span class="string">&quot;[\&quot;171.20.45.27\&quot;]&quot;</span>  <span class="attr">name:</span> <span class="string">fixed-pod-ip</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">name:</span> <span class="string">nginx</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f fixed-pod-ip.yaml<span class="comment"># 查看Pod，使用的正是分配的IP</span>$ kubectl get pods -o wide -wNAME           READY   STATUS              RESTARTS   AGE   IP       NODE         NOMINATED NODE   READINESS GATESfixed-pod-ip   0/1     ContainerCreating   0          3s    &lt;none&gt;   k8s-node01   &lt;none&gt;           &lt;none&gt;fixed-pod-ip   0/1     ContainerCreating   0          3s    &lt;none&gt;   k8s-node01   &lt;none&gt;           &lt;none&gt;fixed-pod-ip   1/1     Running             0          7s    171.20.45.27   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 测试访问</span>$ curl http://171.20.45.27:80&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="4-2-创建-Deployment"><a href="#4-2-创建-Deployment" class="headerlink" title="4.2 创建 Deployment"></a>4.2 创建 Deployment</h3><p>资源清单：<code>fixed-deploy-ip.yaml</code></p><pre><code class="highlight bash">apiVersion: apps/v1kind: Deploymentmetadata:  name: fixed-deploy-ip  labels:    app: my-deployspec:  selector:    matchLabels:      app: fixed-deploy  template:    metadata:      labels:        app: fixed-deploy      annotations:        <span class="comment"># 设置Pod固定ip地址</span>        <span class="string">&quot;cni.projectcalico.org/ipAddrs&quot;</span>: <span class="string">&quot;[\&quot;171.20.42.65\&quot;]&quot;</span>    spec:      containers:        - image: nginx:1.29.0          imagePullPolicy: IfNotPresent          name: nginx</code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f fixed-deploy-ip.yaml<span class="comment"># Pod使用Ip为手动分配的IP</span>$ kubectl get pods -o wideNAME                               READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATESfixed-deploy-ip-6fcf56c75b-tk6nb   1/1     Running   0          78s   171.20.42.65   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 删除Pod，重新生成Pod</span>$ kubectl delete pod fixed-deploy-ip-6fcf56c75b-tk6nb<span class="comment"># 新的Pod ip 依旧是手动分配的IP</span>$ kubectl get pods -o wide -wNAME                               READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATESfixed-deploy-ip-6fcf56c75b-25pxm   1/1     Running   0          11s   171.20.42.65   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p><strong>注意：</strong> 使用 Deployment 自动分配IP， replicas 副本数必须是1，多个Pod会存在IP冲突问题，如下：</p><pre><code class="highlight yaml"><span class="string">$</span> <span class="string">kubectl</span> <span class="string">describe</span> <span class="string">pod</span> <span class="string">fixed-deploy-ip-6fcf56c75b-cgksd</span><span class="attr">Name:</span>             <span class="string">fixed-deploy-ip-6fcf56c75b-cgksd</span><span class="attr">Namespace:</span>        <span class="string">default</span><span class="attr">Priority:</span>         <span class="number">0</span><span class="attr">Service Account:</span>  <span class="string">default</span><span class="attr">Node:</span>             <span class="string">k8s-node01/10.20.1.140</span><span class="attr">Start Time:</span>       <span class="string">Mon,</span> <span class="number">28</span> <span class="string">Jul</span> <span class="number">2025 10:59:27</span> <span class="string">+0800</span><span class="attr">Labels:</span>           <span class="string">app=fixed-deploy</span>                  <span class="string">pod-template-hash=6fcf56c75b</span><span class="attr">Annotations:      cni.projectcalico.org/ipAddrs:</span> [<span class="string">&quot;171.20.42.65&quot;</span>]                  <span class="attr">cni.projectcalico.org/podIP:</span>                   <span class="attr">cni.projectcalico.org/podIPs:</span> <span class="attr">Status:</span>           <span class="string">Pending</span><span class="attr">IP:</span>               <span class="attr">IPs:</span>              <span class="string">&lt;none&gt;</span><span class="attr">Controlled By:</span>    <span class="string">ReplicaSet/fixed-deploy-ip-6fcf56c75b</span><span class="attr">Containers:</span>  <span class="attr">nginx:</span>    <span class="attr">Container ID:</span>       <span class="attr">Image:</span>          <span class="string">nginx:1.29.0</span>    <span class="attr">Image ID:</span>           <span class="attr">Port:</span>           <span class="string">&lt;none&gt;</span>    <span class="attr">Host Port:</span>      <span class="string">&lt;none&gt;</span>    <span class="attr">State:</span>          <span class="string">Waiting</span>      <span class="attr">Reason:</span>       <span class="string">ContainerCreating</span>    <span class="attr">Ready:</span>          <span class="literal">False</span>    <span class="attr">Restart Count:</span>  <span class="number">0</span>    <span class="attr">Environment:</span>    <span class="string">&lt;none&gt;</span>    <span class="attr">Mounts:</span>      <span class="string">/var/run/secrets/kubernetes.io/serviceaccount</span> <span class="string">from</span> <span class="string">kube-api-access-dd6zw</span> <span class="string">(ro)</span><span class="attr">Conditions:</span>  <span class="string">Type</span>                        <span class="string">Status</span>  <span class="string">PodReadyToStartContainers</span>   <span class="literal">False</span>   <span class="string">Initialized</span>                 <span class="literal">True</span>   <span class="string">Ready</span>                       <span class="literal">False</span>   <span class="string">ContainersReady</span>             <span class="literal">False</span>   <span class="string">PodScheduled</span>                <span class="literal">True</span> <span class="attr">Volumes:</span>  <span class="attr">kube-api-access-dd6zw:</span>    <span class="attr">Type:</span>                    <span class="string">Projected</span> <span class="string">(a</span> <span class="string">volume</span> <span class="string">that</span> <span class="string">contains</span> <span class="string">injected</span> <span class="string">data</span> <span class="string">from</span> <span class="string">multiple</span> <span class="string">sources)</span>    <span class="attr">TokenExpirationSeconds:</span>  <span class="number">3607</span>    <span class="attr">ConfigMapName:</span>           <span class="string">kube-root-ca.crt</span>    <span class="attr">ConfigMapOptional:</span>       <span class="string">&lt;nil&gt;</span>    <span class="attr">DownwardAPI:</span>             <span class="literal">true</span><span class="attr">QoS Class:</span>                   <span class="string">BestEffort</span><span class="attr">Node-Selectors:</span>              <span class="string">&lt;none&gt;</span><span class="attr">Tolerations:</span>                 <span class="string">node.kubernetes.io/not-ready:NoExecute</span> <span class="string">op=Exists</span> <span class="string">for</span> <span class="string">300s</span>                             <span class="string">node.kubernetes.io/unreachable:NoExecute</span> <span class="string">op=Exists</span> <span class="string">for</span> <span class="string">300s</span><span class="attr">Events:</span>  <span class="string">Type</span>     <span class="string">Reason</span>                  <span class="string">Age</span>               <span class="string">From</span>               <span class="string">Message</span>  <span class="string">----</span>     <span class="string">------</span>                  <span class="string">----</span>              <span class="string">----</span>               <span class="string">-------</span>  <span class="string">Normal</span>   <span class="string">Scheduled</span>               <span class="string">28s</span>               <span class="string">default-scheduler</span>  <span class="string">Successfully</span> <span class="string">assigned</span> <span class="string">default/fixed-deploy-ip-6fcf56c75b-cgksd</span> <span class="string">to</span> <span class="string">k8s-node01</span>  <span class="attr">Warning  FailedCreatePodSandBox  24s               kubelet            Failed to create pod sandbox: rpc error:</span> <span class="string">code</span> <span class="string">=</span> <span class="string">Unknown</span> <span class="string">desc</span> <span class="string">=</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">sandbox</span> <span class="string">container</span> <span class="string">&quot;f1b3f4fc77eeca1672a1ddd935bdbda2d7a1dbd237a5be89b7422a56a315dc0a&quot;</span> <span class="string">network</span> <span class="string">for</span> <span class="string">pod</span> <span class="attr">&quot;fixed-deploy-ip-6fcf56c75b-cgksd&quot;:</span> <span class="string">networkPlugin</span> <span class="string">cni</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">pod</span> <span class="string">&quot;fixed-deploy-ip-6fcf56c75b-cgksd_default&quot;</span> <span class="attr">network:</span> <span class="string">plugin</span> <span class="string">type=&quot;calico&quot;</span> <span class="string">failed</span> <span class="string">(add):</span> <span class="attr">error getting IP from IPAM: resource already exists:</span> <span class="number">171.20</span><span class="number">.42</span><span class="number">.65</span>  <span class="attr">Warning  FailedCreatePodSandBox  20s               kubelet            Failed to create pod sandbox: rpc error:</span> <span class="string">code</span> <span class="string">=</span> <span class="string">Unknown</span> <span class="string">desc</span> <span class="string">=</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">sandbox</span> <span class="string">container</span> <span class="string">&quot;bf2d21340a820b55b1f202d2f89f68d42523859dacd1e1c9a5d757e814fc34b4&quot;</span> <span class="string">network</span> <span class="string">for</span> <span class="string">pod</span> <span class="attr">&quot;fixed-deploy-ip-6fcf56c75b-cgksd&quot;:</span> <span class="string">networkPlugin</span> <span class="string">cni</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">pod</span> <span class="string">&quot;fixed-deploy-ip-6fcf56c75b-cgksd_default&quot;</span> <span class="attr">network:</span> <span class="string">plugin</span> <span class="string">type=&quot;calico&quot;</span> <span class="string">failed</span> <span class="string">(add):</span> <span class="attr">error getting IP from IPAM: resource already exists:</span> <span class="number">171.20</span><span class="number">.42</span><span class="number">.65</span>  <span class="attr">Warning  FailedCreatePodSandBox  16s               kubelet            Failed to create pod sandbox: rpc error:</span> <span class="string">code</span> <span class="string">=</span> <span class="string">Unknown</span> <span class="string">desc</span> <span class="string">=</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">sandbox</span> <span class="string">container</span> <span class="string">&quot;230660cce4caaf260bfb2079479d8885aa19059441759246db3ef8ac5f93ba6c&quot;</span> <span class="string">network</span> <span class="string">for</span> <span class="string">pod</span> <span class="attr">&quot;fixed-deploy-ip-6fcf56c75b-cgksd&quot;:</span> <span class="string">networkPlugin</span> <span class="string">cni</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">pod</span> <span class="string">&quot;fixed-deploy-ip-6fcf56c75b-cgksd_default&quot;</span> <span class="attr">network:</span> <span class="string">plugin</span> <span class="string">type=&quot;calico&quot;</span> <span class="string">failed</span> <span class="string">(add):</span> <span class="attr">error getting IP from IPAM: resource already exists:</span> <span class="number">171.20</span><span class="number">.42</span><span class="number">.65</span>  <span class="attr">Warning  FailedCreatePodSandBox  11s               kubelet            Failed to create pod sandbox: rpc error:</span> <span class="string">code</span> <span class="string">=</span> <span class="string">Unknown</span> <span class="string">desc</span> <span class="string">=</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">sandbox</span> <span class="string">container</span> <span class="string">&quot;7b28648e2799adc7c5e73f5038279586ac36226f157349ae8054b0048953f41c&quot;</span> <span class="string">network</span> <span class="string">for</span> <span class="string">pod</span> <span class="attr">&quot;fixed-deploy-ip-6fcf56c75b-cgksd&quot;:</span> <span class="string">networkPlugin</span> <span class="string">cni</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">pod</span> <span class="string">&quot;fixed-deploy-ip-6fcf56c75b-cgksd_default&quot;</span> <span class="attr">network:</span> <span class="string">plugin</span> <span class="string">type=&quot;calico&quot;</span> <span class="string">failed</span> <span class="string">(add):</span> <span class="attr">error getting IP from IPAM: resource already exists:</span> <span class="number">171.20</span><span class="number">.42</span><span class="number">.65</span>  <span class="attr">Warning  FailedCreatePodSandBox  5s                kubelet            Failed to create pod sandbox: rpc error:</span> <span class="string">code</span> <span class="string">=</span> <span class="string">Unknown</span> <span class="string">desc</span> <span class="string">=</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">sandbox</span> <span class="string">container</span> <span class="string">&quot;2eed3030e3bfecbc5668a1621454a26dfd67688c5d152e638c86b58baa66b826&quot;</span> <span class="string">network</span> <span class="string">for</span> <span class="string">pod</span> <span class="attr">&quot;fixed-deploy-ip-6fcf56c75b-cgksd&quot;:</span> <span class="string">networkPlugin</span> <span class="string">cni</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">pod</span> <span class="string">&quot;fixed-deploy-ip-6fcf56c75b-cgksd_default&quot;</span> <span class="attr">network:</span> <span class="string">plugin</span> <span class="string">type=&quot;calico&quot;</span> <span class="string">failed</span> <span class="string">(add):</span> <span class="attr">error getting IP from IPAM: resource already exists:</span> <span class="number">171.20</span><span class="number">.42</span><span class="number">.65</span></code></pre><h2 id="5-手动释放IP"><a href="#5-手动释放IP" class="headerlink" title="5. 手动释放IP"></a>5. 手动释放IP</h2><p>在使用过程中可能会遇到 IP 没有释放等问题导致 pod 启动失败，导致这种原因可能是 pod 被删除后，使用的 IP 地址未被释放，所以需要使用以下命令对地址池的 IP 进行释放，才能够被 pod 重新使用</p><pre><code class="highlight bash">$ calicoctl ipam release --ip 171.20.42.65</code></pre><p><strong>参考链接</strong></p><blockquote><p><a href="https://blog.csdn.net/weixin_48711696/article/details/136049633?csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%22136049633%22,%22source%22:%22weixin_48711696%22%7D">https://blog.csdn.net/weixin_48711696/article/details/136049633?csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%22136049633%22,%22source%22:%22weixin_48711696%22%7D</a></p><p><a href="https://blog.csdn.net/weixin_48711696/article/details/135749305">https://blog.csdn.net/weixin_48711696/article/details/135749305</a></p><p><a href="https://www.cnblogs.com/chuanzhang053/p/17584488.html">https://www.cnblogs.com/chuanzhang053/p/17584488.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;需求：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在某种情况下，创建 Pod 时主动给它分配IP地址，并要求即使重启Pod IP地址也不变。&lt;/p&gt;
&lt;p&gt;这里演示 Calico 网络插件环境中，如何给 Pod 分配固定的 IP 地址。&lt;/p&gt;
&lt;h1 id=&quot;一、确</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Pod" scheme="https://georgechan95.github.io/tags/Pod/"/>
    
  </entry>
  
  <entry>
    <title>015-K8S-Prometheus部署及监控告警</title>
    <link href="https://georgechan95.github.io/blog/e62b8338.html"/>
    <id>https://georgechan95.github.io/blog/e62b8338.html</id>
    <published>2025-07-19T08:39:00.000Z</published>
    <updated>2025-07-24T13:06:41.589Z</updated>
    
    <content type="html"><![CDATA[<p><strong>概要：</strong></p><p>简述 Loki 相关组件原理，并演示两种使用 Loki 监控Pod日志的部署方式：<strong>使用 yaml 资源清单部署</strong> 和 <strong>使用 Helm 部署</strong></p><p><strong>集群环境</strong></p><table><thead><tr><th>IP</th><th>Hostname</th><th>用途</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td><td>Master节点</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td><td>Node节点</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td><td>Node节点</td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td><td>Node节点</td></tr></tbody></table><h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>对于 Kubernetes 集群本身的监控也是非常重要的，我们需要时时刻刻了解集群的运行状态。</p><p>对于集群的监控一般我们需要考虑以下几个方面：</p><ul><li>Kubernetes 节点的监控：比如节点的 cpu、load、disk、memory 等指标</li><li>内部系统组件的状态：比如 kube-scheduler、kube-controller-manager、kubedns&#x2F;coredns 等组件的详细运行状态</li><li>编排级的 metrics：比如 Deployment 的状态、资源请求、调度和 API 延迟等数据指标</li></ul><p>Kubernetes 集群的监控方案目前主要有以下几种方案：</p><ul><li><p>cAdvisor : 是一个轻量级的容器监控工具，用于收集容器运行时的资源使用情况（如 CPU、内存、磁盘、网络等）以及性能统计数据。</p><ul><li><p>作用</p><ul><li>提供容器级别的资源使用和性能指标。</li><li>暴露这些指标，供其他监控工具（如 Metrics Server 或 Prometheus）采集。</li><li>内置于 Kubernetes 的 <strong>Kubelet</strong> 中，自动为集群中的每个节点收集容器数据。</li></ul></li><li><p>特点</p><ul><li><p><strong>轻量级</strong>：资源占用低，适合在每个节点运行。</p></li><li><p><strong>实时性</strong>：提供实时的容器性能数据。</p></li><li><p><strong>原生支持</strong>：在 Kubernetes 中默认集成到 Kubelet，无需单独部署。</p></li><li><p><strong>开放接口</strong>：通过 HTTP API 暴露指标，易于集成到其他监控系统。</p></li></ul></li></ul></li><li><p>metrics-server : 是一个轻量级的、可扩展的组件，用于从 Kubernetes 集群中的节点和 Pod 收集资源使用情况（如 CPU 和内存）的指标数据，并通过 Kubernetes API 提供这些数据。</p><ul><li><p>作用</p><ul><li>提供实时的资源使用指标，供用户或工具（如 kubectl、HPA）查询。</li><li>支持基于资源使用情况的自动扩展决策。</li><li>替代了早期的 Heapster（已废弃），是 Kubernetes 生态系统中默认的监控数据收集工具。</li></ul></li><li><p>特点</p><ul><li><p>轻量级：Metrics Server 只存储内存中的瞬时数据，不持久化历史数据。</p></li><li><p>高效：通过 Kubernetes API 聚合层提供指标，易于集成。</p></li><li><p>可扩展：支持与更复杂的监控系统（如 Prometheus）集成。</p></li></ul></li></ul></li><li><p>kube-state-metrics : 是一个服务，通过 Kubernetes API 收集集群中资源对象（如 Pod、Deployment、Service 等）的状态和元数据，并以 Prometheus 兼容的格式通过 HTTP 端点暴露这些指标。</p><ul><li><p>作用：</p><ul><li>提供 Kubernetes 资源对象的状态信息（如 Pod 运行状态、Deployment 副本数等）。</li><li>补充 cAdvisor 和 node_exporter 的功能，专注于 Kubernetes 对象的元数据而非系统或容器级资源使用。</li><li>支持 Prometheus 抓取数据，用于监控、告警和可视化。</li></ul></li><li><p>特点：</p><ul><li><p><strong>轻量级</strong>：以单一 Deployment 运行，资源占用低。</p></li><li><p><strong>专注于状态</strong>：提供资源对象的元数据和状态（如 Pod 是否 Running、Job 是否完成）。</p></li><li><p><strong>Prometheus 集成</strong>：通过 &#x2F;metrics 端点暴露数据，易于与 Prometheus 和 Grafana 集成。</p></li><li><p><strong>动态更新</strong>：实时监听 Kubernetes API 的资源变化。</p></li></ul></li></ul></li><li><p>node_exporter : 一个 Prometheus 导出器（exporter），专门用于收集主机（节点）的系统级指标，如 CPU、内存、磁盘、网络、文件系统等，并以 Prometheus 兼容的格式通过 HTTP 端点暴露这些指标。</p><ul><li><strong>作用</strong>：<ul><li>提供节点级别的详细系统监控数据，弥补 Kubernetes Metrics Server 和 cAdvisor 的局限性（后者主要聚焦于容器指标）。</li><li>支持 Prometheus 抓取指标，用于长期存储、分析和可视化。</li><li>广泛用于 Kubernetes 集群、裸机或虚拟机环境的监控。</li></ul></li><li><strong>特点</strong>：<ul><li><strong>轻量级</strong>：资源占用低，适合在每个节点运行。</li><li><strong>模块化</strong>：支持多种收集器（collector），可按需启用或禁用。</li><li><strong>跨平台</strong>：主要支持 Linux，也支持部分 Unix 系统（如 macOS、FreeBSD）。</li><li><strong>Prometheus 集成</strong>：通过标准化的 &#x2F;metrics 端点暴露数据，易于与 Prometheus 和 Grafana 集成。</li></ul></li></ul></li></ul><p>不过 kube-state-metrics 和 metrics-server 之间还是有很大不同的，二者的主要区别如下：</p><ul><li>kube-state-metrics 主要关注的是业务相关的一些元数据，比如 Deployment、Pod、副本状态等</li><li>metrics-server 主要关注的是<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/resource-metrics-api.md">资源度量 API</a> 的实现，比如 CPU、文件描述符、内存、请求延时等指标</li></ul><h1 id="二、部署-StorageClass"><a href="#二、部署-StorageClass" class="headerlink" title="二、部署 StorageClass"></a>二、部署 StorageClass</h1><h2 id="1-安装NFS"><a href="#1-安装NFS" class="headerlink" title="1. 安装NFS"></a>1. 安装NFS</h2><p>安装 NFS,配置存储卷自动分配 PV，用于持久化日志数据。</p><p>这里选用 k8s-master (10.20.1.139) 作为 nfs 服务端，其它节点作为 nfs 客户端</p><h3 id="1-1-安装-NFS-服务"><a href="#1-1-安装-NFS-服务" class="headerlink" title="1.1 安装 NFS 服务"></a>1.1 安装 NFS 服务</h3><blockquote><p>master节点、node01、node02、node03 节点都需要安装执行</p></blockquote><pre><code class="highlight bash">$ yum install -y nfs-utils rpcbind</code></pre><h3 id="1-2-创建共享目录"><a href="#1-2-创建共享目录" class="headerlink" title="1.2 创建共享目录"></a>1.2 创建共享目录</h3><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash"><span class="comment"># 创建 共享目录</span>$ <span class="built_in">mkdir</span> -p /root/data/prometheus/<span class="comment"># 目录提权</span><span class="built_in">chmod</span> 777 /root/data/prometheus/<span class="comment"># 变更用户组</span><span class="built_in">chown</span> nobody /root/data/prometheus/</code></pre><h3 id="1-3-编辑共享目录读写配置"><a href="#1-3-编辑共享目录读写配置" class="headerlink" title="1.3 编辑共享目录读写配置"></a>1.3 编辑共享目录读写配置</h3><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash">$ vim /etc/exports/root/data     10.20.1.0/24(rw,fsid=0,no_root_squash)/root/data/prometheus       10.20.1.0/24(rw,no_root_squash,no_all_squash,no_subtree_check,<span class="built_in">sync</span>)</code></pre><p>这里使用的是 NFS4 服务，上面的配置表示 10.20.1.0&#x2F;24 网段的 ip 都可以与 nfs 主服务器共享 <code>/root/data/prometheus</code> 目录内容</p><h3 id="1-4-启动NFS服务"><a href="#1-4-启动NFS服务" class="headerlink" title="1.4 启动NFS服务"></a>1.4 启动NFS服务</h3><blockquote><p>集群内所有节点都需要操作</p></blockquote><pre><code class="highlight bash"> <span class="comment"># 启动服务</span>$ systemctl start rpcbind$ systemctl restart nfs-server.service<span class="comment"># 设置开机自启</span>$ systemctl <span class="built_in">enable</span> rpcbind$ systemctl <span class="built_in">enable</span> nfs-server.service</code></pre><h3 id="1-5-测试-NFS-目录挂载"><a href="#1-5-测试-NFS-目录挂载" class="headerlink" title="1.5 测试 NFS 目录挂载"></a>1.5 测试 NFS 目录挂载</h3><pre><code class="highlight bash"><span class="comment"># NFS 客户端执行：创建目录</span>$ <span class="built_in">mkdir</span> /data/test1<span class="comment"># NFS 客户端执行：挂载目录到NFS服务端</span>$ mount -t nfs4 10.20.1.139:/prometheus /data/test1<span class="comment"># NFS 客户端执行：查看挂载结果</span>$ mount | grep /data/test110.20.1.139:/prometheus on /data/test1 <span class="built_in">type</span> nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.1.141,local_lock=none,addr=10.20.1.139)<span class="comment"># NFS 客户端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;this is client&quot;</span> &gt; /data/test1/a.txt<span class="comment"># NFS 服务端执行：查看数据， 结论：客户端数据已写入服务端挂载目录</span>$ <span class="built_in">cat</span> /root/data/prometheus/a.txt this is client<span class="comment"># NFS 服务端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;This is Server&quot;</span> &gt;&gt; /root/data/prometheus/a.txt<span class="comment"># NFS 客户端执行：查看数据， 结论：服务端数据已写入客户端挂载目录</span>$ <span class="built_in">cat</span> /data/test1/a.txtthis is clientThis is Server</code></pre><p><strong>取消挂载</strong></p><pre><code class="highlight bash"><span class="comment"># 取消挂载</span>umount /data/test1<span class="comment"># 如果取消挂载出现报错，例如：</span>$ umount /data/test1umount.nfs4: /data/test1: device is busy<span class="comment"># 查看目录占用进程</span>$ fuser -m /data/test1/data/test1:         32679c<span class="comment"># kill 进程</span>$ <span class="built_in">kill</span> -9 32679<span class="comment"># 方式二：强制卸载</span>umount -l /data/test1</code></pre><h2 id="2-创建-StorageClass"><a href="#2-创建-StorageClass" class="headerlink" title="2. 创建 StorageClass"></a>2. 创建 StorageClass</h2><p>资源清单：<code>prometheus-storage.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.存储类</span><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">StorageClass</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">prometheus-storage</span>  <span class="attr">name:</span> <span class="string">prometheus-storage</span><span class="comment"># provisioner: nfs-provisioner</span><span class="attr">provisioner:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定动态配置器，NFS 子目录外部配置器</span><span class="attr">parameters:</span>  <span class="attr">pathPattern:</span> <span class="string">$&#123;.PVC.namespace&#125;/$&#123;.PVC.name&#125;</span> <span class="comment"># 动态生成的 NFS 路径，格式为 &lt;PVC 命名空间&gt;/&lt;PVC 名称&gt;，例如 loki-storageclass/test-claim。</span>  <span class="attr">archiveOnDelete:</span> <span class="string">&quot;true&quot;</span> <span class="comment">##删除 pv,pv内容是否备份</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">prometheus-storage</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 指定使用的 ServiceAccountName</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span>          <span class="attr">image:</span> <span class="string">k8s.dockerproxy.com/sig-storage/nfs-subdir-external-provisioner:v4.0.2</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 挂载的卷名称，与 volumes 部分定义的卷对应</span>              <span class="attr">mountPath:</span> <span class="string">/persistentvolumes</span> <span class="comment"># 将 NFS 卷挂载到容器内的 /persistentvolumes 路径，供容器读写 NFS 共享数据。</span>          <span class="attr">env:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PROVISIONER_NAME</span>              <span class="attr">value:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定配置器名称，与 StorageClass 保持一致</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_SERVER</span>              <span class="attr">value:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_PATH</span>              <span class="attr">value:</span> <span class="string">/root/data/prometheus</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 定义一个名为 nfs-client-root 的 NFS 卷，连接到 NFS 服务器的指定地址和路径</span>          <span class="attr">nfs:</span>            <span class="attr">server:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="attr">path:</span> <span class="string">/root/data/prometheus</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">nodeSelector:</span> <span class="comment"># 指定Pod运行的节点</span>        <span class="attr">kubernetes.io/hostname:</span> <span class="string">k8s-node01</span>      <span class="comment"># nodeName: k8s-node01 # 指定 Pod 运行在 k8s-node01 节点上</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4.服务账户</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># SA 的名称</span>  <span class="attr">namespace:</span> <span class="string">prometheus-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 5.集群角色</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;nodes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumeclaims&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;storage.k8s.io&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;storageclasses&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;events&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># 6.集群角色绑定</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-nfs-client-provisioner</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定类型 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># ServiceAccount 的名称</span>    <span class="attr">namespace:</span> <span class="string">prometheus-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span> <span class="comment"># 绑定的角色类型</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span> <span class="comment"># 集群角色名称 nfs-client-provisioner-runner</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 角色</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称，表明它与 NFS 客户端存储提供者的领导者选举（leader election）机制相关。</span>  <span class="attr">namespace:</span> <span class="string">prometheus-storage</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 空字符串表示核心 API 组（core API group），包含 Kubernetes 的基本资源，如 endpoints。</span>    <span class="attr">resources:</span> [<span class="string">&quot;endpoints&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># SA角色绑定</span><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-leader-locking-nfs-client-provisioner</span>  <span class="attr">namespace:</span> <span class="string">prometheus-storage</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定资源类型为 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 绑定的ServiceAccount 名称</span>    <span class="attr">namespace:</span> <span class="string">prometheus-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">Role</span> <span class="comment"># 绑定角色（loki-storage名称空间的角色）</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 创建 StorageClass</span>$ kubectl apply -f prometheus-storage.yaml<span class="comment"># 查看 StorageClass</span>$ kubectl get StorageClassNAME                 PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGEloki-storage         k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  5d21hnfs-client           k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  6d5hprometheus-storage   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  11m<span class="comment"># 查看 Pod</span>$ kubectl get pods -n prometheus-storage -o wideNAME                                      READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESnfs-client-provisioner-6cb79b9755-7q2t4   1/1     Running   0          11m   192.168.85.207   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h1 id="三、部署-Prometheus"><a href="#三、部署-Prometheus" class="headerlink" title="三、部署 Prometheus"></a>三、部署 Prometheus</h1><h2 id="1-创建命名空间"><a href="#1-创建命名空间" class="headerlink" title="1. 创建命名空间"></a>1. 创建命名空间</h2><p>资源清单：<code>kube-ops.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">kube-ops</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f kube-ops.yaml<span class="comment"># 查看命名空间</span>$ kubectl get namespace | grep kube-opskube-ops             Active   50s</code></pre><h2 id="2-创建Prometheus-ConfigMap"><a href="#2-创建Prometheus-ConfigMap" class="headerlink" title="2. 创建Prometheus ConfigMap"></a>2. 创建Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]</code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 查看 ConfigMap</span>$ kubectl get cm -n kube-opsNAME                DATA   AGEkube-root-ca.crt    1      32mprometheus-config   1      38s</code></pre><h2 id="3-部署-Prometheus"><a href="#3-部署-Prometheus" class="headerlink" title="3. 部署 Prometheus"></a>3. 部署 Prometheus</h2><p>资源清单：<code>prometheus.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 定义 PVC</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">storageClassName:</span> <span class="string">prometheus-storage</span>  <span class="comment"># 指定使用的 StorageClass</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteMany</span>                     <span class="comment"># 存储卷可以被多个节点（Node）以读写模式同时挂载</span>  <span class="attr">resources:</span>    <span class="attr">requests:</span>      <span class="attr">storage:</span> <span class="string">10Gi</span>                     <span class="comment"># 定义 PVC 请求的资源量，这里特指存储容量</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 创建 SA</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 集群角色</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span>      <span class="bullet">-</span> <span class="string">&quot;&quot;</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="string">nodes</span>      <span class="bullet">-</span> <span class="string">services</span>      <span class="bullet">-</span> <span class="string">endpoints</span>      <span class="bullet">-</span> <span class="string">pods</span>      <span class="bullet">-</span> <span class="string">nodes/proxy</span>    <span class="attr">verbs:</span>      <span class="bullet">-</span> <span class="string">get</span>      <span class="bullet">-</span> <span class="string">list</span>      <span class="bullet">-</span> <span class="string">watch</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span>      <span class="bullet">-</span> <span class="string">&quot;&quot;</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="string">configmaps</span>      <span class="bullet">-</span> <span class="string">nodes/metrics</span>    <span class="attr">verbs:</span>      <span class="bullet">-</span> <span class="string">get</span>  <span class="bullet">-</span> <span class="attr">nonResourceURLs:</span>      <span class="bullet">-</span> <span class="string">/metrics</span>    <span class="attr">verbs:</span>      <span class="bullet">-</span> <span class="string">get</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 集群角色绑定</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span><span class="attr">roleRef:</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">name:</span> <span class="string">prometheus</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>    <span class="attr">name:</span> <span class="string">prometheus</span>    <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="meta">---</span><span class="meta"></span><span class="comment"># Deployment</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">prometheus</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>               <span class="comment"># Pod 副本数为1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">prometheus</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">prometheus</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">prometheus</span>    <span class="comment"># 指定 Pod 使用的 Kubernetes 服务账号（ServiceAccount）为 prometheus</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">prometheus</span>          <span class="attr">image:</span> <span class="string">prom/prometheus:v2.4.3</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&quot;/bin/prometheus&quot;</span>         <span class="comment"># 指定容器启动时运行的命令为 /bin/prometheus，这是 Prometheus 的主可执行文件</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">&quot;--config.file=/etc/prometheus/prometheus.yml&quot;</span>    <span class="comment"># 指定 Prometheus 的配置文件路径为 /etc/prometheus/prometheus.yml，这个文件由 ConfigMap（prometheus-config）提供，挂载到容器内</span>            <span class="bullet">-</span> <span class="string">&quot;--storage.tsdb.path=/prometheus&quot;</span>                 <span class="comment"># 指定 Prometheus 时间序列数据库（TSDB）的存储路径为 /prometheus，这个路径由 PVC（prometheus）提供，持久化存储数据</span>            <span class="bullet">-</span> <span class="string">&quot;--storage.tsdb.retention=24h&quot;</span>                    <span class="comment"># 设置数据保留时间为 24 小时，意味着 Prometheus 只保留最近 24 小时的监控数据，旧数据将被删除。生产环境建议 15-30天</span>            <span class="bullet">-</span> <span class="string">&quot;--web.enable-admin-api&quot;</span>                          <span class="comment"># 启用 Prometheus 的 Admin HTTP API，允许执行管理操作（如删除时间序列）</span>            <span class="bullet">-</span> <span class="string">&quot;--web.enable-lifecycle&quot;</span>                          <span class="comment"># 启用生命周期 API，支持通过 HTTP 请求（如 localhost:9090/-/reload）动态重新加载配置文件。</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9090</span>       <span class="comment"># 指定 Prometheus 监听端口，用于提供 Web UI 和 API</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>              <span class="attr">name:</span> <span class="string">http</span>          <span class="attr">volumeMounts:</span>                 <span class="comment"># 定义容器内的挂载点，将卷挂载到指定路径</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/prometheus&quot;</span>  <span class="comment"># 将名为 data 的卷挂载到容器内的 /prometheus 路径，用于存储 TSDB 数据</span>              <span class="attr">subPath:</span> <span class="string">prometheus</span>       <span class="comment"># 表示使用卷中的子路径 prometheus，避免覆盖整个卷的其他内容</span>              <span class="attr">name:</span> <span class="string">data</span>                <span class="comment"># 卷由 PVC（prometheus）提供</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/etc/prometheus&quot;</span>      <span class="comment"># 将名为 config-volume 的卷挂载到容器内的 /etc/prometheus 路径，用于存储配置文件</span>              <span class="attr">name:</span> <span class="string">config-volume</span>               <span class="comment"># 由 ConfigMap（prometheus-config）提供</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="string">100m</span>                 <span class="comment"># 请求 100 毫核（0.1 CPU 核心），表示容器需要的最小 CPU 资源</span>              <span class="attr">memory:</span> <span class="string">512Mi</span>             <span class="comment"># 请求 512 MiB 内存，表示容器需要的最小内存</span>            <span class="attr">limits:</span>              <span class="attr">cpu:</span> <span class="string">100m</span>                 <span class="comment"># 限制容器最多使用 100 毫核 CPU，防止过量占用</span>              <span class="attr">memory:</span> <span class="string">512Mi</span>             <span class="comment"># 限制容器最多使用 512 MiB 内存，防止内存溢出</span>      <span class="attr">securityContext:</span>                  <span class="comment"># 定义 Pod 的安全上下文，控制容器运行时的权限</span>        <span class="attr">runAsUser:</span> <span class="number">0</span>                    <span class="comment"># 指定容器以用户 ID 0（即 root 用户）运行</span>      <span class="attr">volumes:</span>                          <span class="comment"># 定义 Pod 使用的卷，供容器挂载</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span>          <span class="attr">persistentVolumeClaim:</span>        <span class="comment"># 指定挂载的PVC</span>            <span class="attr">claimName:</span> <span class="string">prometheus</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span>          <span class="attr">configMap:</span>                    <span class="comment"># 指定挂载的 configMap</span>            <span class="attr">name:</span> <span class="string">prometheus-config</span><span class="meta">---</span><span class="meta"></span><span class="comment"># Service</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">prometheus</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">prometheus</span>  <span class="attr">type:</span> <span class="string">NodePort</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web-prometheus</span>  <span class="comment"># 端口名称</span>      <span class="attr">port:</span> <span class="number">9090</span>            <span class="comment"># service 对外端口 9090</span>      <span class="attr">targetPort:</span> <span class="string">http</span>      <span class="comment"># 内部名为 http 的端口 （9090）</span><span class="meta">---</span><span class="meta"></span><span class="comment"># Ingress， 安装参考：https://georgechan95.github.io/blog/6436eaf1.html</span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-ui</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span>           <span class="comment"># 指定 Ingress 控制器为 nginx，由 Nginx Ingress Controller 处理</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">my.prometheus.com</span>       <span class="comment"># 定义一个基于域名 my.prometheus.com 的路由规则</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">prometheus</span>    <span class="comment"># 流量转发到 kube-ops 命名空间中的 prometheus 服务</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">9090</span>            <span class="attr">path:</span> <span class="string">/</span>                 <span class="comment"># 匹配根路径 / 及所有以 / 开头的子路径（如 /graph, /api/v1）</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f prometheus.yaml<span class="comment"># 查看PVC</span>$ kubectl get pvc -n kube-opsNAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS         VOLUMEATTRIBUTESCLASS   AGEprometheus   Bound    pvc-b85318bf-0ef5-449f-ab40-200238200e10   10Gi       RWX            prometheus-storage   &lt;<span class="built_in">unset</span>&gt;                 3h15m<span class="comment"># 查看 ServiceAccount</span>$ kubectl get serviceaccount -n kube-opsNAME         SECRETS   AGEdefault      0         4h4mprometheus   0         3h11m<span class="comment"># 查看 Deployment</span>$ kubectl get deploy -n kube-opsNAME         READY   UP-TO-DATE   AVAILABLE   AGEprometheus   1/1     1            1           125m<span class="comment"># 查看 Pods</span>$ kubectl get pods -n kube-opsNAME                          READY   STATUS    RESTARTS   AGEprometheus-844847f5c7-7gwck   1/1     Running   0          125m<span class="comment"># 查看 Service</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   18m<span class="comment"># 查看 Ingress</span>$ kubectl get ingress -n kube-opsNAME            CLASS   HOSTS               ADDRESS   PORTS   AGEprometheus-ui   nginx   my.prometheus.com             80      9m56s</code></pre><p><strong>添加Host域名映射</strong></p><pre><code class="highlight plaintext">10.20.1.140 my.prometheus.com</code></pre><p><strong>浏览器访问 Prometheus</strong></p><p><a href="http://my.prometheus.com/">http://my.prometheus.com/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/22/20250722-193045.png" alt="Prometheus"></p><h1 id="四、配置-Prometheus-抓取-Ingress-Nginx-指标"><a href="#四、配置-Prometheus-抓取-Ingress-Nginx-指标" class="headerlink" title="四、配置 Prometheus 抓取 Ingress-Nginx 指标"></a>四、配置 Prometheus 抓取 Ingress-Nginx 指标</h1><h2 id="1、开启-Ingress-nginx-监听端口"><a href="#1、开启-Ingress-nginx-监听端口" class="headerlink" title="1、开启 Ingress-nginx 监听端口"></a>1、开启 Ingress-nginx 监听端口</h2><p>这里的 ingress-nginx 使用的是 helm 安装的，安装过程见：<a href="https://georgechan95.github.io/blog/6436eaf1.html">https://georgechan95.github.io/blog/6436eaf1.html</a></p><p>开启 Ingress-nginx 指标监听端口，默认：10254</p><p><strong>编辑 <code>value.yaml</code></strong></p><pre><code class="highlight yaml"><span class="attr">metrics:</span>  <span class="attr">port:</span> <span class="number">10254</span>  <span class="attr">portName:</span> <span class="string">metrics</span>  <span class="comment"># if this port is changed, change healthz-port: in extraArgs: accordingly</span>  <span class="attr">enabled:</span> <span class="literal">true</span></code></pre><p><strong>更新 Ingress-Nginx</strong></p><pre><code class="highlight bash">$ helm upgrade ingress-nginx -n ingress-nginx -f values.yaml .</code></pre><h2 id="2-修改-Prometheus-ConfigMap"><a href="#2-修改-Prometheus-ConfigMap" class="headerlink" title="2. 修改 Prometheus ConfigMap"></a>2. 修改 Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]</code></pre><p>重新执行资源清单</p><p>方式一：</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f prometheus-cm.yaml$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   111m<span class="comment"># 请求uri，重新加载</span>curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p>方式二：</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 查看 prometheus pod</span>$ kubectl get pods -n kube-opsNAME                          READY   STATUS    RESTARTS   AGEprometheus-844847f5c7-7gwck   1/1     Running   0          3h29m<span class="comment"># 杀死重启Pod，重新加载 ConfigMap</span>$ kubectl delete pod prometheus-844847f5c7-7gwck -n kube-opspod <span class="string">&quot;prometheus-844847f5c7-7gwck&quot;</span> deleted</code></pre><p>再次从浏览器查看 Prometheus </p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/22/20250722-205857.png" alt="抓取 Ingress-Nginx 指标"></p><h1 id="五、创建-node-exporter，监控节点资源"><a href="#五、创建-node-exporter，监控节点资源" class="headerlink" title="五、创建 node_exporter，监控节点资源"></a>五、创建 node_exporter，监控节点资源</h1><p>node_exporter 就是抓取用于采集服务器节点的各种运行指标，目前 node_exporter 支持几乎所有常见的监控点，比如 conntrack，cpu，diskstats，filesystem，loadavg，meminfo，netstat 等，详细的监控点列表可以参考其 <a href="https://github.com/prometheus/node_exporter">Node_Exporter</a></p><p><strong>说明：</strong></p><p>在 Kubernetes 下，Promethues 通过与 Kubernetes API 集成，目前主要支持5中服务发现模式，分别是：Node、Service、Pod、Endpoints、Ingress</p><p>通过指定 <code>kubernetes_sd_configs</code> 的模式为 <code>node</code>，Prometheus 就会自动从 Kubernetes 中发现所有的 node 节点并作为当前 job 监控的目标实例，发现的节点 <code>/metrics</code> 接口是默认的 kubelet 的 HTTP 接口</p><p>prometheus 去发现 Node 模式的服务的时候，访问的端口默认是<strong>10250</strong>，而现在该端口下面已经没有了<code>/metrics</code>指标数据了，现在 kubelet 只读的数据接口统一通过 <strong>10255</strong> 端口进行暴露了，所以我们应该去替换掉这里的端口，但是我们是要替换成 <strong>10255</strong> 端口吗？不是的，因为我们是要去配置上面通过<code>node-exporter</code>抓取到的节点指标数据，而我们上面是不是指定了 <code>hostNetwork=true</code> ，所以在每个节点上就会绑定一个端口 <strong>9100</strong>，所以我们应该将这里的 <strong>10250</strong> 替换成 <strong>9100</strong></p><p>这里我们就需要使用到 Prometheus 提供的<code>relabel_configs</code>中的<code>replace</code>能力了，relabel 可以在 Prometheus 采集数据之前，通过Target 实例的 Metadata 信息，动态重新写入 Label 的值。除此之外，我们还能根据 Target 实例的 Metadata 信息选择是否采集或者忽略该 Target 实例</p><p>添加了一个 action 为<code>labelmap</code>，正则表达式是<code>__meta_kubernetes_node_label_(.+)</code>的配置，这里的意思就是表达式中匹配都的数据也添加到指标数据的 Label 标签中去。</p><p>对于 kubernetes_sd_configs 下面可用的标签如下： 可用元标签：</p><ul><li>__meta_kubernetes_node_name：节点对象的名称</li><li><em>_meta_kubernetes_node_label</em>：节点对象中的每个标签</li><li><em>_meta_kubernetes_node_annotation</em>：来自节点对象的每个注释</li><li><em>_meta_kubernetes_node_address</em>：每个节点地址类型的第一个地址（如果存在） *</li></ul><blockquote><p>关于 kubernets_sd_configs 更多信息可以查看官方文档：<a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#">kubernetes_sd_config</a></p></blockquote><p>Kubernetes 1.11+ 版本以后，kubelet 就移除了 10255 端口， metrics 接口又回到了 10250 端口，所以这里不需要替换端口，但是需要使用 https 的协议</p><h2 id="1-部署-node-exporter"><a href="#1-部署-node-exporter" class="headerlink" title="1. 部署 node-exporter"></a>1. 部署 node-exporter</h2><p>资源清单：<code>prometheus-node-exporter.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">DaemonSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">node-exporter</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">name:</span> <span class="string">node-exporter</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">name:</span> <span class="string">node-exporter</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">name:</span> <span class="string">node-exporter</span>    <span class="attr">spec:</span>      <span class="attr">hostPID:</span> <span class="literal">true</span>                         <span class="comment"># 允许 Pod 使用主机节点的 PID 命名空间, Node Exporter 需要访问主机的 /proc 文件系统以收集进程相关指标（如 CPU、内存使用情况），因此需要 hostPID: true</span>      <span class="attr">hostIPC:</span> <span class="literal">true</span>                         <span class="comment"># 允许 Pod 使用主机节点的 IPC（进程间通信）命名空间，这通常用于访问主机的共享内存或其他 IPC 机制，但在 Node Exporter 中可能不是必需，建议评估是否需要以降低安全风险。</span>      <span class="attr">hostNetwork:</span> <span class="literal">true</span>                     <span class="comment"># Pod 使用主机节点的网络命名空间，直接绑定到主机的网络接口和端口，Node Exporter 的端口（9100）将直接绑定到主机网络，便于 Prometheus 抓取节点的指标（如通过节点 IP:9100）</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node-exporter</span>          <span class="attr">image:</span> <span class="string">prom/node-exporter:v0.16.0</span>   <span class="comment"># Node Exporter 收集主机系统的指标（如 CPU、内存、磁盘、文件系统等）并通过 HTTP 端点（默认 /metrics）暴露</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9100</span>             <span class="comment"># Node Exporter 监听 9100 端口，暴露 Prometheus 格式的指标端点（默认 /metrics）</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="number">0.15</span>                       <span class="comment"># 请求 0.15 CPU 核心（150 毫核），表示 Node Exporter 的最小 CPU 需求</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">true</span>                  <span class="comment"># 容器以特权模式运行，拥有对主机的广泛访问权限</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">--path.procfs</span>                   <span class="comment"># 指定进程文件系统路径为 /host/proc，映射到主机的 /proc，用于收集进程、CPU、内存等指标</span>            <span class="bullet">-</span> <span class="string">/host/proc</span>            <span class="bullet">-</span> <span class="string">--path.sysfs</span>                    <span class="comment"># 指定系统文件系统路径为 /host/sys，映射到主机的 /sys，用于收集硬件相关指标（如设备信息）</span>            <span class="bullet">-</span> <span class="string">/host/sys</span>            <span class="bullet">-</span> <span class="string">--collector.filesystem.ignored-mount-points</span>   <span class="comment"># 配置文件系统收集器，忽略以 /sys, /proc, /dev, /host, /etc 开头的挂载点，防止收集容器内部或无关的文件系统指标，专注于主机文件系统</span>            <span class="bullet">-</span> <span class="string">&#x27;&quot;^/(sys|proc|dev|host|etc)($|/)&quot;&#x27;</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dev</span>              <span class="attr">mountPath:</span> <span class="string">/host/dev</span>      <span class="comment"># 挂载主机的 /dev 到容器内的 /host/dev</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">proc</span>              <span class="attr">mountPath:</span> <span class="string">/host/proc</span>     <span class="comment"># 挂载主机的 /proc 到 /host/proc</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sys</span>              <span class="attr">mountPath:</span> <span class="string">/host/sys</span>      <span class="comment"># 挂载主机的 /sys 到 /host/sys</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">rootfs</span>              <span class="attr">mountPath:</span> <span class="string">/rootfs</span>        <span class="comment"># 挂载主机的根文件系统（/）到 /rootfs</span>      <span class="attr">tolerations:</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;node-role.kubernetes.io/control-plane&quot;</span>    <span class="comment"># 允许 Pod 调度到带有 node-role.kubernetes.io/control-plane 污点的节点</span>          <span class="attr">operator:</span> <span class="string">Exists</span>          <span class="attr">effect:</span> <span class="string">NoSchedule</span>      <span class="attr">volumes:</span>                          <span class="comment"># 定义 Pod 使用的卷，映射主机文件系统到容器</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">proc</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/proc</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dev</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/dev</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sys</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/sys</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">rootfs</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 node-exporter</span>$ kubectl apply -f prometheus-node-exporter.yaml<span class="comment"># 查看 Pod</span>$ kubectl get pods -n kube-opsNAME                          READY   STATUS    RESTARTS   AGEnode-exporter-d85s5           1/1     Running   0          165mnode-exporter-gmwln           1/1     Running   0          165mnode-exporter-kjdm9           1/1     Running   0          165mnode-exporter-vg29l           1/1     Running   0          165mprometheus-844847f5c7-2zvbn   1/1     Running   0          17h</code></pre><h2 id="2-修改-Prometheus-ConfigMap-1"><a href="#2-修改-Prometheus-ConfigMap-1" class="headerlink" title="2. 修改 Prometheus ConfigMap"></a>2. 修改 Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span></code></pre><p><strong>重新执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行更新 ConfigMap 资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 等待一会，待ConfigMap更新后，执行请求，让 Prometheus 配置热更新</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   18h$ curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p>再次从浏览器查看 Prometheus 控制台，发现 node_exporter 和 kubelet 已被监听</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-141026.png" alt="node_exporter 和 kubelet"></p><h1 id="六、使用-cAdvisor-监控容器资源指标"><a href="#六、使用-cAdvisor-监控容器资源指标" class="headerlink" title="六、使用 cAdvisor 监控容器资源指标"></a>六、使用 cAdvisor 监控容器资源指标</h1><p>说到容器监控我们自然会想到 <code>cAdvisor</code>，我们前面也说过<code>cAdvisor</code>已经内置在了 kubelet 组件之中，所以我们不需要单独去安装，<code>cAdvisor</code> 的数据路径为<code>/api/v1/nodes/&lt;node&gt;/proxy/metrics</code>，同样我们这里使用 node 的服务发现模式，因为每一个节点下面都有 kubelet</p><h2 id="1-修改-Prometheus-ConfigMap"><a href="#1-修改-Prometheus-ConfigMap" class="headerlink" title="1. 修改 Prometheus ConfigMap"></a>1. 修改 Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-cadvisor&#x27;</span>                                         <span class="comment"># 抓取任务名称为 kubernetes-cadvisor，用于监控 Kubernetes 节点的 cAdvisor 指标</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                           <span class="comment"># 指定使用 HTTPS 协议访问目标（Kubernetes API 服务器的 443 端口）</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Pod 内部的服务账号卷挂载的 CA 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌</span>      <span class="attr">relabel_configs:</span>                                              <span class="comment"># 定义标签重写规则，修改服务发现的目标地址和路径</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                                          <span class="comment"># 规则1：将节点的标签（如 kubernetes.io/hostname）映射到 Prometheus 指标标签 </span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span>                   <span class="comment"># 规则2：将抓取目标地址设置为 kubernetes.default.svc:443，即 Kubernetes API 服务器的 ClusterIP 服务（默认命名空间 default，端口 443）</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]              <span class="comment"># 规则3：使用节点名称（__meta_kubernetes_node_name，如 node01）动态构造指标路径</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span></code></pre><p><strong>重新执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行更新 ConfigMap 资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 等待一会，待ConfigMap更新后，执行请求，让 Prometheus 配置热更新</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   18h$ curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p>再次从浏览器查看 Prometheus 控制台，发现 cAdvisor 已被监听</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-150843.png" alt="Prometheus 监听 cAdvisor"></p><h1 id="七、Prometheus-监控-kube-apiserver"><a href="#七、Prometheus-监控-kube-apiserver" class="headerlink" title="七、Prometheus 监控 kube-apiserver"></a>七、Prometheus 监控 kube-apiserver</h1><p><code>kube-apiserver</code> 监听在节点的 6443 端口，通过以下配置可以使 Prometheus 读取 <code>kube-apiserver</code> 的指标数据</p><h2 id="1-修改-Prometheus-ConfigMap-1"><a href="#1-修改-Prometheus-ConfigMap-1" class="headerlink" title="1. 修改 Prometheus ConfigMap"></a>1. 修改 Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-cadvisor&#x27;</span>                                         <span class="comment"># 抓取任务名称为 kubernetes-cadvisor，用于监控 Kubernetes 节点的 cAdvisor 指标</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                           <span class="comment"># 指定使用 HTTPS 协议访问目标（Kubernetes API 服务器的 443 端口）</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Pod 内部的服务账号卷挂载的 CA 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌</span>      <span class="attr">relabel_configs:</span>                                              <span class="comment"># 定义标签重写规则，修改服务发现的目标地址和路径</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                                          <span class="comment"># 规则1：将节点的标签（如 kubernetes.io/hostname）映射到 Prometheus 指标标签 </span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span>                   <span class="comment"># 规则2：将抓取目标地址设置为 kubernetes.default.svc:443，即 Kubernetes API 服务器的 ClusterIP 服务（默认命名空间 default，端口 443）</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]              <span class="comment"># 规则3：使用节点名称（__meta_kubernetes_node_name，如 node01）动态构造指标路径</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-apiservers&#x27;</span>                             <span class="comment"># 抓取任务名称为 kubernetes-apiservers，用于监控 Kubernetes API 服务器的指标，包括请求速率、延迟、错误率等（如 apiserver_request_total, apiserver_request_duration_seconds）</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                                           <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中的所有 Endpoints 对象</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                 <span class="comment"># Kubernetes API 服务器默认通过 HTTPS（端口 443）暴露 /metrics 端点</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Prometheus Pod 内部的服务账号卷挂载的 CA 证书（位于 /var/run/secrets/kubernetes.io/serviceaccount/ca.crt）验证 API 服务器的 TLS 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌（位于 /var/run/secrets/kubernetes.io/serviceaccount/token）进行身份验证</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>, <span class="string">__meta_kubernetes_service_name</span>, <span class="string">__meta_kubernetes_endpoint_port_name</span>]    <span class="comment"># 断点所在的名称空间，断点所在的 Service， 断点端口名称</span>          <span class="attr">action:</span> <span class="string">keep</span>                      <span class="comment"># 仅保留匹配正则表达式的端点，未匹配的端点被丢弃。</span>          <span class="attr">regex:</span> <span class="string">default;kubernetes;https</span>   <span class="comment"># 确保 Prometheus 只抓取 default 命名空间中 kubernetes 服务的 HTTPS 端点（即 API 服务器的 /metrics）</span></code></pre><p><strong>重新执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行更新 ConfigMap 资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 等待一会，待ConfigMap更新后，执行请求，让 Prometheus 配置热更新</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   18h$ curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p>再次从浏览器查看 Prometheus 控制台，发现 apiServer 已被监听</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-155007.png" alt="Prometheus 监听 apiServer"></p><h1 id="八、Prometheus-通过-Service-监控服务"><a href="#八、Prometheus-通过-Service-监控服务" class="headerlink" title="八、Prometheus 通过 Service 监控服务"></a>八、Prometheus 通过 Service 监控服务</h1><h2 id="1-修改-Prometheus-ConfigMap-2"><a href="#1-修改-Prometheus-ConfigMap-2" class="headerlink" title="1. 修改 Prometheus ConfigMap"></a>1. 修改 Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-cadvisor&#x27;</span>                                         <span class="comment"># 抓取任务名称为 kubernetes-cadvisor，用于监控 Kubernetes 节点的 cAdvisor 指标</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                           <span class="comment"># 指定使用 HTTPS 协议访问目标（Kubernetes API 服务器的 443 端口）</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Pod 内部的服务账号卷挂载的 CA 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌</span>      <span class="attr">relabel_configs:</span>                                              <span class="comment"># 定义标签重写规则，修改服务发现的目标地址和路径</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                                          <span class="comment"># 规则1：将节点的标签（如 kubernetes.io/hostname）映射到 Prometheus 指标标签 </span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span>                   <span class="comment"># 规则2：将抓取目标地址设置为 kubernetes.default.svc:443，即 Kubernetes API 服务器的 ClusterIP 服务（默认命名空间 default，端口 443）</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]              <span class="comment"># 规则3：使用节点名称（__meta_kubernetes_node_name，如 node01）动态构造指标路径</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-apiservers&#x27;</span>                             <span class="comment"># 抓取任务名称为 kubernetes-apiservers，用于监控 Kubernetes API 服务器的指标，包括请求速率、延迟、错误率等（如 apiserver_request_total, apiserver_request_duration_seconds）</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                                           <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中的所有 Endpoints 对象</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                 <span class="comment"># Kubernetes API 服务器默认通过 HTTPS（端口 443）暴露 /metrics 端点</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Prometheus Pod 内部的服务账号卷挂载的 CA 证书（位于 /var/run/secrets/kubernetes.io/serviceaccount/ca.crt）验证 API 服务器的 TLS 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌（位于 /var/run/secrets/kubernetes.io/serviceaccount/token）进行身份验证</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>, <span class="string">__meta_kubernetes_service_name</span>, <span class="string">__meta_kubernetes_endpoint_port_name</span>]    <span class="comment"># 断点所在的名称空间，断点所在的 Service， 断点端口名称</span>          <span class="attr">action:</span> <span class="string">keep</span>                      <span class="comment"># 仅保留匹配正则表达式的端点，未匹配的端点被丢弃。</span>          <span class="attr">regex:</span> <span class="string">default;kubernetes;https</span>   <span class="comment"># 确保 Prometheus 只抓取 default 命名空间中 kubernetes 服务的 HTTPS 端点（即 API 服务器的 /metrics）</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-service-endpoints&#x27;</span>        <span class="comment"># 抓取任务名称为 kubernetes-service-endpoints，用于监控 Kubernetes Service 的 Endpoints 指标。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                             <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中所有 Service 的 Endpoints 对象</span>      <span class="attr">relabel_configs:</span>                                <span class="comment"># 定义标签重写规则，过滤和配置服务发现的目标，确保只抓取符合条件的 Service Endpoints</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scrape</span>]          <span class="attr">action:</span> <span class="string">keep</span>                                <span class="comment"># 仅保留注解 prometheus.io/scrape: &quot;true&quot; 的 Service Endpoints，未匹配的被丢弃</span>          <span class="attr">regex:</span> <span class="literal">true</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scheme</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将匹配的值替换到 __scheme__ 标签，决定抓取协议（http 或 https），允许 Service 指定是否通过 HTTPS 抓取指标，适用于需要安全连接的场景</span>          <span class="attr">target_label:</span> <span class="string">__scheme__</span>          <span class="attr">regex:</span> <span class="string">(https?)</span>                             <span class="comment"># 匹配 http 或 https，若注解未设置，默认使用 http</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_path</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 检查 Service 的注解 prometheus.io/path，将匹配的值替换到 __metrics_path__ 标签，指定指标端点的路径</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>, <span class="string">__meta_kubernetes_service_annotation_prometheus_io_port</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将地址和端口组合替换到 __address__ 标签，允许 Service 指定抓取端口（如 prometheus.io/port: &quot;8080&quot;），覆盖 Endpoints 的默认端口</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">regex:</span> <span class="string">([^:]+)(?::\d+)?;(\d+)</span>          <span class="attr">replacement:</span> <span class="string">$1:$2</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                            <span class="comment"># 将 Service 的标签（如 app=my-app）映射到 Prometheus 指标标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_service_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>]      <span class="comment"># 将 Service 的命名空间（__meta_kubernetes_namespace）写入指标标签 kubernetes_namespace</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_namespace</span>                  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_name</span>]   <span class="comment"># 将 Service 名称（__meta_kubernetes_service_name）写入指标标签 kubernetes_name</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_name</span></code></pre><p><strong>重新执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行更新 ConfigMap 资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 等待一会，待ConfigMap更新后，执行请求，让 Prometheus 配置热更新</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   18h$ curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p>再次从浏览器查看 Prometheus 控制台，发现 Service 已被监听</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-163620.png" alt="Prometheus 监听 Service"></p><h1 id="九、部署-kube-state-metrics，并使用-Prometheus-监控"><a href="#九、部署-kube-state-metrics，并使用-Prometheus-监控" class="headerlink" title="九、部署 kube-state-metrics，并使用 Prometheus 监控"></a>九、部署 kube-state-metrics，并使用 Prometheus 监控</h1><h2 id="1-部署-kube-state-metrics"><a href="#1-部署-kube-state-metrics" class="headerlink" title="1. 部署 kube-state-metrics"></a>1. 部署 kube-state-metrics</h2><pre><code class="highlight bash"><span class="comment"># 克隆 kube-state-metrics 仓库代码</span>git <span class="built_in">clone</span> https://github.com/kubernetes/kube-state-metrics.git<span class="comment"># 克隆后，进入资源清单目录</span><span class="built_in">cd</span> kube-state-metrics/examples/standard<span class="comment"># 修改 service.yaml</span>$ vim service.yaml<span class="comment"># 添加 annotations 信息，用于被prometheus发现</span>metadata:  annotations:    prometheus.io/scrape: <span class="string">&#x27;true&#x27;</span>    prometheus.io/port: <span class="string">&quot;8080&quot;</span><span class="comment"># 执行所有资源清单，注意：这里是 -k 不是 -f</span>$ kubectl apply -k .</code></pre><p><strong>查看部署资源</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 Service</span>$ kubectl get pods -n kube-system | grep kube-state-metricskube-state-metrics-54c8f8787f-6jnp5        1/1     Running   0              107s<span class="comment"># 查看 Pod</span>$ kubectl get svc -n kube-system | grep kube-state-metricskube-state-metrics   ClusterIP   None            &lt;none&gt;        8080/TCP,8081/TCP        119s</code></pre><p>部署完成后，等待一会，等待 Prometheus 抓取 kube-state-metrics 指标信息。</p><p>在浏览器查看 Prometheus ，kube-state-metrics 信息已经被成功抓取。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-195227.png" alt="Prometheus 监听 kube-state-metrics"></p><h1 id="十、部署-Grafana"><a href="#十、部署-Grafana" class="headerlink" title="十、部署 Grafana"></a>十、部署 Grafana</h1><p>用于展示 Prometheus 抓取保存的指标数据</p><p>资源清单：<code>prometheus-grafana.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.声明 PVC ，使用 StorageClass 动态创建PV</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-pvc</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">resources:</span>    <span class="attr">requests:</span>      <span class="attr">storage:</span> <span class="string">5Gi</span>  <span class="attr">storageClassName:</span> <span class="string">prometheus-storage</span> <span class="comment"># 使用 StorageClass 动态创建PV</span>  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.创建Deployment</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">name:</span> <span class="string">grafana</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">grafana</span>    <span class="attr">spec:</span>      <span class="attr">securityContext:</span>        <span class="attr">fsGroup:</span> <span class="number">472</span>        <span class="attr">supplementalGroups:</span>          <span class="bullet">-</span> <span class="number">0</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grafana</span>          <span class="attr">image:</span> <span class="string">grafana/grafana:8.3.5</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">env:</span>                                    <span class="comment"># 设置grafana初始华用户名和密码</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GF_SECURITY_ADMIN_USER</span>              <span class="attr">value:</span> <span class="string">admin</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GF_SECURITY_ADMIN_PASSWORD</span>              <span class="attr">value:</span> <span class="string">admin</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3000</span>              <span class="attr">name:</span> <span class="string">http-grafana</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">readinessProbe:</span>                         <span class="comment"># 就绪探测</span>            <span class="attr">failureThreshold:</span> <span class="number">10</span>            <span class="attr">httpGet:</span>              <span class="attr">path:</span> <span class="string">/api/health</span>              <span class="attr">port:</span> <span class="number">3000</span>              <span class="attr">scheme:</span> <span class="string">HTTP</span>            <span class="attr">initialDelaySeconds:</span> <span class="number">60</span>               <span class="comment"># 延迟 60秒探测，等待job执行完成</span>            <span class="attr">periodSeconds:</span> <span class="number">10</span>            <span class="attr">successThreshold:</span> <span class="number">1</span>            <span class="attr">timeoutSeconds:</span> <span class="number">30</span>          <span class="attr">livenessProbe:</span>                          <span class="comment"># 存活探测</span>            <span class="attr">failureThreshold:</span> <span class="number">3</span>            <span class="attr">httpGet:</span>              <span class="attr">path:</span> <span class="string">/api/health</span>              <span class="attr">port:</span> <span class="number">3000</span>              <span class="attr">scheme:</span> <span class="string">HTTP</span>            <span class="attr">periodSeconds:</span> <span class="number">10</span>            <span class="attr">successThreshold:</span> <span class="number">1</span>            <span class="attr">timeoutSeconds:</span> <span class="number">1</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="string">500m</span>              <span class="attr">memory:</span> <span class="string">1024Mi</span>            <span class="attr">limits:</span>              <span class="attr">cpu:</span> <span class="string">1000m</span>              <span class="attr">memory:</span> <span class="string">2048Mi</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/lib/grafana</span>              <span class="attr">subPath:</span> <span class="string">grafana</span>              <span class="attr">name:</span> <span class="string">grafana-pv</span>          <span class="attr">securityContext:</span>                  <span class="comment"># 容器以用户id 472 运行</span>            <span class="attr">runAsUser:</span> <span class="number">472</span>      <span class="attr">volumes:</span>                              <span class="comment"># 挂载容器卷</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grafana-pv</span>          <span class="attr">persistentVolumeClaim:</span>            <span class="attr">claimName:</span> <span class="string">grafana-pvc</span>          <span class="comment"># 使用声明的PVC，通过 StorageClass 动态创建PV</span>      <span class="attr">nodeSelector:</span> <span class="comment"># 指定Pod运行的节点</span>        <span class="attr">kubernetes.io/hostname:</span> <span class="string">k8s-node02</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.创建Service</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">3000</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="string">http-grafana</span>      <span class="attr">nodePort:</span> <span class="number">30339</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">type:</span> <span class="string">NodePort</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 创建 job，调整 grafana 挂载目录权限</span><span class="attr">apiVersion:</span> <span class="string">batch/v1</span><span class="attr">kind:</span> <span class="string">Job</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-chown</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">template:</span>    <span class="attr">spec:</span>      <span class="attr">restartPolicy:</span> <span class="string">Never</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grafana-chown</span>          <span class="attr">command:</span> [<span class="string">&quot;chown&quot;</span>, <span class="string">&quot;-R&quot;</span>, <span class="string">&quot;472:472&quot;</span>, <span class="string">&quot;/var/lib/grafana&quot;</span>]          <span class="attr">image:</span> <span class="string">busybox:1.37.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">storage</span>              <span class="attr">subPath:</span> <span class="string">grafana</span>              <span class="attr">mountPath:</span> <span class="string">/var/lib/grafana</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">storage</span>          <span class="attr">persistentVolumeClaim:</span>            <span class="attr">claimName:</span> <span class="string">grafana-pvc</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4.创建 Ingress</span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-ui</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">grafana</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span>       <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">prom.grafana.com</span>    <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 prom.grafana.com 的流量。客户端必须通过该域名访问</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>             <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>    <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">grafana</span>   <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">3000</span>  <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f prometheus-grafana.yaml<span class="comment"># 查看 NFS Server 挂载目录权限</span>$ <span class="built_in">cd</span> /root/data/prometheus/kube-ops/grafana-pvc/$ lltotal 0drwxrwxrwx 6 472 472 77 Jul 23 20:19 grafana<span class="comment"># 查看 Service</span>$ kubectl get svc -n kube-ops | grep grafanagrafana      NodePort   10.109.7.30      &lt;none&gt;        3000:30339/TCP   8m33s<span class="comment"># 查看 Pod</span>$ kubectl get pods -n kube-ops | grep grafanagrafana-b85d687cc-gtrhh       1/1     Running     0          8m41sgrafana-chown-z55rs           0/1     Completed   0          8m41s<span class="comment"># 查看 Job</span>$ kubectl get job -n kube-ops | grep grafanagrafana-chown   1/1           4s         8m50s</code></pre><p><strong>添加 Host 域名映射</strong></p><pre><code class="highlight plaintext">10.20.1.140 prom.grafana.com</code></pre><p><strong>浏览器访问 Grafana</strong></p><p><a href="http://prom.grafana.com/">http://prom.grafana.com/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-204348.png" alt="浏览器访问 Grafana"></p><p>用户名&#x2F;密码：admin&#x2F;admin</p><p><strong>添加Prometheus数据源</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-204501.png" alt="添加Prometheus数据"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-204521.png" alt="添加Prometheus数据源"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-204708.png" alt="配置数据源"></p><p><strong>导入监控配置Json文件</strong></p><p>文件内容如下</p><pre><code class="highlight json"><span class="punctuation">&#123;</span><span class="attr">&quot;__inputs&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;DS_PROMETHEUS&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="string">&quot;prometheus&quot;</span><span class="punctuation">,</span><span class="attr">&quot;description&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;datasource&quot;</span><span class="punctuation">,</span><span class="attr">&quot;pluginId&quot;</span><span class="punctuation">:</span><span class="string">&quot;prometheus&quot;</span><span class="punctuation">,</span><span class="attr">&quot;pluginName&quot;</span><span class="punctuation">:</span><span class="string">&quot;Prometheus&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;__requires&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;grafana&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;grafana&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Grafana&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;5.3.4&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;panel&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;5.0.0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;datasource&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;prometheus&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Prometheus&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;5.0.0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;panel&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;5.0.0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;annotations&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;list&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;builtIn&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;-- Grafana --&quot;</span><span class="punctuation">,</span><span class="attr">&quot;enable&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;hide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;iconColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(0, 211, 255, 1)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Annotations &amp; Alerts&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;dashboard&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;editable&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;gnetId&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;graphTooltip&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;panels&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">40</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Kubernetes 指标&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;row&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">38</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;alignAsTable&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;hideEmpty&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;rightSide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(apiserver_request_total[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;一分钟平均&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(apiserver_request_total[5m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;五分钟平均&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;ApiServer 每分钟请求数&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;cacheTimeout&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;colorBackground&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colorValue&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colors&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;#299c46&quot;</span><span class="punctuation">,</span><span class="string">&quot;rgba(237, 129, 40, 0.89)&quot;</span><span class="punctuation">,</span><span class="string">&quot;#d44a3a&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;gauge&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;maxValue&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;minValue&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdLabels&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdMarkers&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">32</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;mappingType&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;mappingTypes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;value to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;range to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;maxDataPoints&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;connected&quot;</span><span class="punctuation">,</span><span class="attr">&quot;nullText&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;postfix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;postfixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;rangeMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;sparkline&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;fillColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(31, 118, 189, 0.18)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;full&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;lineColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgb(31, 120, 193)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;tableColumn&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;kubelet_active_pods&#123;beta_kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,beta_kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;,instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;,job=\\&quot;</span>kubernetes-kubelet\\<span class="string">&quot;,kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,kubernetes_io_hostname=\\&quot;</span>k8s-master01\\<span class="string">&quot;,kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;,static=\\&quot;</span>\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01 节点 Pod 总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;80%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;op&quot;</span><span class="punctuation">:</span><span class="string">&quot;=&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;valueName&quot;</span><span class="punctuation">:</span><span class="string">&quot;avg&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;cacheTimeout&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;colorBackground&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colorValue&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colors&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;#299c46&quot;</span><span class="punctuation">,</span><span class="string">&quot;rgba(237, 129, 40, 0.89)&quot;</span><span class="punctuation">,</span><span class="string">&quot;#d44a3a&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;gauge&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;maxValue&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;minValue&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdLabels&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdMarkers&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">12</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">34</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;mappingType&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;mappingTypes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;value to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;range to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;maxDataPoints&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;connected&quot;</span><span class="punctuation">,</span><span class="attr">&quot;nullText&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;postfix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;postfixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;rangeMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;sparkline&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;fillColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(31, 118, 189, 0.18)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;full&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;lineColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgb(31, 120, 193)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;tableColumn&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;kubelet_active_pods&#123;kubernetes_io_hostname=\\&quot;</span>k8s-node01\\<span class="string">&quot;,static=\\&quot;</span>\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01 节点 Pod 总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;80%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;op&quot;</span><span class="punctuation">:</span><span class="string">&quot;=&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;valueName&quot;</span><span class="punctuation">:</span><span class="string">&quot;avg&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;cacheTimeout&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;colorBackground&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colorValue&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colors&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;#299c46&quot;</span><span class="punctuation">,</span><span class="string">&quot;rgba(237, 129, 40, 0.89)&quot;</span><span class="punctuation">,</span><span class="string">&quot;#d44a3a&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;gauge&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;maxValue&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;minValue&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdLabels&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdMarkers&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">16</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">36</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;mappingType&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;mappingTypes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;value to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;range to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;maxDataPoints&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;connected&quot;</span><span class="punctuation">,</span><span class="attr">&quot;nullText&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;postfix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;postfixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;rangeMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;sparkline&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;fillColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(31, 118, 189, 0.18)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;full&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;lineColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgb(31, 120, 193)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;tableColumn&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;kubelet_active_pods&#123;kubernetes_io_hostname=\\&quot;</span>k8s-node02\\<span class="string">&quot;,static=\\&quot;</span>\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02 节点 Pod 总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;80%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;op&quot;</span><span class="punctuation">:</span><span class="string">&quot;=&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;valueName&quot;</span><span class="punctuation">:</span><span class="string">&quot;avg&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;collapsed&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;panels&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Kubernetes 物理机&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;row&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;decimals&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">9</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;alignAsTable&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;hideEmpty&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;rightSide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;100 * (1 - avg by (instance) (rate(node_cpu_seconds_total&#123;mode=\\&quot;</span>idle\\<span class="string">&quot;, instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125;[1m])))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;hide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;100 * (1 - avg by (instance) (rate(node_cpu_seconds_total&#123;mode=\\&quot;</span>idle\\<span class="string">&quot;, instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125;[1m])))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;hide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;100 * (1 - avg by (instance) (rate(node_cpu_seconds_total&#123;mode=\\&quot;</span>idle\\<span class="string">&quot;, instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125;[1m])))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;hide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;C&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;CPU 使用量（百分比）&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;current&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">9</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;alignAsTable&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;hideEmpty&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;rightSide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;(node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125; - (node_memory_MemFree_bytes&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125; + node_memory_Buffers_bytes&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125; + node_memory_Cached_bytes&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125;)) / node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125; * 100&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01 节点&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;(node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125; - (node_memory_MemFree_bytes&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125; + node_memory_Buffers_bytes&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125; + node_memory_Cached_bytes&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125;)) / node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125; * 100&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01 节点&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;(node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125; - (node_memory_MemFree_bytes&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125; + node_memory_Buffers_bytes&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125; + node_memory_Cached_bytes&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125;)) / node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125; * 100&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;hide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02 节点&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;C&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;内存使用量（百分比）&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;current&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;decimals&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">16</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">9</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">18</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;node_filesystem_avail_bytes&#123;device=\\&quot;</span>/dev/mapper/rl-root\\<span class="string">&quot;,mountpoint=\\&quot;</span>/rootfs\\<span class="string">&quot;,instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;node_filesystem_avail_bytes&#123;device=\\&quot;</span>/dev/mapper/rl-root\\<span class="string">&quot;,mountpoint=\\&quot;</span>/rootfs\\<span class="string">&quot;,instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;node_filesystem_avail_bytes&#123;device=\\&quot;</span>/dev/mapper/rl-root\\<span class="string">&quot;,mountpoint=\\&quot;</span>/rootfs\\<span class="string">&quot;,instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;C&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;存储空间剩余量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;current&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;bytes&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">15</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">12</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_receive_bytes_total&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01 下行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_transmit_bytes_total&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01 上行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_receive_bytes_total&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01  下行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;C&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_transmit_bytes_total&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01 上行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;D&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_receive_bytes_total&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02 下行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;E&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_transmit_bytes_total&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02 上行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;F&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;网络 IO&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;collapsed&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">21</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">16</span><span class="punctuation">,</span><span class="attr">&quot;panels&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;repeat&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Pod&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;row&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">22</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">20</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;100 *  (sum(rate(container_cpu_usage_seconds_total&#123;namespace=\\&quot;</span>kube-system\\<span class="string">&quot;, pod=\\&quot;</span>kube-apiserver-k8s-master01\\<span class="string">&quot;&#125;[1m])) by (namespace, pod))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;apiServer&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Pod  CPU 使用量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">22</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">22</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(container_memory_usage_bytes&#123;namespace=\\&quot;</span>kube-system\\<span class="string">&quot;, pod=\\&quot;</span>kube-apiserver-k8s-master01\\<span class="string">&quot;&#125;) by (namespace, pod)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;apiServer&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Pod 内存使用量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;bytes&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;collapsed&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">29</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;panels&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Ingress-Nginx&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;row&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;cacheTimeout&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;colorBackground&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colorValue&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colors&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;#299c46&quot;</span><span class="punctuation">,</span><span class="string">&quot;rgba(237, 129, 40, 0.89)&quot;</span><span class="punctuation">,</span><span class="string">&quot;#d44a3a&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;gauge&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;maxValue&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;minValue&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdLabels&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdMarkers&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">30</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">28</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;mappingType&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;mappingTypes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;value to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;range to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;maxDataPoints&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;connected&quot;</span><span class="punctuation">,</span><span class="attr">&quot;nullText&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;postfix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;postfixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;rangeMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;sparkline&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;fillColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(31, 118, 189, 0.18)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;full&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;lineColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgb(31, 120, 193)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;tableColumn&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;nginx_ingress_controller_success&#123;job=\\&quot;</span>ingressnginx12\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;node01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;node01 节点 Nginx-ingress 重载次数&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;80%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;op&quot;</span><span class="punctuation">:</span><span class="string">&quot;=&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;valueName&quot;</span><span class="punctuation">:</span><span class="string">&quot;avg&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;cacheTimeout&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;colorBackground&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colorValue&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colors&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;#299c46&quot;</span><span class="punctuation">,</span><span class="string">&quot;rgba(237, 129, 40, 0.89)&quot;</span><span class="punctuation">,</span><span class="string">&quot;#d44a3a&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;gauge&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;maxValue&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;minValue&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdLabels&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdMarkers&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">30</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">30</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;mappingType&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;mappingTypes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;value to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;range to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;maxDataPoints&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;connected&quot;</span><span class="punctuation">,</span><span class="attr">&quot;nullText&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;postfix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;postfixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;rangeMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;sparkline&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;fillColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(31, 118, 189, 0.18)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;full&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;lineColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgb(31, 120, 193)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;tableColumn&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;nginx_ingress_controller_success&#123;job=\\&quot;</span>ingressnginx13\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;node02 节点 Nginx-ingress 重载次数&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;80%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;op&quot;</span><span class="punctuation">:</span><span class="string">&quot;=&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;valueName&quot;</span><span class="punctuation">:</span><span class="string">&quot;avg&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">32</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;nginx_ingress_controller_nginx_process_requests_total&#123;controller_class=\\&quot;</span>k8s.io/ingress-nginx\\<span class="string">&quot;,controller_namespace=\\&quot;</span>ingress\\<span class="string">&quot;,controller_pod=\\&quot;</span>ingress-nginx-controller-c5h6j\\<span class="string">&quot;,instance=\\&quot;</span><span class="number">192.168</span><span class="number">.10</span><span class="number">.12</span><span class="punctuation">:</span><span class="number">10254</span>\\<span class="string">&quot;,job=\\&quot;</span>ingressnginx12\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;node01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;nginx_ingress_controller_nginx_process_requests_total&#123;controller_class=\\&quot;</span>k8s.io/ingress-nginx\\<span class="string">&quot;,controller_namespace=\\&quot;</span>ingress\\<span class="string">&quot;,controller_pod=\\&quot;</span>ingress-nginx-controller-c5h6j\\<span class="string">&quot;,instance=\\&quot;</span><span class="number">192.168</span><span class="number">.10</span><span class="number">.12</span><span class="punctuation">:</span><span class="number">10254</span>\\<span class="string">&quot;,job=\\&quot;</span>ingressnginx12\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;node02&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Ingress-Nginx 请求量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;collapsed&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">37</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;panels&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;NFS-StorageClass&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;row&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">38</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">14</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;node_nfsd_disk_bytes_read_total&#123;beta_kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,beta_kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;,instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;,job=\\&quot;</span>kubernetes-nodes\\<span class="string">&quot;,kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,kubernetes_io_hostname=\\&quot;</span>k8s-master01\\<span class="string">&quot;,kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;读取总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;node_nfsd_disk_bytes_written_total&#123;beta_kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,beta_kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;,instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;,job=\\&quot;</span>kubernetes-nodes\\<span class="string">&quot;,kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,kubernetes_io_hostname=\\&quot;</span>k8s-master01\\<span class="string">&quot;,kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;写入总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;NFS storageClass 读取文件总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;decbytes&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;refresh&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;schemaVersion&quot;</span><span class="punctuation">:</span><span class="number">16</span><span class="punctuation">,</span><span class="attr">&quot;style&quot;</span><span class="punctuation">:</span><span class="string">&quot;dark&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tags&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;templating&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;list&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;time&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;now-6h&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;now&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;timepicker&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;refresh_intervals&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;5s&quot;</span><span class="punctuation">,</span><span class="string">&quot;10s&quot;</span><span class="punctuation">,</span><span class="string">&quot;30s&quot;</span><span class="punctuation">,</span><span class="string">&quot;1m&quot;</span><span class="punctuation">,</span><span class="string">&quot;5m&quot;</span><span class="punctuation">,</span><span class="string">&quot;15m&quot;</span><span class="punctuation">,</span><span class="string">&quot;30m&quot;</span><span class="punctuation">,</span><span class="string">&quot;1h&quot;</span><span class="punctuation">,</span><span class="string">&quot;2h&quot;</span><span class="punctuation">,</span><span class="string">&quot;1d&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;time_options&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;5m&quot;</span><span class="punctuation">,</span><span class="string">&quot;15m&quot;</span><span class="punctuation">,</span><span class="string">&quot;1h&quot;</span><span class="punctuation">,</span><span class="string">&quot;6h&quot;</span><span class="punctuation">,</span><span class="string">&quot;12h&quot;</span><span class="punctuation">,</span><span class="string">&quot;24h&quot;</span><span class="punctuation">,</span><span class="string">&quot;2d&quot;</span><span class="punctuation">,</span><span class="string">&quot;7d&quot;</span><span class="punctuation">,</span><span class="string">&quot;30d&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;timezone&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Kubernetes 监控&quot;</span><span class="punctuation">,</span><span class="attr">&quot;uid&quot;</span><span class="punctuation">:</span><span class="string">&quot;Lwdu47xIk&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="number">33</span><span class="punctuation">&#125;</span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-082411.png" alt="导入监控配置Json文件"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-082434.png" alt="选择json文件"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-082630.png" alt="点击导入"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-082736.png" alt="查看监控指标"></p><h1 id="十一、监控-metrics-server"><a href="#十一、监控-metrics-server" class="headerlink" title="十一、监控 metrics.server"></a>十一、监控 metrics.server</h1><p>从 Kubernetes v1.8 开始，资源使用情况的监控可以通过 Metrics API 的形式获取，例如容器 CPU 和内存使用率。这些度量可以由用户直接访问（例如，通过使用 kubectl top 命令），或者由集群中的控制器（例如，Horizontal Pod Autoscaler）使用来进行决策，具体的组件为 Metrics Server，用来替换之前的 heapster，heapster 从 1.11 开始逐渐被废弃。</p><p>Metrics-Server 是集群核心监控数据的聚合器。通俗地说，它存储了集群中各节点的监控数据，并且提供了 API 以供分析和使用。Metrics-Server 作为一个 Deployment 对象默认部署在 Kubernetes 集群中。不过准确地说，它是 Deployment，Service，ClusterRole，ClusterRoleBinding，APIService，RoleBinding 等资源对象的综合体。</p><pre><code class="highlight bash"><span class="comment"># https://github.com/kubernetes-sigs/metrics-server</span>https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.7.0/components.yaml</code></pre><p>当前 K8S 版本 1.29.0 ，使用 Metrics Server 版本 0.7.0.</p><p>下载后的资源清单稍作修改，<strong>跳过 Kubelet TLS 验证</strong></p><p><code>components.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>    <span class="attr">rbac.authorization.k8s.io/aggregate-to-admin:</span> <span class="string">&quot;true&quot;</span>    <span class="attr">rbac.authorization.k8s.io/aggregate-to-edit:</span> <span class="string">&quot;true&quot;</span>    <span class="attr">rbac.authorization.k8s.io/aggregate-to-view:</span> <span class="string">&quot;true&quot;</span>  <span class="attr">name:</span> <span class="string">system:aggregated-metrics-reader</span><span class="attr">rules:</span><span class="bullet">-</span> <span class="attr">apiGroups:</span>  <span class="bullet">-</span> <span class="string">metrics.k8s.io</span>  <span class="attr">resources:</span>  <span class="bullet">-</span> <span class="string">pods</span>  <span class="bullet">-</span> <span class="string">nodes</span>  <span class="attr">verbs:</span>  <span class="bullet">-</span> <span class="string">get</span>  <span class="bullet">-</span> <span class="string">list</span>  <span class="bullet">-</span> <span class="string">watch</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">system:metrics-server</span><span class="attr">rules:</span><span class="bullet">-</span> <span class="attr">apiGroups:</span>  <span class="bullet">-</span> <span class="string">&quot;&quot;</span>  <span class="attr">resources:</span>  <span class="bullet">-</span> <span class="string">nodes/metrics</span>  <span class="attr">verbs:</span>  <span class="bullet">-</span> <span class="string">get</span><span class="bullet">-</span> <span class="attr">apiGroups:</span>  <span class="bullet">-</span> <span class="string">&quot;&quot;</span>  <span class="attr">resources:</span>  <span class="bullet">-</span> <span class="string">pods</span>  <span class="bullet">-</span> <span class="string">nodes</span>  <span class="attr">verbs:</span>  <span class="bullet">-</span> <span class="string">get</span>  <span class="bullet">-</span> <span class="string">list</span>  <span class="bullet">-</span> <span class="string">watch</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server-auth-reader</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="attr">roleRef:</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">Role</span>  <span class="attr">name:</span> <span class="string">extension-apiserver-authentication-reader</span><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server:system:auth-delegator</span><span class="attr">roleRef:</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">name:</span> <span class="string">system:auth-delegator</span><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">system:metrics-server</span><span class="attr">roleRef:</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">name:</span> <span class="string">system:metrics-server</span><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="attr">spec:</span>  <span class="attr">ports:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https</span>    <span class="attr">port:</span> <span class="number">443</span>    <span class="attr">protocol:</span> <span class="string">TCP</span>    <span class="attr">targetPort:</span> <span class="string">https</span>  <span class="attr">selector:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">strategy:</span>    <span class="attr">rollingUpdate:</span>      <span class="attr">maxUnavailable:</span> <span class="number">0</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>      <span class="bullet">-</span> <span class="attr">args:</span>        <span class="bullet">-</span> <span class="string">--cert-dir=/tmp</span>        <span class="bullet">-</span> <span class="string">--secure-port=10250</span>        <span class="bullet">-</span> <span class="string">--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span>        <span class="bullet">-</span> <span class="string">--kubelet-use-node-status-port</span>        <span class="bullet">-</span> <span class="string">--kubelet-insecure-tls</span>  <span class="comment"># 跳过 Kubelet TLS 验证</span>        <span class="bullet">-</span> <span class="string">--metric-resolution=15s</span>        <span class="attr">image:</span> <span class="string">registry.k8s.io/metrics-server/metrics-server:v0.7.0</span>        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>        <span class="attr">livenessProbe:</span>          <span class="attr">failureThreshold:</span> <span class="number">3</span>          <span class="attr">httpGet:</span>            <span class="attr">path:</span> <span class="string">/livez</span>            <span class="attr">port:</span> <span class="string">https</span>            <span class="attr">scheme:</span> <span class="string">HTTPS</span>          <span class="attr">periodSeconds:</span> <span class="number">10</span>        <span class="attr">name:</span> <span class="string">metrics-server</span>        <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">10250</span>          <span class="attr">name:</span> <span class="string">https</span>          <span class="attr">protocol:</span> <span class="string">TCP</span>        <span class="attr">readinessProbe:</span>          <span class="attr">failureThreshold:</span> <span class="number">3</span>          <span class="attr">httpGet:</span>            <span class="attr">path:</span> <span class="string">/readyz</span>            <span class="attr">port:</span> <span class="string">https</span>            <span class="attr">scheme:</span> <span class="string">HTTPS</span>          <span class="attr">initialDelaySeconds:</span> <span class="number">20</span>          <span class="attr">periodSeconds:</span> <span class="number">10</span>        <span class="attr">resources:</span>          <span class="attr">requests:</span>            <span class="attr">cpu:</span> <span class="string">100m</span>            <span class="attr">memory:</span> <span class="string">200Mi</span>        <span class="attr">securityContext:</span>          <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span>          <span class="attr">capabilities:</span>            <span class="attr">drop:</span>            <span class="bullet">-</span> <span class="string">ALL</span>          <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span>          <span class="attr">runAsNonRoot:</span> <span class="literal">true</span>          <span class="attr">runAsUser:</span> <span class="number">1000</span>          <span class="attr">seccompProfile:</span>            <span class="attr">type:</span> <span class="string">RuntimeDefault</span>        <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/tmp</span>          <span class="attr">name:</span> <span class="string">tmp-dir</span>      <span class="attr">nodeSelector:</span>        <span class="attr">kubernetes.io/os:</span> <span class="string">linux</span>      <span class="attr">priorityClassName:</span> <span class="string">system-cluster-critical</span>      <span class="attr">serviceAccountName:</span> <span class="string">metrics-server</span>      <span class="attr">volumes:</span>      <span class="bullet">-</span> <span class="attr">emptyDir:</span> &#123;&#125;        <span class="attr">name:</span> <span class="string">tmp-dir</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">apiregistration.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">APIService</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">v1beta1.metrics.k8s.io</span><span class="attr">spec:</span>  <span class="attr">group:</span> <span class="string">metrics.k8s.io</span>  <span class="attr">groupPriorityMinimum:</span> <span class="number">100</span>  <span class="attr">insecureSkipTLSVerify:</span> <span class="literal">true</span>  <span class="attr">service:</span>    <span class="attr">name:</span> <span class="string">metrics-server</span>    <span class="attr">namespace:</span> <span class="string">kube-system</span>  <span class="attr">version:</span> <span class="string">v1beta1</span>  <span class="attr">versionPriority:</span> <span class="number">100</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，部署 metrics-server</span>$ kubectl apply -f components.yaml<span class="comment"># 查看 Pod</span>$ kubectl get pod -n kube-system  -o wide -w | grep metrics-server metrics-server-56cfc8b678-b77wb            1/1     Running   0               59s   192.168.85.217   k8s-node01     &lt;none&gt;           &lt;none&gt;</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-104820.png" alt="metric-server 监控数据原理"></p><h1 id="十二、alertmanager-部署"><a href="#十二、alertmanager-部署" class="headerlink" title="十二、alertmanager 部署"></a>十二、alertmanager 部署</h1><h2 id="1-创建-alertmanager-配置文件"><a href="#1-创建-alertmanager-配置文件" class="headerlink" title="1. 创建 alertmanager 配置文件"></a>1. 创建 alertmanager 配置文件</h2><p>资源清单：<code>alertmanager-conf.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">alert-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">config.yml:</span> <span class="string">|-</span><span class="string">    global:</span><span class="string">      # 定义告警在没有新触发的情况下被标记为已解决（resolved）的时间，设置为 5 分钟。</span><span class="string">      resolve_timeout: 5m</span><span class="string">      # 配置邮件发送信息</span><span class="string">      smtp_smarthost: &#x27;smtp.163.com:25&#x27;             # 指定 SMTP 服务器地址和端口，用于发送邮件通知</span><span class="string">      smtp_from: &#x27;18326088610@163.com&#x27;              # 邮件发送者的地址，显示为发件人（From 字段）</span><span class="string">      smtp_auth_username: &#x27;18326088610@163.com&#x27;     # SMTP 认证用户名，与发件人地址一致</span><span class="string">      smtp_auth_password: &#x27;xxxxxxxxxxxxxxxx&#x27;        # SMTP 认证密码，通常是 163 邮箱的授权码（非登录密码）</span><span class="string">      smtp_hello: &#x27;163.com&#x27;                         # SMTP 客户端在与服务器建立连接时发送的 HELO/EHLO 域名，设置为 163.com</span><span class="string">      smtp_require_tls: false                       # 禁用 TLS 加密，邮件通过明文传输（端口 25 通常不加密）</span><span class="string">    route:    # 定义告警的路由策略，决定如何分组、处理和分发告警</span><span class="string">      # 这里的标签列表是接收到报警信息后的重新分组标签，例如，接收到的报警信息里面有许多具有 cluster=A 和 alertname=LatncyHigh 这样的标签的报警信息将会批量被聚合到一个分组里面</span><span class="string">      group_by: [&#x27;alertname&#x27;, &#x27;cluster&#x27;]</span><span class="string">      # 当一个新的报警分组被创建后，需要等待至少group_wait时间来初始化通知，这种方式可以确保您能有足够的时间为同一分组来获取多个警报，然后一起触发这个报警信息。</span><span class="string">      group_wait: 30s</span><span class="string">      # 当第一个报警发送后，等待&#x27;group_interval&#x27;时间来发送新的一组报警信息。</span><span class="string">      group_interval: 5m</span><span class="string">      # 如果一个报警信息已经发送成功了，等待&#x27;repeat_interval&#x27;时间来重新发送他们</span><span class="string">      repeat_interval: 5m</span><span class="string">      # 默认的receiver：如果一个报警没有被一个route匹配，则发送给默认的接收器</span><span class="string">      receiver: default</span><span class="string">      # 上面所有的属性都由所有子路由继承，并且可以在每个子路由上进行覆盖。</span><span class="string">      routes:</span><span class="string">        - receiver: email   # 匹配子路由的告警发送到 email 接收器</span><span class="string">          group_wait: 10s   # 子路由覆盖父路由的 group_wait，仅等待 10 秒发送通知</span><span class="string">          match:</span><span class="string">            team: node      # 仅匹配带有标签 team=node 的告警（如 Prometheus 规则中定义的 HighNodeCPU 告警）</span><span class="string">    receivers:              # 定义告警通知的接收器，指定通知方式和目标</span><span class="string">      - name: &#x27;default&#x27;</span><span class="string">        email_configs:</span><span class="string">          - to: &#x27;george_95@126.com&#x27;     # 告警邮件发送到 george_95@126.com</span><span class="string">            send_resolved: true         # 当告警解决时，发送“已恢复”通知邮件</span><span class="string">      - name: &#x27;email&#x27;                   # 自定义接收器，处理匹配 team: node 的告警</span><span class="string">        email_configs:</span><span class="string">          - to: &#x27;george_95@126.com&#x27;     # 告警邮件发送到 george_95@126.com</span><span class="string">            send_resolved: true         # 当告警解决时，发送“已恢复”通知邮件</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f alertmanager-conf.yaml</code></pre><h2 id="2-修改-Prometheus-ConfigMap-2"><a href="#2-修改-Prometheus-ConfigMap-2" class="headerlink" title="2. 修改 Prometheus ConfigMap"></a>2. 修改 Prometheus ConfigMap</h2><p><code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">rules.yml:</span> <span class="string">|</span>          <span class="comment"># 配置Prometheus告警规则，内存使用超过 20% 就告警</span>    <span class="attr">groups:</span>      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-rule</span>        <span class="attr">rules:</span>          <span class="bullet">-</span> <span class="attr">alert:</span> <span class="string">NodeMemoryUsage</span>            <span class="attr">expr:</span> <span class="string">(node_memory_MemTotal_bytes</span> <span class="bullet">-</span> <span class="string">(node_memory_MemFree_bytes</span> <span class="string">+</span> <span class="string">node_memory_Buffers_bytes</span> <span class="string">+</span> <span class="string">node_memory_Cached_bytes))</span> <span class="string">/</span> <span class="string">node_memory_MemTotal_bytes</span> <span class="string">*</span> <span class="number">100</span> <span class="string">&gt;</span> <span class="number">20</span>            <span class="attr">for:</span> <span class="string">2m</span>       <span class="comment"># 告警条件需持续满足 2 分钟（2m）才会触发</span>            <span class="attr">labels:</span>       <span class="comment"># 为告警添加标签 team=node，用于路由和分组</span>              <span class="attr">team:</span> <span class="string">node</span>            <span class="attr">annotations:</span>  <span class="comment"># 提供告警的附加信息，显示在通知（如邮件）中</span>              <span class="attr">summary:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>: High Memory usage detected&quot;</span>              <span class="attr">description:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>: Memory usage is above 20% (current value is: <span class="template-variable">&#123;&#123; $value &#125;&#125;</span>&quot;</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-cadvisor&#x27;</span>                                         <span class="comment"># 抓取任务名称为 kubernetes-cadvisor，用于监控 Kubernetes 节点的 cAdvisor 指标</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                           <span class="comment"># 指定使用 HTTPS 协议访问目标（Kubernetes API 服务器的 443 端口）</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Pod 内部的服务账号卷挂载的 CA 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌</span>      <span class="attr">relabel_configs:</span>                                              <span class="comment"># 定义标签重写规则，修改服务发现的目标地址和路径</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                                          <span class="comment"># 规则1：将节点的标签（如 kubernetes.io/hostname）映射到 Prometheus 指标标签 </span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span>                   <span class="comment"># 规则2：将抓取目标地址设置为 kubernetes.default.svc:443，即 Kubernetes API 服务器的 ClusterIP 服务（默认命名空间 default，端口 443）</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]              <span class="comment"># 规则3：使用节点名称（__meta_kubernetes_node_name，如 node01）动态构造指标路径</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-apiservers&#x27;</span>                             <span class="comment"># 抓取任务名称为 kubernetes-apiservers，用于监控 Kubernetes API 服务器的指标，包括请求速率、延迟、错误率等（如 apiserver_request_total, apiserver_request_duration_seconds）</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                                           <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中的所有 Endpoints 对象</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                 <span class="comment"># Kubernetes API 服务器默认通过 HTTPS（端口 443）暴露 /metrics 端点</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Prometheus Pod 内部的服务账号卷挂载的 CA 证书（位于 /var/run/secrets/kubernetes.io/serviceaccount/ca.crt）验证 API 服务器的 TLS 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌（位于 /var/run/secrets/kubernetes.io/serviceaccount/token）进行身份验证</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>, <span class="string">__meta_kubernetes_service_name</span>, <span class="string">__meta_kubernetes_endpoint_port_name</span>]    <span class="comment"># 断点所在的名称空间，断点所在的 Service， 断点端口名称</span>          <span class="attr">action:</span> <span class="string">keep</span>                      <span class="comment"># 仅保留匹配正则表达式的端点，未匹配的端点被丢弃。</span>          <span class="attr">regex:</span> <span class="string">default;kubernetes;https</span>   <span class="comment"># 确保 Prometheus 只抓取 default 命名空间中 kubernetes 服务的 HTTPS 端点（即 API 服务器的 /metrics）</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-service-endpoints&#x27;</span>        <span class="comment"># 抓取任务名称为 kubernetes-service-endpoints，用于监控 Kubernetes Service 的 Endpoints 指标。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                             <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中所有 Service 的 Endpoints 对象</span>      <span class="attr">relabel_configs:</span>                                <span class="comment"># 定义标签重写规则，过滤和配置服务发现的目标，确保只抓取符合条件的 Service Endpoints</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scrape</span>]          <span class="attr">action:</span> <span class="string">keep</span>                                <span class="comment"># 仅保留注解 prometheus.io/scrape: &quot;true&quot; 的 Service Endpoints，未匹配的被丢弃</span>          <span class="attr">regex:</span> <span class="literal">true</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scheme</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将匹配的值替换到 __scheme__ 标签，决定抓取协议（http 或 https），允许 Service 指定是否通过 HTTPS 抓取指标，适用于需要安全连接的场景</span>          <span class="attr">target_label:</span> <span class="string">__scheme__</span>          <span class="attr">regex:</span> <span class="string">(https?)</span>                             <span class="comment"># 匹配 http 或 https，若注解未设置，默认使用 http</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_path</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 检查 Service 的注解 prometheus.io/path，将匹配的值替换到 __metrics_path__ 标签，指定指标端点的路径</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>, <span class="string">__meta_kubernetes_service_annotation_prometheus_io_port</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将地址和端口组合替换到 __address__ 标签，允许 Service 指定抓取端口（如 prometheus.io/port: &quot;8080&quot;），覆盖 Endpoints 的默认端口</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">regex:</span> <span class="string">([^:]+)(?::\d+)?;(\d+)</span>          <span class="attr">replacement:</span> <span class="string">$1:$2</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                            <span class="comment"># 将 Service 的标签（如 app=my-app）映射到 Prometheus 指标标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_service_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>]      <span class="comment"># 将 Service 的命名空间（__meta_kubernetes_namespace）写入指标标签 kubernetes_namespace</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_namespace</span>                  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_name</span>]   <span class="comment"># 将 Service 名称（__meta_kubernetes_service_name）写入指标标签 kubernetes_name</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_name</span>              <span class="attr">alerting:</span>               <span class="comment"># 定义 Prometheus 与 Alertmanager 的连接，用于发送告警</span>      <span class="attr">alertmanagers:</span>        <span class="comment"># 指定 Alertmanager 实例的地址</span>        <span class="bullet">-</span> <span class="attr">static_configs:</span>            <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&quot;prometheus.kube-ops.svc.cluster.local:9093&quot;</span>]   <span class="comment"># &lt;service-name&gt;.&lt;namespace&gt;.svc.&lt;cluster-domain&gt;，注意 这里Service名称是 prometheus</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f prometheus-cm.yaml</code></pre><h2 id="3-修改-Prometheus-Service"><a href="#3-修改-Prometheus-Service" class="headerlink" title="3. 修改 Prometheus Service"></a>3. 修改 Prometheus Service</h2><p>资源清单：<code>prometheus.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># Service</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">prometheus</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">prometheus</span>  <span class="attr">type:</span> <span class="string">NodePort</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="comment"># 端口名称</span>      <span class="attr">port:</span> <span class="number">9090</span>            <span class="comment"># service 对外端口 9090</span>      <span class="attr">targetPort:</span> <span class="number">9090</span>      <span class="comment"># 内部名为 http 的端口 （9090）</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alertmanager</span>    <span class="comment"># altermanager 端口配置</span>      <span class="attr">port:</span> <span class="number">9093</span>      <span class="attr">targetPort:</span> <span class="number">9093</span></code></pre><h2 id="4-合并-altermanager-至-prometheus-deploy-文件"><a href="#4-合并-altermanager-至-prometheus-deploy-文件" class="headerlink" title="4. 合并 altermanager 至 prometheus deploy 文件"></a>4. 合并 altermanager 至 prometheus deploy 文件</h2><p>资源清单：<code>prometheus.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">prometheus</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>               <span class="comment"># Pod 副本数为1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">prometheus</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">prometheus</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">prometheus</span>    <span class="comment"># 指定 Pod 使用的 Kubernetes 服务账号（ServiceAccount）为 prometheus</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alertmanager</span>          <span class="attr">image:</span> <span class="string">prom/alertmanager:v0.28.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">&quot;--config.file=/etc/alertmanager/config.yml&quot;</span>            <span class="bullet">-</span> <span class="string">&quot;--storage.path=/alertmanager/data&quot;</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9093</span>              <span class="attr">name:</span> <span class="string">alertmanager</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/etc/alertmanager&quot;</span>              <span class="attr">name:</span> <span class="string">alertcfg</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="string">300m</span>              <span class="attr">memory:</span> <span class="string">512Mi</span>            <span class="attr">limits:</span>              <span class="attr">cpu:</span> <span class="string">300m</span>              <span class="attr">memory:</span> <span class="string">512Mi</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">prometheus</span>          <span class="attr">image:</span> <span class="string">prom/prometheus:v2.54.1</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&quot;/bin/prometheus&quot;</span>         <span class="comment"># 指定容器启动时运行的命令为 /bin/prometheus，这是 Prometheus 的主可执行文件</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">&quot;--config.file=/etc/prometheus/prometheus.yml&quot;</span>    <span class="comment"># 指定 Prometheus 的配置文件路径为 /etc/prometheus/prometheus.yml，这个文件由 ConfigMap（prometheus-config）提供，挂载到容器内</span>            <span class="bullet">-</span> <span class="string">&quot;--storage.tsdb.path=/prometheus&quot;</span>                 <span class="comment"># 指定 Prometheus 时间序列数据库（TSDB）的存储路径为 /prometheus，这个路径由 PVC（prometheus）提供，持久化存储数据</span>            <span class="bullet">-</span> <span class="string">&quot;--storage.tsdb.retention=24h&quot;</span>                    <span class="comment"># 设置数据保留时间为 24 小时，意味着 Prometheus 只保留最近 24 小时的监控数据，旧数据将被删除。生产环境建议 15-30天</span>            <span class="bullet">-</span> <span class="string">&quot;--web.enable-admin-api&quot;</span>                          <span class="comment"># 启用 Prometheus 的 Admin HTTP API，允许执行管理操作（如删除时间序列）</span>            <span class="bullet">-</span> <span class="string">&quot;--web.enable-lifecycle&quot;</span>                          <span class="comment"># 启用生命周期 API，支持通过 HTTP 请求（如 localhost:9090/-/reload）动态重新加载配置文件。</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9090</span>       <span class="comment"># 指定 Prometheus 监听端口，用于提供 Web UI 和 API</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>              <span class="attr">name:</span> <span class="string">http</span>          <span class="attr">volumeMounts:</span>                 <span class="comment"># 定义容器内的挂载点，将卷挂载到指定路径</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/prometheus&quot;</span>  <span class="comment"># 将名为 data 的卷挂载到容器内的 /prometheus 路径，用于存储 TSDB 数据</span>              <span class="attr">subPath:</span> <span class="string">prometheus</span>       <span class="comment"># 表示使用卷中的子路径 prometheus，避免覆盖整个卷的其他内容</span>              <span class="attr">name:</span> <span class="string">data</span>                <span class="comment"># 卷由 PVC（prometheus）提供</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/etc/prometheus&quot;</span>      <span class="comment"># 将名为 config-volume 的卷挂载到容器内的 /etc/prometheus 路径，用于存储配置文件</span>              <span class="attr">name:</span> <span class="string">config-volume</span>               <span class="comment"># 由 ConfigMap（prometheus-config）提供</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="string">500m</span>                 <span class="comment"># 请求 100 毫核（0.1 CPU 核心），表示容器需要的最小 CPU 资源</span>              <span class="attr">memory:</span> <span class="string">1024Mi</span>             <span class="comment"># 请求 512 MiB 内存，表示容器需要的最小内存</span>            <span class="attr">limits:</span>              <span class="attr">cpu:</span> <span class="string">500m</span>                 <span class="comment"># 限制容器最多使用 100 毫核 CPU，防止过量占用</span>              <span class="attr">memory:</span> <span class="string">1024Mi</span>             <span class="comment"># 限制容器最多使用 512 MiB 内存，防止内存溢出</span>      <span class="attr">securityContext:</span>                  <span class="comment"># 定义 Pod 的安全上下文，控制容器运行时的权限</span>        <span class="attr">runAsUser:</span> <span class="number">0</span>                    <span class="comment"># 指定容器以用户 ID 0（即 root 用户）运行</span>      <span class="attr">volumes:</span>                          <span class="comment"># 定义 Pod 使用的卷，供容器挂载</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span>          <span class="attr">persistentVolumeClaim:</span>        <span class="comment"># 指定挂载的PVC</span>            <span class="attr">claimName:</span> <span class="string">prometheus</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span>          <span class="attr">configMap:</span>                    <span class="comment"># 指定挂载的 configMap</span>            <span class="attr">name:</span> <span class="string">prometheus-config</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alertcfg</span>                <span class="comment"># 挂载AlertManager ConfigMap</span>          <span class="attr">configMap:</span>            <span class="attr">name:</span> <span class="string">alert-config</span></code></pre><p>这里要注意 prometheus 和 alertmanager 不能太旧，否则无法适配当前的 SMTP 协议。</p><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，重新加载 Service 和 Deployment</span>$ kubectl apply -f prometheus.yaml</code></pre><h2 id="5-添加报警演示"><a href="#5-添加报警演示" class="headerlink" title="5. 添加报警演示"></a>5. 添加报警演示</h2><p>修改 Prometheus ConfigMap，添加监控 <strong>内存使用量</strong></p><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">rules.yml:</span> <span class="string">|</span>          <span class="comment"># 配置Prometheus告警规则，内存使用超过 20% 就告警</span>    <span class="attr">groups:</span>      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-rule</span>        <span class="attr">rules:</span>          <span class="bullet">-</span> <span class="attr">alert:</span> <span class="string">NodeMemoryUsage</span>            <span class="attr">expr:</span> <span class="string">(node_memory_MemTotal_bytes</span> <span class="bullet">-</span> <span class="string">(node_memory_MemFree_bytes</span> <span class="string">+</span> <span class="string">node_memory_Buffers_bytes</span> <span class="string">+</span> <span class="string">node_memory_Cached_bytes))</span> <span class="string">/</span> <span class="string">node_memory_MemTotal_bytes</span> <span class="string">*</span> <span class="number">100</span> <span class="string">&gt;</span> <span class="number">20</span>            <span class="attr">for:</span> <span class="string">2m</span>       <span class="comment"># 告警条件需持续满足 2 分钟（2m）才会触发</span>            <span class="attr">labels:</span>       <span class="comment"># 为告警添加标签 team=node，用于路由和分组</span>              <span class="attr">team:</span> <span class="string">node</span>            <span class="attr">annotations:</span>  <span class="comment"># 提供告警的附加信息，显示在通知（如邮件）中</span>              <span class="attr">summary:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>: High Memory usage detected&quot;</span>              <span class="attr">description:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>: Memory usage is above 20% (current value is: <span class="template-variable">&#123;&#123; $value &#125;&#125;</span>&quot;</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-cadvisor&#x27;</span>                                         <span class="comment"># 抓取任务名称为 kubernetes-cadvisor，用于监控 Kubernetes 节点的 cAdvisor 指标</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                           <span class="comment"># 指定使用 HTTPS 协议访问目标（Kubernetes API 服务器的 443 端口）</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Pod 内部的服务账号卷挂载的 CA 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌</span>      <span class="attr">relabel_configs:</span>                                              <span class="comment"># 定义标签重写规则，修改服务发现的目标地址和路径</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                                          <span class="comment"># 规则1：将节点的标签（如 kubernetes.io/hostname）映射到 Prometheus 指标标签 </span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span>                   <span class="comment"># 规则2：将抓取目标地址设置为 kubernetes.default.svc:443，即 Kubernetes API 服务器的 ClusterIP 服务（默认命名空间 default，端口 443）</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]              <span class="comment"># 规则3：使用节点名称（__meta_kubernetes_node_name，如 node01）动态构造指标路径</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-apiservers&#x27;</span>                             <span class="comment"># 抓取任务名称为 kubernetes-apiservers，用于监控 Kubernetes API 服务器的指标，包括请求速率、延迟、错误率等（如 apiserver_request_total, apiserver_request_duration_seconds）</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                                           <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中的所有 Endpoints 对象</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                 <span class="comment"># Kubernetes API 服务器默认通过 HTTPS（端口 443）暴露 /metrics 端点</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Prometheus Pod 内部的服务账号卷挂载的 CA 证书（位于 /var/run/secrets/kubernetes.io/serviceaccount/ca.crt）验证 API 服务器的 TLS 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌（位于 /var/run/secrets/kubernetes.io/serviceaccount/token）进行身份验证</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>, <span class="string">__meta_kubernetes_service_name</span>, <span class="string">__meta_kubernetes_endpoint_port_name</span>]    <span class="comment"># 断点所在的名称空间，断点所在的 Service， 断点端口名称</span>          <span class="attr">action:</span> <span class="string">keep</span>                      <span class="comment"># 仅保留匹配正则表达式的端点，未匹配的端点被丢弃。</span>          <span class="attr">regex:</span> <span class="string">default;kubernetes;https</span>   <span class="comment"># 确保 Prometheus 只抓取 default 命名空间中 kubernetes 服务的 HTTPS 端点（即 API 服务器的 /metrics）</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-service-endpoints&#x27;</span>        <span class="comment"># 抓取任务名称为 kubernetes-service-endpoints，用于监控 Kubernetes Service 的 Endpoints 指标。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                             <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中所有 Service 的 Endpoints 对象</span>      <span class="attr">relabel_configs:</span>                                <span class="comment"># 定义标签重写规则，过滤和配置服务发现的目标，确保只抓取符合条件的 Service Endpoints</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scrape</span>]          <span class="attr">action:</span> <span class="string">keep</span>                                <span class="comment"># 仅保留注解 prometheus.io/scrape: &quot;true&quot; 的 Service Endpoints，未匹配的被丢弃</span>          <span class="attr">regex:</span> <span class="literal">true</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scheme</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将匹配的值替换到 __scheme__ 标签，决定抓取协议（http 或 https），允许 Service 指定是否通过 HTTPS 抓取指标，适用于需要安全连接的场景</span>          <span class="attr">target_label:</span> <span class="string">__scheme__</span>          <span class="attr">regex:</span> <span class="string">(https?)</span>                             <span class="comment"># 匹配 http 或 https，若注解未设置，默认使用 http</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_path</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 检查 Service 的注解 prometheus.io/path，将匹配的值替换到 __metrics_path__ 标签，指定指标端点的路径</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>, <span class="string">__meta_kubernetes_service_annotation_prometheus_io_port</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将地址和端口组合替换到 __address__ 标签，允许 Service 指定抓取端口（如 prometheus.io/port: &quot;8080&quot;），覆盖 Endpoints 的默认端口</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">regex:</span> <span class="string">([^:]+)(?::\d+)?;(\d+)</span>          <span class="attr">replacement:</span> <span class="string">$1:$2</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                            <span class="comment"># 将 Service 的标签（如 app=my-app）映射到 Prometheus 指标标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_service_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>]      <span class="comment"># 将 Service 的命名空间（__meta_kubernetes_namespace）写入指标标签 kubernetes_namespace</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_namespace</span>                  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_name</span>]   <span class="comment"># 将 Service 名称（__meta_kubernetes_service_name）写入指标标签 kubernetes_name</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_name</span>              <span class="attr">alerting:</span>               <span class="comment"># 定义 Prometheus 与 Alertmanager 的连接，用于发送告警</span>      <span class="attr">alertmanagers:</span>        <span class="comment"># 指定 Alertmanager 实例的地址</span>        <span class="bullet">-</span> <span class="attr">static_configs:</span>            <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&quot;prometheus.kube-ops.svc.cluster.local:9093&quot;</span>]   <span class="comment"># &lt;service-name&gt;.&lt;namespace&gt;.svc.&lt;cluster-domain&gt;</span>                  <span class="attr">rule_files:</span>             <span class="comment"># 指定告警规则文件路径</span>      <span class="bullet">-</span> <span class="string">/etc/prometheus/rules.yml</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，重新加载 ConfigMap</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment">#  热更新 ConfingMap</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGEgrafana      NodePort   10.109.7.30      &lt;none&gt;        3000:30339/TCP                  19hprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP,9093:31878/TCP   44h$ curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p><strong>浏览器访问 Prometheus 查看告警规则是否生效</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-162449.png" alt="查看告警规则是否生效"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-205334.png" alt="AlertManager触发告警"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-205424.png" alt="接收到告警邮件"></p><p><strong>参考链接</strong></p><blockquote><p><a href="https://zhangquan.me/2022/09/04/shi-yong-prometheus-jian-kong-kubernetes-ji-qun-jie-dian/">https://zhangquan.me/2022/09/04/shi-yong-prometheus-jian-kong-kubernetes-ji-qun-jie-dian/</a></p><p><a href="https://cloudmessage.top/archives/prometheus-shou-dong-pei-zhi-jian-kong-kubernetesji-qun">https://cloudmessage.top/archives/prometheus-shou-dong-pei-zhi-jian-kong-kubernetesji-qun</a></p><p><a href="https://www.cnblogs.com/cyh00001/p/16725312.html">https://www.cnblogs.com/cyh00001/p/16725312.html</a></p><p><a href="https://csms.tech/202212141608/#%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF">https://csms.tech/202212141608/#%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;概要：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;简述 Loki 相关组件原理，并演示两种使用 Loki 监控Pod日志的部署方式：&lt;strong&gt;使用 yaml 资源清单部署&lt;/strong&gt; 和 &lt;strong&gt;使用 Helm 部署&lt;/strong&gt;&lt;/p&gt;
&lt;p</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Prometheus" scheme="https://georgechan95.github.io/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>014-K8S-部署Loki+Promtail+Grafana实现日志监控</title>
    <link href="https://georgechan95.github.io/blog/f8cf646f.html"/>
    <id>https://georgechan95.github.io/blog/f8cf646f.html</id>
    <published>2025-07-10T13:00:00.000Z</published>
    <updated>2025-07-22T06:19:53.678Z</updated>
    
    <content type="html"><![CDATA[<p><strong>概要：</strong></p><p>简述 Loki 相关组件原理，并演示两种使用 Loki 监控Pod日志的部署方式：<strong>使用 yaml 资源清单部署</strong> 和 <strong>使用 Helm 部署</strong></p><p><strong>集群环境</strong></p><table><thead><tr><th>IP</th><th>Hostname</th><th>用途</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td><td>Master节点，NFS Server</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td><td>Node节点, NFS Client</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td><td>Node节点, NFS Client</td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td><td>安装NFS，Harbor, NFS Client</td></tr></tbody></table><h1 id="一、Loki-简介"><a href="#一、Loki-简介" class="headerlink" title="一、Loki 简介"></a>一、Loki 简介</h1><p>是一个水平可扩展，高可用性，多租户的日志聚合系统，Loki 是基于仅索引有关日志元数据的想法而构建的：<strong>标签</strong>（就像 Prometheus 标签一样）。日志数据本身被压缩然后并存储在对象存储（例如 S3 或 GCS）的块中，甚至存储在本地文件系统上，轻量级的索引和高度压缩的块简化了操作，并显著降低了 Loki 的成本，Loki 更适合中小团队。由于 Loki 使用和 Prometheus 类似的标签概念，所以如果你熟悉 Prometheus 那么将很容易上手，也可以直接和 Grafana 集成，只需要添加 Loki 数据源就可以开始查询日志数据了。</p><p>Loki 还提供了一个专门用于日志查询的 <code>LogQL</code> 查询语句，类似于 <code>PromQL</code>，通过 LogQL 我们可以很容易查询到需要的日志，也可以很轻松获取监控指标。Loki 还能够将 LogQL 查询直接转换为 Prometheus 指标。此外 Loki 允许我们定义有关 LogQL 指标的报警，并可以将它们和 Alertmanager 进行对接。</p><p>Loki技术栈中使用了以下组件。</p><ul><li><p>Promtail</p><p>用来将容器日志发送到 Loki 或者 Grafana 服务上的日志收集工具，该工具主要包括发现采集目标以及给日志流添加上 Label 标签 然后发送给 Loki，Promtail 的服务发现是基于 Prometheus 的服务发现机制实现的。</p><p>相当于 EFK 中的 Filebeat&#x2F;Fluentd ，用于采集日志并将其发送给 Loki 。</p></li><li><p>Loki</p><p>受 Prometheus 启发的可以水平扩展、高可用以及支持多租户的日志聚合系统，使用了和 Prometheus 相同的服务发现机制，将标签添加到日志流中而不是构建全文索引，从 Promtail 接收到的日志和应用的 metrics 指标就具有相同的标签集，不仅提供了更好的日志和指标之间的上下文切换，还避免了对日志进行全文索引。</p><p>相当于 EFK 中的 ElasticSearch ，用于存储日志和处理查询。</p></li><li><p>Grafana</p><p>一个用于监控和可视化观测的开源平台，支持非常丰富的数据源，在 Loki 技术栈中它专门用来展示来自 Prometheus 和 Loki 等数据源的时间序列数据，可进行查询、可视化、报警等操作，可以用于创建、探索和共享数据 Dashboard，鼓励数据驱动。</p><p>相当于 EFK 中的 Kibana ，用于 UI 的展示。</p></li></ul><p><strong>Loki的工作原理如下图所示：</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/12/20250712-131130.png" alt="Loki原理"></p><p>Loki 针对本地运行（或小规模运行）和水平扩展进行了优化，Loki 带有单一进程模式，可在一个进程中运行所有必需的微服务。单进程模式非常适合测试 Loki 或以小规模运行。为了实现水平可伸缩性，可以将 Loki 的服务拆分为单独的组件，从而使它们彼此独立地扩展。每个组件都产生一个用于内部请求的 gRPC 服务器和一个用于外部 API 请求的 HTTP 服务，所有组件都带有 HTTP 服务器，但是大多数只暴露就绪接口、运行状况和指标端点。</p><h2 id="1-Loki-组件"><a href="#1-Loki-组件" class="headerlink" title="1. Loki 组件"></a>1. Loki 组件</h2><p>Loki 运行哪个组件取决于命令行中的 <code>-target</code> 标志或 Loki 的配置文件中的 <code>target：&lt;string&gt;</code> 配置。 当 target 的值为 <code>all</code> 时，Loki 将在单进程中运行其所有组件。这称为 <code>单进程</code> 或 <code>单体模式</code> 。 <em>使用 Helm 安装 Loki 时，单体模式是默认部署方式</em>。</p><p>当 target 未设置为 all（即被设置为 <code>querier</code>、<code>ingester</code>、<code>query-frontend</code> 或 <code>distributor</code>），则可以说 Loki 在 <code>水平伸缩</code> 或 <code>微服务模式</code> 下运行。</p><p>Loki 的每个组件，例如 <code>ingester</code> 和 <code>distributors</code> 都使用 Loki 配置中定义的 gRPC 监听端口通过 gRPC 相互通信。当以单体模式运行组件时，仍然是这样的，尽管每个组件都以相同的进程运行，但它们仍将通过本地网络相互连接进行组件之间的通信。</p><p>单体模式非常适合于本地开发、小规模等场景，单体模式可以通过多个进程进行扩展，但有以下限制：</p><ul><li>当运行带有多个副本的单体模式时，当前无法使用本地索引和本地存储，因为每个副本必须能够访问相同的存储后端，并且本地存储对于并发访问并不安全。</li><li>各个组件无法独立缩放，因此读取组件的数量不能超过写入组件的数量。</li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/12/20250712-132416.png" alt="Loki组件"></p><h3 id="1-1-Distributor"><a href="#1-1-Distributor" class="headerlink" title="1.1 Distributor"></a>1.1 Distributor</h3><p><code>distributor</code> 服务负责处理客户端写入的日志，它本质上是日志数据写入路径中的<strong>第一站</strong>，一旦 <code>distributor</code> 收到日志数据，会将其拆分为多个批次，然后并行发送给多个 <code>ingester</code>。<code>distributor</code> 通过 gRPC 与 <code>ingester</code> 通信，它们都是无状态的，所以可以根据需要扩大或缩小规模。</p><p><strong>Hashing</strong></p><p><code>distributor</code> 将<strong>一致性 Hash</strong>和可配置的复制因子结合使用，以确定 <code>ingester</code> 服务的哪些实例应该接收指定的数据流。</p><p>流是一组与<strong>租户和唯一标签集</strong>关联的日志，使用租户 ID 和标签集对流进行 hash 处理，然后使用哈希查询要发送流的 <code>ingester</code>。</p><p>存储在 <strong>Consul&#x2F;Etcd</strong> 中的哈希环被用来实现一致性哈希，所有的 <code>ingester</code> 都会使用自己拥有的一组 Token 注册到哈希环中，每个 Token 是一个随机的无符号 32 位数字，与一组 Token 一起，<code>ingester</code> 将其状态注册到哈希环中，状态 <code>JOINING</code> 和 <code>ACTIVE</code> 都可以接收写请求，而 <code>ACTIVE</code> 和 <code>LEAVING</code> 的 <code>ingester</code> 可以接收读请求。在进行哈希查询时，<code>distributor</code> 只使用处于请求的适当状态的 ingester 的 Token。</p><p>为了进行哈希查找，<code>distributor</code> 找到最小合适的 Token，其值大于日志流的哈希值，当复制因子大于 1 时，属于不同 <code>ingester</code> 的下一个后续 Token（在环中顺时针方向）也将被包括在结果中。</p><p>这种哈希配置的效果是，一个 <code>ingester</code> 拥有的每个 Token 都负责一个范围的哈希值，如果有三个值为 0、25 和 50 的 Token，那么 3 的哈希值将被给予拥有 25 这个 Token 的 <code>ingester</code>，拥有 25 这个 Token 的 <code>ingester</code> 负责<code>1-25</code>的哈希值范围。</p><h3 id="1-2-Ingester"><a href="#1-2-Ingester" class="headerlink" title="1.2 Ingester"></a>1.2 Ingester</h3><p><code>ingester</code> 负责接收 <code>distributor</code>  发送过来的日志数据，存储日志的索引数据以及内容数据。此外 <code>ingester</code> 会验证摄取的日志行是否按照时间戳递增的顺序接收的（即每条日志的时间戳都比前面的日志晚一些），当 <code>ingester</code> 收到不符合这个顺序的日志时，该日志行会被拒绝并返回一个错误。</p><ul><li><p>如果传入的行与之前收到的行完全匹配（与之前的时间戳和日志文本都匹配），传入的行将被视为完全重复并被忽略。</p></li><li><p>如果传入的行与前一行的时间戳相同，但内容不同，则接受该日志行，表示同一时间戳有两个不同的日志行是可能的。</p></li></ul><p>来自每个唯一标签集的日志在内存中被建立成 <code>chunks(块)</code>，然后可以根据配置的时间间隔刷新到支持的后端存储。在下列情况下，块被压缩并标记为只读：</p><ul><li>当前块容量已满（该值可配置）</li><li>过了太长时间没有更新当前块的内容</li><li>刷新了</li></ul><p>每当一个数据块被压缩并标记为只读时，一个可写的数据块就会取代它。<em>如果一个 <code>ingester</code> 进程崩溃或突然退出，所有尚未刷新的数据都会丢失，Loki 通常配置为多个副本来降低这种风险</em>。</p><p>当向持久存储刷新时，该块将根据其租户、标签和内容进行哈希处理，这意味着具有相同数据副本的多个 <code>ingester</code> 实例不会将相同的数据两次写入备份存储中，但如果对其中一个副本的写入失败，则会在备份存储中创建多个不同的块对象。（当写入因子大于1时，比如：3， 那么日志数据将会由3个不同的 Ingester 共同处理。每个日志都会计算出一个唯一hash值，同一个日志在不同的Ingester中 hash 值是相同的，正常情况下只会往持久存储中（入S3，minio）写入一次，如果某个Ingester 写入失败了，可能导入数据被重复写入持久存储中。）</p><p><strong>WAL</strong></p><p>上面我们提到了 <code>ingester</code> 将数据临时存储在内存中，如果发生了崩溃，可能会导致数据丢失，而 <code>WAL</code> 就可以帮助我们来提高这方面的可靠性。</p><p>在计算机领域，WAL（Write-ahead logging，预写式日志）是数据库系统提供原子性和持久化的一系列技术。</p><p>在使用 WAL 的系统中，所有的修改都先被写入到日志中，然后再被应用到系统状态中。通常包含 redo 和 undo 两部分信息。为什么需要使用 WAL，然后包含 redo 和 undo 信息呢？举个例子，如果一个系统直接将变更应用到系统状态中，那么在机器断电重启之后系统需要知道操作是成功了，还是只有部分成功或者是失败了（为了恢复状态）。如果使用了 WAL，那么在重启之后系统可以通过比较日志和系统状态来决定是继续完成操作还是撤销操作。</p><p><code>redo log</code> 称为重做日志，每当有操作时，在数据变更之前将操作写入 <code>redo log</code>，这样当发生断电之类的情况时系统可以在重启后继续操作。<code>undo log</code> 称为撤销日志，当一些变更执行到一半无法完成时，可以根据撤销日志恢复到变更之前的状态。</p><p>Loki 中的 WAL 记录了传入的数据，并将其存储在本地文件系统中，以保证在进程崩溃的情况下持久保存已确认的数据。重新启动后，Loki 将<strong>重放</strong>日志中的所有数据，然后将自身注册，准备进行后续写操作。这使得 Loki 能够保持在内存中缓冲数据的性能和成本优势，以及持久性优势（一旦写被确认，它就不会丢失数据）。</p><p>Loki 通过校验日志的 Hash 值，以及在 WAL 中创建检查点，确保重放时数据不会重复。</p><h3 id="1-3-Querier"><a href="#1-3-Querier" class="headerlink" title="1.3 Querier"></a>1.3 Querier</h3><p><code>Querier</code> 接收日志数据查询、聚合统计请求，使用 LogQL 查询语言处理查询，从 <code>ingester</code> 和长期存储中获取日志。</p><p>查询器查询所有 <code>ingester</code> 的内存数据，然后再到后端存储运行相同的查询。由于复制因子，查询器有可能会收到重复的数据。为了解决这个问题，查询器在内部对具有相同纳秒时间戳、标签集和日志信息的数据进行重复数据删除。</p><h3 id="1-4-Query-Frontend"><a href="#1-4-Query-Frontend" class="headerlink" title="1.4 Query Frontend"></a>1.4 Query Frontend</h3><p><code>Query Frontend</code> 查询前端是一个可选的服务，可以用来加速读取路径。当查询前端就位时，将传入的查询请求定向到查询前端，而不是 <code>querier</code>, 为了执行实际的查询，群集中仍需要 <code>querier</code> 服务。</p><p>查询前端在内部执行一些查询调整，并在内部队列中保存查询。<code>querier</code> 作为 workers 从队列中提取作业，执行它们，并将它们返回到查询前端进行汇总。<code>querier</code> 需要配置查询前端地址，以便允许它们连接到查询前端。</p><p>查询前端是无状态的，然而，由于内部队列的工作方式，建议运行几个查询前台的副本，以获得公平调度的好处，在大多数情况下，两个副本应该足够了。</p><p><strong>队列</strong></p><p>查询前端的排队机制用于：</p><ul><li>确保可能导致 <code>querier</code> 出现内存不足（OOM）错误的查询在失败时被重试。这样管理员就可以为查询提供稍低的内存，或者并行运行更多的小型查询，这有助于降低总成本。</li><li>通过使用先进先出队列（FIFO）将多个大型请求分配到所有 <code>querier</code> 上，以防止在单个 <code>querier</code> 中进行多个大型请求。</li><li>通过在租户之间公平调度查询。</li></ul><p><strong>分割</strong></p><p>查询前端将较大的查询分割成多个较小的查询，在下游 <code>querier</code> 上并行执行这些查询，并将结果再次拼接起来。这可以防止大型查询在单个查询器中造成内存不足的问题，并有助于更快地执行这些查询。</p><p><strong>缓存</strong></p><p>查询前端支持缓存查询结果，并在后续查询中重复使用。如果缓存的结果不完整，查询前端会计算所需的子查询，并在下游 <code>querier</code> 上并行执行这些子查询。查询前端可以选择将查询与其 <code>step</code> 参数对齐，以提高查询结果的可缓存性。</p><p><strong>举例</strong></p><p>假设你用 Grafana 查询 Loki 中的日志数据，系统中有 Query Frontend 和多个 Querier：</p><ol><li>客户端发送查询：<ul><li>你在 Grafana 输入查询 {app&#x3D;”frontend”} |~ “error”，请求发送到 Query Frontend。</li></ul></li><li>Query Frontend 处理：<ul><li>Query Frontend 接收请求，可能将查询拆分成多个子查询（比如按时间范围分成 3 段）。</li><li>这些子查询被放入内部队列，等待处理。</li></ul></li><li>Querier 执行查询：<ul><li>集群中有 3 个 Querier（Q1、Q2、Q3），它们连接到 Query Frontend，从队列中领取子查询任务。</li><li>Q1 取第一个子查询，Q2 取第二个，Q3 取第三个，分别去 ingester 或 S3 查询日志数据。</li></ul></li><li>结果汇总：<ul><li>Querier 完成查询后，将结果返回给 Query Frontend。</li><li>Query Frontend 合并 3 个子查询的结果，形成完整的日志列表，返回给 Grafana。</li></ul></li><li>多个副本：<ul><li>如果有 2 个 Query Frontend 副本，客户端请求可能随机分配到其中一个。</li><li>Querier 同时连接到两个副本的队列，动态领取任务，确保负载均衡。</li></ul></li></ol><h3 id="1-5-读取路径"><a href="#1-5-读取路径" class="headerlink" title="1.5 读取路径"></a>1.5 读取路径</h3><p>日志读取路径的流程如下所示：</p><ul><li>查询器收到一个对数据的 HTTP 请求。</li><li>查询器将查询传递给所有 <code>ingester</code>。</li><li><code>ingester</code> 收到读取请求，并返回与查询相匹配的数据。</li><li>如果没有 <code>ingester</code> 返回数据，查询器会从后端存储加载数据，并对其运行查询。</li><li>查询器对所有收到的数据进行迭代和重复计算，通过 HTTP 连接返回最后一组数据。</li></ul><p><strong>举个例子</strong></p><p>假设你在 Grafana 中查询 {app&#x3D;”frontend”} |~ “error”，时间范围是过去 6 小时：</p><ol><li>客户端发送请求：<ul><li>Grafana 通过 HTTP 发送查询到 Querier。</li></ul></li><li>Querier 分发查询：<ul><li>Querier 将查询 {app&#x3D;”frontend”} |~ “error” 广播给集群中的 3 个 Ingester（I1、I2、I3）。</li></ul></li><li>Ingester 处理：<ul><li>I1 发现自己有部分匹配的日志（比如过去 2 小时的数据），返回这些日志。</li><li>I2 和 I3 可能也有部分数据（由于复制因子），返回相同的或不同的日志。</li></ul></li><li>后端存储查询：<ul><li>如果查询的 6 小时范围超出了 Ingester 的内存存储（比如 Ingester 只存 4 小时数据），Querier 会从 S3 加载更老的块（4-6 小时的数据），并执行查询。</li></ul></li><li>合并和去重：<ul><li>Querier 收集 I1、I2、I3 和 S3 返回的数据。</li><li>如果 I1 和 I2 返回了相同的日志（由于复制），Querier 通过哈希值或时间戳去重。</li><li>Querier 按时间排序所有日志，生成最终结果。</li></ul></li><li>返回结果：<ul><li>Querier 通过 HTTP 返回整理好的日志列表，Grafana 显示这些日志。</li></ul></li></ol><h3 id="1-6-写入路径"><a href="#1-6-写入路径" class="headerlink" title="1.6 写入路径"></a>1.6 写入路径</h3><p>整体的日志写入路径如下所示：</p><ul><li><code>distributor</code> 收到一个 HTTP 请求，以存储流的数据。</li><li>每个流都使用哈希环进行哈希操作。</li><li><code>distributor</code> 将每个流发送到合适的 <code>ingester</code> 和他们的副本（基于配置的复制因子）。</li><li>每个 <code>ingester</code> 将为日志流数据创建一个块或附加到一个现有的块上。每个租户和每个标签集的块是唯一的。</li></ul><h2 id="2-Promtail"><a href="#2-Promtail" class="headerlink" title="2. Promtail"></a>2. Promtail</h2><p><a href="https://grafana.com/docs/loki/latest/send-data/promtail/">官方文档</a></p><p>promtail 是 loki 架构中最常用的采集器, 相当于 EFK 中的 filebeat&#x2F;fluentd 。</p><p>Promtail 是 Loki 官方支持的日志采集端，在需要采集日志的节点上运行采集代理，再统一发送到 Loki 进行处理。除了使用 Promtail，社区还有很多采集日志的组件，比如 fluentd、fluent bit、logstash 等，也都支持发送到 Loki。</p><p>但是 Promtail 是运行 Kubernetes 时的首选客户端，因为你可以将其配置为自动从 Promtail 运行的同一节点上运行的 Pod 中抓取日志。Promtail 和 Prometheus 在 Kubernetes 中一起运行，还可以实现非常强大的调试功能，如果 Prometheus 和 Promtail 使用相同的标签，用户还可以使用 Grafana 根据标签集在指标和日志之间切换。</p><p>它的主要工作流程:</p><ul><li>使用 fsnotify 监听指定目录下（例如：&#x2F;var&#x2F;log&#x2F;*.log）的文件创建与删除</li><li>对每个活跃的日志文件起一个 goroutine 进行类似 tail -f 的读取，读取到的内容发送给 channel</li><li>有一个单独的 goroutine 会读取 channel 中的日志行，分批并附加上标签后推送给 Loki</li></ul><h1 id="二、使用YAML部署-Loki"><a href="#二、使用YAML部署-Loki" class="headerlink" title="二、使用YAML部署 Loki"></a>二、使用YAML部署 Loki</h1><p>这次部署的 loki 整体架构如下, </p><ul><li>loki 使用 <code>StatefulSet</code> 的方式运行,</li><li>Promtail 以 <code>DaemonSet</code> 的方式运行在 k8s 集群的每个节点</li><li>Grafana 以 Deploment 方式运行，通过 Ingress 暴露访问端口</li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/12/20250712-161149.jpeg" alt="Loki-Promtail部署"></p><h2 id="1-Promtail部署"><a href="#1-Promtail部署" class="headerlink" title="1. Promtail部署"></a>1. Promtail部署</h2><h3 id="1-1-Promtail-部署文件"><a href="#1-1-Promtail-部署文件" class="headerlink" title="1.1 Promtail 部署文件"></a>1.1 Promtail 部署文件</h3><p>资源清单：<code>loki-promtail.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">logging</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.ServiceAccount</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki-promtail</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">promtail</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.集群角色</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">promtail-clusterrole</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">promtail</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 核心组</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="string">nodes</span>      <span class="bullet">-</span> <span class="string">nodes/proxy</span>      <span class="bullet">-</span> <span class="string">services</span>      <span class="bullet">-</span> <span class="string">endpoints</span>      <span class="bullet">-</span> <span class="string">pods</span>    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># 4.集群角色绑定</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">promtail-clusterrolebinding</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">promtail</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">loki-promtail</span>    <span class="attr">kind:</span> <span class="string">ServiceAccount</span>    <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">roleRef:</span>  <span class="attr">name:</span> <span class="string">promtail-clusterrole</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 5.ConfigMap</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki-promtail</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">promtail</span><span class="attr">data:</span>  <span class="attr">promtail.yaml:</span> <span class="string">|</span><span class="string">    client:                # 定义 Promtail 如何与 Loki 服务器通信，发送收集到的日志</span><span class="string">      backoff_config:      # 配置当请求失败时的重试策略</span><span class="string">        max_period: 1s     # 重试间隔的最大时间为 1 秒</span><span class="string">        max_retries: 20    # 最多重试 20 次</span><span class="string">        min_period: 500ms  # 重试间隔的最小时间为 500 毫秒</span><span class="string">      batchsize: 10240        # 每次发送到 Loki 的日志批次最大大小为 10240 字节（约 10KB）</span><span class="string">      batchwait: 2s           # 即使批次大小未达到 batchsize，Promtail 最多等待 2 秒后也会发送日志。这是为了避免延迟过高</span><span class="string">      external_labels: &#123;&#125;     # 为所有发送到 Loki 的日志添加静态标签，这里为空（可以手动添加标签，如 env: prod）</span><span class="string">      timeout: 15s            # 等待 Loki 服务器响应的最大时间为 15 秒，超时后请求失败并触发重试</span><span class="string">    positions:</span><span class="string">      filename: /run/promtail/positions.yaml # Promtail 使用一个文件来记录它读取日志文件的位置（类似于书签），以避免重复读取或遗漏日志</span><span class="string">    server:</span><span class="string">      http_listen_port: 3101  # 配置 Promtail 自身的 HTTP 服务，用于暴露监控指标或调试</span><span class="string">    target_config:</span><span class="string">      sync_period: 10s        # 控制 Promtail 如何定期同步其发现目标（如 Kubernetes Pods）的元数据。</span><span class="string">    scrape_configs:           # 定义 Promtail 如何发现和收集 Kubernetes 集群中的日志。scrape_configs 包含多个任务（job），每个任务针对不同类型的 Pod 进行日志收集</span><span class="string">      - job_name: kubernetes-pods-name  # 收集由 name 标签定义的 Pod 日志</span><span class="string">        pipeline_stages:</span><span class="string">          - docker: &#123;&#125;                  # 指定日志格式为 Docker 格式（JSON 格式的容器日志）。Promtail 会解析 Docker 容器日志，提取时间戳和日志内容</span><span class="string">        kubernetes_sd_configs:</span><span class="string">          - role: pod                   # Promtail 通过 Kubernetes 服务发现（Service Discovery）查找 Pod，收集它们的日志</span><span class="string">        relabel_configs:</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_name  # 从 Pod 的标签中提取 name 标签的值，设置为 __service__ 标签</span><span class="string">            target_label: __service__             # Kubernetes Pod 可能有标签 name=my-app，Promtail 将其值 my-app 保存为 __service__，用于标识服务</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_node_name   # 将 Pod 所在节点的名称设置为 __host__ 标签</span><span class="string">            target_label: __host__                # 记录 Pod 运行在哪个 Kubernetes 节点上（比如 node-1），便于日志追踪</span><span class="string">          - action: drop                          # 如果 __service__ 标签为空（即 Pod 没有 name 标签），丢弃该 Pod，不收集其日志</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __service__</span><span class="string">          - action: labelmap                      # 将所有以 __meta_kubernetes_pod_label_ 开头的元数据标签（如 __meta_kubernetes_pod_label_app）映射为普通标签</span><span class="string">            regex: __meta_kubernetes_pod_label_(.+)</span><span class="string">          - action: replace                       # 将命名空间（namespace）和 __service__ 组合成 job 标签，格式为 namespace/service</span><span class="string">            replacement: $1</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace       # 如果命名空间是 default，__service__ 是 my-app，则 job 标签为 default/my-app</span><span class="string">              - __service__</span><span class="string">            target_label: job</span><span class="string">          - action: replace                       # 将 Pod 的命名空间设置为 namespace 标签</span><span class="string">            source_labels:                        # 如果 Pod 在 default 命名空间，日志会带上 namespace=default 标签</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">            target_label: namespace</span><span class="string">          - action: replace                       # 将 Pod 的名称设置为 pod 标签</span><span class="string">            source_labels:                        # 如果 Pod 名为 my-app-1234，日志会带上 pod=my-app-1234 标签</span><span class="string">              - __meta_kubernetes_pod_name</span><span class="string">            target_label: pod</span><span class="string">          - action: replace                       # 将容器的名称设置为 container 标签</span><span class="string">            source_labels:                        # 如果容器名为 app-container，日志会带上 container=app-container 标签</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: container</span><span class="string">          - replacement: /var/log/pods/*$1/*.log  # 生成日志文件的路径，告诉 Promtail 从哪里读取日志，路径格式为 /var/log/pods/*&lt;pod_uid&gt;/&lt;container_name&gt;.log</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_uid               # Pod 的唯一 ID</span><span class="string">              - __meta_kubernetes_pod_container_name    # 容器名称</span><span class="string">            target_label: __path__                      # 例如，Pod UID 是 abc-123，容器名为 app-container，日志路径为 /var/log/pods/*abc-123/app-container.log</span><span class="string">      - job_name: kubernetes-pods-app # 收集由 app 标签定义的 Pod 日志</span><span class="string">        pipeline_stages:</span><span class="string">          - docker: &#123;&#125;</span><span class="string">        kubernetes_sd_configs:</span><span class="string">          - role: pod</span><span class="string">        relabel_configs:</span><span class="string">          - action: drop</span><span class="string">            regex: .+</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_name</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_app</span><span class="string">            target_label: __service__</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_node_name</span><span class="string">            target_label: __host__</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __service__</span><span class="string">          - action: labelmap</span><span class="string">            regex: __meta_kubernetes_pod_label_(.+)</span><span class="string">          - action: replace</span><span class="string">            replacement: $1</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">              - __service__</span><span class="string">            target_label: job</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">            target_label: namespace</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_name</span><span class="string">            target_label: pod</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: container</span><span class="string">          - replacement: /var/log/pods/*$1/*.log</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_uid</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: __path__</span><span class="string">      - job_name: kubernetes-pods-direct-controllers # 收集由直接控制器（如 Deployment）管理的 Pod 日志</span><span class="string">        pipeline_stages:</span><span class="string">          - docker: &#123;&#125;</span><span class="string">        kubernetes_sd_configs:</span><span class="string">          - role: pod</span><span class="string">        relabel_configs:</span><span class="string">          - action: drop # 首先检查 __meta_kubernetes_pod_label_name（name 标签）</span><span class="string">            regex: .+       # 如果 name 标签存在（匹配正则 .+，即非空），执行 drop 动作，丢弃该 Pod</span><span class="string">            separator: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_name</span><span class="string">              - __meta_kubernetes_pod_label_app</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;[0-9a-z-.]+-[0-9a-f]&#123;8,10&#125;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_controller_name</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_controller_name</span><span class="string">            target_label: __service__</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_node_name</span><span class="string">            target_label: __host__</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __service__</span><span class="string">          - action: labelmap</span><span class="string">            regex: __meta_kubernetes_pod_label_(.+)</span><span class="string">          - action: replace</span><span class="string">            replacement: $1</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">              - __service__</span><span class="string">            target_label: job</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">            target_label: namespace</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_name</span><span class="string">            target_label: pod</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: container</span><span class="string">          - replacement: /var/log/pods/*$1/*.log</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_uid</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: __path__</span><span class="string">      - job_name: kubernetes-pods-indirect-controller # 收集由间接控制器（如 ReplicaSet）管理的 Pod 日志</span><span class="string">        pipeline_stages:</span><span class="string">          - docker: &#123;&#125;</span><span class="string">        kubernetes_sd_configs:</span><span class="string">          - role: pod</span><span class="string">        relabel_configs:</span><span class="string">          - action: drop        # 如果 Pod 有 name 或 app 标签，触发 drop 动作，丢弃该 Pod</span><span class="string">            regex: .+</span><span class="string">            separator: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_name</span><span class="string">              - __meta_kubernetes_pod_label_app</span><span class="string">          - action: keep        # 如果 Pod 由 ReplicaSet 控制器管理（控制器名称匹配 xxx-12345678 模式），触发 keep 动作，保留该 Pod</span><span class="string">            regex: &#x27;[0-9a-z-.]+-[0-9a-f]&#123;8,10&#125;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_controller_name</span><span class="string">          - action: replace</span><span class="string">            regex: &#x27;([0-9a-z-.]+)-[0-9a-f]&#123;8,10&#125;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_controller_name</span><span class="string">            target_label: __service__</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_node_name</span><span class="string">            target_label: __host__</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __service__</span><span class="string">          - action: labelmap</span><span class="string">            regex: __meta_kubernetes_pod_label_(.+)</span><span class="string">          - action: replace</span><span class="string">            replacement: $1</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">              - __service__</span><span class="string">            target_label: job</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">            target_label: namespace</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_name</span><span class="string">            target_label: pod</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: container</span><span class="string">          - replacement: /var/log/pods/*$1/*.log</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_uid</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: __path__</span><span class="string">      - job_name: kubernetes-pods-static # 收集静态配置的 Pod 日志（基于特定的注解）</span><span class="string">        pipeline_stages:</span><span class="string">          - docker: &#123;&#125;</span><span class="string">        kubernetes_sd_configs:</span><span class="string">          - role: pod</span><span class="string">        relabel_configs:</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_annotation_kubernetes_io_config_mirror</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_component</span><span class="string">            target_label: __service__</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_node_name</span><span class="string">            target_label: __host__</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __service__</span><span class="string">          - action: labelmap</span><span class="string">            regex: __meta_kubernetes_pod_label_(.+)</span><span class="string">          - action: replace</span><span class="string">            replacement: $1</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">              - __service__</span><span class="string">            target_label: job</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">            target_label: namespace</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_name</span><span class="string">            target_label: pod</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: container</span><span class="string">          - replacement: /var/log/pods/*$1/*.log</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_annotation_kubernetes_io_config_mirror</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: __path__</span><span class="string"></span><span class="meta">---</span><span class="meta"></span><span class="comment"># 6.DaemonSet</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">DaemonSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki-promtail</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">promtail</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">promtail</span>  <span class="attr">updateStrategy:</span> <span class="comment"># 更新策略</span>    <span class="attr">rollingUpdate:</span>      <span class="attr">maxUnavailable:</span> <span class="number">1</span> <span class="comment"># 滚动更新时最多一个pod不可用，即同一时刻只允许一个节点上的Pod不可用</span>    <span class="attr">type:</span> <span class="string">RollingUpdate</span> <span class="comment"># 滚动更新</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">promtail</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">loki-promtail</span> <span class="comment"># 绑定的SA</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">promtail</span>          <span class="attr">image:</span> <span class="string">grafana/promtail:2.9.2</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">-config.file=/etc/promtail/promtail.yaml</span>        <span class="comment"># 指定 Promtail 的配置文件路径，位于容器内的 /etc/promtail/promtail.yaml（由 ConfigMap 提供）</span>            <span class="bullet">-</span> <span class="string">-client.url=http://loki:3100/loki/api/v1/push</span>   <span class="comment"># 指定 Loki 服务器的地址，Promtail 将日志发送到 http://loki:3100/loki/api/v1/push</span>          <span class="attr">env:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">HOSTNAME</span>              <span class="attr">valueFrom:</span>                <span class="attr">fieldRef:</span>                  <span class="attr">apiVersion:</span> <span class="string">v1</span>                  <span class="attr">fieldPath:</span> <span class="string">spec.nodeName</span>      <span class="comment"># 从 Kubernetes Pod 的元数据中获取节点名称（如 k8s-node01）</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/promtail</span>          <span class="comment"># 挂载 config 卷，包含 Promtail 配置文件（promtail.yaml）</span>              <span class="attr">name:</span> <span class="string">config</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/run/promtail</span>          <span class="comment"># 挂载 run 卷，存储 Promtail 的位置文件（positions.yaml），用于记录日志读取偏移量</span>              <span class="attr">name:</span> <span class="string">run</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/data/docker/containers</span>    <span class="comment"># 挂载 docker 卷，包含 Docker 容器的日志文件（路径需要根据容器运行时调整,如果使用 containerd 可忽略）</span>              <span class="attr">name:</span> <span class="string">docker</span>              <span class="attr">readOnly:</span> <span class="literal">true</span>        <span class="comment"># 挂载卷只读</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/log/pods</span>              <span class="comment"># 挂载 pods 卷，包含 Kubernetes Pod 的日志文件（标准路径）</span>              <span class="attr">name:</span> <span class="string">pods</span>              <span class="attr">readOnly:</span> <span class="literal">true</span>        <span class="comment"># 挂载卷只读</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3101</span>   <span class="comment">#Promtail 容器在 3101 端口提供 HTTP 服务，与 promtail.yaml 中的 server.http_listen_port: 3101 一致</span>              <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">securityContext:</span>          <span class="comment"># 定义容器的安全上下文，控制运行权限和文件系统访问</span>            <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span>    <span class="comment"># 容器根文件系统为只读，增强安全性，防止意外修改。Promtail 需要 root 权限访问节点上的日志文件（如 /var/log/pods）</span>            <span class="attr">runAsGroup:</span> <span class="number">0</span>                   <span class="comment"># 容器以 root 用户（UID 0）运行</span>            <span class="attr">runAsUser:</span> <span class="number">0</span>                    <span class="comment"># 容器以 root 组（GID 0）运行</span>          <span class="attr">readinessProbe:</span>             <span class="comment"># 定义就绪探针，检查 Promtail 容器是否准备好提供服务</span>            <span class="attr">httpGet:</span>              <span class="attr">path:</span> <span class="string">/ready</span>            <span class="comment"># 访问 /ready 端点</span>              <span class="attr">port:</span> <span class="string">http</span>              <span class="comment"># 使用命名为 http 的端口（3101）</span>              <span class="attr">scheme:</span> <span class="string">HTTP</span>            <span class="attr">failureThreshold:</span> <span class="number">5</span>       <span class="comment"># 连续 5 次探测失败后，标记容器为未就绪</span>            <span class="attr">initialDelaySeconds:</span> <span class="number">10</span>   <span class="comment"># 容器启动后等待 10 秒开始第一次探测</span>            <span class="attr">periodSeconds:</span> <span class="number">10</span>         <span class="comment"># 每 10 秒探测一次</span>            <span class="attr">successThreshold:</span> <span class="number">1</span>       <span class="comment"># 一次探测成功即标记为就绪</span>            <span class="attr">timeoutSeconds:</span> <span class="number">1</span>         <span class="comment"># 每次探测的超时时间为 1 秒</span>      <span class="attr">tolerations:</span>        <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">Exists</span>            <span class="comment"># 允许 Pod 调度到带有任何污点（taint）的节点上</span>      <span class="attr">volumes:</span>                <span class="comment"># 定义 Pod 使用的卷，供容器挂载</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span>          <span class="attr">configMap:</span>            <span class="attr">defaultMode:</span> <span class="number">420</span>              <span class="comment"># 文件权限为 0644（即 rw-r--r--），适合配置文件（420为十进制，0644是Linux系统中使用的八进制）</span>            <span class="attr">name:</span> <span class="string">loki-promtail</span>           <span class="comment"># 使用名为 loki-promtail 的 ConfigMap（即之前提供的配置）</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/run/promtail</span>           <span class="comment"># 挂载节点上的 /run/promtail 目录</span>            <span class="attr">type:</span> <span class="string">&quot;&quot;</span>                      <span class="comment"># 默认类型，目录不存在时不会自动创建</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">docker</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/data/docker/containers</span> <span class="comment"># 挂载节点上的 Docker 容器日志目录</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pods</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/var/log/pods</span>           <span class="comment"># 挂载节点上的 Kubernetes Pod 日志目录</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f loki-promtail.yaml</code></pre><p><strong>查看资源</strong></p><pre><code class="highlight bash"><span class="comment"># 查看命名空间</span>$ kubectl get nsNAME              STATUS   AGEdefault           Active   13dharbor            Active   7d4hkube-node-lease   Active   13dkube-public       Active   13dkube-system       Active   13dlogging           Active   2d4h<span class="comment"># 查看 ServiceAccount</span>$ kubectl get sa -n loggingNAME            SECRETS   AGEdefault         0         2d4hloki-promtail   0         2d4h<span class="comment"># 查看集群角色</span>$ kubectl get ClusterRole | grep promtailpromtail-clusterrole<span class="comment"># 查看集群角色绑定</span>$ kubectl get ClusterRoleBinding | grep promtailpromtail-clusterrolebinding                              ClusterRole/promtail-clusterrole                                                   2d4h<span class="comment"># 查看 ConfigMap</span>$ kubectl get cm -n loggingNAME               DATA   AGEkube-root-ca.crt   1      2d4hloki-promtail      1      2d1h<span class="comment"># 查看 DaemonSet</span>$ kubectl get ds -n loggingNAME            DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGEloki-promtail   4         4         4       4            4           &lt;none&gt;          27m<span class="comment"># 查看Pod</span>$ kubectl get pods -n loggingNAME                  READY   STATUS    RESTARTS   AGEloki-promtail-lsqsg   1/1     Running   0          27mloki-promtail-r7vjh   1/1     Running   0          27mloki-promtail-szd8m   1/1     Running   0          27mloki-promtail-whffb   1/1     Running   0          27m</code></pre><h3 id="1-2-scrape-configs-配置详解"><a href="#1-2-scrape-configs-配置详解" class="headerlink" title="1.2 scrape_configs 配置详解"></a>1.2 scrape_configs 配置详解</h3><p><code>scrape_configs</code> 配置了 Promtail 如何使用指定的发现方法从一系列目标中抓取日志，类似于 Prometheus 中的抓取配置。</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">任务名称，用于在 Promtail 中识别该抓取配置的名称。</span>job_name: &lt;string&gt;<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">描述如何对目标日志进行结构化</span>[pipeline_stages: &lt;pipeline_stages&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">如何从 jounal 抓取日志</span>[journal: &lt;journal_config&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">如何从 syslog 抓取日志</span>[syslog: &lt;syslog_config&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">如何通过 Loki push API 接收日志 (例如从其他 Promtail 或 Docker Logging Driver 中获取的数据)</span>[loki_push_api: &lt;loki_push_api_config&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">描述了如何 relabel 目标</span>relabel_configs:  - [&lt;relabel_config&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">抓取日志静态目标配置</span>static_configs:  - [&lt;static_config&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">包含要抓取的目标文件</span>file_sd_configs:  - [&lt;file_sd_configs&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">基于kubernetes的自动发现配置</span>kubernetes_sd_configs:  - [&lt;kubernetes_sd_config&gt;]</code></pre><p><strong>relabel_configs</strong></p><p><code>Relabeling</code> 是一个强大的工具，可以在日志被抓取之前动态地重写其标签集。每个抓取配置可以配置多个 <code>relabeling</code> 步骤，按照它们在配置文件中出现的顺序应用于每个目标的标签集。和 Prometheus 中的 Relabel 操作也非常类似。</p><p>在 <code>relabeling</code> 之后，如果 <code>instance</code> 标签在 relabeling 的时候没有被设置，则默认设置为 <code>__address__</code> 的值。<code>__param_&lt;name&gt;</code> 标签被设置为第一个传递的 URL 参数 <code>&lt;name&gt;</code> 的值。</p><p>在 <code>relabeling</code> 阶段，以 <code>__meta_</code> 为前缀的额外标签也是可用的，它们是由提供目标的服务发现机制设置的，不同的机制之间有所不同。</p><p>在目标 <code>relabeling</code> 完成后，以 <code>__</code> 开头的标签将从标签集中删除。</p><p>如果一个 <code>relabeling</code> 操作只需要临时存储一个标签值（作为后续重新标注步骤的输入），则可以使用 <code>__tmp</code> 标签名称前缀。</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">从现有标签中选择 values 值的源标签</span><span class="meta prompt_"># </span><span class="language-bash">它们的内容使用配置的分隔符连接起来，并与配置的正则表达式相匹配，以进行替换、保留和删除操作。</span>[ source_labels: &#x27;[&#x27; &lt;labelname&gt; [, ...] &#x27;]&#x27; ]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">连接源标签值之间的分隔符</span>[ separator: &lt;string&gt; | default = ; ]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">在一个 replace 替换操作后结果值被写入的标签</span><span class="meta prompt_"># </span><span class="language-bash">它对替换动作是强制性的，Regex 捕获组是可用的。</span>[ target_label: &lt;labelname&gt; ]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">正则表达式，提取的值与之匹配</span>[ regex: &lt;regex&gt; | default = (.*) ][ modulus: &lt;uint64&gt; ]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">Replacement 值：如果正则表达式匹配，则对其进行 regex 替换</span>[ replacement: &lt;string&gt; | default = $1 ]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">根据正则匹配结果执行的动作</span>[ action: &lt;relabel_action&gt; | default = replace ]</code></pre><p><code>&lt;regex&gt;</code> 是任何有效的 <code>RE2</code> 正则表达式，它是 <code>replace</code>、<code>keep</code>、<code>drop</code>、<code>labelmap</code>、<code>labeldrop</code> 和 <code>labelkeep</code> 操作的必要条件。</p><p><code>&lt;relabel_action&gt;</code> 决定了要采取的 <code>relabeling</code> 动作：</p><ul><li><code>replace</code>：将正则表达式与连接的 <code>source_labels</code> 匹配，然后设置 <code>target_label</code> 为 <code>replacement</code>，用 replacement 中的匹配组引用（${1}、${2}…）替换其值，如果正则表达式不匹配，则不会进行替换。</li><li><code>keep</code>：删除那些 regex 与 <code>source_labels</code> 不匹配的目标。</li><li><code>drop</code>：删除与 regex 相匹配的 <code>source_labels</code> 目标。</li><li><code>hashmod</code>：将 <code>target_label</code> 设置为 <code>source_labels</code> 的哈希值的模。</li><li><code>labelmap</code>：将正则表达式与所有标签名称匹配，然后将匹配的标签值复制到由 <code>replacement</code> 给出的标签名中，replacement 中的匹配组引用（${1}, ${2}, …）由其值代替。</li><li><code>labeldrop</code>：将正则表达式与所有标签名称匹配，任何匹配的标签都将从标签集中删除。</li><li><code>labelkeep</code>：将正则表达式与所有标签名称匹配，任何不匹配的标签将被从标签集中删除。</li></ul><p>关于 Promotail 配置更加详细的介绍，见：<a href="https://www.qikqiak.com/k3s/logging/loki/promtail/">https://www.qikqiak.com/k3s/logging/loki/promtail/</a></p><h2 id="2-Loki-部署"><a href="#2-Loki-部署" class="headerlink" title="2. Loki 部署"></a>2. Loki 部署</h2><h3 id="2-1-安装NFS"><a href="#2-1-安装NFS" class="headerlink" title="2.1 安装NFS"></a>2.1 安装NFS</h3><p>安装 NFS,配置存储卷自动分配 PV，用于持久化日志数据。</p><p>这里选用 k8s-master (10.20.1.139) 作为 nfs 服务端，其它节点作为 nfs 客户端</p><h4 id="2-1-1-安装-NFS-服务"><a href="#2-1-1-安装-NFS-服务" class="headerlink" title="2.1.1 安装 NFS 服务"></a>2.1.1 安装 NFS 服务</h4><blockquote><p>master节点、node01、node02、node03 节点都需要安装执行</p></blockquote><pre><code class="highlight bash">$ yum install -y nfs-utils rpcbind</code></pre><h4 id="2-1-2-创建共享目录"><a href="#2-1-2-创建共享目录" class="headerlink" title="2.1.2 创建共享目录"></a>2.1.2 创建共享目录</h4><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash"><span class="comment"># 创建 共享目录</span>$ <span class="built_in">mkdir</span> -p /root/data/loki/<span class="comment"># 目录提权</span><span class="built_in">chmod</span> 777 /root/data/loki/<span class="comment"># 变更用户组</span><span class="built_in">chown</span> nobody /root/data/loki/</code></pre><h4 id="2-1-3-编辑共享目录读写配置"><a href="#2-1-3-编辑共享目录读写配置" class="headerlink" title="2.1.3 编辑共享目录读写配置"></a>2.1.3 编辑共享目录读写配置</h4><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash">$ vim /etc/exports/root/data     10.20.1.0/24(rw,fsid=0,no_root_squash)/root/data/loki       10.20.1.0/24(rw,no_root_squash,no_all_squash,no_subtree_check,<span class="built_in">sync</span>)</code></pre><p>这里使用的是 NFS4 服务，上面的配置表示 10.20.1.0&#x2F;24 网段的 ip 都可以与 nfs 主服务器共享 <code>/root/data/prometheus</code> 目录内容</p><h4 id="2-1-4-启动NFS服务"><a href="#2-1-4-启动NFS服务" class="headerlink" title="2.1.4 启动NFS服务"></a>2.1.4 启动NFS服务</h4><blockquote><p>集群内所有节点都需要操作</p></blockquote><pre><code class="highlight bash"> <span class="comment"># 启动服务</span>$ systemctl start rpcbind$ systemctl restart nfs-server.service<span class="comment"># 设置开机自启</span>$ systemctl <span class="built_in">enable</span> rpcbind$ systemctl <span class="built_in">enable</span> nfs-server.service</code></pre><h4 id="2-1-5-测试-NFS-目录挂载"><a href="#2-1-5-测试-NFS-目录挂载" class="headerlink" title="2.1.5 测试 NFS 目录挂载"></a>2.1.5 测试 NFS 目录挂载</h4><pre><code class="highlight bash"><span class="comment"># NFS 客户端执行：创建目录</span>$ <span class="built_in">mkdir</span> /data/test1<span class="comment"># NFS 客户端执行：挂载目录到NFS服务端</span>$ mount -t nfs4 10.20.1.139:/loki /data/test1<span class="comment"># NFS 客户端执行：查看挂载结果</span>$ mount | grep /data/test110.20.1.139:/loki on /data/test1 <span class="built_in">type</span> nfs4 (rw,relatime,vers=4.2,rsize=524288,wsize=524288,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.1.142,local_lock=none,addr=10.20.1.139)<span class="comment"># NFS 客户端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;this is client&quot;</span> &gt; /data/test1/a.txt<span class="comment"># NFS 服务端执行：查看数据， 结论：客户端数据已写入服务端挂载目录</span>$ <span class="built_in">cat</span> /root/data/loki/a.txt this is client<span class="comment"># NFS 服务端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;This is Server&quot;</span> &gt;&gt; /root/data/loki/a.txt<span class="comment"># NFS 客户端执行：查看数据， 结论：服务端数据已写入客户端挂载目录</span>$ <span class="built_in">cat</span> /data/test1/a.txt this is clientThis is Server</code></pre><p><strong>取消挂载</strong></p><pre><code class="highlight bash"><span class="comment"># 取消挂载</span>umount /data/test1<span class="comment"># 如果取消挂载出现报错，例如：</span>$ umount /data/test1umount.nfs4: /data/test1: device is busy<span class="comment"># 查看目录占用进程</span>$ fuser -m /data/test1/data/test1:         32679c<span class="comment"># kill 进程</span>$ <span class="built_in">kill</span> -9 32679<span class="comment"># 方式二：强制卸载</span>umount -l /data/test1</code></pre><h3 id="2-2-创建-StorageClass"><a href="#2-2-创建-StorageClass" class="headerlink" title="2.2 创建 StorageClass"></a>2.2 创建 StorageClass</h3><p>promtail 抓取到的日志，推送给 Loki 存储，这里将 Loki 的数据通过 StorageClass 动态创建PV，将数据存储起来。</p><p>资源清单：<code>loki-storage.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.存储类</span><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">StorageClass</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span>  <span class="attr">name:</span> <span class="string">loki-storage</span><span class="comment"># provisioner: nfs-provisioner</span><span class="attr">provisioner:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定动态配置器，NFS 子目录外部配置器</span><span class="attr">parameters:</span>  <span class="attr">pathPattern:</span> <span class="string">$&#123;.PVC.namespace&#125;/$&#123;.PVC.name&#125;</span> <span class="comment"># 动态生成的 NFS 路径，格式为 &lt;PVC 命名空间&gt;/&lt;PVC 名称&gt;，例如 loki-storageclass/test-claim。</span>  <span class="attr">archiveOnDelete:</span> <span class="string">&quot;true&quot;</span> <span class="comment">##删除 pv,pv内容是否备份</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 指定使用的 ServiceAccountName</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span>          <span class="attr">image:</span> <span class="string">k8s.dockerproxy.com/sig-storage/nfs-subdir-external-provisioner:v4.0.2</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 挂载的卷名称，与 volumes 部分定义的卷对应</span>              <span class="attr">mountPath:</span> <span class="string">/persistentvolumes</span> <span class="comment"># 将 NFS 卷挂载到容器内的 /persistentvolumes 路径，供容器读写 NFS 共享数据。</span>          <span class="attr">env:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PROVISIONER_NAME</span>              <span class="attr">value:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定配置器名称，与 StorageClass 保持一致</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_SERVER</span>              <span class="attr">value:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_PATH</span>              <span class="attr">value:</span> <span class="string">/root/data/loki</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 定义一个名为 nfs-client-root 的 NFS 卷，连接到 NFS 服务器的指定地址和路径</span>          <span class="attr">nfs:</span>            <span class="attr">server:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="attr">path:</span> <span class="string">/root/data/loki</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">nodeSelector:</span> <span class="comment"># 指定Pod运行的节点</span>        <span class="attr">kubernetes.io/hostname:</span> <span class="string">k8s-node01</span>      <span class="comment"># nodeName: k8s-node01 # 指定 Pod 运行在 k8s-node02 节点上</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4.服务账户</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># SA 的名称</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 5.集群角色</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;nodes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumeclaims&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;storage.k8s.io&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;storageclasses&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;events&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># 6.集群角色绑定</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-nfs-client-provisioner</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定类型 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># ServiceAccount 的名称</span>    <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span> <span class="comment"># 绑定的角色类型</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span> <span class="comment"># 集群角色名称 nfs-client-provisioner-runner</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 角色</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称，表明它与 NFS 客户端存储提供者的领导者选举（leader election）机制相关。</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 空字符串表示核心 API 组（core API group），包含 Kubernetes 的基本资源，如 endpoints。</span>    <span class="attr">resources:</span> [<span class="string">&quot;endpoints&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># SA角色绑定</span><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-leader-locking-nfs-client-provisioner</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定资源类型为 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 绑定的ServiceAccount 名称</span>    <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">Role</span> <span class="comment"># 绑定角色（loki-storage名称空间的角色）</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 创建 StorageClass</span>$ kubectl apply -f loki-storage.yaml<span class="comment"># 查看 StorageClass</span>$ kubectl get StorageClassNAME           PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGEloki-storage   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  16mnfs-client     k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  109m<span class="comment"># 查看 Pod</span>$ kubectl get pods -n loki-storage -o wideNAME                                      READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESnfs-client-provisioner-79f97f7689-w2mtj   1/1     Running   0          15m   192.168.85.236   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h3 id="2-3-部署-Loki"><a href="#2-3-部署-Loki" class="headerlink" title="2.3 部署 Loki"></a>2.3 部署 Loki</h3><p>Loki在接收日志后会对日志数据进行一定的加工整理，因为存储的数据为有状态的，安装时候推荐使用StatefulSet。</p><p>资源清单：<code>loki.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">logging</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.ServiceAccount</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.Role</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span>      <span class="bullet">-</span> <span class="string">extensions</span>          <span class="comment"># 指定 API 组为 extensions，这是 PodSecurityPolicy 在 Kubernetes 早期版本（v1.21 之前）使用的 API 组，v1.25 后完全移除</span>    <span class="attr">resourceNames:</span>      <span class="bullet">-</span> <span class="string">loki</span>    <span class="attr">resources:</span>              <span class="comment"># 指定权限针对的资源类型为 podsecuritypolicies（PSP）</span>      <span class="bullet">-</span> <span class="string">podsecuritypolicies</span> <span class="comment"># PSP 是一种 Kubernetes 资源，用于控制 Pod 的安全策略，例如是否允许以 root 运行、挂载主机路径等。在 v1.29 中，podsecuritypolicies 资源不存在，规则无效</span>    <span class="attr">verbs:</span>      <span class="bullet">-</span> <span class="string">use</span>                 <span class="comment"># 指定允许的操作是 use，表示主体可以应用指定的 PSP（loki）到 Pod</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4. RoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">roleRef:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">Role</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">loki</span>    <span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 5. ConfigMap</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">loki</span><span class="attr">data:</span>  <span class="attr">loki.yaml:</span> <span class="string">|</span>    <span class="comment"># Loki 的核心配置文件，控制认证、日志存储、索引、块存储、保留策略等</span>    <span class="comment"># 通过 X-Scope-OrgID Header 启用身份验证，如果为 true，该 Header 必须存在。</span>    <span class="comment"># 如果为 false，OrgID 将始终设置为 &quot;fake&quot;。（用于多租户隔离）</span>    <span class="attr">auth_enabled:</span> <span class="literal">false</span>    <span class="attr">ingester:</span>      <span class="attr">chunk_idle_period:</span> <span class="string">3m</span>        <span class="comment"># 如果一个块在 3 分钟内没有新日志写入，且未达到最大大小，Loki 会将其刷新到存储</span>      <span class="attr">chunk_block_size:</span> <span class="number">65535</span>      <span class="comment"># 每个块的最大大小（字节），这里约为 64KB</span>      <span class="attr">chunk_retain_period:</span> <span class="string">1m</span>      <span class="comment"># 块刷新到存储后，在内存中保留 1 分钟，允许查询最近的日志</span>      <span class="attr">max_transfer_retries:</span> <span class="number">0</span>      <span class="comment"># 当 ingester 退出时，尝试将块转移到其他 ingester 的次数（0 表示不转移，直接刷新到存储）</span>      <span class="attr">lifecycler:</span>                  <span class="comment"># 配置 ingester 的生命周期管理，决定如何注册和发现其他 ingester</span>        <span class="attr">ring:</span>          <span class="attr">kvstore:</span>            <span class="attr">store:</span> <span class="string">inmemory</span>        <span class="comment"># 使用内存作为环存储（其他选项如 consul、etcd）</span>          <span class="attr">replication_factor:</span> <span class="number">1</span>    <span class="comment"># 写入和读取的ingesters数量，至少为1（为了冗余和弹性，默认情况下为3)</span>      <span class="attr">wal:</span>                         <span class="comment"># 配置日志预写</span>        <span class="attr">enabled:</span> <span class="literal">true</span>              <span class="comment"># 启用预写日志（Write-Ahead Log, WAL），在崩溃恢复时确保数据不丢失</span>        <span class="attr">dir:</span> <span class="string">/data/wal</span>             <span class="comment"># WAL 文件存储路径</span>    <span class="attr">limits_config:</span>                 <span class="comment"># 设置日志写入的限制规则</span>      <span class="attr">enforce_metric_name:</span> <span class="literal">false</span>          <span class="comment"># 不强制要求日志流具有指标名称（metric name）</span>      <span class="attr">reject_old_samples:</span> <span class="literal">true</span>            <span class="comment"># 拒绝时间戳早于当前时间的旧日志</span>      <span class="attr">reject_old_samples_max_age:</span> <span class="string">8h</span>      <span class="comment"># 拒绝时间戳早于当前时间 8 小时的日志</span>    <span class="attr">schema_config:</span>                        <span class="comment"># 配置从特定时间段开始应该使用哪些索引模式</span>      <span class="attr">configs:</span>                       <span class="comment"># 定义 Loki 的索引模式和存储配置，指定从某个日期开始的存储方式</span>        <span class="bullet">-</span> <span class="attr">from:</span> <span class="number">2025-07-15</span>           <span class="comment"># 指定此配置从 2023-12-05 开始生效</span>          <span class="attr">store:</span> <span class="string">boltdb-shipper</span>      <span class="comment"># 索引存储使用 boltdb-shipper，一种高效的键值存储，适合分布式环境</span>          <span class="attr">object_store:</span> <span class="string">filesystem</span>   <span class="comment"># 日志块（chunks）存储在本地文件系统，支持 S3、GCS 等，filesystem 适合单节点或测试环境</span>          <span class="attr">schema:</span> <span class="string">v11</span>           <span class="comment"># 使用 Loki 的 v11 索引模式（Loki 的版本化架构）</span>          <span class="attr">index:</span>                <span class="comment"># 配置如何更新和存储索引</span>            <span class="attr">prefix:</span> <span class="string">index_</span>      <span class="comment"># 索引表的名称前缀（如 index_2025_07_15 ）</span>            <span class="attr">period:</span> <span class="string">24h</span>         <span class="comment"># 索引表的时间周期为 24 小时（每天生成新表）</span>    <span class="attr">server:</span>      <span class="attr">http_listen_port:</span> <span class="number">3100</span>    <span class="comment"># 配置 Loki 的 HTTP 服务端口，Promtail 将日志发送到 http://loki:3100/loki/api/v1/push（与之前的 Promtail 配置一致）</span>    <span class="attr">storage_config:</span>            <span class="comment"># 为索引和块配置一个或多个存储</span>      <span class="attr">boltdb_shipper:</span>        <span class="attr">active_index_directory:</span> <span class="string">/data/loki/boltdb-shipper-active</span>    <span class="comment"># 活动索引存储路径</span>        <span class="attr">cache_location:</span> <span class="string">/data/loki/boltdb-shipper-cache</span>             <span class="comment"># 索引缓存路径</span>        <span class="attr">cache_ttl:</span> <span class="string">24h</span>                                              <span class="comment"># 缓存有效期为 24 小时</span>        <span class="attr">shared_store:</span> <span class="string">filesystem</span>                                    <span class="comment"># 索引使用文件系统存储</span>      <span class="attr">filesystem:</span>        <span class="attr">directory:</span> <span class="string">/data/loki/chunks</span>                                <span class="comment"># 日志块存储路径</span>    <span class="attr">chunk_store_config:</span>             <span class="comment"># 配置日志块的缓存和查询行为</span>      <span class="attr">max_look_back_period:</span> <span class="string">0s</span>      <span class="comment"># 限制查询数据的时间，默认是禁用的，这个值应该小于或等于table_manager.retention_period中的值</span>    <span class="attr">table_manager:</span>                  <span class="comment"># 管理索引表的保留和删除</span>      <span class="attr">retention_deletes_enabled:</span> <span class="literal">true</span>   <span class="comment"># 启用索引表和日志的删除</span>      <span class="attr">retention_period:</span> <span class="string">48h</span>             <span class="comment"># 日志和索引保留 48 小时，超过的会被删除，保留期必须是索引周期（schema_config.index.period: 24h）的倍数</span>    <span class="attr">compactor:</span>                      <span class="comment"># 配置 Loki 的压缩器（compactor），用于压缩和清理索引</span>      <span class="attr">working_directory:</span> <span class="string">/data/loki/boltdb-shipper-compactor</span>  <span class="comment"># 压缩器工作目录</span>      <span class="attr">shared_store:</span> <span class="string">filesystem</span>                                <span class="comment"># 压缩器使用文件系统存储，工作目录需持久化存储，避免数据丢失</span>    <span class="comment"># ruler:                              # 配置 Loki 的告警规则（ruler），用于基于日志触发告警。如果需要告警功能，需取消注释并确保 Alertmanager 服务可用</span>    <span class="comment">#   storage:                          # rules规则存储</span>    <span class="comment">#     type: local                     # 主要支持本地存储（local）和对象文件系统（azure, gcs, s3, swift）</span>    <span class="comment">#     local:</span>    <span class="comment">#       directory: /etc/loki/rules    # 告警文件存放目录</span>    <span class="comment">#   rule_path: /data/loki/rules-temp  # rules临时规则文件存储路径</span>    <span class="comment">#   flush_period: 1m                  # 规则刷新间隔为 1 分钟。</span>    <span class="comment">#   alertmanager_url: http://alertmanager-main.monitoring.svc:9093 # alertmanager地址 </span>    <span class="comment">#   external_url: http://alertmanager.od.com           # 外部访问 alertmanager</span>    <span class="comment">#   ring:</span>    <span class="comment">#     kvstore:</span>    <span class="comment">#       store: inmemory           # 规则环存储使用内存</span>    <span class="comment">#   enable_api: true              # 启用规则管理 API</span>    <span class="comment">#   enable_alertmanager_v2: true  # 支持 Alertmanager v2 协议</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 6.Lock Pod</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">StatefulSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">loki</span><span class="attr">spec:</span>  <span class="attr">podManagementPolicy:</span> <span class="string">OrderedReady</span>   <span class="comment"># 指定 Pod 的管理策略为 OrderedReady：Pod 按顺序（0, 1, 2...）创建和删除，等待前一个 Pod 就绪后再创建下一个</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">loki</span>  <span class="attr">serviceName:</span> <span class="string">loki</span>  <span class="attr">updateStrategy:</span>    <span class="attr">type:</span> <span class="string">RollingUpdate</span>               <span class="comment"># 使用滚动更新策略，逐步替换旧 Pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">loki</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">loki</span>        <span class="comment"># 指定 Pod 使用 loki 服务账号（之前定义的 ServiceAccount）</span>      <span class="attr">securityContext:</span>          <span class="comment"># 定义 Pod 级别的安全上下文，控制文件系统权限和用户/组 ID</span>        <span class="attr">fsGroup:</span> <span class="number">10001</span>          <span class="comment"># Pod 挂载的卷（如 /data）将归属组 ID 10001</span>        <span class="attr">runAsGroup:</span> <span class="number">10001</span>       <span class="comment"># 容器进程以组 ID 10001 运行，确保挂载的卷（如 PVC）归属组 10001，Loki 进程可以访问</span>        <span class="attr">runAsNonRoot:</span> <span class="literal">true</span>      <span class="comment"># 强制容器以非 root 用户运行，增强安全性</span>        <span class="attr">runAsUser:</span> <span class="number">10001</span>        <span class="comment"># 容器进程以用户 ID 10001 运行</span>      <span class="attr">initContainers:</span>           <span class="comment"># 定义初始化容器，在主容器启动前调整存储路径的权限</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fix-permissions</span> <span class="comment"># 初始化容器名称</span>          <span class="attr">image:</span> <span class="string">busybox:1.37.0</span> <span class="comment"># 使用 busybox 镜像，适合执行简单命令</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">true</span>    <span class="comment"># 以特权模式运行，允许修改文件系统权限</span>            <span class="attr">runAsGroup:</span> <span class="number">0</span>       <span class="comment"># 以 root 用户运行</span>            <span class="attr">runAsNonRoot:</span> <span class="literal">false</span>            <span class="attr">runAsUser:</span> <span class="number">0</span>          <span class="attr">command:</span>              <span class="comment"># 创建 /data/loki 目录，将 /data 及其子目录的拥有者改为 UID 10001 和 GID 10001，列出 /data 目录内容，验证权限</span>            <span class="bullet">-</span> <span class="string">sh</span>            <span class="bullet">-</span> <span class="string">-c</span>            <span class="bullet">-</span> <span class="string">&gt;-</span><span class="string">              id;</span><span class="string">              mkdir -p /data/loki;</span><span class="string">              chown 10001:10001 /data -R;</span><span class="string">              ls -la /data/</span><span class="string"></span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/data</span>  <span class="comment"># 挂载 storage 卷到 /data，与主容器共享</span>              <span class="attr">name:</span> <span class="string">storage</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">loki</span>          <span class="attr">image:</span> <span class="string">grafana/loki:2.9.2</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">-config.file=/etc/loki/config/loki.yaml</span>   <span class="comment"># 指定配置文件路径</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span>              <span class="attr">mountPath:</span> <span class="string">/etc/loki/config/loki.yaml</span>     <span class="comment"># 挂载 ConfigMap loki 的 loki.yaml 到 /etc/loki/config/loki.yaml</span>              <span class="attr">subPath:</span> <span class="string">loki.yaml</span>                        <span class="comment"># subPath: loki.yaml 表示只挂载 ConfigMap 中 loki.yaml 键对应的文件内容到 mountPath 指定的路径（/etc/loki/config/loki.yaml）</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">storage</span>              <span class="attr">mountPath:</span> <span class="string">&quot;/data&quot;</span>                        <span class="comment"># 挂载 PVC 到 /data，用于存储 WAL、索引和块</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http-metrics</span>              <span class="attr">containerPort:</span> <span class="number">3100</span>       <span class="comment"># Loki 监听 3100 端口（HTTP），用于接收日志和监控指标</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">livenessProbe:</span>                <span class="comment"># 存活探测</span>            <span class="attr">httpGet:</span>              <span class="attr">path:</span> <span class="string">/ready</span>              <span class="comment"># 检查 /ready 端点，确认 Loki 是否健康/就绪</span>              <span class="attr">port:</span> <span class="string">http-metrics</span>              <span class="attr">scheme:</span> <span class="string">HTTP</span>            <span class="attr">initialDelaySeconds:</span> <span class="number">45</span>     <span class="comment"># 启动后 45 秒开始探测</span>            <span class="attr">timeoutSeconds:</span> <span class="number">1</span>           <span class="comment"># 每次探测超时 1 秒</span>            <span class="attr">periodSeconds:</span> <span class="number">10</span>           <span class="comment"># 每 10 秒探测一次</span>            <span class="attr">successThreshold:</span> <span class="number">1</span>         <span class="comment"># 1 次成功即健康</span>            <span class="attr">failureThreshold:</span> <span class="number">3</span>         <span class="comment"># 3 次失败标记不健康</span>          <span class="attr">readinessProbe:</span>               <span class="comment"># 就绪探测</span>            <span class="attr">httpGet:</span>              <span class="attr">path:</span> <span class="string">/ready</span>              <span class="attr">port:</span> <span class="string">http-metrics</span>              <span class="attr">scheme:</span> <span class="string">HTTP</span>            <span class="attr">initialDelaySeconds:</span> <span class="number">45</span>            <span class="attr">timeoutSeconds:</span> <span class="number">1</span>            <span class="attr">periodSeconds:</span> <span class="number">10</span>            <span class="attr">successThreshold:</span> <span class="number">1</span>            <span class="attr">failureThreshold:</span> <span class="number">3</span>          <span class="attr">securityContext:</span>            <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span>    <span class="comment"># 容器根文件系统为只读，增强安全性。</span>      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">4800</span>   <span class="comment"># Pod 终止时的宽限期为 4800 秒（80 分钟）</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span>          <span class="comment"># 定义卷，将 ConfigMap loki 挂载到容器</span>          <span class="attr">configMap:</span>            <span class="attr">defaultMode:</span> <span class="number">0640</span>   <span class="comment"># 文件权限为 rw-r-----（所有者读写，组可读）。0640 前面有0，因此被解析为八进制数</span>            <span class="attr">name:</span> <span class="string">loki</span>          <span class="comment"># 引用名为 loki ConfigMap</span>  <span class="attr">volumeClaimTemplates:</span>    <span class="bullet">-</span> <span class="attr">metadata:</span>        <span class="attr">name:</span> <span class="string">storage</span>        <span class="attr">labels:</span>          <span class="attr">app:</span> <span class="string">loki</span>      <span class="attr">spec:</span>        <span class="attr">storageClassName:</span> <span class="string">&quot;loki-storage&quot;</span>   <span class="comment"># 注意修改 storageClass 名称</span>        <span class="attr">accessModes:</span>          <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>        <span class="attr">resources:</span>          <span class="attr">requests:</span>            <span class="attr">storage:</span> <span class="string">&quot;10Gi&quot;</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 7.Loki Service</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">loki</span><span class="attr">spec:</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">3100</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">targetPort:</span> <span class="string">http-metrics</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">loki</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f loki.yaml<span class="comment"># ConfigMap</span>$ kubectl get configMap -n loggingNAME               DATA   AGEkube-root-ca.crt   1      55mloki               1      54mloki-promtail      1      55m<span class="comment"># StatefulSet</span>$ kubectl get StatefulSet -n loggingNAME   READY   AGEloki   1/1     55m<span class="comment"># Pod</span>$ kubectl get pod -n loggingNAME                  READY   STATUS    RESTARTS   AGEloki-0                1/1     Running   0          55mloki-promtail-cbllm   1/1     Running   0          56mloki-promtail-h7pz5   1/1     Running   0          56mloki-promtail-rrwtf   1/1     Running   0          56mloki-promtail-vs4df   1/1     Running   0          56m<span class="comment"># Service</span>$ kubectl get svc -n loggingNAME   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGEloki   ClusterIP   10.106.23.220   &lt;none&gt;        3100/TCP   55m</code></pre><h2 id="3-部署-Grafana"><a href="#3-部署-Grafana" class="headerlink" title="3. 部署 Grafana"></a>3. 部署 Grafana</h2><p>部署 Grafana， 展示推送到 Loki 的日志数据</p><h3 id="3-1-Grafana-资源清单"><a href="#3-1-Grafana-资源清单" class="headerlink" title="3.1 Grafana 资源清单"></a>3.1 Grafana 资源清单</h3><p><strong>资源清单：</strong> <code>loki-grafana.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.声明 PVC ，使用 StorageClass 动态创建PV</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-pvc</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">spec:</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">resources:</span>    <span class="attr">requests:</span>      <span class="attr">storage:</span> <span class="string">5Gi</span>  <span class="attr">storageClassName:</span> <span class="string">loki-storage</span> <span class="comment"># 使用 StorageClass 动态创建PV</span>  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.创建Deployment</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">name:</span> <span class="string">grafana</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">grafana</span>    <span class="attr">spec:</span>      <span class="attr">securityContext:</span>        <span class="attr">fsGroup:</span> <span class="number">472</span>        <span class="attr">supplementalGroups:</span>          <span class="bullet">-</span> <span class="number">0</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grafana</span>          <span class="attr">image:</span> <span class="string">grafana/grafana:8.3.5</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3000</span>              <span class="attr">name:</span> <span class="string">http-grafana</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="string">500m</span>              <span class="attr">memory:</span> <span class="string">1024Mi</span>            <span class="attr">limits:</span>              <span class="attr">cpu:</span> <span class="string">1000m</span>              <span class="attr">memory:</span> <span class="string">2048Mi</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/lib/grafana</span>              <span class="attr">name:</span> <span class="string">grafana-pv</span>      <span class="attr">volumes:</span>                              <span class="comment"># 挂载容器卷</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grafana-pv</span>          <span class="attr">persistentVolumeClaim:</span>            <span class="attr">claimName:</span> <span class="string">grafana-pvc</span>          <span class="comment"># 使用声明的PVC，通过 StorageClass 动态创建PV</span>      <span class="attr">nodeSelector:</span> <span class="comment"># 指定Pod运行的节点</span>        <span class="attr">kubernetes.io/hostname:</span> <span class="string">k8s-node02</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.创建Service</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">3000</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="string">http-grafana</span>      <span class="attr">nodePort:</span> <span class="number">30339</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">type:</span> <span class="string">NodePort</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4.创建 Ingress</span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-ui</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">grafana</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span>       <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">loki.grafana.com</span>    <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 loki.grafana.com 的流量。客户端必须通过该域名访问</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>             <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>    <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">grafana</span>   <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">3000</span>  <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f loki-grafana.yaml <span class="comment"># 查看 Ingress</span>$ kubectl get ingress -n loggingNAME         CLASS   HOSTS              ADDRESS   PORTS   AGEgrafana-ui   nginx   loki.grafana.com             80      10s<span class="comment"># 查看 Serivce</span>$ kubectl get svc -n loggingNAME      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEgrafana   NodePort    10.104.180.186   &lt;none&gt;        3000:30339/TCP   6m13sloki      ClusterIP   10.106.23.220    &lt;none&gt;        3100/TCP         148m<span class="comment"># 查看 PVC</span>$ kubectl get pvc -n loggingNAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGEgrafana-pvc      Bound    pvc-649c73ed-2885-4924-a219-ee58a8ab0166   5Gi        RWO            loki-storage   &lt;<span class="built_in">unset</span>&gt;                 6m28sstorage-loki-0   Bound    pvc-819fb39b-1ad9-48ff-8dfe-fafa62885af7   10Gi       RWO            loki-storage   &lt;<span class="built_in">unset</span>&gt;                 149m<span class="comment"># 查看 PV</span>$ kubectl get pv -n loggingNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                    STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGEpvc-649c73ed-2885-4924-a219-ee58a8ab0166   5Gi        RWO            Delete           Bound    logging/grafana-pvc                      loki-storage   &lt;<span class="built_in">unset</span>&gt;                          6m36spvc-819fb39b-1ad9-48ff-8dfe-fafa62885af7   10Gi       RWO            Delete           Bound    logging/storage-loki-0                   loki-storage   &lt;<span class="built_in">unset</span>&gt;                          149m<span class="comment"># 查看 Pod</span>$ kubectl get pods -n loggingNAME                       READY   STATUS    RESTARTS   AGEgrafana-599d67bdbb-m6zjz   1/1     Running   0          6m54sloki-0                     1/1     Running   0          149mloki-promtail-cbllm        1/1     Running   0          150mloki-promtail-h7pz5        1/1     Running   0          150mloki-promtail-rrwtf        1/1     Running   0          150mloki-promtail-vs4df        1/1     Running   0          150m</code></pre><h3 id="3-2-配置-Host-域名映射"><a href="#3-2-配置-Host-域名映射" class="headerlink" title="3.2 配置 Host 域名映射"></a>3.2 配置 Host 域名映射</h3><p>在浏览器所在主机编辑 <code>/etc/hosts</code> </p><pre><code class="highlight plaintext">10.20.1.140 loki.grafana.com</code></pre><p>保存后，使用浏览器访问 Grafana，地址：<a href="https://loki.grafana.com/">https://loki.grafana.com/</a></p><h2 id="4-Grafana-基础使用"><a href="#4-Grafana-基础使用" class="headerlink" title="4. Grafana 基础使用"></a>4. Grafana 基础使用</h2><h3 id="4-1-登录-Grafana"><a href="#4-1-登录-Grafana" class="headerlink" title="4.1 登录 Grafana"></a>4.1 登录 Grafana</h3><p>默认用户名：admin  </p><p>默认密码：admin</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135129.png" alt="登录Grafana"></p><p><strong>Grafana 首页</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135208.png" alt="Grafana首页"></p><h3 id="4-2-添加-Loki-作为数据源"><a href="#4-2-添加-Loki-作为数据源" class="headerlink" title="4.2 添加 Loki 作为数据源"></a>4.2 添加 Loki 作为数据源</h3><p><strong>添加数据源</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135300.png" alt="添加 Loki 作为数据源1"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135317.png" alt="添加 Loki 作为数据源2"></p><p><strong>选择 Loki</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135333.png" alt="添加 Loki 作为数据源3"></p><p><strong>Loki数据源设置</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135515.png" alt="添加 Loki 作为数据源4"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135555.png" alt="添加 Loki 作为数据源5"></p><h3 id="4-3-查看日志"><a href="#4-3-查看日志" class="headerlink" title="4.3 查看日志"></a>4.3 查看日志</h3><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-140241.png" alt="查看日志"></p><p>至此，基于资源清单 yaml 部署 Loki、Promtail、Grafana 就完成了。</p><h1 id="三、使用-Helm-部署-Loki"><a href="#三、使用-Helm-部署-Loki" class="headerlink" title="三、使用 Helm 部署 Loki"></a>三、使用 Helm 部署 Loki</h1><p><strong>使用 Helm 部署 Loki 需要保持网络通畅，如果你的服务器无法连接外网，那就需要提前将loki的helm安装包下载到服务器，并且提前将需要的镜像导入到服务器中。</strong></p><h2 id="1-部署-StorageClass"><a href="#1-部署-StorageClass" class="headerlink" title="1. 部署 StorageClass"></a>1. 部署 StorageClass</h2><p>使用 StorageClass 自动创建 PV，管理文件存储。</p><p>资源清单：<code>loki-storage.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.存储类</span><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">StorageClass</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span>  <span class="attr">name:</span> <span class="string">loki-storage</span><span class="comment"># provisioner: nfs-provisioner</span><span class="attr">provisioner:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定动态配置器，NFS 子目录外部配置器</span><span class="attr">parameters:</span>  <span class="attr">pathPattern:</span> <span class="string">$&#123;.PVC.namespace&#125;/$&#123;.PVC.name&#125;</span> <span class="comment"># 动态生成的 NFS 路径，格式为 &lt;PVC 命名空间&gt;/&lt;PVC 名称&gt;，例如 loki-storageclass/test-claim。</span>  <span class="attr">archiveOnDelete:</span> <span class="string">&quot;true&quot;</span> <span class="comment">##删除 pv,pv内容是否备份</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 指定使用的 ServiceAccountName</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span>          <span class="attr">image:</span> <span class="string">k8s.dockerproxy.com/sig-storage/nfs-subdir-external-provisioner:v4.0.2</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 挂载的卷名称，与 volumes 部分定义的卷对应</span>              <span class="attr">mountPath:</span> <span class="string">/persistentvolumes</span> <span class="comment"># 将 NFS 卷挂载到容器内的 /persistentvolumes 路径，供容器读写 NFS 共享数据。</span>          <span class="attr">env:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PROVISIONER_NAME</span>              <span class="attr">value:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定配置器名称，与 StorageClass 保持一致</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_SERVER</span>              <span class="attr">value:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_PATH</span>              <span class="attr">value:</span> <span class="string">/root/data/loki</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 定义一个名为 nfs-client-root 的 NFS 卷，连接到 NFS 服务器的指定地址和路径</span>          <span class="attr">nfs:</span>            <span class="attr">server:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="attr">path:</span> <span class="string">/root/data/loki</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">nodeSelector:</span> <span class="comment"># 指定Pod运行的节点</span>        <span class="attr">kubernetes.io/hostname:</span> <span class="string">k8s-node01</span>      <span class="comment"># nodeName: k8s-node01 # 指定 Pod 运行在 k8s-node02 节点上</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4.服务账户</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># SA 的名称</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 5.集群角色</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;nodes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumeclaims&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;storage.k8s.io&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;storageclasses&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;events&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># 6.集群角色绑定</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-nfs-client-provisioner</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定类型 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># ServiceAccount 的名称</span>    <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span> <span class="comment"># 绑定的角色类型</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span> <span class="comment"># 集群角色名称 nfs-client-provisioner-runner</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 角色</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称，表明它与 NFS 客户端存储提供者的领导者选举（leader election）机制相关。</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 空字符串表示核心 API 组（core API group），包含 Kubernetes 的基本资源，如 endpoints。</span>    <span class="attr">resources:</span> [<span class="string">&quot;endpoints&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># SA角色绑定</span><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-leader-locking-nfs-client-provisioner</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定资源类型为 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 绑定的ServiceAccount 名称</span>    <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">Role</span> <span class="comment"># 绑定角色（loki-storage名称空间的角色）</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行</span>$ kubectl apply -f loki-storage.yaml<span class="comment"># 查看Pod</span>$ kubectl get pods -n loki-storageNAME                                      READY   STATUS    RESTARTS   AGEnfs-client-provisioner-79f97f7689-h5rrl   1/1     Running   0          20h</code></pre><h2 id="2-下载-Helm-Chat-包"><a href="#2-下载-Helm-Chat-包" class="headerlink" title="2. 下载 Helm Chat 包"></a>2. 下载 Helm Chat 包</h2><pre><code class="highlight bash"><span class="comment"># 添加grafana仓库</span>$ helm repo add grafana https://grafana.github.io/helm-charts<span class="comment"># 更新仓库</span>$ helm repo update<span class="comment"># 拉取 Chart 包</span>$ helm pull grafana/loki-stack --version=2.9.11<span class="comment"># 查看下载的 chat 包</span>$ ll-rw-r--r-- 1 root root 132807 Jul 16 15:09 loki-stack-2.9.11.tgz<span class="comment"># 如果上面的命令由于网络问题无法下载 Chat 包, 就手动下载，然后上传到服务器上</span><span class="comment"># helm包下载地址 https://github.com/grafana/helm-charts/releases/download/loki-stack-2.9.11/loki-stack-2.9.11.tgz</span></code></pre><p><strong>解压 Chart 包</strong></p><pre><code class="highlight bash"><span class="comment"># 解压</span>$ tar -zxvf loki-stack-2.9.11.tgz<span class="comment"># 查看解压目录</span>$ <span class="built_in">ls</span> loki-stack  loki-stack-2.9.11.tgz</code></pre><h2 id="3-编辑-values-yaml"><a href="#3-编辑-values-yaml" class="headerlink" title="3. 编辑 values.yaml"></a>3. 编辑 values.yaml</h2><p><code>vim loki-stack/values.yaml</code></p><p>内容如下：</p><pre><code class="highlight yaml"><span class="attr">loki:</span>  <span class="attr">enabled:</span> <span class="literal">true</span>  <span class="attr">isDefault:</span> <span class="literal">true</span>  <span class="attr">url:</span> <span class="string">http://&#123;&#123;(include</span> <span class="string">&quot;loki.serviceName&quot;</span> <span class="string">.)&#125;&#125;:&#123;&#123;</span> <span class="string">.Values.loki.service.port</span> <span class="string">&#125;&#125;</span>  <span class="attr">readinessProbe:</span>    <span class="attr">httpGet:</span>      <span class="attr">path:</span> <span class="string">/ready</span>      <span class="attr">port:</span> <span class="string">http-metrics</span>    <span class="attr">initialDelaySeconds:</span> <span class="number">45</span>  <span class="attr">livenessProbe:</span>    <span class="attr">httpGet:</span>      <span class="attr">path:</span> <span class="string">/ready</span>      <span class="attr">port:</span> <span class="string">http-metrics</span>    <span class="attr">initialDelaySeconds:</span> <span class="number">45</span>  <span class="attr">datasource:</span>    <span class="attr">jsonData:</span> <span class="string">&quot;&#123;&#125;&quot;</span>    <span class="attr">uid:</span> <span class="string">&quot;&quot;</span>  <span class="attr">persistence:</span> <span class="comment"># 添加存储设置</span>    <span class="attr">enabled:</span> <span class="literal">true</span>    <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>    <span class="attr">size:</span> <span class="string">10Gi</span>    <span class="attr">storageClassName:</span> <span class="string">loki-storage</span> <span class="comment"># 使用 loki-storage 自动创建PV</span><span class="attr">promtail:</span>  <span class="attr">enabled:</span> <span class="literal">true</span>  <span class="attr">config:</span>    <span class="attr">logLevel:</span> <span class="string">info</span>    <span class="attr">serverPort:</span> <span class="number">3101</span>    <span class="attr">clients:</span>      <span class="bullet">-</span> <span class="attr">url:</span> <span class="string">http://&#123;&#123;</span> <span class="string">.Release.Name</span> <span class="string">&#125;&#125;:3100/loki/api/v1/push</span>  <span class="attr">defaultVolumes:</span> <span class="comment"># 定时 Promtail Pod 使用的卷</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span>      <span class="attr">hostPath:</span>        <span class="attr">path:</span> <span class="string">/run/promtail</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">containers</span>      <span class="attr">hostPath:</span>        <span class="attr">path:</span> <span class="string">/data/docker/containers</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pods</span>      <span class="attr">hostPath:</span>        <span class="attr">path:</span> <span class="string">/var/log/pods</span>  <span class="attr">defaultVolumeMounts:</span> <span class="comment"># 定义容器内的挂载点，将上述卷挂载到 Promtail 容器</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span>      <span class="attr">mountPath:</span> <span class="string">/run/promtail</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">containers</span>      <span class="attr">mountPath:</span> <span class="string">/data/docker/containers</span>      <span class="attr">readOnly:</span> <span class="literal">true</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pods</span>      <span class="attr">mountPath:</span> <span class="string">/var/log/pods</span>      <span class="attr">readOnly:</span> <span class="literal">true</span><span class="attr">grafana:</span>  <span class="attr">enabled:</span> <span class="literal">true</span>     <span class="comment"># 启用部署Grafana</span>  <span class="attr">persistence:</span>    <span class="attr">enabled:</span> <span class="literal">true</span>    <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>    <span class="attr">size:</span> <span class="string">5Gi</span>    <span class="attr">storageClassName:</span> <span class="string">loki-storage</span> <span class="comment"># 使用 loki-storage 自动创建PV</span>    <span class="comment"># 显式禁用不需要的子 Chart</span><span class="attr">test_pod:</span>  <span class="attr">enabled:</span> <span class="literal">false</span>  <span class="attr">filebeat:</span>  <span class="attr">enabled:</span> <span class="literal">false</span><span class="attr">fluent-bit:</span>  <span class="attr">enabled:</span> <span class="literal">false</span><span class="attr">prometheus:</span>  <span class="attr">enabled:</span> <span class="literal">false</span><span class="attr">logstash:</span>  <span class="attr">enabled:</span> <span class="literal">false</span></code></pre><p>如上，修改了 loki、promtail、grafana ，使用 helm 部署时会依次安装这3个组件，并且关闭其它不需要的模块</p><h2 id="4-修改-grafana-密码"><a href="#4-修改-grafana-密码" class="headerlink" title="4. 修改 grafana 密码"></a>4. 修改 grafana 密码</h2><p>编辑 grafana 目录下的 <code>values.yaml</code> 文件</p><pre><code class="highlight bash">$ vim loki-stack/charts/grafana/values.yaml<span class="comment"># 编辑下面的内容，将 admin 用户的密码也设置成 admin</span><span class="comment"># Administrator credentials when not using an existing secret (see below)</span>adminUser: adminadminPassword: admin</code></pre><h2 id="5-使用Helm部署Loki"><a href="#5-使用Helm部署Loki" class="headerlink" title="5. 使用Helm部署Loki"></a>5. 使用Helm部署Loki</h2><pre><code class="highlight bash"><span class="comment"># 进入 loki 解压目录</span>$ <span class="built_in">cd</span> loki-stack<span class="comment"># 查看文件夹内容</span>$ lltotal 20-rw-r--r-- 1 root root  374 Jul 16 16:50 Chart.yaml-rw-r--r-- 1 root root 2027 Jul 16 16:50 README.mddrwxr-xr-x 9 root root  117 Jul 16 16:50 charts-rw-r--r-- 1 root root  729 Jul 16 16:50 requirements.lock-rw-r--r-- 1 root root  867 Jul 16 16:50 requirements.yamldrwxr-xr-x 3 root root   80 Jul 16 16:50 templates-rw-r--r-- 1 root root 1455 Jul 16 16:50 values.yaml<span class="comment"># 执行 helm 命令，安装 loki</span>$ helm install loki -n loki --create-namespace -f values.yaml .NAME: lokiLAST DEPLOYED: Wed Jul 16 17:00:37 2025NAMESPACE: lokiSTATUS: deployedREVISION: 1NOTES:The Loki stack has been deployed to your cluster. Loki can now be added as a datasource <span class="keyword">in</span> Grafana.See http://docs.grafana.org/features/datasources/loki/ <span class="keyword">for</span> more detail.<span class="comment"># 补充命令：更新部署</span>helm upgrade loki -n loki -f values.yaml .</code></pre><p>查看部署资源</p><pre><code class="highlight bash">$ helm list -n lokiNAMENAMESPACEREVISIONUPDATED                                STATUS  CHART            APP VERSIONlokiloki     1       2025-07-16 17:15:50.136762865 +0800 CSTdeployedloki-stack-2.9.11v2.6.1$ kubectl get pods -n lokiNAME                           READY   STATUS    RESTARTS   AGEloki-0                         1/1     Running   0          3m38sloki-grafana-8869df8b7-ggnnh   1/1     Running   0          3m38sloki-promtail-5gvgd            1/1     Running   0          3m38sloki-promtail-bb5l9            1/1     Running   0          3m38sloki-promtail-gbv8t            1/1     Running   0          3m38sloki-promtail-mrw6n            1/1     Running   0          3m38s$ kubectl get svc -n lokiNAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGEloki              ClusterIP   10.97.142.238   &lt;none&gt;        3100/TCP   76sloki-grafana      ClusterIP   10.111.244.51   &lt;none&gt;        80/TCP     76sloki-headless     ClusterIP   None            &lt;none&gt;        3100/TCP   76sloki-memberlist   ClusterIP   None            &lt;none&gt;        7946/TCP   76s$ kubectl get statefulset -n lokiNAME   READY   AGEloki   1/1     91s$ kubectl get deployment -n lokiNAME           READY   UP-TO-DATE   AVAILABLE   AGEloki-grafana   1/1     1            1           99s$ kubectl get cm -n lokiNAME               DATA   AGEkube-root-ca.crt   1      16mloki-grafana       1      107s</code></pre><h2 id="6-部署-Ingress"><a href="#6-部署-Ingress" class="headerlink" title="6. 部署 Ingress"></a>6. 部署 Ingress</h2><p>用于浏览器访问 Grafana</p><p>资源清单：<code>loki-ingress.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-ui</span>  <span class="attr">namespace:</span> <span class="string">loki</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">grafana</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span>       <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">loki.grafana.com</span>    <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 loki.grafana.com 的流量。客户端必须通过该域名访问</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>             <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>    <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">loki-grafana</span>   <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span>  <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f loki-ingress.yaml</code></pre><p><strong>修改 HOSTS 文件</strong></p><p>添加域名映射</p><pre><code class="highlight plaintext">10.20.1.140 loki.grafana.com</code></pre><p><strong>补充：如果没有设置 grafana 的初始密码，grafana 在创建时会默认生成密码</strong></p><pre><code class="highlight bash"><span class="comment"># 查看有哪些 Secret</span>$ kubectl get secret -n lokiNAME                         TYPE                 DATA   AGEloki                         Opaque               1      13mloki-grafana                 Opaque               3      13mloki-promtail                Opaque               1      13msh.helm.release.v1.loki.v1   helm.sh/release.v1   1      13m<span class="comment"># 查看默认用户名</span>$ kubectl get secret -n loki loki-grafana -o jsonpath=<span class="string">&quot;&#123;.data.admin-user&#125;&quot;</span> | <span class="built_in">base64</span> --decode admin<span class="comment"># 查看默认密码</span>$ $ kubectl get secret -n loki loki-grafana -o jsonpath=<span class="string">&quot;&#123;.data.admin-password&#125;&quot;</span> | <span class="built_in">base64</span> --decodeUnBUY0EbcPuaLrHnBybhYuZOSFb5rmDvNpXQn2vr</code></pre><h2 id="7-添加-Loki-数据源"><a href="#7-添加-Loki-数据源" class="headerlink" title="7. 添加 Loki 数据源"></a>7. 添加 Loki 数据源</h2><p><strong>登录 Grafana</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135126.png" alt="Grafana"></p><p><strong>添加数据源</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135316.png" alt="添加数据源"></p><p><strong>选择 Loki 作为数据源</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135346.png" alt="选择默认的 Loki 数据源"></p><p><strong>编辑数据源</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135559.png" alt="编辑数据源"></p><p><strong>保存数据源配置</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135639.png" alt="保存数据源配置"></p><p><strong>选择数据源，搜索查看日志</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135917.png" alt="查看日志"></p><p><strong>选择标签，点击查询</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-140204.png" alt="选择标签，点击查询"></p><p><strong>至此，关于如何使用 Helm 部署 Loki 就介绍完成了</strong></p><p><strong>参考链接：</strong></p><blockquote><p><a href="https://grafana.org.cn/docs/loki/latest/get-started/overview/">https://grafana.org.cn/docs/loki/latest/get-started/overview/</a></p><p><a href="https://www.cnblogs.com/starsray/p/17549842.html">https://www.cnblogs.com/starsray/p/17549842.html</a></p><p><a href="https://www.boysec.cn/boy/632ed78c.html">https://www.boysec.cn/boy/632ed78c.html</a></p><p><a href="https://www.qikqiak.com/k3s/logging/loki/overview/">https://www.qikqiak.com/k3s/logging/loki/overview/</a></p><p><a href="https://blog.frognew.com/tags/loki.html">https://blog.frognew.com/tags/loki.html</a></p><p><a href="https://blog.csdn.net/sj1163739403/article/details/142638504">https://blog.csdn.net/sj1163739403/article/details/142638504</a></p><p><a href="https://blog.csdn.net/ichen820/article/details/134287977">https://blog.csdn.net/ichen820/article/details/134287977</a></p><p><a href="https://www.ywbj.cc/?p=951">https://www.ywbj.cc/?p=951</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;概要：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;简述 Loki 相关组件原理，并演示两种使用 Loki 监控Pod日志的部署方式：&lt;strong&gt;使用 yaml 资源清单部署&lt;/strong&gt; 和 &lt;strong&gt;使用 Helm 部署&lt;/strong&gt;&lt;/p&gt;
&lt;p</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Loki" scheme="https://georgechan95.github.io/tags/Loki/"/>
    
  </entry>
  
  <entry>
    <title>013-K8S-使用Helm安装Harbor</title>
    <link href="https://georgechan95.github.io/blog/3fee6d19.html"/>
    <id>https://georgechan95.github.io/blog/3fee6d19.html</id>
    <published>2025-07-07T14:37:00.000Z</published>
    <updated>2025-07-10T05:33:47.929Z</updated>
    
    <content type="html"><![CDATA[<p><strong>当前集群环境</strong></p><table><thead><tr><th>IP</th><th>Hostname</th><th>用途</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td><td></td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td><td></td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td><td></td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td><td>安装NFS，Harbor</td></tr></tbody></table><h1 id="一、安装准备"><a href="#一、安装准备" class="headerlink" title="一、安装准备"></a>一、安装准备</h1><h2 id="1-安装NFS-配置存储卷"><a href="#1-安装NFS-配置存储卷" class="headerlink" title="1. 安装NFS,配置存储卷"></a>1. 安装NFS,配置存储卷</h2><p>安装 NFS,配置存储卷自动分配 PV，用于持久化 Harbor 存储的镜像。</p><p>这里选用 k8s-master (10.20.1.139) 作为 nfs 服务端，其它节点作为 nfs 客户端</p><h3 id="1-1-安装-NFS-服务"><a href="#1-1-安装-NFS-服务" class="headerlink" title="1.1 安装 NFS 服务"></a>1.1 安装 NFS 服务</h3><blockquote><p>master节点、node01、node02、node03 节点都需要安装执行</p></blockquote><pre><code class="highlight bash">$ yum install -y nfs-utils rpcbind</code></pre><h3 id="1-2-创建共享目录"><a href="#1-2-创建共享目录" class="headerlink" title="1.2 创建共享目录"></a>1.2 创建共享目录</h3><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash"><span class="comment"># 创建 共享目录</span>$ <span class="built_in">mkdir</span> -p /root/data/harbor/<span class="comment"># 目录提权</span><span class="built_in">chmod</span> 777 /root/data/harbor/<span class="comment"># 变更用户组</span><span class="built_in">chown</span> nobody /root/data/harbor/</code></pre><h3 id="1-3-编辑共享目录读写配置"><a href="#1-3-编辑共享目录读写配置" class="headerlink" title="1.3 编辑共享目录读写配置"></a>1.3 编辑共享目录读写配置</h3><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash">$ vim /etc/exports/root/data     10.20.1.0/24(rw,fsid=0,no_root_squash)/root/data/harbor     10.20.1.0/24(rw,no_root_squash,no_all_squash,<span class="built_in">sync</span>)</code></pre><p>这里使用的是 NFS4 服务，上面的配置表示 10.20.1.0&#x2F;24 网段的 ip 都可以与 nfs 主服务器共享 <code>/root/data/harbor</code> 目录内容</p><h3 id="1-4-启动NFS服务"><a href="#1-4-启动NFS服务" class="headerlink" title="1.4 启动NFS服务"></a>1.4 启动NFS服务</h3><blockquote><p>集群内所有节点都需要操作</p></blockquote><pre><code class="highlight bash"> <span class="comment"># 启动服务</span>$ systemctl start rpcbind$ systemctl restart nfs-server.service<span class="comment"># 设置开机自启</span>$ systemctl <span class="built_in">enable</span> rpcbind$ systemctl <span class="built_in">enable</span> nfs-server.service</code></pre><h3 id="1-5-测试-NFS-目录挂载"><a href="#1-5-测试-NFS-目录挂载" class="headerlink" title="1.5 测试 NFS 目录挂载"></a>1.5 测试 NFS 目录挂载</h3><pre><code class="highlight bash"><span class="comment"># NFS 客户端执行：创建目录</span>$ <span class="built_in">mkdir</span> /data/test1<span class="comment"># NFS 客户端执行：挂载目录到NFS服务端</span>$ mount -t nfs4 10.20.1.139:/harbor /data/test1<span class="comment"># NFS 客户端执行：查看挂载结果</span>$ mount | grep /data/test110.20.1.139:/harbor on /data/test1 <span class="built_in">type</span> nfs4 (rw,relatime,vers=4.2,rsize=524288,wsize=524288,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.1.142,local_lock=none,addr=10.20.1.139)<span class="comment"># NFS 客户端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;this is client&quot;</span> &gt; /data/test1/a.txt<span class="comment"># NFS 服务端执行：查看数据， 结论：客户端数据已写入服务端挂载目录</span>$ <span class="built_in">cat</span> /root/data/harbor/a.txt this is client<span class="comment"># NFS 服务端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;This is Server&quot;</span> &gt;&gt; /root/data/harbor/a.txt<span class="comment"># NFS 客户端执行：查看数据， 结论：服务端数据已写入客户端挂载目录</span>$ <span class="built_in">cat</span> /data/test1/a.txt this is clientThis is Server</code></pre><p><strong>取消挂载</strong></p><pre><code class="highlight bash"><span class="comment"># 取消挂载</span>umount /data/test1<span class="comment"># 如果取消挂载出现报错，例如：</span>$ umount /data/test1umount.nfs4: /data/test1: device is busy<span class="comment"># 查看目录占用进程</span>$ fuser -m /data/test1/data/test1:         32679c<span class="comment"># kill 进程</span>$ <span class="built_in">kill</span> -9 32679<span class="comment"># 方式二：强制卸载</span>umount -l /data/test1</code></pre><h3 id="1-6-配置存储卷"><a href="#1-6-配置存储卷" class="headerlink" title="1.6 配置存储卷"></a>1.6 配置存储卷</h3><h4 id="1-6-1-创建命名空间"><a href="#1-6-1-创建命名空间" class="headerlink" title="1.6.1 创建命名空间"></a>1.6.1 创建命名空间</h4><p>nfs存储卷相关配置放到指定的命名空间中</p><pre><code class="highlight bash"><span class="comment"># 创建命名空间，</span>$ kubectl create ns nfs-storagenamespace/nfs-storage created</code></pre><h4 id="1-6-2-配置nfs-storage-yaml并运行"><a href="#1-6-2-配置nfs-storage-yaml并运行" class="headerlink" title="1.6.2 配置nfs-storage.yaml并运行"></a>1.6.2 配置<code>nfs-storage.yaml</code>并运行</h4><pre><code class="highlight bash">apiVersion: storage.k8s.io/v1kind: StorageClassmetadata:  namespace: nfs-storage  name: nfs-client<span class="comment"># provisioner: nfs-provisioner</span>provisioner: k8s-sigs.io/nfs-subdir-external-provisioner <span class="comment"># 指定动态配置器，NFS 子目录外部配置器</span>parameters:  pathPattern: <span class="variable">$&#123;.PVC.namespace&#125;</span>/<span class="variable">$&#123;.PVC.name&#125;</span> <span class="comment"># 动态生成的 NFS 路径，格式为 &lt;PVC 命名空间&gt;/&lt;PVC 名称&gt;，例如 nfs-storageclass/test-claim。</span>  archiveOnDelete: <span class="string">&quot;true&quot;</span> <span class="comment">##删除 pv,pv内容是否备份</span>---apiVersion: apps/v1kind: Deploymentmetadata:  namespace: nfs-storage  name: nfs-client-provisioner <span class="comment"># NFS 动态存储配置器，用于自动为 PVC 创建 PV</span>spec:  replicas: 1  selector:    matchLabels:      app: nfs-client-provisioner  template:    metadata:      labels:        app: nfs-client-provisioner    spec:      serviceAccountName: nfs-client-provisioner <span class="comment"># 指定使用的 ServiceAccountName</span>      containers:        - name: nfs-client-provisioner          image: k8s.dockerproxy.com/sig-storage/nfs-subdir-external-provisioner:v4.0.2          imagePullPolicy: IfNotPresent          volumeMounts:            - name: nfs-client-root <span class="comment"># 挂载的卷名称，与 volumes 部分定义的卷对应</span>              mountPath: /persistentvolumes <span class="comment"># 将 NFS 卷挂载到容器内的 /persistentvolumes 路径，供容器读写 NFS 共享数据。</span>          <span class="built_in">env</span>:            - name: PROVISIONER_NAME              value: k8s-sigs.io/nfs-subdir-external-provisioner <span class="comment"># 指定配置器名称，与 StorageClass 保持一致</span>            - name: NFS_SERVER              value: 10.20.1.139 <span class="comment"># NFS 服务器地址</span>            - name: NFS_PATH              value: /root/data/harbor <span class="comment"># NFS 共享路径</span>      volumes:        - name: nfs-client-root <span class="comment"># 定义一个名为 nfs-client-root 的 NFS 卷，连接到 NFS 服务器的指定地址和路径</span>          nfs:            server: 10.20.1.139 <span class="comment"># NFS 服务器地址</span>            path: /root/data/harbor <span class="comment"># NFS 共享路径</span>      nodeName: k8s-node02 <span class="comment"># 指定 Pod 运行在 k8s-node02 节点上</span>---apiVersion: v1kind: ServiceAccountmetadata:  name: nfs-client-provisioner <span class="comment"># SA 的名称</span>  namespace: nfs-storage---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata:  name: nfs-client-provisioner-runnerrules:  - apiGroups: [<span class="string">&quot;&quot;</span>]    resources: [<span class="string">&quot;nodes&quot;</span>]    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  - apiGroups: [<span class="string">&quot;&quot;</span>]    resources: [<span class="string">&quot;persistentvolumes&quot;</span>]    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>]  - apiGroups: [<span class="string">&quot;&quot;</span>]    resources: [<span class="string">&quot;persistentvolumeclaims&quot;</span>]    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]  - apiGroups: [<span class="string">&quot;storage.k8s.io&quot;</span>]    resources: [<span class="string">&quot;storageclasses&quot;</span>]    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  - apiGroups: [<span class="string">&quot;&quot;</span>]    resources: [<span class="string">&quot;events&quot;</span>]    verbs: [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata:  name: run-nfs-client-provisionersubjects:  - kind: ServiceAccount <span class="comment"># 绑定类型 ServiceAccount</span>    name: nfs-client-provisioner <span class="comment"># ServiceAccount 的名称</span>    namespace: nfs-storageroleRef:  kind: ClusterRole <span class="comment"># 绑定的角色类型</span>  name: nfs-client-provisioner-runner <span class="comment"># 集群角色名称 nfs-client-provisioner-runner</span>  apiGroup: rbac.authorization.k8s.io---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata:  name: leader-locking-nfs-client-provisioner <span class="comment"># 角色的名称，表明它与 NFS 客户端存储提供者的领导者选举（leader election）机制相关。</span>  namespace: nfs-storagerules:  - apiGroups: [<span class="string">&quot;&quot;</span>] <span class="comment"># 空字符串表示核心 API 组（core API group），包含 Kubernetes 的基本资源，如 endpoints。</span>    resources: [<span class="string">&quot;endpoints&quot;</span>]    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]---kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata:  name: run-leader-locking-nfs-client-provisioner  namespace: nfs-storagesubjects:  - kind: ServiceAccount <span class="comment"># 绑定资源类型为 ServiceAccount</span>    name: nfs-client-provisioner <span class="comment"># 绑定的ServiceAccount 名称</span>    namespace: nfs-storageroleRef:  kind: Role <span class="comment"># 绑定角色（nfs-storage名称空间的角色）</span>  apiGroup: rbac.authorization.k8s.io  name: leader-locking-nfs-client-provisioner <span class="comment"># 角色的名称</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f nfs-storage.yaml$ kubectl get all -n nfs-storageNAME                                         READY   STATUS    RESTARTS   AGEpod/nfs-client-provisioner-c485df84f-44hmr   1/1     Running   0          112sNAME                                     READY   UP-TO-DATE   AVAILABLE   AGEdeployment.apps/nfs-client-provisioner   1/1     1            1           112sNAME                                               DESIRED   CURRENT   READY   AGEreplicaset.apps/nfs-client-provisioner-c485df84f   1         1         1       112s</code></pre><h3 id="2-安装-Helm，添加-Harbor-仓库"><a href="#2-安装-Helm，添加-Harbor-仓库" class="headerlink" title="2. 安装 Helm，添加 Harbor 仓库"></a>2. 安装 Helm，添加 Harbor 仓库</h3><h4 id="2-1-安装-Helm"><a href="#2-1-安装-Helm" class="headerlink" title="2.1 安装 Helm"></a>2.1 安装 Helm</h4><p>参考：<a href="https://georgechan95.github.io/blog/d8e3c7b3.html">https://georgechan95.github.io/blog/d8e3c7b3.html</a></p><p><strong>下载二进制安装包</strong></p><p>下载地址：<a href="https://github.com/helm/helm/releases">https://github.com/helm/helm/releases</a></p><pre><code class="highlight bash">wget https://get.helm.sh/helm-v3.12.3-linux-amd64.tar.gz</code></pre><p><strong>解压二进制包</strong></p><pre><code class="highlight bash">$ tar -zxvf helm-v3.12.3-linux-amd64.tar.gz</code></pre><p><strong>将二进制文件移动到对应的目录中</strong></p><pre><code class="highlight bash">$ <span class="built_in">mv</span> linux-amd64/helm /usr/local/bin/helm</code></pre><p><strong>测试</strong></p><pre><code class="highlight bash"><span class="comment"># 查看Helm版本</span>$ helm versionversion.BuildInfo&#123;Version:<span class="string">&quot;v3.12.3&quot;</span>, GitCommit:<span class="string">&quot;3a31588ad33fe3b89af5a2a54ee1d25bfe6eaa5e&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, GoVersion:<span class="string">&quot;go1.20.7&quot;</span>&#125;</code></pre><h3 id="3-安装-Ingress-控制器"><a href="#3-安装-Ingress-控制器" class="headerlink" title="3. 安装 Ingress 控制器"></a>3. 安装 Ingress 控制器</h3><p>参考：<a href="https://georgechan95.github.io/blog/6436eaf1.html">https://georgechan95.github.io/blog/6436eaf1.html</a> 第三节</p><pre><code class="highlight bash"><span class="comment"># 下载 ingress-nginx 需要的镜像</span><span class="comment"># k8s-node03 节点需要导入这些镜像</span>docker pull registry.k8s.io/ingress-nginx/controller:v1.9.4docker pull registry.k8s.io/defaultbackend-amd64:1.5docker pull registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231011-8b53cabe0docker pull registry.k8s.io/ingress-nginx/opentelemetry:v20230721-3e2062ee5</code></pre><p>master节点重新安装 Ingress-nginx ，让 k8s-node03 节点安装上 Ingress 控制器</p><pre><code class="highlight bash"><span class="comment"># 卸载原有的 ingress-nginx</span>[root@k8s-master01 /opt/k8s/10/ingress-nginx]$ helm uninstall ingress-nginx --namespace ingress-nginx<span class="comment"># 或者更新 ingress-nginx</span>$ helm upgrade ingress-nginx /opt/k8s/10/ingress-nginx --namespace ingress-nginx -f /opt/k8s/10/ingress-nginx/values.yaml<span class="comment"># 重新安装</span>[root@k8s-master01 /opt/k8s/10/ingress-nginx]$ helm install ingress-nginx --namespace ingress-nginx --create-namespace .<span class="comment"># 查看 Ingress，k8s-node03 成功运行了 ingress控制器</span>$ kubectl get pod -n ingress-nginx -o wideNAME                             READY   STATUS    RESTARTS   AGE     IP            NODE         NOMINATED NODE   READINESS GATESingress-nginx-controller-5wzqt   1/1     Running   0          2m33s   10.20.1.141   k8s-node02   &lt;none&gt;           &lt;none&gt;ingress-nginx-controller-9wfpq   1/1     Running   0          2m33s   10.20.1.142   k8s-node03   &lt;none&gt;           &lt;none&gt;ingress-nginx-controller-z9sl8   1/1     Running   0          2m33s   10.20.1.140   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h2 id="2-安装-Harbor"><a href="#2-安装-Harbor" class="headerlink" title="2. 安装 Harbor"></a>2. 安装 Harbor</h2><h3 id="2-1-添加-Harbor-仓库，下载安装包"><a href="#2-1-添加-Harbor-仓库，下载安装包" class="headerlink" title="2.1  添加 Harbor 仓库，下载安装包"></a>2.1  添加 Harbor 仓库，下载安装包</h3><pre><code class="highlight bash"><span class="comment"># 添加Harbor仓库</span>$ helm repo add harbor https://helm.goharbor.io<span class="comment"># 从仓库中查看harbor安装包，最新的4个</span>$ helm search repo harbor -l |  grep harbor/harbor  | <span class="built_in">head</span>  -4<span class="comment"># 拉取指定版本的harbor helm安装包</span>$ helm pull harbor/harbor --version 1.17.1<span class="comment"># 解压</span>tar -zxvf harbor-1.17.1.tgz harbor</code></pre><h3 id="2-2-创建命名空间，指定安装节点"><a href="#2-2-创建命名空间，指定安装节点" class="headerlink" title="2.2 创建命名空间，指定安装节点"></a>2.2 创建命名空间，指定安装节点</h3><p>这里将 harbor 安装到 k8s-node03 节点上，并在单独的命名空间中。</p><pre><code class="highlight bash"><span class="comment"># 给 k8s-node03 节点打一个标签</span>$ kubectl label node k8s-node03 harbor=<span class="built_in">env</span></code></pre><p><strong>创建命名空间，并指定节点</strong></p><pre><code class="highlight bash">$ <span class="built_in">cat</span> namespace-harbor.yaml apiVersion: v1kind: Namespacemetadata:  name: harbor<span class="comment"># 执行资源清单</span>$ kubectl apply -f namespace-harbor.yaml<span class="comment"># 查看命名空间</span>$ kubectl get ns | grep harborharbor            Active   44m</code></pre><h3 id="2-3-修改-harbor-目录下的-values-yaml"><a href="#2-3-修改-harbor-目录下的-values-yaml" class="headerlink" title="2.3 修改 harbor 目录下的 values.yaml"></a>2.3 修改 harbor 目录下的 values.yaml</h3><h4 id="2-3-1-修改-hostname-定义自己的域名"><a href="#2-3-1-修改-hostname-定义自己的域名" class="headerlink" title="2.3.1 修改 hostname 定义自己的域名"></a>2.3.1 修改 hostname 定义自己的域名</h4><pre><code class="highlight yaml"><span class="attr">expose:</span>  <span class="attr">type:</span> <span class="string">ingress</span>  <span class="attr">ingress:</span>    <span class="attr">hosts:</span>      <span class="attr">core:</span> <span class="string">my.harbor.docker</span> <span class="comment"># 自定义域名</span><span class="attr">externalURL:</span> <span class="string">https://my.harbor.docker</span> <span class="comment"># 与上面保持一致</span></code></pre><h4 id="2-3-2-持久卷配置"><a href="#2-3-2-持久卷配置" class="headerlink" title="2.3.2 持久卷配置"></a>2.3.2 持久卷配置</h4><p>持久卷修改storageClass ，改成前面定义 nfs-client</p><pre><code class="highlight yaml"><span class="attr">persistence:</span>  <span class="attr">enabled:</span> <span class="literal">true</span>  <span class="attr">resourcePolicy:</span> <span class="string">&quot;keep&quot;</span>  <span class="attr">persistentVolumeClaim:</span>    <span class="attr">registry:</span>      <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span>      <span class="attr">accessMode:</span> <span class="string">ReadWriteOnce</span>      <span class="attr">size:</span> <span class="string">5Gi</span>    <span class="attr">jobservice:</span>      <span class="attr">jobLog:</span>        <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span>        <span class="attr">accessMode:</span> <span class="string">ReadWriteOnce</span>        <span class="attr">size:</span> <span class="string">1Gi</span>    <span class="attr">database:</span>      <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span>      <span class="attr">accessMode:</span> <span class="string">ReadWriteOnce</span>      <span class="attr">size:</span> <span class="string">1Gi</span>    <span class="attr">redis:</span>      <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span>      <span class="attr">accessMode:</span> <span class="string">ReadWriteOnce</span>      <span class="attr">size:</span> <span class="string">1Gi</span>    <span class="attr">trivy:</span>      <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span>      <span class="attr">accessMode:</span> <span class="string">ReadWriteOnce</span>      <span class="attr">size:</span> <span class="string">5Gi</span></code></pre><h4 id="2-3-3-修改Pod节点选择器"><a href="#2-3-3-修改Pod节点选择器" class="headerlink" title="2.3.3 修改Pod节点选择器"></a>2.3.3 修改Pod节点选择器</h4><p>修改 nodeSelector ，让 harbor 所有 Pod 都运行在 k8s-node03 节点上。</p><pre><code class="highlight yaml"><span class="attr">nginx:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">portal:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">core:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">jobservice:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">registry:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">trivy:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">database:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">redis:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">exporter:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span></code></pre><p>修改database资源</p><pre><code class="highlight yaml"><span class="attr">database:</span>  <span class="attr">internal:</span>    <span class="attr">resources:</span>      <span class="attr">requests:</span>        <span class="attr">memory:</span> <span class="string">256Mi</span>        <span class="attr">cpu:</span> <span class="string">100m</span></code></pre><h3 id="2-4-安装-Harbor-到集群"><a href="#2-4-安装-Harbor-到集群" class="headerlink" title="2.4 安装 Harbor 到集群"></a>2.4 安装 Harbor 到集群</h3><pre><code class="highlight bash"><span class="comment"># 进入Harbor 解压目录，安装Harbor</span>$ helm install harbor /opt/software/harbor -n harbor<span class="comment"># 修改 values.yaml 更新安装</span><span class="comment">#$ helm upgrade harbor /opt/software/harbor -n harbor -f /opt/software/harbor/values.yaml</span><span class="comment"># 在任务目录下安装Harbor</span><span class="comment">#$ helm install harbor /opt/software/harbor -n harbor -f /opt/software/harbor/values.yaml</span></code></pre><p><strong>特别注意：</strong></p><p>由于 habor 运行依赖的镜像都在国外仓库，因此在执行安装时会出现镜像拉取失败的情况，这里我通过docker代理的形式下载镜像，并导入到 k8s-node03 节点上。具体参考：<a href="https://georgechan95.github.io/blog/b01d5c62.html">Docker配置网络代理实现外网镜像下载</a></p><p>所有镜像都在 values.yaml 文件中</p><pre><code class="highlight bash">docker pull goharbor/nginx-photon:v2.13.1docker pull goharbor/harbor-portal:v2.13.1docker pull goharbor/harbor-core:v2.13.1docker pull goharbor/harbor-jobservice:v2.13.1docker pull goharbor/registry-photon:v2.13.1docker pull goharbor/harbor-registryctl:v2.13.1docker pull goharbor/trivy-adapter-photon:v2.13.1docker pull goharbor/harbor-db:v2.13.1docker pull goharbor/redis-photon:v2.13.1docker pull goharbor/harbor-exporter:v2.13.1<span class="built_in">echo</span> <span class="string">&quot;镜像下载完成&quot;</span>docker save goharbor/nginx-photon:v2.13.1 -o nginx-photon-v2.13.1.tardocker save goharbor/harbor-portal:v2.13.1 -o harbor-portal-v2.13.1.tardocker save goharbor/harbor-core:v2.13.1 -o harbor-core-v2.13.1.tardocker save goharbor/harbor-jobservice:v2.13.1 -o harbor-jobservice-v2.13.1.tardocker save goharbor/registry-photon:v2.13.1 -o registry-photon-v2.13.1.tardocker save goharbor/harbor-registryctl:v2.13.1 -o harbor-registryctl-v2.13.1.tardocker save goharbor/trivy-adapter-photon:v2.13.1 -o trivy-adapter-photon-v2.13.1.tardocker save goharbor/harbor-db:v2.13.1 -o harbor-db-v2.13.1.tardocker save goharbor/redis-photon:v2.13.1 -o redis-photon-v2.13.1.tardocker save goharbor/harbor-exporter:v2.13.1 -o harbor-exporter-v2.13.1.tar<span class="built_in">echo</span> <span class="string">&quot;镜像打包完成&quot;</span>docker load -i nginx-photon-v2.13.1.tardocker load -i harbor-portal-v2.13.1.tardocker load -i harbor-core-v2.13.1.tardocker load -i harbor-jobservice-v2.13.1.tardocker load -i registry-photon-v2.13.1.tardocker load -i harbor-registryctl-v2.13.1.tardocker load -i trivy-adapter-photon-v2.13.1.tardocker load -i harbor-db-v2.13.1.tardocker load -i redis-photon-v2.13.1.tardocker load -i harbor-exporter-v2.13.1.tar<span class="built_in">echo</span> <span class="string">&quot;镜像加载完成&quot;</span></code></pre><h3 id="2-5-Docker-导入-Harbor-密钥"><a href="#2-5-Docker-导入-Harbor-密钥" class="headerlink" title="2.5 Docker 导入 Harbor 密钥"></a>2.5 Docker 导入 Harbor 密钥</h3><h4 id="2-5-1-导出-Harbor-公钥"><a href="#2-5-1-导出-Harbor-公钥" class="headerlink" title="2.5.1 导出 Harbor 公钥"></a>2.5.1 导出 Harbor 公钥</h4><pre><code class="highlight bash"><span class="comment"># 查看Harbor生成的Secret</span>$ kubectl get secret -n harborNAME                           TYPE                 DATA   AGEharbor-core                    Opaque               8      13mharbor-database                Opaque               1      13mharbor-ingress                 kubernetes.io/tls    3      13mharbor-jobservice              Opaque               2      13mharbor-registry                Opaque               2      13mharbor-registry-htpasswd       Opaque               1      13mharbor-registryctl             Opaque               0      13mharbor-trivy                   Opaque               2      13msh.helm.release.v1.harbor.v1   helm.sh/release.v1   1      13m<span class="comment"># 1. 查看 harbor 公钥内容，ca.crt 就是公钥</span>$ kubectl get secret harbor-ingress -n harbor -o yamlapiVersion: v1data:  ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lRTlZRd3VoTk5ERjNSQmZPTTM3c25sakFOQmdrcWhraUc5dzBCQVFzRkFEQVUKTVJJd0VBWURWUVFERXdsb1lYSmliM0l0WTJFd0hoY05NalV3TnpBNE1EWXhNRE0wV2hjTk1qWXdOekE0TURZeApNRE0wV2pBVU1SSXdFQVlEVlFRREV3bG9ZWEppYjNJdFkyRXdnZ0VpTUEwR0NTcUdTSWIzRFFFQkFRVUFBNElCCkR3QXdnZ0VLQW9JQkFRRGZQdjFoWDhPYVpYWkNkOXFzSld0RUtWbXdUakRrMlhGZFJQRS93dnV5T2V5UW1tZDYKSzFJUW0zYXpqQThvMGlvSHdScXhZaGNjYjN2SmUxRld1TDFoTTBQTkRWRWRVakxzc0kzWm1pcXlTano1N1YxMgpVeWlabGRqcHVCYlBQcGNhL3dLc0V6bG04SFFhMkI4NndsaEJzUFUxd0dxT1FPbSt5WlVBdEZ1dGVrT2xDNGZHCnM0SFd5MlVJNm5pclFKRXFWc2Foek83dHFaRzhNK1NZQTJLRnpkTEN1R0pkTnpjR3QrTzJ2NjRyNy9SVVRHTk8KVWlpRTIweXhYVFl2NTVrcnd6dlhRNXhKRlBzb0w1YmsycjVxU3lKVTlydmtpNEhjV0pubUhHSFN3OTJTU3FGZwpwVUZKNm4rQkEzbThEdk1CL2pZOW5EcUk1NzluM3dxSm9QaURBZ01CQUFHallUQmZNQTRHQTFVZER3RUIvd1FFCkF3SUNwREFkQmdOVkhTVUVGakFVQmdnckJnRUZCUWNEQVFZSUt3WUJCUVVIQXdJd0R3WURWUjBUQVFIL0JBVXcKQXdFQi96QWRCZ05WSFE0RUZnUVVoZXRCUEpwUkxSKzdOTHFFWEZyN2FXakJ6VDB3RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFINDJqOGtSUFNMdjNjaGFEU3BMUDdWeG9obU9lRythajYvMVBSTmFpWjlvZVdDd3kveGVRODlZCnFycEViVmF5anVJUlpFcDh2VE4yL3pxcUFzOGh5MHRSY3NxNzAraE8rUlJpdStNUFJ0ZzNmTlY3RlZVVzd5aXkKMG0xTmpPL1U1RXpxbnlQQkNGbWJZM1Z6Q3Vmdzc0bElFU0JDZHc4SW03ODRTeDBoa1dTRmd4RFY3djZZZDlKdgorN3laek4zQ2Flem1KS2xXT3VNQjByeTZNTC95bldPKzJxWVFZQjB6OGhyTFFwMS9aTzhpb05rMEVtL1pDL1JXCkNocVRmUFFsYzZUbGhJUFkrSnVYRDNVLzlIRXd4YWVWVzVqblI4cXpXdEJMVHUzSTE5ZERSUGJUQVN0N0w4MUoKU1BTb1lJMTFLTCt2cDBPRDY2ankzWjZ6VDQ4enNtbz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUROakNDQWg2Z0F3SUJBZ0lRTTh2VW9aMlhzMHowbVJFNXYyVU1BekFOQmdrcWhraUc5dzBCQVFzRkFEQVUKTVJJd0VBWURWUVFERXdsb1lYSmliM0l0WTJFd0hoY05NalV3TnpBNE1EWXhNRE0wV2hjTk1qWXdOekE0TURZeApNRE0wV2pBYk1Sa3dGd1lEVlFRREV4QnRlUzVvWVhKaWIzSXVaRzlqYTJWeU1JSUJJakFOQmdrcWhraUc5dzBCCkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXpLVEVmcjg1S1hza1JUVjF4TGhYbnRraExTUmhGM25GV0hYSzZyQ3QKMjdSRXhTSnlabDdZQU81U2RlT2tCRGs1dE5oRVhVTG83MHhYbThRdTQxNC9oeThtdHpvYmJXWWJrcHNtNGxlYQp2UmM1dTl3REhiSjVhNVpnV1FLaWJTd01nUWtLR3RmbHdhUUFUcTVMQm05TXRVc2hCN1hUQXB6R1dENXZEc3MzCm5MZXpCbFp0TUFyZmtncU9vLzQxMFVWTWtYV05CcVFpNFFkUUFoTVVuclR6d0ovdWo5UDhFR3podGxBMkVMTU4KamIrL1FUK05HcGVEQmFGWXcrNDdJa0V5RkY2RFJqdE9VTSt0SWt0Q2hCek5xd1BVUjJ0UCtSWWhrZnM4TnJlYQp2bDdwNC8rWnlIRWkwVXMwV3B4R2lqbXZITHY3Rmw0dENXam5LZkRoMVZjZ253SURBUUFCbzMwd2V6QU9CZ05WCkhROEJBZjhFQkFNQ0JhQXdIUVlEVlIwbEJCWXdGQVlJS3dZQkJRVUhBd0VHQ0NzR0FRVUZCd01DTUF3R0ExVWQKRXdFQi93UUNNQUF3SHdZRFZSMGpCQmd3Rm9BVWhldEJQSnBSTFIrN05McUVYRnI3YVdqQnpUMHdHd1lEVlIwUgpCQlF3RW9JUWJYa3VhR0Z5WW05eUxtUnZZMnRsY2pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQVAyZnUwd2p1CkQ0em1uWFdNRVYxMnhPbnJmZEUwNkxiUysxTXZMcmwyVGluZkwvY1F2M1VuNkZJWlVDVEsrSFJkUWxLdmZsK2cKSTZJUzJHWXJpcWQ1ZWk5Q1Z5YjZORUMrZzZ2RkhCZjZlK0tQaFNYNTVVTDhFQ2pDaUU4aURRdEZjOEdVUWg5MwoxNTFSdmo3VTZxVTV1WnBuck10NURJTy9LQ2F3NHRjcEpJUjhBR3RUUVFQUnRXRExvYzB5UityNWlaVWRpZyszClJNVzNReS9LZEtqamprK0UzYUU1Y2Z1RmFzeHNVZU9IcDcxQ2lhaEtGN3MwRW96QzhJRSsySFNEK3pLTFhpV3kKM203Q2pTdWhyTnhVL1pkNXZKSmkvVUUxWjB6dUh4dFBZenlHTWVQYWN0VFBDK1ZOWDJlU3hHRGgrN2tNS0Y3cQpqcmk1RVlRanNHQU43QT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K  tls.key: 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kind: Secretmetadata:  annotations:    meta.helm.sh/release-name: harbor    meta.helm.sh/release-namespace: harbor  creationTimestamp: <span class="string">&quot;2025-07-08T06:10:36Z&quot;</span>  labels:    app: harbor    app.kubernetes.io/instance: harbor    app.kubernetes.io/managed-by: Helm    app.kubernetes.io/name: harbor    app.kubernetes.io/part-of: harbor    app.kubernetes.io/version: 2.13.1    chart: harbor    heritage: Helm    release: harbor  name: harbor-ingress  namespace: harbor  resourceVersion: <span class="string">&quot;866456&quot;</span>  uid: f816d990-e733-45a1-999c-51ea9efeb1f7<span class="built_in">type</span>: kubernetes.io/tls<span class="comment"># 2. 将 ca.crt 解密后导出</span>$ <span class="built_in">echo</span> <span class="string">&#x27;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lRTlZRd3VoTk5ERjNSQmZPTTM3c25sakFOQmdrcWhraUc5dzBCQVFzRkFEQVUKTVJJd0VBWURWUVFERXdsb1lYSmliM0l0WTJFd0hoY05NalV3TnpBNE1EWXhNRE0wV2hjTk1qWXdOekE0TURZeApNRE0wV2pBVU1SSXdFQVlEVlFRREV3bG9ZWEppYjNJdFkyRXdnZ0VpTUEwR0NTcUdTSWIzRFFFQkFRVUFBNElCCkR3QXdnZ0VLQW9JQkFRRGZQdjFoWDhPYVpYWkNkOXFzSld0RUtWbXdUakRrMlhGZFJQRS93dnV5T2V5UW1tZDYKSzFJUW0zYXpqQThvMGlvSHdScXhZaGNjYjN2SmUxRld1TDFoTTBQTkRWRWRVakxzc0kzWm1pcXlTano1N1YxMgpVeWlabGRqcHVCYlBQcGNhL3dLc0V6bG04SFFhMkI4NndsaEJzUFUxd0dxT1FPbSt5WlVBdEZ1dGVrT2xDNGZHCnM0SFd5MlVJNm5pclFKRXFWc2Foek83dHFaRzhNK1NZQTJLRnpkTEN1R0pkTnpjR3QrTzJ2NjRyNy9SVVRHTk8KVWlpRTIweXhYVFl2NTVrcnd6dlhRNXhKRlBzb0w1YmsycjVxU3lKVTlydmtpNEhjV0pubUhHSFN3OTJTU3FGZwpwVUZKNm4rQkEzbThEdk1CL2pZOW5EcUk1NzluM3dxSm9QaURBZ01CQUFHallUQmZNQTRHQTFVZER3RUIvd1FFCkF3SUNwREFkQmdOVkhTVUVGakFVQmdnckJnRUZCUWNEQVFZSUt3WUJCUVVIQXdJd0R3WURWUjBUQVFIL0JBVXcKQXdFQi96QWRCZ05WSFE0RUZnUVVoZXRCUEpwUkxSKzdOTHFFWEZyN2FXakJ6VDB3RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFINDJqOGtSUFNMdjNjaGFEU3BMUDdWeG9obU9lRythajYvMVBSTmFpWjlvZVdDd3kveGVRODlZCnFycEViVmF5anVJUlpFcDh2VE4yL3pxcUFzOGh5MHRSY3NxNzAraE8rUlJpdStNUFJ0ZzNmTlY3RlZVVzd5aXkKMG0xTmpPL1U1RXpxbnlQQkNGbWJZM1Z6Q3Vmdzc0bElFU0JDZHc4SW03ODRTeDBoa1dTRmd4RFY3djZZZDlKdgorN3laek4zQ2Flem1KS2xXT3VNQjByeTZNTC95bldPKzJxWVFZQjB6OGhyTFFwMS9aTzhpb05rMEVtL1pDL1JXCkNocVRmUFFsYzZUbGhJUFkrSnVYRDNVLzlIRXd4YWVWVzVqblI4cXpXdEJMVHUzSTE5ZERSUGJUQVN0N0w4MUoKU1BTb1lJMTFLTCt2cDBPRDY2ankzWjZ6VDQ4enNtbz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=&#x27;</span> | <span class="built_in">base64</span> -d &gt; ca.crt</code></pre><h4 id="2-5-2-Docker-安装公钥"><a href="#2-5-2-Docker-安装公钥" class="headerlink" title="2.5.2 Docker 安装公钥"></a>2.5.2 Docker 安装公钥</h4><pre><code class="highlight bash"><span class="comment"># 将harbor证书保存在docker目录下，创建根域名相同的子目录，这一步建议所有机器都执行</span>$ <span class="built_in">mkdir</span> -p /etc/docker/certs.d/my.harbor.docker$ <span class="built_in">cp</span> ca.crt /etc/docker/certs.d/my.harbor.docker/</code></pre><h4 id="2-5-3-修改Docker-daemon-json"><a href="#2-5-3-修改Docker-daemon-json" class="headerlink" title="2.5.3 修改Docker daemon.json"></a>2.5.3 修改Docker daemon.json</h4><pre><code class="highlight bash">sudo vi /etc/docker/daemon.json<span class="comment"># 添加如下配置，my.harbor.docker 是自定义的harbor域名</span>&#123;  <span class="string">&quot;insecure-registries&quot;</span>: [<span class="string">&quot;my.harbor.docker&quot;</span>]&#125;<span class="comment"># 保存后重启Docker</span>systemctl daemon-reloadsystemctl restart docker</code></pre><h4 id="2-5-4-Dockers-登录Harbor"><a href="#2-5-4-Dockers-登录Harbor" class="headerlink" title="2.5.4 Dockers 登录Harbor"></a>2.5.4 Dockers 登录Harbor</h4><pre><code class="highlight bash"><span class="comment"># 服务器写入Host域名映射</span>$ <span class="built_in">echo</span> <span class="string">&quot;10.20.1.142 my.harbor.docker&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># docker 登录Harbor私服</span>$ docker login -u admin -p Harbor12345 my.harbor.dockerWARNING! Using --password via the CLI is insecure. Use --password-stdin.WARNING! Your credentials are stored unencrypted <span class="keyword">in</span> <span class="string">&#x27;/root/.docker/config.json&#x27;</span>.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/go/credential-store/Login Succeeded</code></pre><h4 id="2-5-6-浏览器访问"><a href="#2-5-6-浏览器访问" class="headerlink" title="2.5.6 浏览器访问"></a>2.5.6 浏览器访问</h4><p>客户端写入 Host 域名映射</p><pre><code class="highlight plaintext">10.20.1.142 my.harbor.docker</code></pre><p>访问地址：<a href="https://my.harbor.docker/">https://my.harbor.docker/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/08/20250708-151720.png" alt="浏览器登录Harbor"></p><h4 id="2-5-6-测试推送镜像到-Harbor-私服"><a href="#2-5-6-测试推送镜像到-Harbor-私服" class="headerlink" title="2.5.6 测试推送镜像到 Harbor 私服"></a>2.5.6 测试推送镜像到 Harbor 私服</h4><p><strong>在Harbor中创建一个新的项目</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/08/20250708-145248.png" alt="新建项目"></p><pre><code class="highlight bash"><span class="comment"># 给镜像打标签</span>$ docker tag busybox:latest my.harbor.docker/my-harbor/busybox:latest<span class="comment"># 查看镜像</span>$ docker images | grep busyboxbusybox                                                                       latest                ff7a7936e930   9 months ago    4.28MBmy.harbor.docker/my-harbor/busybox                                            latest                ff7a7936e930   9 months ago    4.28MB<span class="comment"># 将镜像推送到Harbor</span>$ docker push my.harbor.docker/my-harbor/busybox:latestThe push refers to repository [my.harbor.docker/my-harbor/busybox]068f50152bbc: Pushed latest: digest: sha256:f2e98ad37e4970f48e85946972ac4acb5574c39f27c624efbd9b17a3a402bfe4 size: 527</code></pre><p><strong>再次查看Harbor，镜像已推送到Harbor中</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/08/20250708-145650.png" alt="查看镜像"></p><h3 id="2-6-卸载-Harbor"><a href="#2-6-卸载-Harbor" class="headerlink" title="2.6 卸载 Harbor"></a>2.6 卸载 Harbor</h3><pre><code class="highlight bash">$ helm uninstall harbor -n harbor$ kubectl delete pvc -n harbor --all</code></pre><p><strong>参考链接</strong></p><blockquote><p><a href="https://www.cnblogs.com/qlsem/p/17714509.html">https://www.cnblogs.com/qlsem/p/17714509.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;当前集群环境&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;Hostname&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;10.20.1.139&lt;/td</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Harbor" scheme="https://georgechan95.github.io/tags/Harbor/"/>
    
  </entry>
  
  <entry>
    <title>012-新建Node节点添加到K8S集群中</title>
    <link href="https://georgechan95.github.io/blog/b42f2c7b.html"/>
    <id>https://georgechan95.github.io/blog/b42f2c7b.html</id>
    <published>2025-07-07T12:32:00.000Z</published>
    <updated>2025-10-03T07:25:32.344Z</updated>
    
    <content type="html"><![CDATA[<p>需求：当前集群为一主两从，共3个节点，基于 kube-admin 方式安装，需要增加一个从节点。</p><p><strong>当前集群如下：</strong></p><table><thead><tr><th>IP</th><th>Hostname</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td></tr><tr><td><strong>需新增如下节点</strong></td><td></td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td></tr></tbody></table><h1 id="一、节点初始化设置"><a href="#一、节点初始化设置" class="headerlink" title="一、节点初始化设置"></a>一、节点初始化设置</h1><p>参考：<a href="https://georgechan95.github.io/blog/b00f53e9.html">基于Rocky9.3系统使用kubeadm安装 k8s1.29 集群</a></p><h2 id="1-设置主机名"><a href="#1-设置主机名" class="headerlink" title="1. 设置主机名"></a>1. 设置主机名</h2><pre><code class="highlight bash">hostnamectl set-hostname k8s-node03</code></pre><h2 id="2-修改Host文件"><a href="#2-修改Host文件" class="headerlink" title="2. 修改Host文件"></a>2. 修改Host文件</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt; <span class="string">&quot;EOF&quot;</span>10.20.1.139 k8s-master0110.20.1.140 k8s-node0110.20.1.141 k8s-node0210.20.1.142 k8s-node03EOF</code></pre><h2 id="3-修改终端颜色"><a href="#3-修改终端颜色" class="headerlink" title="3. 修改终端颜色"></a>3. 修改终端颜色</h2><p>这里只是修改shell终端显示文本的颜色，非必要步骤。</p><pre><code class="highlight bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF &gt;&gt; ~/.bashrc</span><span class="string">PS1=&quot;\[\e[37;47m\][\[\e[32;47m\]\u\[\e[34;47m\]@\h \[\e[36;47m\]\w\[\e[0m\]]\\$ &quot;</span><span class="string">EOF</span><span class="comment"># 让修改立即见效</span><span class="built_in">source</span> ~/.bashrc</code></pre><h2 id="4-更换系统软件源"><a href="#4-更换系统软件源" class="headerlink" title="4. 更换系统软件源"></a>4. 更换系统软件源</h2><pre><code class="highlight bash"><span class="comment"># 更新源</span>sed -e <span class="string">&#x27;s|^mirrorlist=|#mirrorlist=|g&#x27;</span> \    -e <span class="string">&#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27;</span> \    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo    <span class="comment"># 刷新dnf缓存</span>dnf makecache<span class="comment"># 验证源更新</span>dnf repolist</code></pre><ul><li><p>命令解析</p><pre><code class="highlight plaintext"># 使用 sed 命令修改 Rocky Linux 的 YUM/DNF 源配置文件，切换到阿里云的镜像源。sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \    -e &#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27; \    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo    # 将以 mirrorlist= 开头的行注释掉（在前面加 #）-e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27;# 将以 #baseurl= 开头并指向默认 Rocky Linux 源的行取消注释，并替换为阿里云镜像源 URL。&#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27;# -i.bak：直接修改文件，并为原文件创建备份（扩展名为 .bak）。# 修改 /etc/yum.repos.d/ 目录下所有以 rocky 或 Rocky 开头的 .repo 文件。# 修改完成后，原始文件会被备份为 .bak 文件。-i.bak /etc/yum.repos.d/[Rr]ocky*.repo# 更新本地缓存，确保系统可以快速查询软件包信息。dnf makecache</code></pre></li></ul><h2 id="5-修改防火墙"><a href="#5-修改防火墙" class="headerlink" title="5. 修改防火墙"></a>5. 修改防火墙</h2><pre><code class="highlight bash">systemctl stop firewalldsystemctl <span class="built_in">disable</span> firewalldyum -y install iptables-servicessystemctl start iptablesiptables -Fsystemctl <span class="built_in">enable</span> iptablesservice iptables save</code></pre><ul><li><p>命令解析</p><pre><code class="highlight plaintext"># 停止运行 firewalldsystemctl stop firewalld# 禁止 firewalld 开机自启systemctl disable firewalld# 安装 iptables 服务，用于管理 Linux 的防火墙规则yum -y install iptables-services# 使防火墙规则立即生效，并开始运行 iptables 防火墙服务。systemctl start iptables# 删除当前的防火墙规则，通常用于重置或清理防火墙规则。iptables -F# 设置 iptables 服务开机自启动，确保服务器重启后，iptables 服务会自动加载防火墙规则。systemctl enable iptables# 将当前 iptables 的规则配置保存到文件中（通常是 /etc/sysconfig/iptables），以便在系统重启或 iptables 服务重新启动后，能够自动加载保存的规则。service iptables save</code></pre></li></ul><h2 id="6-禁用-Selinux"><a href="#6-禁用-Selinux" class="headerlink" title="6 禁用 Selinux"></a>6 禁用 Selinux</h2><pre><code class="highlight bash">setenforce 0sed -i <span class="string">&quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot;</span> /etc/selinux/configgrubby --update-kernel ALL --args selinux=0</code></pre><ul><li><p>命令解析</p><pre><code class="highlight plaintext"># 将 SELinux 的模式设置为 Permissive（宽容模式）。# 0：表示设置为 Permissive 模式，此模式下 SELinux 不会强制执行安全策略，而是记录违规日志。# 1：表示 Enforcing 模式，此模式下 SELinux 会强制执行安全策略。setenforce 0# 修改 SELinux 配置文件 /etc/selinux/config，将 SELINUX 设置为 disabled。永久禁用 SELinux，即使系统重启也不会再启用。sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config# 通过 grubby 工具将 selinux=0 参数添加到所有内核启动配置中。grubby --update-kernel ALL --args selinux=0grubby --info DEFAULT# 查看是否禁用，grubby --info DEFAULT# 回滚内核层禁用操作，、grubby --update-kernel ALL --remove-args selinux</code></pre></li><li><p>修改完成后重启系统</p><pre><code class="highlight bash">reboot</code></pre></li></ul><h2 id="7-设置时区"><a href="#7-设置时区" class="headerlink" title="7 设置时区"></a>7 设置时区</h2><pre><code class="highlight bash">timedatectl set-timezone Asia/Shanghai</code></pre><h2 id="8-集群时间同步设置"><a href="#8-集群时间同步设置" class="headerlink" title="8 集群时间同步设置"></a>8 集群时间同步设置</h2><pre><code class="highlight bash">timedatectldnf install -y chronysystemctl <span class="built_in">enable</span> chronyd.servicesystemctl restart chronyd.servicesystemctl status chronyd.servicevim /etc/chrony.conf<span class="comment"># 修改完chrony配置后，重启chrony服务</span>systemctl <span class="built_in">enable</span> chronyd  --now</code></pre><ul><li><p>chrony配置内容如下</p><pre><code class="highlight plaintext"># 添加阿里云NTP服务器pool ntp1.aliyun.com iburstpool ntp2.aliyun.com iburstpool cn.pool.ntp.org iburst    # 允许指定网段访问此时间服务器，不然只允许本地网络allow 10.20.0.0/16</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/07/20250707-111802.png" alt="chrony配置内容"></p><p>chrony配置内容</p></li><li><p>命令解析</p><pre><code class="highlight plaintext"># 检查时区和时间timedatectl# 安装chrony进行时间同步，ntpdate在Rocky 9中不再支持dnf install -y chrony# 启用chronyd服务systemctl enable chronyd.service# 重启chronyd服务systemctl restart chronyd.service# 查看chronyd服务状态systemctl status chronyd.service</code></pre></li></ul><h2 id="9-修改系统最大打开文件数"><a href="#9-修改系统最大打开文件数" class="headerlink" title="9 修改系统最大打开文件数"></a>9 修改系统最大打开文件数</h2><p>在 <code>/etc/security/limits.conf</code> 文件的末尾追加以下内容</p><pre><code class="highlight bash">*softnofile65535*hardnofile65535</code></pre><p>目的：修改最大打开文件数限制</p><h2 id="10-安装必要的库和修改-sysctl-conf-内核参数配置"><a href="#10-安装必要的库和修改-sysctl-conf-内核参数配置" class="headerlink" title="10 安装必要的库和修改 sysctl.conf 内核参数配置"></a>10 安装必要的库和修改 <code>sysctl.conf</code> 内核参数配置</h2><pre><code class="highlight bash">dnf install -y epel-releasednf install -y bridge-utilsmodprobe br_netfilter<span class="built_in">echo</span> <span class="string">&#x27;br_netfilter&#x27;</span> &gt;&gt; /etc/modules-load.d/bridge.conf<span class="built_in">cat</span> &gt;&gt; /etc/sysctl.conf &lt;&lt;<span class="string">EOF</span><span class="string">net.bridge.bridge-nf-call-iptables=1</span><span class="string">net.bridge.bridge-nf-call-ip6tables=1</span><span class="string">net.ipv4.ip_forward=1</span><span class="string">net.ipv4.tcp_syncookies = 1</span><span class="string">net.ipv4.tcp_max_tw_buckets = 20480</span><span class="string">net.ipv4.tcp_max_syn_backlog = 20480</span><span class="string">net.core.netdev_max_backlog = 262144</span><span class="string">net.ipv4.tcp_fin_timeout = 20</span><span class="string">EOF</span><span class="comment"># 重新加载 /etc/sysctl.conf 中的所有内核参数配置，并使其立即生效。</span>sysctl -p</code></pre><ul><li><p>命令解释</p><pre><code class="highlight plaintext"># 安装 EPEL（Extra Packages for Enterprise Linux） 仓库的 Release 包。# EPEL 是由 Fedora 社区维护的一个软件仓库，提供许多额外的软件包，这些包在默认的 RHEL（或其衍生版如 CentOS、Rocky Linux 等）中没有包含。yum install -y epel-release# 安装 bridge-utils 软件包。# bridge-utils 是一个 Linux 工具集，用于创建和管理网络桥接（bridging）。yum install -y bridge-utils# 加载 br_netfilter 内核模块。# 该模块用于启用网络桥接（bridge）时的流量过滤功能。# 允许通过桥接的网络流量被 iptables 规则管理。# 在容器或虚拟化环境中，确保桥接网络的流量可以被正确处理。modprobe br_netfilter# 将 br_netfilter 模块名称添加到 /etc/modules-load.d/bridge.conf 文件中。# 配置系统在启动时自动加载 br_netfilter 模块。echo &#x27;br_netfilter&#x27; &gt;&gt; /etc/modules-load.d/bridge.conf# 向 /etc/sysctl.conf 文件添加配置，使桥接流量可以通过 iptables 规则管理。# 启用桥接网络上的 IPv4 流量通过 iptables 的规则处理。net.bridge.bridge-nf-call-iptables=1# 向 /etc/sysctl.conf 文件添加配置，使桥接流量中的 IPv6 流量可以通过 ip6tables 规则管理。net.bridge.bridge-nf-call-ip6tables=1# 向 /etc/sysctl.conf 文件添加配置，启用 IP 转发功能。# 用途：在容器网络或 Kubernetes 集群中，允许跨子网通信。net.ipv4.ip_forward=1# 启用 TCP SYN Cookie 技术，用于防范 SYN Flood 攻击。# 在服务器收到大量的 TCP SYN 请求但无法分配足够资源时，启用 SYN Cookie 可通过一种临时编码方式验证连接合法性，避免资源耗尽。net.ipv4.tcp_syncookies = 1# 设置系统同时保持的 TCP TIME_WAIT 状态的连接数上限。达到上限后，系统会直接丢弃多余的连接（而不是继续占用资源）。# 默认值180000,对于高并发的 Web 服务器或反向代理，适当调低该值（如 20480）以避免 TIME_WAIT 数量过多。net.ipv4.tcp_max_tw_buckets = 20480# 设置 TCP 三次握手中 SYN 请求的队列长度上限。# 当服务器接收的 SYN 请求超过该值时，新的连接请求会被丢弃。# 如果服务器负载较高且连接数较多，可以调高到 20480 或更高。net.ipv4.tcp_max_syn_backlog = 20480# 设置网络设备接收队列的最大长度。# 如果接收队列中的数据包数量超过该值，内核将直接丢弃后续数据包。# 在高流量环境中，设置为较高值（如 262144）以避免丢包，提高吞吐量。net.core.netdev_max_backlog = 262144# 设置 TCP 连接处于 FIN_WAIT2 状态的超时时间（单位：秒）。# FIN_WAIT2 状态表示服务端已发送 FIN 包等待客户端确认，此状态会持续占用资源。# 默认值：通常为 60 秒。# 在高并发服务器上，将该值调低（如 20）以减少 FIN_WAIT2 状态的资源占用。net.ipv4.tcp_fin_timeout = 20# 重新加载 /etc/sysctl.conf 中的所有内核参数配置，并使其立即生效。sysctl -p</code></pre></li></ul><h2 id="11-关闭-swap-分区"><a href="#11-关闭-swap-分区" class="headerlink" title="11 关闭 swap 分区"></a>11 关闭 swap 分区</h2><pre><code class="highlight bash">swapoff -ased -i <span class="string">&#x27;s:/dev/mapper/rl-swap:#/dev/mapper/rl-swap:g&#x27;</span> /etc/fstab</code></pre><ul><li><p>命令解释</p><pre><code class="highlight bash"><span class="comment">#  立即关闭系统中所有的交换分区</span>swapoff -a<span class="comment"># 注释掉 /etc/fstab 文件中定义的交换分区挂载条目，防止系统在重启后重新启用交换分区。</span>sed -i <span class="string">&#x27;s:/dev/mapper/rl-swap:#/dev/mapper/rl-swap:g&#x27;</span> /etc/fstab<span class="comment"># 验证交换分区是否关系</span>free -h输出中 Swap 一栏的值会变为 0。</code></pre></li></ul><h1 id="二、安装Docker服务"><a href="#二、安装Docker服务" class="headerlink" title="二、安装Docker服务"></a>二、安装Docker服务</h1><h2 id="1-添加-docker-ce-yum-源"><a href="#1-添加-docker-ce-yum-源" class="headerlink" title="1 添加 docker-ce yum 源"></a>1 添加 docker-ce yum 源</h2><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight bash">sudo dnf config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.reposudo sed -i <span class="string">&#x27;s+download.docker.com+mirrors.aliyun.com/docker-ce+&#x27;</span> /etc/yum.repos.d/docker-ce.reposudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</code></pre><ul><li><p>命令解析</p><pre><code class="highlight bash"><span class="comment"># 使用 dnf config-manager 命令添加 Docker 软件包的官方仓库（在这里是阿里云的镜像）。</span>sudo dnf config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo<span class="comment"># 修改 docker-ce.repo 文件中的镜像源地址，将默认的 download.docker.com 替换为阿里云的镜像地址 mirrors.aliyun.com/docker-ce。</span>sudo sed -i <span class="string">&#x27;s+download.docker.com+mirrors.aliyun.com/docker-ce+&#x27;</span> /etc/yum.repos.d/docker-ce.repo<span class="comment"># 安装最新版本docker</span>sudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</code></pre></li></ul><h2 id="2-开启Docker服务"><a href="#2-开启Docker服务" class="headerlink" title="2 开启Docker服务"></a>2 开启Docker服务</h2><pre><code class="highlight plaintext">systemctl start dockersystemctl enable docker</code></pre><h2 id="3-配置-daemon-json"><a href="#3-配置-daemon-json" class="headerlink" title="3 配置 daemon.json"></a>3 配置 daemon.json</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt;&gt;/etc/docker/daemon.json &lt;&lt;<span class="string">EOF</span><span class="string">&#123;</span><span class="string">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><span class="string">  &quot;log-opts&quot;: &#123;</span><span class="string">        &quot;max-size&quot;: &quot;100m&quot;,</span><span class="string">        &quot;max-file&quot;: &quot;10&quot;</span><span class="string">  &#125;,</span><span class="string">  &quot;data-root&quot;:&quot;/data/docker&quot;,</span><span class="string">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><span class="string">  &quot;registry-mirrors&quot;: [</span><span class="string">   &quot;https://kfp63jaj.mirror.aliyuncs.com&quot;,</span><span class="string">    &quot;https://hub-mirror.c.163.com&quot;,</span><span class="string">    &quot;https://mirror.baidubce.com&quot;</span><span class="string">  ]</span><span class="string">&#125;</span><span class="string">EOF</span></code></pre><ul><li><p>配置解析</p><pre><code class="highlight plaintext">&quot;data-root&quot;: &quot;/data/docker&quot;指定 Docker 数据的存储目录为 /data/docker。包括容器、镜像、卷等内容。默认存储在 /var/lib/docker，此配置用于更改默认路径。&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]配置 Docker 使用 systemd 作为 Cgroup 驱动程序。推荐在使用现代 Linux 发行版（如 Rocky Linux 9）或 Kubernetes 时采用此配置，以实现更好的资源管理和兼容性。&quot;log-driver&quot;: &quot;json-file&quot;指定 Docker 的日志驱动为 json-file。json-file 是 Docker 默认的日志存储方式，将日志保存在 JSON 文件中。&quot;log-opts&quot;: &#123;&#125;配置日志驱动的选项：&quot;max-size&quot;: &quot;100m&quot;：每个日志文件的最大大小为 100MB。&quot;max-file&quot;: &quot;100&quot;：最多保留 100 个日志文件（滚动日志机制）。&quot;insecure-registries&quot;: [&quot;harbor.xinxainghf.com&quot;]配置不安全的私有镜像仓库地址（即未启用 HTTPS 的仓库）。例如，harbor.xinxainghf.com 是一个私有仓库地址。&quot;registry-mirrors&quot;: [&quot;https://kfp63jaj.mirror.aliyuncs.com&quot;]配置 Docker 镜像加速器。镜像地址为阿里云镜像服务，加速从官方 Docker Hub 拉取镜像的速度。</code></pre></li></ul><h2 id="4-创建-Docker-服务的自定义配置目录"><a href="#4-创建-Docker-服务的自定义配置目录" class="headerlink" title="4 创建 Docker 服务的自定义配置目录"></a>4 创建 Docker 服务的自定义配置目录</h2><pre><code class="highlight bash"><span class="built_in">mkdir</span> -p /etc/systemd/system/docker.service.d</code></pre><p>用于存放 Docker 服务的自定义配置文件。</p><h2 id="5-重新加载-Docker-配置"><a href="#5-重新加载-Docker-配置" class="headerlink" title="5 重新加载 Docker 配置"></a>5 重新加载 Docker 配置</h2><pre><code class="highlight bash">systemctl daemon-reloadsystemctl restart docker</code></pre><ul><li><p>验证配置是否生效</p><pre><code class="highlight plaintext">docker info</code></pre></li></ul><h1 id="三、安装-cri-docker"><a href="#三、安装-cri-docker" class="headerlink" title="三、安装 cri-docker"></a>三、安装 cri-docker</h1><p>从 kubernetes 1.24 开始，dockershim 已经从 kubelet 中移除（ dockershim 是 Kubernetes 的一个组件，主要目的是为了通过 CRI 操作 Docker），但因为历史问题 docker 却不支持 kubernetes 主推的CRI（容器运行时接口）标准，所以 docker 不能再作为 kubernetes 的容器运行时了，即从 kubernetesv1.24 开始不再使用 docker 了，默认使用的容器运行时是 containerd 。目前 containerd 比较新，可能存在一些功能不稳定的情况，所以这里我们使用容器运行时还是选择 docker。</p><p>如果想继续使用 docker 的话，可以在 kubelet 和 docker 之间加上一个中间层 cri-docker 。cri-docker 是一个支持CRI标准的 shim（垫片）。一头通过CRI跟kubelet 交互，另一头跟 docker api 交互，从而间接的实现了 kubernetes 以 docker 作为容器运行时。这里需要在全部节点执行 cri-docker 安装。</p><h2 id="1-下载-cri-docker"><a href="#1-下载-cri-docker" class="headerlink" title="1 下载 cri-docker"></a>1 下载 cri-docker</h2><pre><code class="highlight bash"><span class="comment"># 创建目录,并下载 cri-docker 安装文件到目录中</span><span class="built_in">mkdir</span> -p /opt/software<span class="built_in">cd</span> /opt/softwarewget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.16/cri-dockerd-0.3.16.amd64.tgz</code></pre><h2 id="2-解压-cri-docker"><a href="#2-解压-cri-docker" class="headerlink" title="2 解压 cri-docker"></a>2 解压 cri-docker</h2><pre><code class="highlight bash">tar -xvf /opt/software/cri-dockerd-0.3.16.amd64.tgz --strip-components=1 -C /usr/local/bin/</code></pre><h2 id="3-下载并修改-cri-docker-配置文件"><a href="#3-下载并修改-cri-docker-配置文件" class="headerlink" title="3 下载并修改 cri-docker 配置文件"></a>3 下载并修改 cri-docker 配置文件</h2><h3 id="3-1-下载-cri-docker-配置文件"><a href="#3-1-下载-cri-docker-配置文件" class="headerlink" title="3.1 下载 cri-docker 配置文件"></a>3.1 下载 cri-docker 配置文件</h3><p>在浏览器下载文件，通过xftp传到服务器上</p><pre><code class="highlight bash"><span class="comment"># 下载 cri-docker.service</span><span class="comment"># cri-docker.service 下载地址：https://github.com/Mirantis/cri-dockerd/blob/v0.3.16/packaging/systemd/cri-docker.service</span><span class="built_in">mv</span> /opt/software/cri-docker.service /etc/systemd/system/<span class="comment"># 下载 cri-docker.socket</span><span class="comment"># cri-docker.socket 下载地址：https://github.com/Mirantis/cri-dockerd/blob/v0.3.16/packaging/systemd/cri-docker.socket</span><span class="built_in">mv</span> /opt/software/cri-docker.socket /etc/systemd/system/</code></pre><h3 id="3-2-修改-cri-docker-配置文件"><a href="#3-2-修改-cri-docker-配置文件" class="headerlink" title="3.2 修改 cri-docker 配置文件"></a>3.2 修改 cri-docker 配置文件</h3><p><strong>修改 cri-docker.service 的启动命令 ExecStart</strong></p><pre><code class="highlight bash">vim /etc/systemd/system/cri-docker.service</code></pre><ul><li><p>修改内容如下：</p><pre><code class="highlight bash"><span class="comment"># ExecStart=/usr/bin/cri-dockerd --container-runtime-endpoint fd://</span>ExecStart=/usr/local/bin/cri-dockerd --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9 --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --cri-dockerd-root-directory=/data/dockershim --cri-dockerd-root-directory=/data/docker</code></pre><ul><li><p>配置解析</p><pre><code class="highlight plaintext">ExecStart作用: 定义 Systemd 启动服务时执行的命令。此命令会在服务启动时运行。/usr/local/bin/cri-dockerd解释: cri-dockerd 的可执行文件路径。作用: 启动 cri-dockerd 服务，为 Kubernetes 提供 CRI（容器运行时接口）支持。--pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9解释: 定义 Pod 的基础容器镜像。--container-runtime-endpoint=unix:///var/run/cri-dockerd.sock解释: 定义 CRI 的监听端点。作用: cri-dockerd 使用 Unix Socket 文件 /var/run/cri-dockerd.sock 提供与 Kubernetes 的交互接口。--cri-dockerd-root-directory=/data/dockershim解释: 定义 cri-dockerd 的根目录，用于存储临时文件或配置数据。作用: /data/dockershim 是修改后的 cri-dockerd 数据目录，默认存放在 /var/lib/dockershim，用于存放与 Docker 和 Kubernetes 通信相关的数据。--cri-dockerd-root-directory=/data/docker解释: 定义 Docker 的根目录。作用: Docker 的所有容器数据、镜像数据都存放在 /data/docker 目录下。</code></pre></li></ul></li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-213036.png" alt="cri-docker.service"></p><ul><li><p>修改cri-docker.socket的ListenStream参数</p><pre><code class="highlight bash">vim /etc/systemd/system/cri-docker.socket</code></pre><ul><li><p>修改内容如下：</p><pre><code class="highlight bash"><span class="comment"># ListenStream=%t/cri-dockerd.sock</span>ListenStream=/var/run/cri-dockerd.sock</code></pre><ul><li><p>配置解析</p><pre><code class="highlight plaintext">ListenStream作用:定义 cri-dockerd 服务监听的通信地址和端口。在这里，指定了一个 Unix Socket 文件 /var/run/cri-dockerd.sock。/var/run/cri-dockerd.sock解释:这是一个 Unix Domain Socket 文件路径。Unix Sockets 是一种轻量级的进程间通信（IPC）方式，通常用于本地通信（与网络无关）。cri-dockerd 和 Kubernetes 的 kubelet 通过这个 Socket 文件进行交互。</code></pre></li></ul></li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/07/20250707-130350.png" alt="cri-dockerd.sock"></p></li></ul><p><strong>注意每个节点 cri-docker 都需要这么配置</strong></p><h2 id="4-启动-cri-docker-对应服务"><a href="#4-启动-cri-docker-对应服务" class="headerlink" title="4 启动 cri-docker 对应服务"></a>4 启动 cri-docker 对应服务</h2><pre><code class="highlight bash">systemctl daemon-reloadsystemctl <span class="built_in">enable</span> cri-dockersystemctl start cri-dockersystemctl is-active cri-docker</code></pre><ul><li><p>命令解析</p><pre><code class="highlight bash"><span class="comment"># 告诉 Systemd 重新加载所有服务配置文件。</span>systemctl daemon-reload<span class="comment"># 设置 cri-docker 服务为 开机自启。</span>systemctl <span class="built_in">enable</span> cri-docker<span class="comment"># 启动 cri-docker 服务。</span>systemctl start cri-docker<span class="comment"># 检查 cri-docker 服务是否正在运行。</span>systemctl is-active cri-docker</code></pre></li></ul><h1 id="四、节点加入集群"><a href="#四、节点加入集群" class="headerlink" title="四、节点加入集群"></a>四、节点加入集群</h1><h2 id="1-配置阿里云K8S源"><a href="#1-配置阿里云K8S源" class="headerlink" title="1 配置阿里云K8S源"></a>1 配置阿里云K8S源</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><span class="string">[kubernetes]</span><span class="string">name=Kubernetes</span><span class="string">baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/</span><span class="string">enabled=1</span><span class="string">gpgcheck=1</span><span class="string">gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/repodata/repomd.xml.key</span><span class="string">EOF</span></code></pre><h2 id="2-安装K8S集群管理工具"><a href="#2-安装K8S集群管理工具" class="headerlink" title="2 安装K8S集群管理工具"></a>2 安装K8S集群管理工具</h2><pre><code class="highlight bash">yum install -y kubelet kubeadm kubectl</code></pre><h2 id="3-配置k8s-Cgoup控制组"><a href="#3-配置k8s-Cgoup控制组" class="headerlink" title="3 配置k8s Cgoup控制组"></a>3 配置k8s Cgoup控制组</h2><pre><code class="highlight bash">vim /etc/sysconfig/kubelet</code></pre><ul><li><p>配置内容如下：</p><pre><code class="highlight plaintext">KUBELET_EXTRA_ARGS=&quot;--cgroup-driver=systemd&quot;</code></pre></li><li><p>配置解析</p><pre><code class="highlight plaintext">KUBELET_EXTRA_ARGS含义:KUBELET_EXTRA_ARGS 是一个变量，用于为 kubelet 添加自定义的启动参数。这些参数会被系统初始化脚本或服务文件加载并传递给 kubelet 进程。--cgroup-driver=systemd作用:指定 kubelet 使用的 cgroup 驱动（Cgroup Driver）。Cgroup Driver 是 Kubernetes 用来与 Linux 内核 cgroup（控制组）交互的机制，负责资源（CPU、内存等）的限制和管理。该参数将驱动类型设置为 systemd，表示使用 systemd 来管理 cgroup。</code></pre></li></ul><h2 id="4-配置kubelet自启动"><a href="#4-配置kubelet自启动" class="headerlink" title="4 配置kubelet自启动"></a>4 配置kubelet自启动</h2><pre><code class="highlight bash">systemctl <span class="built_in">enable</span> kubelet.service</code></pre><h2 id="5-Master-节点重新生成-Token"><a href="#5-Master-节点重新生成-Token" class="headerlink" title="5 Master 节点重新生成 Token"></a>5 Master 节点重新生成 Token</h2><pre><code class="highlight bash"><span class="comment"># 在集群 Master 节点执行命令</span>$ kubeadm token create --print-join-command<span class="comment"># 生成内容如下：</span>kubeadm <span class="built_in">join</span> 10.20.1.139:6443 --token 4jlfko.bsw2lqp28syw1fb7 --discovery-token-ca-cert-hash sha256:9450138de7634306c27d22950c943dd348662019b710bc00248e815df86fa789</code></pre><h2 id="6-当前节点加入集群中"><a href="#6-当前节点加入集群中" class="headerlink" title="6 当前节点加入集群中"></a>6 当前节点加入集群中</h2><pre><code class="highlight bash">$ kubeadm <span class="built_in">join</span> 10.20.1.139:6443 --token 4jlfko.bsw2lqp28syw1fb7 --discovery-token-ca-cert-hash sha256:9450138de7634306c27d22950c943dd348662019b710bc00248e815df86fa789 --cri-socket=unix:///var/run/cri-dockerd.sock</code></pre><p><strong>在master节点查看节点状态</strong></p><pre><code class="highlight bash">$ kubectl get nodesNAME           STATUS     ROLES           AGE    VERSIONk8s-master01   Ready      control-plane   5d2h   v1.29.15k8s-node01     Ready      &lt;none&gt;          5d     v1.29.15k8s-node02     Ready      &lt;none&gt;          5d     v1.29.15k8s-node03     NotReady   &lt;none&gt;          18s    v1.29.15</code></pre><p>k8s-node03 节点已加入集群中。</p><p>k8s-node03 虽然已经加入集群中，但处于未就绪状态，查看原因：</p><pre><code class="highlight bash"><span class="comment"># 在master节点查看Pod运行情况</span>$ kubectl get pods -n kube-system -o wide</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/07/20250707-140848.png" alt="master节点查看Pod"></p><p>通过查看Pod，了解到是由于 node03 节点的 calico Pod运行异常，calico 镜像拉取失败了。</p><p><strong>导入Calico镜像</strong></p><p>由于 colico 相关镜像在国外，这里使用代理的方式，提前下载好镜像，然后导入到 node03 节点中</p><pre><code class="highlight bash"><span class="comment"># 查看要下载的镜像</span><span class="comment"># 查看集群初始化时，安装 Calico 插件使用的yaml文件，里面有calico所需的相关镜像</span>$ <span class="built_in">cat</span> calico.yaml<span class="comment"># 拉取 Calico 镜像</span>docker pull docker.io/calico/cni:v3.26.3docker pull docker.io/calico/node:v3.26.3docker pull docker.io/calico/kube-controllers:v3.26.3docker pull docker.io/calico/typha:v3.26.3<span class="comment"># Calico 镜像打包</span>docker save docker.io/calico/cni:v3.26.3 cni-v3.26.3.tardocker save docker.io/calico/node:v3.26.3 node-v3.26.3.tardocker save docker.io/calico/kube-controllers:v3.26.3 kube-controllers-v3.26.3.tardocker save docker.io/calico/typha:v3.26.3 typha-v3.26.3.tar<span class="comment"># 导入 Calico 镜像</span>docker load -i cni-v3.26.3.tardocker load -i node-v3.26.3.tardocker load -i kube-controllers-v3.26.3.tardocker load -i typha-v3.26.3.tar</code></pre><p><strong>再次查看集群Node状态</strong></p><p>k8s-node03 节点导入calico镜像后，再次查看</p><pre><code class="highlight bash"><span class="comment"># 在 master 节点查看节点状态</span>$ kubectl get nodesNAME           STATUS   ROLES           AGE    VERSIONk8s-master01   Ready    control-plane   5d3h   v1.29.15k8s-node01     Ready    &lt;none&gt;          5d1h   v1.29.15k8s-node02     Ready    &lt;none&gt;          5d1h   v1.29.15k8s-node03     Ready    &lt;none&gt;          25m    v1.29.15<span class="comment"># 在master节点查看Pod运行情况</span>$ kubectl get pods -n kube-system -o wide</code></pre><h2 id="7-其它配置"><a href="#7-其它配置" class="headerlink" title="7 其它配置"></a>7 其它配置</h2><p>让新加入的 k8s-node03 节点可执行 kubectl 命令，只要把 master上的管理文件 <code>/etc/kubernetes/admin.conf</code> 拷贝到 Worker 节点的 <code>$HOME/.kube/config</code> 就可以让 Worker 节点也可以实现 kubectl 命令管理。</p><pre><code class="highlight bash"><span class="comment"># 在 node03 节点执行</span>[root@k8s-node03 ~]$ <span class="built_in">mkdir</span> /root/.kube<span class="comment"># 在master节点执行</span>[root@k8s-master01 ~]$ scp /etc/kubernetes/admin.conf root@10.20.1.142:/root/.kube/config</code></pre><ul><li><p>测试：在 node03 节点测试</p><pre><code class="highlight bash">[root@k8s-node03 ~]$ kubectl get nodesNAME           STATUS   ROLES           AGE    VERSIONk8s-master01   Ready    control-plane   5d3h   v1.29.15k8s-node01     Ready    &lt;none&gt;          5d1h   v1.29.15k8s-node02     Ready    &lt;none&gt;          5d1h   v1.29.15k8s-node03     Ready    &lt;none&gt;          42m    v1.29.15</code></pre></li></ul><p><strong>至此完成了新节点的的初始化，及加入k8s集群中</strong></p><p><strong>参考链接</strong></p><blockquote><p><a href="https://georgechan95.github.io/blog/3c79d8d9.html">https://georgechan95.github.io/blog/3c79d8d9.html</a></p><p><a href="https://georgechan95.github.io/blog/b00f53e9.html">https://georgechan95.github.io/blog/b00f53e9.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;需求：当前集群为一主两从，共3个节点，基于 kube-admin 方式安装，需要增加一个从节点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;当前集群如下：&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;Hostname&lt;/th&gt;
&lt;</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>011-Kubernetes Ingress-Nginx</title>
    <link href="https://georgechan95.github.io/blog/6436eaf1.html"/>
    <id>https://georgechan95.github.io/blog/6436eaf1.html</id>
    <published>2025-06-25T11:42:00.000Z</published>
    <updated>2025-07-06T09:01:02.206Z</updated>
    
    <content type="html"><![CDATA[<p><strong>K8S集群服务器</strong></p><table><thead><tr><th>IP</th><th>Hostname</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td></tr></tbody></table><h1 id="一、负载均衡器"><a href="#一、负载均衡器" class="headerlink" title="一、负载均衡器"></a>一、负载均衡器</h1><p>负载均衡器有两类，区别在于 <strong>四层网络</strong> 和 <strong>七层网络</strong> 的支持，传输层在第四层，这层协议有 TCP&#x2F;UDP&#x2F;TCP SSL 等，而七层有 HTTP&#x2F;HTTPS。</p><h2 id="1-基于-LVS-的-HTTPS-负载均衡"><a href="#1-基于-LVS-的-HTTPS-负载均衡" class="headerlink" title="1. 基于 LVS 的 HTTPS 负载均衡"></a>1. 基于 LVS 的 HTTPS 负载均衡</h2><p>基于 LVS 的 HTTPS 负载均衡 是 典型的四层代理架构。客户端发出请求，经过LVS直接转发到服务器，然后服务器返回结果，从请求的发出到结果的响应，中间仅仅产生一次完整的TCP连接。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/26/20250626-194737.png" alt="四层代理架构"></p><h2 id="2-基于-Nginx-的-HTTPS-负载均衡"><a href="#2-基于-Nginx-的-HTTPS-负载均衡" class="headerlink" title="2. 基于 Nginx 的 HTTPS 负载均衡"></a>2. 基于 Nginx 的 HTTPS 负载均衡</h2><p>基于 Nginx 的 HTTPS 负载均衡是一种基于七层网络代理架构的实现。客户端发出 https 请求，请求到达nginx服务器，nginx 重新生成一个新的 http 请求发到真实的服务器，服务器计算结果后发往 nginx，nginx再将结果以 https 的方式返回给客户端。从请求的发出到结果的响应，中间产生了两次请求。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/26/20250626-195032.png" alt="七层代理架构"></p><h1 id="二、Ingress简介"><a href="#二、Ingress简介" class="headerlink" title="二、Ingress简介"></a>二、Ingress简介</h1><h2 id="1-Ingress-介绍"><a href="#1-Ingress-介绍" class="headerlink" title="1. Ingress 介绍"></a>1. Ingress 介绍</h2><p>Ingress 是从 Kubernetes 集群外部访问集群内部服务的入口，同时为集群内的 Service 提供七层负载均衡能力。它提供了 HTTP 和 HTTPS 路由功能，使外部流量能够访问集群内部的服务。通过定义 Ingress 资源，可以控制哪些外部请求能够访问集群中的哪些服务，以及如何路由这些请求。</p><p>具体架构图如下：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/26/20250626-193516" alt="Ingress架构"></p><p>我们做网站时，使用 Nginx 做 Web 服务器，会使用一个子域名绑定一个网站，<code>a.xxx.com</code> 绑定 A 网站，<code>b.xxx.com</code> 绑定 B 网站，这样在一个域名的不同子域名可以访问不同的站点，对于现在的大多数互联网网站，依然会使用这种方法划分。</p><p>在微服务架构中，多个模块部署在不同的服务器上，则但是我们希望都通过 <code>xxx.com</code> 这个域名直接访问，就好像所有模块都在一起，让用户感觉只有一个网站。则可能会使用目录路径对模块进行划分，例如如果我们要实现 <code>xxx.com/a</code> 访问 A 模块，<code>xxx.com/b</code> 访问 B 模块，但对用户来说，一直在访问 <code>xxx.com</code> 这个域名。</p><p>这种需求，我们可以使用 nginx 进行反向代理，而在 Kubernetes 中，这种需求也是一模一样的。</p><p>首先，我们可以为 A、B、C 等应用，创建多个 Service，每个 Service 访问一个应用，然后使用 Ingress 配置路由规则，决定 URL 可以访问哪个 Service。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/26/20250626-200950.png" alt="Ingress代理请求"></p><blockquote><p>Ingress 公开了从集群外部到集群内服务的 HTTP 和 HTTPS 路由，Ingress 资源上定义的规则控制了路由。</p></blockquote><p>Ingress 可以让集群中的多个 Service 能够从集群外访问，Ingress 还提供负载均衡、SSL&#x2F;TLS 和基于名称的虚拟服务器等，Ingress 可以配置边缘路由器或其他前端工具来帮助处理网络流量，但是一般都是通自己的负载均衡器来实现。</p><p>Ingress 有两部分，一部分是 LoadBalancer ，提供统一入口，代理请求；另一部分是 Ingress 控制器，复制定义路由规则等。</p><p>如果不使用公有云平台的 LoadBalancer ，那么就自己搭建一个服务器，这台服务器加入到 Kubernetes 集群中，做流量入口，这台服务器网络接口必须够大，抗得住流量。</p><h2 id="2-Ingress-与-Service"><a href="#2-Ingress-与-Service" class="headerlink" title="2.  Ingress 与 Service"></a>2.  Ingress 与 Service</h2><p>在前面，我们已经学习到了 Service，通过 Service 我们可以暴露一个端口到外网中，通过这个端口可以访问应用。</p><p>其中，有两种方法可以暴露 Service，可以让其被集群外部访问：</p><ul><li>使用 <code>Service.Type=LoadBalancer</code></li><li>使用 <code>Service.Type=NodePort</code></li></ul><p>Service 的访问方式是 IP，每次要将服务公开给外界时，都必须创建一个新的 LoadBalancer 并向云服务商获取一个公网 IP 地址。或者使用 <code>NodePort</code>，但是只能在一台服务器上被访问，而且 Service 只能为一种 Pod 服务，暴露一个或多个端口，那么 N 个服务，就需要创建 N 个 Service。Service 虽然能够公开端口到外部网络中，但是无法将这些服务合并到一个 <code>example.com/&#123;服务&#125;</code> 中访问，Service 需要通过不同的端口访问。</p><p>如果你有一个 <code>example.com</code> 域名，你部署了多个 Web 服务，其中有两个子模块分别为课程(course)、考试(exam) 两个微服务，这些模块构成了一个培训网站。此时我们希望访问 <code>example.com/api/course</code> 能够访问课程学习模块，访问 <code>example.com/api/exam</code> 能够访问考试模块。显然，Service 是无法做到的。</p><p>使用 Ingress ，可以轻松设置路由规则，而且无需创建一堆 LoadBalancers&#x2F;Nodes 公开每个服务，并且 Ingress 本身具有很多功能。</p><blockquote><p>Ingress 也需要 Service 。</p></blockquote><h1 id="三、-安装-Ingress-控制器"><a href="#三、-安装-Ingress-控制器" class="headerlink" title="三、 安装 Ingress 控制器"></a>三、 安装 Ingress 控制器</h1><p>Ingress 控制器有多种实现，其中 Kubernetes 官方有一个名为 Ingress-nginx 的实现，其它实现还有 Kong Ingress、Traefik、HAProxy Ingress 等。这里演示 使用 Helm 安装 Ingress-nginx 。</p><p>官方文档：<a href="https://kubernetes.github.io/ingress-nginx/deploy/#using-helm">https://kubernetes.github.io/ingress-nginx/deploy/#using-helm</a></p><h2 id="1-下载-Ingress-nginx-安装包"><a href="#1-下载-Ingress-nginx-安装包" class="headerlink" title="1. 下载 Ingress-nginx 安装包"></a>1. 下载 Ingress-nginx 安装包</h2><p>需要首先安装helm管理工具：<a href="https://georgechan95.github.io/blog/d8e3c7b3.html">https://georgechan95.github.io/blog/d8e3c7b3.html</a></p><p>ingress-nginx 的仓库在国外，国内下载需要vpn支持，参考：<a href="https://georgechan95.github.io/blog/7f174b3e.html">https://georgechan95.github.io/blog/7f174b3e.html</a></p><pre><code class="highlight bash"><span class="comment"># 添加 ingress-nginx仓库</span>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx<span class="comment"># 下载 ingress-nginx 安装包</span>helm pull ingress-nginx/ingress-nginx --version=4.8.3</code></pre><h2 id="2-导入-Ingress-nginx-镜像"><a href="#2-导入-Ingress-nginx-镜像" class="headerlink" title="2. 导入 Ingress-nginx 镜像"></a>2. 导入 Ingress-nginx 镜像</h2><p>这些镜像是 ingress-nginx 启动时所需的镜像，由于国内的网络无法从国外下载镜像，因此需要提前把这些镜像下载好，导入到服务器中。</p><p>关于如何使用 Docker 拉取谷歌镜像，参考这篇博客：<a href="https://georgechan95.github.io/blog/b01d5c62.html">https://georgechan95.github.io/blog/b01d5c62.html</a></p><pre><code class="highlight bash"><span class="comment"># 下载 ingress-nginx 需要的镜像</span><span class="comment"># 所有节点都需要导入这些镜像</span>docker pull registry.k8s.io/ingress-nginx/controller:v1.9.4docker pull registry.k8s.io/defaultbackend-amd64:1.5docker pull registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231011-8b53cabe0docker pull registry.k8s.io/ingress-nginx/opentelemetry:v20230721-3e2062ee5</code></pre><h2 id="3-安装-Ingress-nginx"><a href="#3-安装-Ingress-nginx" class="headerlink" title="3. 安装 Ingress-nginx"></a>3. 安装 Ingress-nginx</h2><h3 id="3-1-解压-Ingress-nginx-压缩包"><a href="#3-1-解压-Ingress-nginx-压缩包" class="headerlink" title="3.1 解压  Ingress-nginx 压缩包"></a>3.1 解压  Ingress-nginx 压缩包</h3><pre><code class="highlight bash"><span class="comment"># 安装包解压</span>$ tar -zxvf ingress-nginx-4.8.3.tgz<span class="comment"># 进入 ingress-nginx 解压后的目录</span>$ <span class="built_in">cd</span> ingress-nginx<span class="comment"># 当前所在目录</span>$ <span class="built_in">pwd</span>/opt/k8s/10/ingress-nginx<span class="comment"># 查看 ingress-nginx 目录结构</span>$ tree ..├── CHANGELOG.md├── Chart.yaml├── .....├── README.md.gotmpl├── changelog│   ├── Changelog-4.5.2.md│   ├── .....│   └── Changelog-4.8.3.md├── changelog.md.gotmpl├── ci│   ├── controller-admission-tls-cert-manager-values.yaml........│   └── deployment-webhook-values.yaml├── templates│   ├── NOTES.txt│   ├── admission-webhooks│   │   ├── cert-manager.yaml│   │   ├── job-patch│   │   │   ├── clusterrole.yaml│   │   │   ├── ......│   │   │   └── serviceaccount.yaml│   │   └── validating-webhook.yaml│   ├── clusterrole.yaml│   ├── .....│   └── default-backend-serviceaccount.yaml└── values.yaml</code></pre><h3 id="3-2-编辑-values-yaml"><a href="#3-2-编辑-values-yaml" class="headerlink" title="3.2 编辑 values.yaml"></a>3.2 编辑 values.yaml</h3><pre><code class="highlight yaml"><span class="comment"># 修改 values.yaml 文件</span><span class="string">$</span> <span class="string">vim</span> <span class="string">values.yaml</span><span class="comment"># 修改1：</span><span class="comment"># 修改如下内容：</span><span class="string">controller</span>  <span class="attr">hostNetwork:</span> <span class="literal">true</span> <span class="comment"># 使用主机网路</span>  <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirstWithHostNet</span> <span class="comment"># Pod 的网络命名空间与主机共享，Pod 使用主机的网络栈</span>  <span class="attr">kind:</span> <span class="string">DaemonSet</span> <span class="comment"># 每个节点部署一个 ingress-nginx-controller</span>  <span class="attr">ingressClassResource:</span>    <span class="attr">default:</span> <span class="literal">true</span> <span class="comment"># 使用默认的Inginx类，默认是 nginx</span><span class="comment"># 修改2：</span><span class="comment">#注释 digest 相关内容</span><span class="string">controller</span>  <span class="attr">image:</span>    <span class="comment">#digest: sha256:xxxxx</span>    <span class="comment">#digestChroot: sha256:xxxxx</span>  <span class="attr">admissionWebhooks:</span>    <span class="attr">patch:</span>      <span class="attr">image:</span>        <span class="comment">#digest: sha256:xxxxx</span></code></pre><blockquote><p>将解压后的 ingress-nginx 目录内 values.yaml 文件中的 digest: sha256xxxx 所在的所有的行注释掉，避免因为下载镜像的指纹与文件要求不一致，无法运行</p></blockquote><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/25/20250625-171224.png" alt="注释digest指纹信息"></p><h3 id="3-3-关于-dnsPolicy"><a href="#3-3-关于-dnsPolicy" class="headerlink" title="3.3 关于 dnsPolicy"></a>3.3 关于 dnsPolicy</h3><p><strong>ClusterFirstWithHostNet</strong>：</p><ul><li>当 Pod 的 <code>hostNetwork</code> 设置为 true 时，使用该 DNS 策略。</li><li>这意味着 Pod 的网络命名空间与主机共享，Pod 使用主机的网络栈。</li><li>在此配置下，Pod 将首先尝试通过主机上的 DNS 解析 DNS 请求。如果主机上没有找到，则会将请求发送到 kube-dns 服务，由 kube-dns 服务进行处理。</li><li>这种策略适用于需要与主机网络共享的特殊情况，但它不会为 Pod 提供专用的 DNS 解析功能。</li></ul><p><strong>ClusterFirst</strong>：</p><ul><li>这是 Kubernetes 中默认的 DNS 策略。</li><li>当 Pod 的 <code>hostNetwork</code> 设置为 false 或未设置时，使用该策略。</li><li>在此策略下，Pod 首先尝试通过 kube-dns 服务解析 DNS 请求。如果 kube-dns 无法解析，则会向上级 DNS 服务器继续发起请求。</li><li>这种策略适用于大多数情况，其中 Pod 需要使用 Kubernetes 集群的 DNS 服务解析其他 Pod 或服务的主机名。</li></ul><h3 id="3-4-安装-ingress-nginx"><a href="#3-4-安装-ingress-nginx" class="headerlink" title="3.4 安装 ingress-nginx"></a>3.4 安装 ingress-nginx</h3><pre><code class="highlight bash"><span class="comment"># 使用 Helm 安装 ingress-nginx</span>$ helm install ingress-nginx --namespace ingress-nginx --create-namespace .<span class="comment"># 查看 ingress-nginx release</span>$ helm list -n ingress-nginxNAME         NAMESPACE    REVISIONUPDATED                                STATUS  CHART              APP VERSIONingress-nginxingress-nginx1       2025-06-26 18:35:32.209570796 +0800 CSTdeployedingress-nginx-4.8.31.9.4<span class="comment"># 查看 IngressClass</span>$ kubectl get ingressclassNAME    CONTROLLER             PARAMETERS   AGEnginx   k8s.io/ingress-nginx   &lt;none&gt;       153m<span class="comment"># 查看 Service</span>$ kubectl get service -n ingress-nginxNAME                                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGEingress-nginx-controller             LoadBalancer   10.105.7.64     &lt;pending&gt;     80:32570/TCP,443:31991/TCP   117mingress-nginx-controller-admission   ClusterIP      10.102.42.201   &lt;none&gt;        443/TCP                      117m<span class="comment"># 查看 Pod</span>$ kubectl get pod -n ingress-nginx -o wideNAME                             READY   STATUS    RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATESingress-nginx-controller-pf6sb   1/1     Running   0          117m   192.168.6.141   k8s-node02   &lt;none&gt;           &lt;none&gt;ingress-nginx-controller-qmb7h   1/1     Running   0          117m   192.168.6.140   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 DaemonSet</span>$ kubectl get daemonset -n ingress-nginx -o wideNAME                       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE    CONTAINERS   IMAGES                                            SELECTORingress-nginx-controller   2         2         2       2            2           kubernetes.io/os=linux   118m   controller   registry.k8s.io/ingress-nginx/controller:v1.9.4   app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx</code></pre><h2 id="4-测试-Ingress-nginx"><a href="#4-测试-Ingress-nginx" class="headerlink" title="4. 测试 Ingress-nginx"></a>4. 测试 Ingress-nginx</h2><h3 id="4-1-创建-Service-和-Deployment"><a href="#4-1-创建-Service-和-Deployment" class="headerlink" title="4.1 创建 Service 和 Deployment"></a>4.1 创建 Service 和 Deployment</h3><p><code>httpproxy-dep-svc.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">protocol:</span> <span class="string">TCP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span></code></pre><blockquote><p>执行资源清单</p></blockquote><pre><code class="highlight bash">$ kubectl apply -f httpproxy-dep-svc.yaml</code></pre><blockquote><p>查看资源</p></blockquote><pre><code class="highlight bash">$ kubectl get svc -o wideNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE   SELECTORkubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   59d   &lt;none&gt;nginx-svc    ClusterIP   10.111.16.251   &lt;none&gt;        80/TCP    8s    app=nginx$ kubectl get deployment -o wide NAME           READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTORnginx-deploy   2/2     2            2           16s   my-nginx     nginx:1.29.0   app=nginx$ kubectl get pods -o wideNAME                            READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnginx-deploy-6fc4ff86dc-n76xc   1/1     Running   0          22s   172.16.58.249   k8s-node02   &lt;none&gt;           &lt;none&gt;nginx-deploy-6fc4ff86dc-nlmw5   1/1     Running   0          22s   172.16.85.206   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h3 id="4-2-创建-Ingress"><a href="#4-2-创建-Ingress" class="headerlink" title="4.2 创建 Ingress"></a>4.2 创建 Ingress</h3><p><code>ingress.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-httpproxy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www.test-http-proxy.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 www.test-http-proxy.com 的流量。客户端必须通过该域名访问, 如果省略 host，Ingress 会匹配所有域名（即通配规则）。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><blockquote><p>执行资源清单</p></blockquote><pre><code class="highlight bash">$ curl http://www.test-http-proxy.com</code></pre><blockquote><p>查看资源</p></blockquote><pre><code class="highlight bash">$ kubectl get ingress -o wideNAME                CLASS   HOSTS                     ADDRESS   PORTS   AGEingress-httpproxy   nginx   www.test-http-proxy.com             80      18</code></pre><h3 id="4-3-修改主机-host-文件"><a href="#4-3-修改主机-host-文件" class="headerlink" title="4.3 修改主机 host 文件"></a>4.3 修改主机 host 文件</h3><p>修改host文件，将其中一台集群节点的IP，映射域名：<a href="http://www.test-http-proxy.com/">www.test-http-proxy.com</a></p><pre><code class="highlight bash">$ <span class="built_in">cat</span> /etc/hosts10.20.1.140 www.test-http-proxy.com</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-151113.png" alt="测试Host文件域名映射"></p><p>10.20.1.140 是 node节点的Ip，部署了 Ingress 控制器。这里通过 Ingress 控制器 将请求转发到 SVC。</p><h3 id="4-4-浏览器访问域名"><a href="#4-4-浏览器访问域名" class="headerlink" title="4.4 浏览器访问域名"></a>4.4 浏览器访问域名</h3><p>打开浏览器，访问 <a href="http://www.test-http-proxy.com,/">http://www.test-http-proxy.com，</a> 通过访问 Ingress Controller ，访问到 Nginx Svc</p><pre><code class="highlight bash">$ kubectl get service -n ingress-nginxNAME                                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGEingress-nginx-controller             LoadBalancer   10.105.7.64     &lt;pending&gt;     80:32570/TCP,443:31991/TCP   117mingress-nginx-controller-admission   ClusterIP      10.102.42.201   &lt;none&gt;        443/TCP                      117m</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-151605.png" alt="Ingress-Nginx 实现 Http 代理"></p><p>至此可以了解到通过使用 Ingress-Nginx 让外部流量能够访问集群内部的服务。</p><h1 id="四、Ingress-Nginx-使用"><a href="#四、Ingress-Nginx-使用" class="headerlink" title="四、Ingress Nginx 使用"></a>四、Ingress Nginx 使用</h1><p>ingress的api版本历经过多次变化他们的配置项也不太一样分别是：</p><ul><li>extensions&#x2F;v1beta1：1.16版本之前使用</li><li>networking.k8s.io&#x2F;v1beta1：1.19版本之前使用</li><li>networking.k8s.io&#x2F;v1：1.19版本之后使用</li></ul><h2 id="1-Ingress-nginx-HTTP-代理"><a href="#1-Ingress-nginx-HTTP-代理" class="headerlink" title="1. Ingress-nginx HTTP 代理"></a>1. Ingress-nginx HTTP 代理</h2><p>资源清单：<code>ingress-nginx-http-proxy.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器监听的端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span> <span class="comment"># 指定端口使用的协议，TCP 表示端口处理 TCP 流量，适合 nginx 的 HTTP 服务</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴露的端口号</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># Service 将流量转发到的目标 Pod 的端口号</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># Service 将流量路由到带有标签 app=nginx 的 Pod</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-httpproxy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www.test-http-proxy.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 www.test-http-proxy.com 的流量。客户端必须通过该域名访问, 如果省略 host，Ingress 会匹配所有域名（即通配规则）。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><blockquote><p>执行资源清单</p></blockquote><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-http-proxy.yaml deployment.apps/nginx-deploy createdservice/nginx-svc createdingress.networking.k8s.io/ingress-httpproxy created</code></pre><blockquote><p>查看部署资源</p></blockquote><pre><code class="highlight bash">$ kubectl get svc -o wideNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE   SELECTORkubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   59d   &lt;none&gt;nginx-svc    ClusterIP   10.111.16.251   &lt;none&gt;        80/TCP    8s    app=nginx$ kubectl get deployment -o wide NAME           READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTORnginx-deploy   2/2     2            2           16s   my-nginx     nginx:1.29.0   app=nginx$ kubectl get pods -o wideNAME                            READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnginx-deploy-6fc4ff86dc-n76xc   1/1     Running   0          22s   172.16.58.249   k8s-node02   &lt;none&gt;           &lt;none&gt;nginx-deploy-6fc4ff86dc-nlmw5   1/1     Running   0          22s   172.16.85.206   k8s-node01   &lt;none&gt;           &lt;none&gt;$ kubectl get ingress -o wideNAME                CLASS   HOSTS                     ADDRESS   PORTS   AGEingress-httpproxy   nginx   www.test-http-proxy.com             80      18</code></pre><blockquote><p>修改主机 Host 文件</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p></blockquote><pre><code class="highlight bash">10.20.1.140 www.test-http-proxy.com</code></pre><blockquote><p>测试访问 HTTP</p></blockquote><pre><code class="highlight bash">$ curl http://www.test-http-proxy.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt;html &#123; color-scheme: light dark; &#125;body &#123; width: 35em; margin: 0 auto;font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=<span class="string">&quot;http://nginx.org/&quot;</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=<span class="string">&quot;http://nginx.com/&quot;</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="2-Ingress-nginx-HTTPS-代理"><a href="#2-Ingress-nginx-HTTPS-代理" class="headerlink" title="2. Ingress-nginx HTTPS 代理"></a>2. Ingress-nginx HTTPS 代理</h2><h3 id="2-1-生成证书和私钥"><a href="#2-1-生成证书和私钥" class="headerlink" title="2.1 生成证书和私钥"></a>2.1 生成证书和私钥</h3><pre><code class="highlight bash"><span class="comment"># 1. 创建证书扩展文件</span>$ vim http.ext[ v3_req ]basicConstraints = CA:FALSEkeyUsage = nonRepudiation, digitalSignature, keyEnciphermentextendedKeyUsage = serverAuthsubjectAltName = @alt_names[ alt_names ]DNS.1 = www.https-proxy.comIP.1 = 127.0.0.1<span class="comment"># 2. 创建证书</span><span class="comment"># 生成证书步骤1 ： 生成 CSR(证书签名请求) 和 私钥文件 tls.key</span>openssl req -new -newkey rsa:2048 -sha256 -nodes -out tls.csr -keyout tls.key -subj <span class="string">&quot;/C=CN/ST=Beijing/L=Beijing/O=Super Inc./OU=Web Security/CN=www.https-proxy.com&quot;</span><span class="comment"># 生成证书步骤2 ： 生成证书tls.crt，并指定证书扩展文件</span>openssl x509 -req -days 365 -<span class="keyword">in</span> tls.csr -signkey tls.key -out tls.crt -extfile http.ext -extensions v3_req<span class="comment"># 查看生成的证书文件</span>$ <span class="built_in">ls</span>http.ext  tls.crt  tls.csr  tls.key<span class="comment"># 3. 将证书和私钥存储到 Secret </span>$ kubectl create secret tls ingress-nginx-tls  --key tls.key --cert tls.crt</code></pre><blockquote><p>查看证书 Secret</p><pre><code class="highlight bash"><span class="comment"># 查看 Secret</span>$ kubectl get secret ingress-nginx-tls -n defaultNAME                TYPE                DATA   AGEingress-nginx-tls   kubernetes.io/tls   2      22s<span class="comment"># 查看 Secret 详情</span>$ kubectl describe secret ingress-nginx-tls -n defaultName:         ingress-nginx-tlsNamespace:    defaultLabels:       &lt;none&gt;Annotations:  &lt;none&gt;Type:  kubernetes.io/tlsData====tls.crt:  1436 bytestls.key:  1708 bytes<span class="comment"># 查看 Secret 数据</span>$ kubectl get secret ingress-nginx-tls -n default -o yamlapiVersion: v1data:  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUQrRENDQXVDZ0F3SUJBZ0lVWk9iZ3V4cUR5bTlVWk1XUDROMEdnR3pTZkw4d0RRWUpLb1pJaHZjTkFRRUwKQlFBd2V6RUxNQWtHQTFVRUJoTUNRMDR4RURBT0JnTlZCQWdNQjBKbGFXcHBibWN4RURBT0JnTlZCQWNNQjBKbAphV3BwYm1jeEV6QVJCZ05WQkFvTUNsTjFjR1Z5SUVsdVl5NHhGVEFUQmdOVkJBc01ERmRsWWlCVFpXTjFjbWwwCmVURWNNQm9HQTFVRUF3d1RkM2QzTG1oMGRIQnpMWEJ5YjNoNUxtTnZiVEFlRncweU5UQTJNamN3TXpBeE1qWmEKRncweU5qQTJNamN3TXpBeE1qWmFNSHN4Q3pBSkJnTlZCQVlUQWtOT01SQXdEZ1lEVlFRSURBZENaV2xxYVc1bgpNUkF3RGdZRFZRUUhEQWRDWldscWFXNW5NUk13RVFZRFZRUUtEQXBUZFhCbGNpQkpibU11TVJVd0V3WURWUVFMCkRBeFhaV0lnVTJWamRYSnBkSGt4SERBYUJnTlZCQU1NRTNkM2R5NW9kSFJ3Y3kxd2NtOTRlUzVqYjIwd2dnRWkKTUEwR0NTcUdTSWIzRFFFQkFRVUFBNElCRHdBd2dnRUtBb0lCQVFDUVJkTE1TZGpNdHQ2NzVPclVhbmNRNTN5eQpTZitEYVZ2Q2xPdjlGNDRkbG1GSFlrVVZXRW9VQkNIRzdCM1pBb0pRWGFpaEJRbUl5UTNJV0o2ODhsWVpEOU1XClgzU212MGp3Q1A0SVcxaTYyVHBwb0JVRHhlNlI3SHhBQXJXeG9pMzV6Q1lFVVRoZzY3OExhWDRma04xR0pYY3AKaERqZ1FFZ3NqTmVwdGNGRVBLaUxicTNhNVlkRWdpTmpVTnh3dWpKY1RFYllkMXgwUFh5V1lYVDNDV29Fd3JUZQozcU0zWUxTdThjRXdIT21VUW13Rzhvc1p4c2lLeXZjN2MwK3JWWUpqeXR1MFJDRVRjY3Njb2hhSWpqT25xaTN0ClVhd0tKbG9Fa3M5Y2dCb05BSzFodXRDRk9UbzJMY3VZSjA1akhSdy84VXI4RG4rc0w4cGFFSWNqZ2VqOUFnTUIKQUFHamREQnlNQWtHQTFVZEV3UUNNQUF3Q3dZRFZSMFBCQVFEQWdYZ01CTUdBMVVkSlFRTU1Bb0dDQ3NHQVFVRgpCd01CTUNRR0ExVWRFUVFkTUJ1Q0UzZDNkeTVvZEhSd2N5MXdjbTk0ZVM1amIyMkhCSDhBQUFFd0hRWURWUjBPCkJCWUVGTU9jdUNxSTVpL3kwazBtSDVWeFFNaEdhRTA0TUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCQVFBeHZ5LzUKWGE1TjRxc3B4WS9rN0NPSTZoT2VBTitqaGF1SWVMeUkrb1UvczkzVnVLTkRrQ0ErakEyRHRWQmhtQ0xrVUdnbQo1enN5MkJHTndZZW4zV05mTXZZUmQ1ZFhjK3ZzUVNaV2VROWwwZ3FKaTdTeEQwaDJZa3BOUlJVcy84RXRSOUJFCmFKSmNkYTV1dlVwT2VFQ3JrWVhGRnIvK09yZW9Mdi9MV3dtK3VLRytLd204YUU1V3Z6czM0SUlqM1pOMlk1ZVQKVDh3dVhhOVJqbU1mRldaaDA4UHJUd3RXT1R1cW5TQUZ3Z2tpeTBab0RtNFd5amlUNmluZWpzTlpSa2ZCcW5ieQpwQVN0eGlmUWk4S2hRNVUzOEhkUVMzYnpNdnFiS2g3ZlZoamh4Si8wNVBQVHE0NGU3eG56dnlEazFUaC9vWnZ0CjJLdUZuVVkxLzlMayt1U1cKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=  tls.key: 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kind: Secretmetadata:  creationTimestamp: <span class="string">&quot;2025-06-27T03:10:37Z&quot;</span>  name: ingress-nginx-tls  namespace: default  resourceVersion: <span class="string">&quot;13338253&quot;</span>  uid: fffb5d77-97c4-4237-8be9-a487d96dbf34<span class="built_in">type</span>: kubernetes.io/tls</code></pre></blockquote><h3 id="2-2-创建资源清单"><a href="#2-2-创建资源清单" class="headerlink" title="2.2 创建资源清单"></a>2.2 创建资源清单</h3><p>资源清单：<code>ingress-nginx-https-proxy.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx-https</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx-https</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器监听的端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span> <span class="comment"># 指定端口使用的协议，TCP 表示端口处理 TCP 流量，适合 nginx 的 HTTP 服务</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-https-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴露的端口号</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># Service 将流量转发到的目标 Pod 的端口号</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx-https</span> <span class="comment"># Service 将流量路由到带有标签 app=nginx-https 的 Pod</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-https-proxy</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/ssl-redirect:</span> <span class="string">&quot;true&quot;</span> <span class="comment"># HTTP 重定向为HTTPS, true表示强制重定向</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www.https-proxy.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 www.www.https-proxy.com 的流量。客户端必须通过该域名访问, 如果省略 host，Ingress 会匹配所有域名（即通配规则）。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-https-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-https-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span>  <span class="attr">tls:</span>    <span class="bullet">-</span> <span class="attr">hosts:</span>        <span class="bullet">-</span> <span class="string">www.https-proxy.com</span> <span class="comment"># 指定域名</span>      <span class="attr">secretName:</span> <span class="string">ingress-nginx-tls</span> <span class="comment"># 证书和私钥保存的 Secret</span></code></pre><p>可以看到Ingress添加TLS配置也非常简单，只需要在 spec下添加一个 tls 字段即可：</p><ul><li>hosts：证书所授权的域名列表</li><li>secretName：证书的 Secret 名字</li><li>ingressClassName: ingress class 的名字，1.22+需要配置</li></ul><blockquote><p>执行资源清单</p></blockquote><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-https-proxy.yaml deployment.apps/nginx-deploy createdservice/nginx-https-svc createdingress.networking.k8s.io/ingress-https-proxy created</code></pre><blockquote><p>查看部署资源</p></blockquote><pre><code class="highlight bash">$ kubectl get svc -o wideNAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE   SELECTORkubernetes        ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   59d   &lt;none&gt;nginx-https-svc   ClusterIP   10.99.219.148   &lt;none&gt;        80/TCP    96s   app=nginx-https$ kubectl get deployment -o wideNAME           READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTORnginx-deploy   2/2     2            2           8s    my-nginx     nginx:1.29.0   app=nginx-https$ kubectl get pods -o wideNAME                            READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnginx-deploy-7d6bd7f587-47kqv   1/1     Running   0          21s   172.16.85.213   k8s-node01   &lt;none&gt;           &lt;none&gt;nginx-deploy-7d6bd7f587-92hhz   1/1     Running   0          21s   172.16.58.233   k8s-node02   &lt;none&gt;           &lt;none&gt;$ kubectl get ingress -o wideNAME                  CLASS   HOSTS                 ADDRESS   PORTS     AGEingress-https-proxy   nginx   www.https-proxy.com             80, 443   2m57s</code></pre><blockquote><p>修改主机 Host 文件</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p></blockquote><pre><code class="highlight bash">10.20.1.140 www.https-proxy.com</code></pre><blockquote><p>测试访问 HTTPS访问<br>端口号通过命令：kubectl get svc -n ingress-nginx 查看 443 映射端口</p></blockquote><pre><code class="highlight bash"><span class="comment"># 用命令行测试 https 请求，其中 -k 表示忽略自签名证书警告</span>$ curl -k https://www.https-proxy.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt;html &#123; color-scheme: light dark; &#125;body &#123; width: 35em; margin: 0 auto;font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=<span class="string">&quot;http://nginx.org/&quot;</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=<span class="string">&quot;http://nginx.com/&quot;</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-152114.png" alt="浏览器访问HTTPS"></p><p>需要将自签发的 tls.crt 证书导入到浏览器中，否则会有 “不安全” 的告警提示</p><p>如果在ingress中设置tls,即默认的http会被强制重定向到https，http即不可访问,如果需要http与https同时可以使用可以设置</p><ul><li>nginx.ingress.kubernetes.io&#x2F;ssl-redirect: “false” ：禁用强制重定向，这样可以同时使用http与https</li></ul><h2 id="3-Ingress-nginx-BasicAuth-代理"><a href="#3-Ingress-nginx-BasicAuth-代理" class="headerlink" title="3. Ingress-nginx BasicAuth 代理"></a>3. Ingress-nginx BasicAuth 代理</h2><p>有些网站可能需要通过密码来访问，对于这类网站可以使用 Nginx 的 basic-auth 设置密码访 问，具体方法如下，由于需要使用 htpasswd 工具，所以需要安装httpd。</p><pre><code class="highlight bash"><span class="comment"># 安装 htpasswd 工具</span>$ dnf -y install httpd-tools<span class="comment"># 使用 htpasswd 命令创建一个新的基本认证密码文件 auth，并为用户 george 设置密码。</span>$ htpasswd -c auth georgeNew password: Re-<span class="built_in">type</span> new password: Adding password <span class="keyword">for</span> user george<span class="comment"># 创建一个 Kubernetes Secret 资源，类型为 generic，用于存储基本认证的密码文件 auth，以便在 Ingress 或 Nginx 中启用 HTTP 基本认证。</span>$ kubectl create secret generic ingress-basic-auth --from-file=auth</code></pre><blockquote><p>查看 Secret</p><pre><code class="highlight bash">$ kubectl get secret ingress-basic-auth -o yamlapiVersion: v1data:  auth: Z2VvcmdlOiRhcHIxJEpoZFB6aVNPJDVXcjhqTDYyQll5Nm5aa3ZHWlB3ejAKkind: Secretmetadata:  creationTimestamp: <span class="string">&quot;2025-06-27T06:12:07Z&quot;</span>  name: ingress-basic-auth  namespace: default  resourceVersion: <span class="string">&quot;13361989&quot;</span>  uid: 9550e4af-4a83-48d7-9b40-fc207303a192<span class="built_in">type</span>: Opaque</code></pre></blockquote><p><strong>创建包含密码认证的Ingress</strong>：</p><ul><li>nginx.ingress.kubernetes.io&#x2F;auth-type：认证类型，可以是 basic 和 digest</li><li>nginx.ingress.kubernetes.io&#x2F;auth-secret：密码文件的 Secret 名称</li><li>nginx.ingress.kubernetes.io&#x2F;auth-realm：需要密码认证的消息提醒</li></ul><p><strong>资源清单</strong></p><p><code>ingress-nginx-basic-auth.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器监听的端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span> <span class="comment"># 指定端口使用的协议，TCP 表示端口处理 TCP 流量，适合 nginx 的 HTTP 服务</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴露的端口号</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># Service 将流量转发到的目标 Pod 的端口号</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># Service 将流量路由到带有标签 app=nginx 的 Pod</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-basic-auth</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/auth-type:</span> <span class="string">basic</span> <span class="comment"># 认证类型</span>    <span class="attr">nginx.ingress.kubernetes.io/auth-secret:</span> <span class="string">ingress-basic-auth</span> <span class="comment"># 密码文件的 Secret 名称</span>    <span class="attr">nginx.ingress.kubernetes.io/auth-realm:</span> <span class="string">&#x27;请输入用户名和密码：&#x27;</span> <span class="comment"># 需要密码认证的消息提醒</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">auth.basic.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 auth.basic.com 的流量。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">ImplementationSpecific</span> <span class="comment"># 表示路径匹配行为由 Ingress 控制器定义,对于 nginx Ingress 控制器，ImplementationSpecific 通常等同于 Prefix，即匹配以指定路径开头的请求。</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-basic-auth.yaml</code></pre></blockquote><blockquote><p>修改主机 Host 文件</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p></blockquote><pre><code class="highlight bash">10.20.1.140 auth.basic.com</code></pre><blockquote><p>浏览器访问测试</p></blockquote><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-152550.png" alt="basic auth 认证测试-登录用户名/密码"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-152642.png" alt="basic auth 认证测试-登录成功"></p><h2 id="4-Ingress-nginx-域名重定向"><a href="#4-Ingress-nginx-域名重定向" class="headerlink" title="4. Ingress-nginx 域名重定向"></a>4. Ingress-nginx 域名重定向</h2><p><strong>官方说明</strong>：<a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#permanent-redirect">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#permanent-redirect</a></p><p>在 Nginx 作为代理服务器时，Redirect 可用于域名的重定向，比如访问 old.com 被重定向到 new.com。Ingress 可以更简单的实现 Redirect 功能，接下来用 ingress-redirect.com 作为旧域名， <a href="http://www.baidu.com/">www.baidu.com</a> 作为新域名进行演示：</p><p><strong>相关配置项</strong>：</p><ul><li>permanent-redirect：重定向到的域名</li><li>permanent-redirect-code：重定向代码，不配置默认301(永久重定向,如有其他原因可自行配置)</li></ul><p>资源清单：<code>ingress-nginx-redirect.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器监听的端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span> <span class="comment"># 指定端口使用的协议，TCP 表示端口处理 TCP 流量，适合 nginx 的 HTTP 服务</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴露的端口号</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># Service 将流量转发到的目标 Pod 的端口号</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># Service 将流量路由到带有标签 app=nginx-https 的 Pod</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-redirect</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">&quot;nginx&quot;</span> <span class="comment"># 指定使用的Ingress控制器类名，与 ingressClassName 作用相同</span>    <span class="attr">nginx.ingress.kubernetes.io/permanent-redirect:</span> <span class="string">https://www.baidu.com</span> <span class="comment"># 永久重定向网址</span>    <span class="attr">nginx.ingress.kubernetes.io/permanent-redirect-code:</span> <span class="string">&#x27;301&#x27;</span> <span class="comment"># 永久重定向状态码</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">ingress-redirect.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 ingress-redirect.com 的流量。客户端必须通过该域名访问, 如果省略 host，Ingress 会匹配所有域名（即通配规则）。</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-redirect.yaml</code></pre></blockquote><blockquote><p>修改主机host文件，添加域名映射</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p><pre><code class="highlight plaintext">10.20.1.140 ingress-redirect.com</code></pre></blockquote><blockquote><p>浏览器访问测试</p><p><a href="http://ingress-redirect.com/">http://ingress-redirect.com</a></p></blockquote><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/27/20250627-134058.png" alt="域名重定向"></p><h2 id="5-Ingress-nginx-Rewrite"><a href="#5-Ingress-nginx-Rewrite" class="headerlink" title="5. Ingress-nginx  Rewrite"></a>5. Ingress-nginx  Rewrite</h2><p>官方示例：<a href="https://kubernetes.github.io/ingress-nginx/examples/rewrite/">https://kubernetes.github.io/ingress-nginx/examples/rewrite/</a></p><p><strong>相关配置项</strong>：</p><ul><li>nginx.ingress.kubernetes.io&#x2F;rewrite-target: 重定向配置</li></ul><h3 id="5-1-案例"><a href="#5-1-案例" class="headerlink" title="5.1 案例"></a>5.1 案例</h3><p>资源清单：<code>ingress-nginx-rewrite.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器监听的端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span> <span class="comment"># 指定端口使用的协议，TCP 表示端口处理 TCP 流量，适合 nginx 的 HTTP 服务</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴露的端口号</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># Service 将流量转发到的目标 Pod 的端口号</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># Service 将流量路由到带有标签 app=nginx-https 的 Pod</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-rewrite</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/rewrite-target:</span> <span class="string">/$2</span> <span class="comment"># 对匹配的 URL 路径进行重写。$2 引用正则表达式捕获组</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">ingress-rewrite.com</span> <span class="comment"># 定义流量路由规则，基于主机名（host）。这里指定只处理发送到 ingress-rewrite.com 的请求</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/api(/|$)(.*)</span> <span class="comment"># 匹配以 /api 开头的路径，后面可以跟 / 或直接结束（|$ 表示路径结束），并捕获剩余部分 (.*) 作为捕获组 $2， 例如：/api、/api/、/api/anything 都会匹配</span>            <span class="attr">pathType:</span> <span class="string">ImplementationSpecific</span> <span class="comment"># 路径匹配的具体行为由 Ingress 控制器（NGINX）定义。通常与正则表达式结合使用，允许更灵活的匹配逻辑</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-rewrite.yaml</code></pre></blockquote><blockquote><p>修改主机host文件，添加域名映射</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p><pre><code class="highlight plaintext">10.20.1.140 ingress-rewrite.com</code></pre></blockquote><blockquote><p>访问域名，不加 &#x2F;api 前缀：404</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-152851.png" alt="不加 /api 前缀：404"></p></blockquote><blockquote><p>访问域名，添加 &#x2F;api 前缀：成功访问到 nginx-svc Service 的默认页面</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-152935.png" alt="添加 /api 前缀：成功访问到 nginx-svc Service 的默认页面"></p></blockquote><blockquote><p>访问域名，添加路径 &#x2F;api&#x2F;index.html 成功访问到 nginx-svc Service 的 &#x2F;index.html 页面</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-153050.png" alt="访问路径 /api/index.html 成功访问到 nginx-svc Service 的 /index.html 页面"></p></blockquote><h3 id="5-1-rewrite-和-redirect"><a href="#5-1-rewrite-和-redirect" class="headerlink" title="5.1 rewrite 和 redirect"></a>5.1 rewrite 和 redirect</h3><p>在 Ingress 控制器中，rewrite 和 redirect 是两种不同的操作，它们的作用和行为有所不同：</p><p><strong>Rewrite（重写）</strong></p><ul><li>作用：重写是指修改请求的路径，但是客户端不会察觉到这个变化，它仅在服务器内部发生。在 Kubernetes 中，可以通过 Ingress 的注解来配置重写规则</li><li>示例：比如你有一个服务部署在 &#x2F;v1 路径下，但是你希望用户访问时不需要输入 &#x2F;v1，那么你可以使用重写将请求从根路径 &#x2F; 重写到 &#x2F;v1</li></ul><p><strong>Redirect（重定向）</strong></p><ul><li>作用：重定向是指服务器向客户端发出一个新的 URL，让客户端进行新的请求。客户端会收到一个 HTTP 3xx 状态码，然后根据其中的重定向地址进行新的请求。这意味着客户端会知道发生了重定向，它会发起新的请求</li><li>示例：比如你有一个网站的旧地址是 <a href="http://example.com,但是你希望所有的请求都转发到/">http://example.com，但是你希望所有的请求都转发到</a> <a href="https://example.com,这时你就可以使用重定向将所有的/">https://example.com，这时你就可以使用重定向将所有的</a> HTTP 请求重定向到 HTTPS</li></ul><p><strong>区别：</strong></p><ul><li>影响范围：Rewrite 只在服务器内部修改请求路径，不会影响到客户端，而 Redirect 则会向客户端发送一个新的 URL，让客户端发起新的请求</li><li>状态码：Rewrite 不涉及状态码的改变，而 Redirect 会向客户端发送一个重定向的 HTTP 状态码（例如 301 永久重定向、302 临时重定向等）</li><li>可见性：Rewrite 对于客户端来说是透明的，而 Redirect 则会告知客户端发生了重定向</li></ul><p>在选择使用 Rewrite 还是 Redirect 时，需要根据具体的需求来决定。如果你希望在不修改客户端请求的情况下修改路径，那么使用 Rewrite；如果你希望客户端知道发生了重定向，并且根据新的 URL 进行新的请求，那么使用 Redirect。</p><h2 id="6-Ingress-nginx-错误代码重定向"><a href="#6-Ingress-nginx-错误代码重定向" class="headerlink" title="6. Ingress-nginx 错误代码重定向"></a>6. Ingress-nginx 错误代码重定向</h2><p>这里的错误代码重定向分为全局设置与某个ingress设置</p><h3 id="6-1-默认错误后端（全局）"><a href="#6-1-默认错误后端（全局）" class="headerlink" title="6.1 默认错误后端（全局）"></a>6.1 默认错误后端（全局）</h3><p>错误代码重定向功能需要使用 helm 重新部署 ingress-nginx 控制器部署步骤如下：</p><h4 id="6-1-1-修改-values-yaml"><a href="#6-1-1-修改-values-yaml" class="headerlink" title="6.1.1 修改 values.yaml"></a>6.1.1 修改 values.yaml</h4><pre><code class="highlight yaml"><span class="comment"># 修改 ingress-nginx 目录内 valume.yml 文件</span><span class="attr">defaultBackend:</span>  <span class="attr">enabled:</span> <span class="literal">true</span> <span class="comment"># 开启全局错误码重定向</span>  <span class="attr">name:</span> <span class="string">defaultbackend</span>  <span class="attr">image:</span>    <span class="attr">registry:</span> <span class="string">registry.k8s.io</span>    <span class="attr">image:</span> <span class="string">defaultbackend-amd64</span>    <span class="attr">tag:</span> <span class="string">&quot;1.5&quot;</span>    <span class="attr">pullPolicy:</span> <span class="string">IfNotPresent</span></code></pre><p><em>这里的镜像是 ingress-nginx 的默认镜像，需要提前下载并导入到服务器中</em></p><h4 id="6-1-2-更新-Ingress-Nginx"><a href="#6-1-2-更新-Ingress-Nginx" class="headerlink" title="6.1.2 更新 Ingress Nginx"></a>6.1.2 更新 Ingress Nginx</h4><pre><code class="highlight bash"><span class="comment"># 更新 Ingress Nginx</span>$ helm upgrade ingress-nginx . -n ingress-nginx<span class="comment"># 查看 Pod 是否更新，如果是则为刚创建的</span>$ kubectl get pod -n ingress-nginxNAME                                           READY   STATUS        RESTARTS   AGEingress-nginx-controller-cpbcd                 1/1     Terminating   0          31hingress-nginx-controller-szlfb                 1/1     Running       0          25singress-nginx-defaultbackend-f7797494f-t77x4   1/1     Running       0          39s<span class="comment"># 旧的 controller 正在关闭，新创建的在运行中，Ingress Nginx 更新成功</span></code></pre><h4 id="6-1-3-测试资源清单"><a href="#6-1-3-测试资源清单" class="headerlink" title="6.1.3 测试资源清单"></a>6.1.3 测试资源清单</h4><p><code>ingress-nginx-global-errorcode.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">protocol:</span> <span class="string">TCP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-global-errorcode</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">global.errorcode.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 global.errorcode.com 的流量。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-global-errorcode.yaml</code></pre></blockquote><blockquote><p>修改主机host文件，添加域名映射</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p><pre><code class="highlight plaintext">10.20.1.140 global.errorcode.com</code></pre></blockquote><p>当开启 Ingress Nginx 全局错误码重定向时，此时请求不存在的路径，服务端会返回默认的内容</p><p>例如请求 <a href="http://ingress-rewrite.com/123.html">http://ingress-rewrite.com/123.html</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/28/20250628-172533.png" alt="全局错误码重定向"></p><h3 id="6-2-单独声明错误后端"><a href="#6-2-单独声明错误后端" class="headerlink" title="6.2 单独声明错误后端"></a>6.2 单独声明错误后端</h3><p><strong>设置某个ingress的错误重定向会覆盖全局设置，示例如下</strong></p><ul><li>nginx.ingress.kubernetes.io&#x2F;default-backend: 默认后端service名称</li><li>nginx.ingress.kubernetes.io&#x2F;custom-http-errors: 那些错误代理重定向到默认后端svc</li></ul><p><strong>资源清单</strong></p><p><code>ingress-nginx-single-errorcode.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">error-code-deploy</span> <span class="comment"># 用于当请求出现规定的错误码时，返回默认内容</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">error</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">error</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">error-web</span>          <span class="attr">image:</span> <span class="string">registry.k8s.io/defaultbackend-amd64:1.5</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">protocol:</span> <span class="string">TCP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">error-code-svc</span> <span class="comment"># 当请求异常，接收到规定的错误码时，请求会重定向到这个service，用来处理错误请求，返回默认内容</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">error</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">protocol:</span> <span class="string">TCP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-single-errorcode</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/default-backend:</span> <span class="string">&#x27;error-code-svc&#x27;</span> <span class="comment"># 指定请求异常时，重定向到哪个SVC处理</span>    <span class="attr">nginx.ingress.kubernetes.io/custom-http-errors:</span> <span class="string">&quot;404,415&quot;</span> <span class="comment"># 哪些错误代理重定向到默认后端svc</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">single.errorcode.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 single.errorcode.com 的流量。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><p>为了体现出单独为 Ingress 声明错误码的处理效果，这里先将 ingress-nginx 的全局错误码处理关闭</p><pre><code class="highlight yaml"><span class="comment"># 修改 values.yaml</span><span class="attr">defaultBackend:</span>  <span class="attr">enabled:</span> <span class="literal">false</span> <span class="comment"># 关闭全局错误码重定向</span>  <span class="attr">name:</span> <span class="string">defaultbackend</span>  <span class="attr">image:</span>    <span class="attr">registry:</span> <span class="string">registry.k8s.io</span>    <span class="attr">image:</span> <span class="string">defaultbackend-amd64</span>    <span class="attr">tag:</span> <span class="string">&quot;1.5&quot;</span>    <span class="attr">pullPolicy:</span> <span class="string">IfNotPresent</span>    <span class="comment"># 更新 Ingress Nginx</span><span class="string">$</span> <span class="string">helm</span> <span class="string">upgrade</span> <span class="string">ingress-nginx</span> <span class="string">.</span> <span class="string">-n</span> <span class="string">ingress-nginx</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-single-errorcode.yaml</code></pre></blockquote><blockquote><p>修改主机host文件，添加域名映射</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p><pre><code class="highlight plaintext">10.20.1.140 single.errorcode.com</code></pre></blockquote><p><strong>测试：</strong></p><p>使用浏览器访问一个不存在的路径，在没有错误码重定向时会返回 404， 如今为 Ingress 单独配置了错误码，会返回配置的 Service 的数据。</p><p><a href="http://single.errorcode.com/api/index1.html">http://single.errorcode.com/api/index1.html</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-153741.png" alt="自定义错误码返回"></p><h2 id="7-Ingress-nginx-匹配请求头"><a href="#7-Ingress-nginx-匹配请求头" class="headerlink" title="7. Ingress-nginx  匹配请求头"></a>7. Ingress-nginx  匹配请求头</h2><p>使用 ingress-nginx 实现根据不同的请求头，将请求转发到不同的服务。需要先开启 ingress-nginx 的 snippet 功能。</p><h3 id="7-1-开启-Snippet"><a href="#7-1-开启-Snippet" class="headerlink" title="7.1 开启 Snippet"></a>7.1 开启 Snippet</h3><pre><code class="highlight bash"><span class="comment"># 编辑 ingress-nginx-controller ConfigMap</span>$ kubectl edit cm ingress-nginx-controller -n ingress-nginx<span class="comment"># 开启 snippet</span>apiVersion: v1data:  allow-snippet-annotations: <span class="string">&quot;true&quot;</span></code></pre><h3 id="7-2-编辑资源清单"><a href="#7-2-编辑资源清单" class="headerlink" title="7.2 编辑资源清单"></a>7.2 编辑资源清单</h3><p><code>ingress-nginx-match-request-header.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">snippet</span>  <span class="attr">name:</span> <span class="string">snippet-dep</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">snippet</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">snippet</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">snippet-deploy</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">snippet</span>  <span class="attr">name:</span> <span class="string">snippet-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">snippet</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">snippet-igs</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/server-snippet:</span> <span class="string">|</span><span class="string">      set $agentflag 0;</span><span class="string">      if ($http_user_agent ~* &quot;(Android|IPhone)&quot;) &#123; # 如果是Android或IPhone访问会重定向到 www.baidu.com 的新网站</span><span class="string">        set $agentflag 1;</span><span class="string">      &#125;</span><span class="string">      if ($agentflag = 1) &#123;</span><span class="string">        return 302 http://www.baidu.com;</span><span class="string">      &#125;</span><span class="string"></span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">snippet.request.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">snippet-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-match-request-header.yaml</code></pre></blockquote><blockquote><p>编辑Host文件</p><pre><code class="highlight bash">$ <span class="built_in">cat</span> /etc/hosts10.20.1.140 snippet.request.com</code></pre><p>10.20.1.140 是 node 节点，部署了 Ingress 控制器</p></blockquote><blockquote><p>测试访问：<strong>默认请求头</strong></p><pre><code class="highlight bash">$ curl http://snippet.request.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt;</code></pre><p>成功访问到 Nginx</p></blockquote><blockquote><p>测试访问：添加请求头</p><pre><code class="highlight bash">$ curl http://snippet.request.com -H <span class="string">&#x27;User-Agent: Android&#x27;</span>  -IHTTP/1.1 302 Moved TemporarilyDate: Fri, 04 Jul 2025 07:08:56 GMTContent-Type: text/htmlContent-Length: 138Connection: keep-aliveLocation: http://www.baidu.com</code></pre><p>请求重定向到了 <a href="http://www.baidu.com/">www.baidu.com</a></p></blockquote><h2 id="8-Ingress-nginx-配置黑白名单"><a href="#8-Ingress-nginx-配置黑白名单" class="headerlink" title="8. Ingress-nginx  配置黑白名单"></a>8. Ingress-nginx  配置黑白名单</h2><h3 id="8-1-配置方案"><a href="#8-1-配置方案" class="headerlink" title="8.1. 配置方案"></a>8.1. 配置方案</h3><p>Ingress-nginx 配置黑白名单有两种方式：</p><ul><li>Annotations：只对指定的ingress生效</li><li>ConfigMap：全局生效</li></ul><p>configmap官方配置文档说明：<a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/</a></p><p><strong>若是同时配置了 Annotations 和 configmap，一般都是 annotations 生效，configmap 不生效，因为 annotations 优先级比 configmap 高</strong></p><h3 id="8-2-黑白名单的区别"><a href="#8-2-黑白名单的区别" class="headerlink" title="8.2 黑白名单的区别"></a>8.2 黑白名单的区别</h3><ul><li>白名单是默认是拒绝所有，只允许一个地址去访问</li><li>黑名单是不允许该地址去访问所有</li></ul><p>黑白名单配置使用 configmap 还是 annotations</p><ul><li>黑名单建议使用 ConfigMap 去配置</li><li>白名单建议使用 Annotations 去配置</li></ul><h3 id="8-3-ConfigMap-添加黑名单"><a href="#8-3-ConfigMap-添加黑名单" class="headerlink" title="8.3 ConfigMap 添加黑名单"></a>8.3 ConfigMap 添加黑名单</h3><p>配置黑名单禁止某一个或某一段 IP，需要在 Nginx Ingress 的 ConfigMap 中配置，比如将 10.20.1.141（多个配置逗号分隔）添加至黑名单。</p><p>configmap官方配置文档说明：<a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/</a></p><h4 id="8-3-1-编辑-Ingress-Nginx-ConfigMap"><a href="#8-3-1-编辑-Ingress-Nginx-ConfigMap" class="headerlink" title="8.3.1 编辑 Ingress-Nginx ConfigMap"></a>8.3.1 编辑 Ingress-Nginx ConfigMap</h4><pre><code class="highlight bash">$ kubectl  edit cm ingress-nginx-controller -n ingress-nginxapiVersion: v1data:  allow-snippet-annotations: <span class="string">&quot;true&quot;</span>  block-cidrs: 10.20.1.141,10.20.1.149</code></pre><p>编辑后保存！</p><h4 id="8-3-2-测试资源清单"><a href="#8-3-2-测试资源清单" class="headerlink" title="8.3.2 测试资源清单"></a>8.3.2 测试资源清单</h4><p><code>ingress-nginx-black-block.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">name:</span> <span class="string">test-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">test</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">name:</span> <span class="string">test-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">global.black.com</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">global.black.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">test-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-global-black.yaml</code></pre><p><strong>修改Host文件</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 global.black.com&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># 在 10.20.1.141 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.141 global.black.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>访问测试</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器上测试，可以成功访问 Ingress</span>$ curl global.block.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;<span class="comment"># 在 10.20.1.141 服务器上测试，访问被禁止，全局配置生效</span>$ curl global.block.com&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="8-4-Annotations-添加黑名单"><a href="#8-4-Annotations-添加黑名单" class="headerlink" title="8.4 Annotations 添加黑名单"></a>8.4 Annotations 添加黑名单</h3><p><strong>资源清单：</strong> <code>ingress-nginx-annotations-black.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">black</span>  <span class="attr">name:</span> <span class="string">black-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">black</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">black</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">black</span>  <span class="attr">name:</span> <span class="string">black-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">black</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/server-snippet:</span> <span class="string">|</span><span class="string">      deny 10.20.1.141;       # 拒绝特定 IP</span><span class="string">      deny 192.168.6.0/24;    # 拒绝特定网段</span><span class="string">      allow all;              # 允许其他 IP</span><span class="string"></span>  <span class="attr">name:</span> <span class="string">annotaions.black.com</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">annotaions.black.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">black-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span>            <span class="attr">path:</span> <span class="string">/</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-annotations-black.yaml</code></pre><p><strong>修改Host文件</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 annotaions.black.com&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># 在 10.20.1.141 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.141 annotaions.black.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>访问测试</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器上测试，可以成功访问 Ingress</span>$ curl annotaions.black.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;<span class="comment"># 在 10.20.1.141 服务器上测试，访问被禁止，全局配置生效</span>$ curl annotaions.black.com&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="8-5-ConfigMap-设置白名单"><a href="#8-5-ConfigMap-设置白名单" class="headerlink" title="8.5 ConfigMap 设置白名单"></a>8.5 ConfigMap 设置白名单</h3><p>白名单表示只允许某个IP可以访问 </p><h4 id="8-5-1-编辑-Ingress-Nginx-ConfigMap"><a href="#8-5-1-编辑-Ingress-Nginx-ConfigMap" class="headerlink" title="8.5.1 编辑 Ingress-Nginx ConfigMap"></a>8.5.1 编辑 Ingress-Nginx ConfigMap</h4><p>添加 <code>whitelist-source-range</code> 配置</p><pre><code class="highlight bash">$ kubectl  edit cm ingress-nginx-controller -n ingress-nginxapiVersion: v1data:  allow-snippet-annotations: <span class="string">&quot;true&quot;</span>  block-cidrs: 10.20.1.141,10.20.1.149  whitelist-source-range: 10.20.1.139,10.20.1.88</code></pre><p>编辑后保存！</p><h4 id="8-5-2-测试资源清单"><a href="#8-5-2-测试资源清单" class="headerlink" title="8.5.2 测试资源清单"></a>8.5.2 测试资源清单</h4><p><code>ingress-nginx-global-white.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">name:</span> <span class="string">test-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">test</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">name:</span> <span class="string">test-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">global.white.com</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">global.white.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">test-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-global-white.yaml</code></pre><p><strong>修改Host文件</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 global.white.com&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># 在 10.20.1.139 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 global.white.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>访问测试</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.139 服务器上测试，可以成功访问 Ingress</span>$ curl global.white.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;<span class="comment"># 在 10.20.1.140 服务器上测试，访问被禁止，全局配置生效</span>$ curl global.white.com&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="8-6-Annotations-添加白名单"><a href="#8-6-Annotations-添加白名单" class="headerlink" title="8.6 Annotations 添加白名单"></a>8.6 Annotations 添加白名单</h3><p><strong>资源清单：</strong> <code>ingress-nginx-annotations-white.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">white</span>  <span class="attr">name:</span> <span class="string">white-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">white</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">white</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">white</span>  <span class="attr">name:</span> <span class="string">white-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">white</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/whitelist-source-range:</span> <span class="string">&quot;10.20.1.140&quot;</span>  <span class="attr">name:</span> <span class="string">annotations.white.com</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">annotations.white.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">white-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-annotations-white.yaml</code></pre><p><strong>修改Host文件</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 annotations.white.com&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># 在 10.20.1.141 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.141 annotations.white.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>访问测试</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器上测试，可以成功访问 Ingress</span>$ curl annotations.white.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;<span class="comment"># 在 10.20.1.141 服务器上测试，访问被禁止，全局配置生效</span>$ curl annotations.white.com&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="9-Ingress-nginx-速率限制"><a href="#9-Ingress-nginx-速率限制" class="headerlink" title="9. Ingress-nginx  速率限制"></a>9. Ingress-nginx  速率限制</h2><p>有时候可能需要限制速率以降低后端压力，或者限制单个IP每秒的访问速率防止攻击。此时可以使用  Nginx 的 rate limit 进行配置</p><h3 id="9-1-速率限制设置"><a href="#9-1-速率限制设置" class="headerlink" title="9.1 速率限制设置"></a>9.1 速率限制设置</h3><pre><code class="highlight bash"><span class="comment">#限制每秒的连接，单个 IP： </span>nginx.ingress.kubernetes.io/limit-rps<span class="comment">#限制每分钟的连接，单个 IP： </span>nginx.ingress.kubernetes.io/limit-rpm <span class="comment">#限制客户端每秒传输的字节数，单位为 K，需要开启 proxy-buffering： </span>nginx.ingress.kubernetes.io/limit-rate <span class="comment">#速率限制白名单 </span>nginx.ingress.kubernetes.io/limit-whitelist</code></pre><h3 id="9-2-测试案例：无速率限制"><a href="#9-2-测试案例：无速率限制" class="headerlink" title="9.2 测试案例：无速率限制"></a>9.2 测试案例：无速率限制</h3><p>资源清单 ：<code>ingress-nginx-rate-limit-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">speed-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">speed</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">speed</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">speed-svc</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">speed</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-rate-limit-pod.yaml</code></pre><p><strong>编辑Host文件</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器写入</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 rate.limit.com&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># 在 10.20.1.141 服务器写入</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.141 rate.limit.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>测试在无Ingress 限制速率的情况下， 发起100次请求</strong></p><pre><code class="highlight bash"><span class="comment"># 安装 ab 工具</span>$ sudo yum install -y httpd-tools<span class="comment"># 测试发起100个请求，并发数是 10</span>$ ab -c 10 -n 100 http://rate.limit.com/ | grep requestsComplete requests:      100Failed requests:        0Time per request:       0.188 [ms] (mean, across all concurrent requests)Percentage of the requests served within a certain time (ms)</code></pre><p>结论：在没有速率限制的情况下，100个请求全部成功。</p><h3 id="9-3-测试案例：使用-Ingress-限制请求速率"><a href="#9-3-测试案例：使用-Ingress-限制请求速率" class="headerlink" title="9.3 测试案例：使用 Ingress 限制请求速率"></a>9.3 测试案例：使用 Ingress 限制请求速率</h3><p>资源清单：<code>ingress-nginx-rate-limit-ingress.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">speed-ingress</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/limit-rps:</span> <span class="string">&quot;10&quot;</span>  <span class="comment"># 每秒最多 10 个请求</span>    <span class="attr">nginx.ingress.kubernetes.io/limit-whitelist:</span> <span class="string">&quot;10.20.1.140,192.168.6.0/24&quot;</span>  <span class="comment"># 这些 IP 范围免于速率限制</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">rate.limit.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">speed-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-rate-limit-ingress.yaml</code></pre><p><strong>测试速率限制</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.141 服务器上使用 ab 同时发起100个请求</span>$ ab -c 10 -n 100 http://rate.limit.com/ | grep requestsComplete requests:      100Failed requests:        49Time per request:       0.205 [ms] (mean, across all concurrent requests)Percentage of the requests served within a certain time (ms)<span class="comment">###</span>由于 Ingress 做了请求速率的限制，发起100个请求，有49个失败了<span class="comment">###</span><span class="comment"># 在 10.20.1.140 服务器上使用 ab 同时发起100个请求</span>$ ab -c 10 -n 100 http://rate.limit.com/ | grep requestsComplete requests:      100Failed requests:        0Time per request:       0.137 [ms] (mean, across all concurrent requests)Percentage of the requests served within a certain time (ms)<span class="comment">###</span>虽然Ingress对请求做了速率限制，由于 10.20.1.140 服务器ip在ingress 速率限制的白名单中，因此请求速率不受限制，100个请求全部成功<span class="comment">###</span></code></pre><h2 id="10-Ingress-nginx-灰度或者金丝雀发布"><a href="#10-Ingress-nginx-灰度或者金丝雀发布" class="headerlink" title="10. Ingress-nginx  灰度或者金丝雀发布"></a>10. Ingress-nginx  灰度或者金丝雀发布</h2><h3 id="10-1-概述"><a href="#10-1-概述" class="headerlink" title="10.1 概述"></a>10.1 概述</h3><p>灰度发布（也称金丝雀发布，Canary Release）是一种软件部署策略，旨在降低新版本上线带来的风险。它通过将新版本逐步推送给一小部分用户或系统（称为“金丝雀”），观察其表现、稳定性及用户反馈，再决定是否推广到全部用户。以下是详细解释：</p><p><strong>核心概念</strong></p><ol><li><strong>逐步推广</strong>：新版本不会一次性部署到所有用户，而是先部署到小规模用户群（如1%的用户或特定区域）。</li><li><strong>监控与验证</strong>：在灰度发布期间，开发团队会密切监控新版本的性能、错误率、用户体验等指标。</li><li><strong>快速回滚</strong>：如果发现问题，可以迅速回滚到旧版本，减少对用户的影响。</li><li><strong>金丝雀的由来</strong>：名称源于煤矿工人使用金丝雀鸟来检测矿井中有毒气体。如果鸟儿出现异常，工人会立即撤离。类似地，灰度发布通过小范围测试来“预警”潜在问题。</li></ol><p><strong>实施步骤</strong></p><ol><li><strong>选择目标群体</strong>：确定一小部分用户或服务器作为“金丝雀”，可以基于地理位置、用户ID、设备类型等条件。</li><li><strong>部署新版本</strong>：将新版本部署到选定群体，同时旧版本继续服务其他用户。</li><li><strong>监控表现</strong>：使用监控工具（如日志分析、性能指标、用户反馈）评估新版本的稳定性。</li><li><strong>逐步扩展</strong>：如果表现良好，逐步增加新版本的覆盖范围（如从1%到10%、50%直至100%）。</li><li><strong>回滚或全量发布</strong>：若发现问题，回滚到旧版本；若一切正常，完成全量发布。</li></ol><h3 id="10-2-创建-V1-版本的-Ingress"><a href="#10-2-创建-V1-版本的-Ingress" class="headerlink" title="10.2 创建  V1 版本的 Ingress"></a>10.2 创建  V1 版本的 Ingress</h3><p><strong>资源清单：</strong> <code>ingress-nginx-canary-release-v1.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">canary-deploy-v1</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">v1</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">10</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">v1</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">v1</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">deploy-v1</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">v1</span>  <span class="attr">name:</span> <span class="string">canary-svc-v1</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">v1</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">ingress-v1</span>  <span class="attr">annotations:</span>    <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">&quot;nginx&quot;</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">&quot;nginx&quot;</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">canary.release.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">canary-svc-v1</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-canary-release-v1.yaml</code></pre><p><strong>编辑Hosts文件</strong></p><pre><code class="highlight bash">$ <span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 canary.release.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>测试请求</strong></p><pre><code class="highlight bash">$ curl http://canary.release.comwww.xinxianghf.com | hello MyAPP | version v1.0</code></pre><h3 id="10-3-创建-V2-版本的-Ingress"><a href="#10-3-创建-V2-版本的-Ingress" class="headerlink" title="10.3 创建 V2 版本的 Ingress"></a>10.3 创建 V2 版本的 Ingress</h3><p><strong>资源清单：</strong><code>ingress-nginx-canary-release-v2.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">canary-deploy-v2</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">v2</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">10</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">v2</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">v2</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">deploy-v2</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v2.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">v2</span>  <span class="attr">name:</span> <span class="string">canary-svc-v2</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">v2</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">ingress-v2</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/canary:</span> <span class="string">&quot;true&quot;</span> <span class="comment"># 启用金丝雀发布模式</span>    <span class="attr">nginx.ingress.kubernetes.io/canary-weight:</span> <span class="string">&quot;10&quot;</span> <span class="comment"># 定义金丝雀服务的流量权重，单位为百分比</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">&quot;nginx&quot;</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">canary.release.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">canary-svc-v2</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-canary-release-v2.yaml</code></pre><p><strong>编辑Hosts文件</strong></p><pre><code class="highlight bash">$ <span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 canary.release.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>测试请求</strong></p><p>测试请求 100次， 查看请求汇总信息</p><pre><code class="highlight bash"><span class="comment"># 做100次请求</span>$ <span class="keyword">for</span> i <span class="keyword">in</span> &#123;1..100&#125;;<span class="keyword">do</span> curl http://canary.release.com  &gt;&gt; <span class="built_in">sum</span>;<span class="keyword">done</span><span class="comment"># 查看请求汇总信息</span>$ <span class="built_in">cat</span> <span class="built_in">sum</span> | <span class="built_in">sort</span> | <span class="built_in">uniq</span> -c     92 www.xinxianghf.com | hello MyAPP | version v1.0      8 www.xinxianghf.com | hello MyAPP | version v2.0</code></pre><p>结论：请求了100次，其中 92次请求到了 v1.0 版本， 8次请求到 v2.0版本。v2.0 大约占了 10%</p><h2 id="11-Ingress-nginx-代理后端-https-协议"><a href="#11-Ingress-nginx-代理后端-https-协议" class="headerlink" title="11. Ingress-nginx  代理后端 https 协议"></a>11. Ingress-nginx  代理后端 https 协议</h2><p>如果后端服务是 https 协议，需要使用 <code>nginx.ingress.kubernetes.io/backend-protocols</code> 声明后端服务是 <code>https</code> 。这里代理K8s的web控制台作为示例。代理后访问默认会强制跳转到 https 协议，返回的证书也是服务本身的证书。</p><p>资源清单：<code>ingress-nginx-proxy-https-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">name:</span> <span class="string">proxyhttps-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">proxyhttps</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">wangyanglinux/tools:httpsv1</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">name:</span> <span class="string">proxyhttps-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">443</span><span class="number">-443</span>      <span class="attr">port:</span> <span class="number">443</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">443</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-proxy-https-pod.yaml</code></pre><p><strong>访问Service</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 Service 资源</span>$ kubectl get svc -o wideNAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE     SELECTORproxyhttps-svc   ClusterIP   10.103.15.21   &lt;none&gt;        443/TCP   3m25s   app=proxyhttps<span class="comment"># 访问Service</span>$ curl -k https://10.103.15.21Hello, HTTPS!$ curl http://10.103.15.21:443Client sent an HTTP request to an HTTPS server.</code></pre><p>当前Service只能使用 HTTPS 访问</p><p><strong>只用 Ingress 代理后端 HTTPS 服务</strong></p><p>资源清单：<code>ingress-nginx-proxy-https-ingress.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/backend-protocol:</span> <span class="string">HTTPS</span>  <span class="attr">name:</span> <span class="string">ingress.https.com</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">ingress.https.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">ImplementationSpecific</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">proxyhttps-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">443</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-proxy-https-ingress.yaml</code></pre><p><strong>编辑Host文件</strong></p><pre><code class="highlight bash">$ <span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 ingress.https.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>请求测试</strong></p><pre><code class="highlight bash">$ curl http://ingress.https.comHello, HTTPS!</code></pre><p>结论：使用 Ingress 代理了后端HTTPS请求</p><h2 id="12-Ingress-nginx-四层代理"><a href="#12-Ingress-nginx-四层代理" class="headerlink" title="12. Ingress-nginx  四层代理"></a>12. Ingress-nginx  四层代理</h2><p>在新版本的nginx也引入了四层代理的概念，可直接代理TCP与UDP协议，在ingress-nginx也可以通过四层代理实现service的代理，实现方式如下：</p><p>官方文档：<a href="https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/">https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/</a></p><p>首先在使用 helm 部署 ingress-nginx 之后，需修改 nginx 启动资源的启动参数添加<code>--tcp-services-configmap</code>、<code>--udp-services-configmap</code> 的配置启用四层代理，通过修改配置 configmap 资源进行四层代理的配置。</p><h3 id="12-1TCP代理"><a href="#12-1TCP代理" class="headerlink" title="12.1TCP代理"></a>12.1TCP代理</h3><p><strong>修改 ingress-nginx 控制器</strong></p><p>在 ingress-nginx-controller 中添加 <code>--tcp-services-configmap</code> 启动参数</p><pre><code class="highlight bash">$ kubectl  edit ds -n ingress-nginx ingress-nginx-controller    spec:      containers:      - args:        - /nginx-ingress-controller        - --tcp-services-configmap=$(POD_NAMESPACE)/nginx-ingress-tcp-configmap        <span class="comment">#参数说明如下</span>--tcp-services-configmap=$(POD_NAMESPACE)/  这里为固定，表示tcp配置选择ingress-nginx安装的命名空间的configmap资源nginx-ingress-tcp-configmap  为configmap资源的名称</code></pre><p><strong>编辑 ConfigMap</strong></p><p><code>nginx-ingress-tcp-configmap.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-ingress-tcp-configmap</span>  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span> <span class="comment"># ingress-nginx 所在的命名空间</span><span class="attr">data:</span>  <span class="attr">&quot;9000&quot;:</span> <span class="string">&quot;default/proxyhttps-svc:443&quot;</span></code></pre><pre><code class="highlight bash">$ kubectl apply -f nginx-ingress-tcp-configmap.yaml</code></pre><p><strong>Pod资源清单</strong></p><p><code>ingress-nginx-tcp-proxy-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">name:</span> <span class="string">proxyhttps-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">proxyhttps</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">wangyanglinux/tools:httpsv1</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">name:</span> <span class="string">proxyhttps-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">443</span><span class="number">-443</span>      <span class="attr">port:</span> <span class="number">443</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">443</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-tcp-proxy-pod.yaml</code></pre><p><strong>测试四层代理访问</strong></p><pre><code class="highlight bash">$ kubectl get svc -o wideNAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE    SELECTORproxyhttps-svc   ClusterIP   10.96.172.123   &lt;none&gt;        443/TCP   63s    app=proxyhttps<span class="comment"># 首先直接访问 SVC，确认服务可用</span>$ curl -k https://10.96.172.123:443Hello, HTTPS!<span class="comment"># 测试通过ingress 4层代理访问</span>$ curl -k https://10.20.1.140:9000Hello, HTTPS!</code></pre><h3 id="12-2-UDP代理"><a href="#12-2-UDP代理" class="headerlink" title="12.2 UDP代理"></a>12.2 UDP代理</h3><p><strong>修改 ingress-nginx 控制器</strong></p><p>在 ingress-nginx-controller 中添加 <code>--tcp-services-configmap</code> 启动参数</p><pre><code class="highlight bash">$ kubectl  edit ds -n ingress-nginx ingress-nginx-controller    spec:      containers:      - args:        - /nginx-ingress-controller        - --udp-services-configmap=$(POD_NAMESPACE)/nginx-ingress-udp-configmap        <span class="comment">#参数说明如下</span>--tcp-services-configmap=$(POD_NAMESPACE)/  这里为固定，表示tcp配置选择ingress-nginx安装的命名空间的configmap资源nginx-ingress-tcp-configmap  为configmap资源的名称</code></pre><p><strong>编辑 ConfigMap</strong></p><p><code>nginx-ingress-udp-configmap.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-ingress-udp-configmap</span>  <span class="attr">namespace:</span> <span class="string">ingress</span><span class="attr">data:</span>  <span class="attr">&quot;53&quot;:</span> <span class="string">&quot;kube-system/kube-dns:53&quot;</span></code></pre><h2 id="13-Ingress-nginx-链路追踪"><a href="#13-Ingress-nginx-链路追踪" class="headerlink" title="13. Ingress-nginx  链路追踪"></a>13. Ingress-nginx  链路追踪</h2><p>官方文档：<a href="https://kubernetes.github.io/ingress-nginx/user-guide/third-party-addons/opentracing/#jaeger">https://kubernetes.github.io/ingress-nginx/user-guide/third-party-addons/opentracing/#jaeger</a></p><p>官方推荐的链路追踪插件为 Zipkin 或者 Jaeger。这里我们选用 Jaeger。</p><p>官方部署示例文件: <a href="https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/all-in-one/jaeger-all-in-one-template.yml">https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/all-in-one/jaeger-all-in-one-template.yml</a></p><h3 id="13-1-部署-Jaeger"><a href="#13-1-部署-Jaeger" class="headerlink" title="13.1 部署 Jaeger"></a>13.1 部署 Jaeger</h3><pre><code class="highlight bash"><span class="comment"># 下载部署资源清单</span>wget https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/all-in-one/jaeger-all-in-one-template.yml</code></pre><p>修改 jaeger 资源清单</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">List</span><span class="attr">items:</span><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># 将版本修改为 apps/v1</span>  <span class="attr">kind:</span> <span class="string">Deployment</span>  <span class="attr">metadata:</span>    <span class="attr">name:</span> <span class="string">jaeger</span>    <span class="attr">labels:</span>      <span class="attr">app:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span>  <span class="attr">spec:</span>    <span class="attr">replicas:</span> <span class="number">1</span>    <span class="attr">selector:</span> <span class="comment"># 添加选择器， apps/v1版本需要</span>      <span class="attr">matchLabels:</span>        <span class="attr">app:</span> <span class="string">jaeger</span>    <span class="attr">strategy:</span>      <span class="attr">type:</span> <span class="string">Recreate</span>    <span class="attr">template:</span>      <span class="attr">metadata:</span>        <span class="attr">labels:</span>          <span class="attr">app:</span> <span class="string">jaeger</span>          <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>          <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span>        <span class="attr">annotations:</span>          <span class="attr">prometheus.io/scrape:</span> <span class="string">&quot;true&quot;</span>          <span class="attr">prometheus.io/port:</span> <span class="string">&quot;16686&quot;</span>      <span class="attr">spec:</span>          <span class="attr">containers:</span>          <span class="bullet">-</span>   <span class="attr">env:</span>              <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">COLLECTOR_ZIPKIN_HTTP_PORT</span>                <span class="attr">value:</span> <span class="string">&quot;9411&quot;</span>              <span class="attr">image:</span> <span class="string">jaegertracing/all-in-one</span>              <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 修改镜像下载策略，提前将镜像下载好</span>              <span class="attr">name:</span> <span class="string">jaeger</span>              <span class="attr">ports:</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">5775</span>                  <span class="attr">protocol:</span> <span class="string">UDP</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">6831</span>                  <span class="attr">protocol:</span> <span class="string">UDP</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">6832</span>                  <span class="attr">protocol:</span> <span class="string">UDP</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">5778</span>                  <span class="attr">protocol:</span> <span class="string">TCP</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">16686</span>                  <span class="attr">protocol:</span> <span class="string">TCP</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9411</span>                  <span class="attr">protocol:</span> <span class="string">TCP</span>              <span class="attr">readinessProbe:</span>                <span class="attr">httpGet:</span>                  <span class="attr">path:</span> <span class="string">&quot;/&quot;</span>                  <span class="attr">port:</span> <span class="number">14269</span>                <span class="attr">initialDelaySeconds:</span> <span class="number">5</span><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">v1</span>  <span class="attr">kind:</span> <span class="string">Service</span>  <span class="attr">metadata:</span>    <span class="attr">name:</span> <span class="string">jaeger-query</span>    <span class="attr">labels:</span>      <span class="attr">app:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">query</span>  <span class="attr">spec:</span>    <span class="attr">ports:</span>      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">query-http</span>        <span class="attr">port:</span> <span class="number">80</span>        <span class="attr">protocol:</span> <span class="string">TCP</span>        <span class="attr">targetPort:</span> <span class="number">16686</span>    <span class="attr">selector:</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span>    <span class="attr">type:</span> <span class="string">LoadBalancer</span><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">v1</span>  <span class="attr">kind:</span> <span class="string">Service</span>  <span class="attr">metadata:</span>    <span class="attr">name:</span> <span class="string">jaeger-collector</span>    <span class="attr">labels:</span>      <span class="attr">app:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">collector</span>  <span class="attr">spec:</span>    <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jaeger-collector-tchannel</span>      <span class="attr">port:</span> <span class="number">14267</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">14267</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jaeger-collector-http</span>      <span class="attr">port:</span> <span class="number">14268</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">14268</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jaeger-collector-zipkin</span>      <span class="attr">port:</span> <span class="number">9411</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">9411</span>    <span class="attr">selector:</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span>    <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">v1</span>  <span class="attr">kind:</span> <span class="string">Service</span>  <span class="attr">metadata:</span>    <span class="attr">name:</span> <span class="string">jaeger-agent</span>    <span class="attr">labels:</span>      <span class="attr">app:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">agent</span>  <span class="attr">spec:</span>    <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">agent-zipkin-thrift</span>      <span class="attr">port:</span> <span class="number">5775</span>      <span class="attr">protocol:</span> <span class="string">UDP</span>      <span class="attr">targetPort:</span> <span class="number">5775</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">agent-compact</span>      <span class="attr">port:</span> <span class="number">6831</span>      <span class="attr">protocol:</span> <span class="string">UDP</span>      <span class="attr">targetPort:</span> <span class="number">6831</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">agent-binary</span>      <span class="attr">port:</span> <span class="number">6832</span>      <span class="attr">protocol:</span> <span class="string">UDP</span>      <span class="attr">targetPort:</span> <span class="number">6832</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">agent-configs</span>      <span class="attr">port:</span> <span class="number">5778</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">5778</span>    <span class="attr">clusterIP:</span> <span class="string">None</span>    <span class="attr">selector:</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">v1</span>  <span class="attr">kind:</span> <span class="string">Service</span>  <span class="attr">metadata:</span>    <span class="attr">name:</span> <span class="string">zipkin</span>    <span class="attr">labels:</span>      <span class="attr">app:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">zipkin</span>  <span class="attr">spec:</span>    <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jaeger-collector-zipkin</span>      <span class="attr">port:</span> <span class="number">9411</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">9411</span>    <span class="attr">clusterIP:</span> <span class="string">None</span>    <span class="attr">selector:</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span></code></pre><blockquote><p>可以将所有的 SVC、Deployment 都放到单独的命名空间中，这样就不会被误删除</p></blockquote><p><strong>执行 Jaeger 资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f jaeger-all-in-one-template.yml <span class="comment"># 查看 SVC, !!! 注意：浏览器访问 jaeger 是通过 jaeger-query， 这里的 31272 就是对外暴露的端口</span>$ kubectl get svcNAME               TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                               AGEjaeger-agent       ClusterIP      None            &lt;none&gt;        5775/UDP,6831/UDP,6832/UDP,5778/TCP   12mjaeger-collector   ClusterIP      10.99.111.240   &lt;none&gt;        14267/TCP,14268/TCP,9411/TCP          12mjaeger-query       LoadBalancer   10.100.53.251   &lt;pending&gt;     80:31272/TCP                          12mkubernetes         ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP                               4d5hzipkin             ClusterIP      None            &lt;none&gt;        9411/TCP                              12m<span class="comment"># 查看 Deployment</span>$ kubectl get deployNAME     READY   UP-TO-DATE   AVAILABLE   AGEjaeger   1/1     1            1           20s<span class="comment"># 查看 Pod</span>$ kubectl get podNAME                     READY   STATUS    RESTARTS   AGEjaeger-cbfbf99b4-cxgq6   1/1     Running   0          22s</code></pre><p>到此 Jaeger 就部署好了</p><p><strong>注意：浏览器访问 jaeger 是通过 jaeger-query， 这里的 31272 就是对外暴露的端口，可以通过：http:&#x2F;&#x2F;物理机ip:31035 访问 Jaeger</strong></p><h3 id="13-2-ingress-设置"><a href="#13-2-ingress-设置" class="headerlink" title="13.2 ingress 设置"></a>13.2 ingress 设置</h3><p>需要修改 ingress 的 configmap 文件，添加相应参数，开启 Ingress 链路追踪</p><pre><code class="highlight bash">$ kubectl edit cm -n ingress-nginx ingress-nginx-controllerapiVersion: v1data:  allow-snippet-annotations: <span class="string">&quot;true&quot;</span>  enable-opentracing: <span class="string">&quot;true&quot;</span>   <span class="comment">#开启链路追踪</span>  jaeger-collector-host: jaeger-agent.default.svc.cluster.local  <span class="comment">#链路追踪的svc名称</span></code></pre><p><strong>重建 Ingress-Nginx Pod</strong></p><pre><code class="highlight bash"><span class="comment"># 查看Pod</span>$ kubectl get pods -n ingress-nginxNAME                             READY   STATUS    RESTARTS   AGEingress-nginx-controller-25wk6   1/1     Running   0          150mingress-nginx-controller-qcbp2   1/1     Running   0          151m<span class="comment"># 删除Pod，等待重建</span>$ kubectl delete pod ingress-nginx-controller-25wk6 ingress-nginx-controller-qcbp2 -n ingress-nginx</code></pre><p><strong>浏览器访问Jaeger</strong></p><p><a href="http://10.20.1.139:31272/">http://10.20.1.139:31272/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/06/20250706-165831.png" alt="浏览器访问Jaeger"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/06/20250706-170040.png" alt="查看请求"></p><p>参考链接</p><blockquote><p><a href="https://zhangzhuo.ltd/articles/2022/03/20/1647773666928.html">https://zhangzhuo.ltd/articles/2022/03/20/1647773666928.html</a></p><p><a href="https://www.cnblogs.com/tencent-cloud-native/p/13865502.html">https://www.cnblogs.com/tencent-cloud-native/p/13865502.html</a></p><p><a href="https://k8s.whuanle.cn/4.network/3.ingress.html">https://k8s.whuanle.cn/4.network/3.ingress.html</a></p><p><a href="https://www.cnblogs.com/linyb-geek/p/18153533">https://www.cnblogs.com/linyb-geek/p/18153533</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;K8S集群服务器&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;Hostname&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;10.20.1.139&lt;/td&gt;
&lt;td&gt;k8s-</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>010-Kubernetes Helm</title>
    <link href="https://georgechan95.github.io/blog/d8e3c7b3.html"/>
    <id>https://georgechan95.github.io/blog/d8e3c7b3.html</id>
    <published>2025-06-21T06:12:00.000Z</published>
    <updated>2025-06-25T05:29:37.300Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h1><p>没有使用 Helm 之前，在 Kubernetes 部署应用，我们要依次部署 deployment、service 等，步骤比较繁琐。况且随着很多项目微服务化，复杂的应用在容器中部署以及管理显得较为复杂。</p><p>helm 通过打包的方式，支持发布的版本管理和控制，很大程度上简化了 Kubernetes 应用的部署和管理。Helm 本质就是让 k8s 的应用管理（Deployment、Service等）可配置，能动态生成。通过动态生成K8S资源清单文件（deployment.yaml、service.yaml）。然后 kubectl 自动调用 K8S 资源部署。</p><p>官网：<a href="https://helm.sh/">Helm</a> </p><p>Helm 具备如下的能力：</p><ul><li><strong>简化部署</strong> ：Helm允许使用单个命令轻松部署和管理应用程序，从而简化了整个部署过程；</li><li><strong>高度可配置</strong>：Helm Charts提供了高度可配置的选项，可以轻松自定义和修改应用程序的部署配置；</li><li><strong>版本控制</strong> ：Helm允许管理应用程序的多个版本，从而轻松实现版本控制和回滚；</li><li><strong>模板化</strong>：Helm Charts使用YAML模板来定义Kubernetes对象的配置，从而简化了配置过程，并提高了可重复性和可扩展性；</li><li><strong>应用程序库</strong>：Helm具有应用程序库的概念，可以轻松地共享和重用Helm Charts，从而简化了多个应用程序的部署和管理；</li><li><strong>插件系统</strong>：Helm拥有一个强大的插件系统，允许您扩展和定制Helm的功能，以满足特定的需求和要求。</li></ul><h1 id="二、Helm-V2-与-V3-的区别"><a href="#二、Helm-V2-与-V3-的区别" class="headerlink" title="二、Helm V2 与 V3 的区别"></a>二、Helm V2 与 V3 的区别</h1><p>Helm v2 是 C&#x2F;S 架构，主要分为客户端 helm 和服务器端 tiller。而由于 RBAC 等权限控制体系的逐渐完善，多租户和安全的需求日益兴起，tiller 变得越来越不安全，社区在权限控制领域遇到了极大的阻碍。所以在 Helm3 版本中，直接将 tiller 这一核心组件移除，helm 直接和 kubernetes API 进行通信。直接带来的好处如下：</p><ul><li>Helm 的架构变的更为简单和灵活</li><li>不再需要创建 ServiceAccount，直接使用当前环境中的 kubeconfig 配置</li><li>可以直接和 kubernetes API 交互，更为安全</li><li>不再需要使用 helm init 来进行初始化</li></ul><h1 id="三、Helm工作流程"><a href="#三、Helm工作流程" class="headerlink" title="三、Helm工作流程"></a>三、Helm工作流程</h1><p>以下是Helm的工作流程（<strong>注意：这里使用的是Helm的v3版本，该版本没有了<code>tiller</code>并并使用更加简单和灵活的架构，直接通过 <code>kubeconfig</code> 连接 <code>apiserver</code> ，简化安全模块，降低了用户的使用壁垒</strong>）：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/21/20250621-143827" alt="Helm工作流程"></p><p><strong>如上图所示，Helm的工作流程总结如下：</strong></p><ol><li>开发者首先创建并编辑 chart 的配置；</li><li>接着打包并发布至 Helm 的仓库（Repository）；</li><li>当管理员使用 helm 命令安装时，相关的依赖会从仓库下载；</li><li>接着helm 会根据下载的配置部署资源至 k8s ；</li></ol><h1 id="四、Helm概念"><a href="#四、Helm概念" class="headerlink" title="四、Helm概念"></a>四、Helm概念</h1><p><strong>在使用Helm的过程中，需要理解如下的几个核心的概念：</strong></p><table><thead><tr><th>概念</th><th>描述</th></tr></thead><tbody><tr><td><strong>Chart</strong></td><td>一个 Helm 包，其中包含了运行一个应用所需要的镜像、依赖和资源定义等，还可能包含 Kubernetes 集群中的服务定义，类似 Homebrew 中的 formula、APT 的 dpkg 或者 Yum 的 rpm 文件</td></tr><tr><td><strong>Repository</strong></td><td>存储 Helm Charts 的地方</td></tr><tr><td><strong>Release</strong></td><td>Chart 在 k8s上运行的 Chart 的一个实例，例如，如果一个 MySQL Chart 想在服务器上运行两个数据库，可以将这个 Chart 安装两次，并在每次安装中生成自己的 Release 以及 Release 名称。</td></tr><tr><td><strong>Value</strong></td><td>Helm Chart 的参数，用于配置 Kubernetes 对象</td></tr><tr><td><strong>Template</strong></td><td>使用 Go 模板语言生成 Kubernetes 对象的定义文件</td></tr><tr><td><strong>Namespace</strong></td><td>Kubernetes 中用于隔离资源的逻辑分区</td></tr></tbody></table><h1 id="五、Helm的使用"><a href="#五、Helm的使用" class="headerlink" title="五、Helm的使用"></a>五、Helm的使用</h1><h2 id="1-安装Helm"><a href="#1-安装Helm" class="headerlink" title="1. 安装Helm"></a>1. 安装Helm</h2><p>参考官方文档：<a href="https://helm.sh/zh/docs/intro/install/">安装Helm</a></p><h3 id="1-1-用二进制版本安装"><a href="#1-1-用二进制版本安装" class="headerlink" title="1.1 用二进制版本安装"></a>1.1 用二进制版本安装</h3><p><strong>下载二进制安装包</strong></p><p>下载地址：<a href="https://github.com/helm/helm/releases">https://github.com/helm/helm/releases</a></p><p><strong>解压二进制包</strong></p><pre><code class="highlight bash">$ tar -zxvf helm-v3.12.3-linux-amd64.tar.gz</code></pre><p><strong>将二进制文件移动到对应的目录中</strong></p><pre><code class="highlight bash">$ <span class="built_in">mv</span> linux-amd64/helm /usr/local/bin/helm</code></pre><p><strong>测试</strong></p><pre><code class="highlight bash"><span class="comment"># 查看Helm版本</span>$ helm versionversion.BuildInfo&#123;Version:<span class="string">&quot;v3.12.3&quot;</span>, GitCommit:<span class="string">&quot;3a31588ad33fe3b89af5a2a54ee1d25bfe6eaa5e&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, GoVersion:<span class="string">&quot;go1.20.7&quot;</span>&#125;</code></pre><h3 id="1-2-使用脚本安装"><a href="#1-2-使用脚本安装" class="headerlink" title="1.2 使用脚本安装"></a>1.2 使用脚本安装</h3><p>Helm现在有个安装脚本可以自动拉取最新的Helm版本并在 <a href="https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3">本地安装</a>。</p><pre><code class="highlight bash"><span class="comment"># 在线安装脚本</span>$ curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3<span class="comment"># 给脚本授权</span>$ <span class="built_in">chmod</span> 700 get_helm.sh<span class="comment"># 执行脚本</span>$ ./get_helm.sh</code></pre><h2 id="2-Helm-初始化"><a href="#2-Helm-初始化" class="headerlink" title="2. Helm 初始化"></a>2. Helm 初始化</h2><p>当您已经安装好了Helm之后，您可以添加一个 chart 仓库。从  <a href="https://artifacthub.io/packages/search?kind=0">Artifact Hub </a>中查找有效的 Helm chart 仓库</p><pre><code class="highlight bash">$ helm repo add bitnami https://charts.bitnami.com/bitnami<span class="string">&quot;bitnami&quot;</span> has been added to your repositories</code></pre><p>当添加完成，您将可以看到可以被您安装的 charts 列表：</p><pre><code class="highlight bash">$ helm search repo bitnamiNAME                                        CHART VERSIONAPP VERSION  DESCRIPTION                                       bitnami/airflow                             24.1.4       3.0.2        Apache Airflow is a tool to express and execute...bitnami/apache                              11.3.16      2.4.63       Apache HTTP Server is an open-source HTTP serve...bitnami/apisix                              5.0.3        3.12.0       Apache APISIX is high-performance, real-time AP...bitnami/appsmith                            6.0.11       1.77.0       Appsmith is an open <span class="built_in">source</span> platform <span class="keyword">for</span> buildin...bitnami/argo-cd                             9.0.22       3.0.9        Argo CD is a continuous delivery tool <span class="keyword">for</span> Kuber...</code></pre><h2 id="3-Helm-仓库管理"><a href="#3-Helm-仓库管理" class="headerlink" title="3. Helm 仓库管理"></a>3. Helm 仓库管理</h2><h3 id="3-1-添加仓库"><a href="#3-1-添加仓库" class="headerlink" title="3.1 添加仓库"></a>3.1 添加仓库</h3><pre><code class="highlight bash"><span class="comment"># 添加 bitnami 仓库</span>$ helm repo add bitnami https://charts.bitnami.com/bitnami<span class="comment"># 添加阿里云仓库</span>$ helm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts<span class="comment"># 添加微软仓库</span>$ helm repo add ms http://mirror.azure.cn/kubernetes/charts/</code></pre><h3 id="3-2-查看仓库"><a href="#3-2-查看仓库" class="headerlink" title="3.2 查看仓库"></a>3.2 查看仓库</h3><pre><code class="highlight bash">$ helm repo listNAME   URL                                                   bitnamihttps://charts.bitnami.com/bitnami                    aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/chartsms     http://mirror.azure.cn/kubernetes/charts/</code></pre><h3 id="3-3-更新仓库索引"><a href="#3-3-更新仓库索引" class="headerlink" title="3.3 更新仓库索引"></a>3.3 更新仓库索引</h3><pre><code class="highlight bash">$ helm repo update</code></pre><h3 id="3-4-删除仓库"><a href="#3-4-删除仓库" class="headerlink" title="3.4 删除仓库"></a>3.4 删除仓库</h3><pre><code class="highlight bash">$ helm repo remove [仓库名称]</code></pre><h3 id="3-5-在仓库中搜索-Chart-应用"><a href="#3-5-在仓库中搜索-Chart-应用" class="headerlink" title="3.5 在仓库中搜索 Chart 应用"></a>3.5 在仓库中搜索 Chart 应用</h3><pre><code class="highlight bash"><span class="comment"># 只在 ms 仓库搜索应用</span>$ helm search repo ms/redis<span class="comment"># 在添加的所有仓库搜索应用</span>$ helm search repo redis</code></pre><h3 id="3-6-查看指定仓库中Chart的版本"><a href="#3-6-查看指定仓库中Chart的版本" class="headerlink" title="3.6  查看指定仓库中Chart的版本"></a>3.6  查看指定仓库中Chart的版本</h3><pre><code class="highlight bash">helm search repo [chart名称] --versions$ helm search repo ms/redis --versionsNAME       CHART VERSIONAPP VERSION    DESCRIPTION                                       ms/redis   10.5.7       5.0.7          DEPRECATED Open <span class="built_in">source</span>, advanced key-value stor...ms/redis   9.5.4        5.0.6          Open <span class="built_in">source</span>, advanced key-value store. It is of...ms/redis   9.5.3        5.0.6          Open <span class="built_in">source</span>, advanced key-value store. It is of...ms/redis   9.5.2        5.0.5          Open <span class="built_in">source</span>, advanced key-value store. It is of...</code></pre><h3 id="3-7-拉取远程仓库的-Chart"><a href="#3-7-拉取远程仓库的-Chart" class="headerlink" title="3.7 拉取远程仓库的 Chart"></a>3.7 拉取远程仓库的 Chart</h3><pre><code class="highlight bash"><span class="comment"># 语法，--version对应的是chart version，--untar自动解压，</span><span class="comment"># --destination：指定下载的 Chart 文件（.tgz）保存的目标目录（默认当前目录）。</span><span class="comment"># --repo [仓库URL]直接从指定 URL 下载 Chart，而不使用已添加的仓库名称。</span>helm pull [chart名出] --version [版本号] --untar --destination [/path] --repo [仓库URL] <span class="comment"># 示例</span>$ helm pull ms/redis --version 10.5.7$ ll-rw-r--r-- 1 root root      31909 Jun 22 15:52 redis-10.5.7.tgz</code></pre><h2 id="4-安装-chart-示例"><a href="#4-安装-chart-示例" class="headerlink" title="4. 安装 chart 示例"></a>4. 安装 chart 示例</h2><h3 id="4-1-在线安装"><a href="#4-1-在线安装" class="headerlink" title="4.1 在线安装"></a>4.1 在线安装</h3><pre><code class="highlight bash"><span class="comment"># 更新 charts 列表</span>$ helm repo updateHang tight <span class="keyword">while</span> we grab the latest from your chart repositories......Successfully got an update from the <span class="string">&quot;bitnami&quot;</span> chart repositoryUpdate Complete. ⎈Happy Helming!⎈<span class="comment"># 显示 Bitnami 提供的 Apache Helm chart 的默认配置文件（values.yaml）内容</span>$ helm show values bitnami/apache<span class="comment"># 在 Kubernetes 集群中安装 Bitnami 提供的 Apache Helm chart，并自动生成一个唯一的 release 名称</span>$ helm install bitnami/apache --generate-name</code></pre><p>上面的操作用的 chart 源是 bitnami , 而 bitnami 服务器在国外，国内无法访问，我尝试服务器翻墙，依然报错，错误信息如下：</p><pre><code class="highlight bash">$ helm install my-apache bitnami/apache --version 11.3.16Error: INSTALLATION FAILED: failed to <span class="keyword">do</span> request: Head <span class="string">&quot;https://registry-1.docker.io/v2/bitnamicharts/apache/manifests/11.3.16&quot;</span>: dial tcp: lookup registry-1.docker.io: i/o <span class="built_in">timeout</span></code></pre><h3 id="4-2-离线安装"><a href="#4-2-离线安装" class="headerlink" title="4.2 离线安装"></a>4.2 离线安装</h3><pre><code class="highlight bash"><span class="comment"># 下载chart安装包</span>wget https://charts.bitnami.com/bitnami/apache-11.3.16.tgz<span class="comment"># 解压</span>tar -zxvf apache-11.3.16.tgz <span class="comment"># 进入解压后的chart目录</span><span class="built_in">cd</span> apache<span class="comment"># 安装Chart，运行生成一个Release</span><span class="comment"># 方式一：使用解压后的chart安装， . 表示当前解压的目录</span>$ helm install my-apache .<span class="comment"># 方式二：直接使用下载的 chart 压缩包安装</span>helm install my-apache apache-11.3.16.tgz<span class="comment"># 查看Release实例</span>$ helm list -n defaultNAME     NAMESPACEREVISIONUPDATED                                STATUS  CHART         APP VERSIONmy-apachedefault  1       2025-06-22 14:05:26.557276416 +0800 CSTdeployedapache-11.3.162.4.63</code></pre><p>查看运行的Pod</p><pre><code class="highlight bash"><span class="comment"># 查看运行的Service</span>$ kubectl get svc -o wideNAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE    SELECTORkubernetes   ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP                      54d    &lt;none&gt;my-apache    LoadBalancer   10.108.203.41   &lt;pending&gt;     80:31349/TCP,443:32630/TCP   105s   app.kubernetes.io/instance=my-apache,app.kubernetes.io/name=apache<span class="comment"># 查看Deployment</span>$ kubectl get deployment -o wideNAME        READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS   IMAGES                                          SELECTORmy-apache   0/1     1            0           112s   apache       docker.io/bitnami/apache:2.4.63-debian-12-r16   app.kubernetes.io/instance=my-apache,app.kubernetes.io/name=apache<span class="comment"># 查看Pod</span>$ kubectl get pods -o wideNAME                         READY   STATUS              RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATESmy-apache-74b6d9f88b-lknsr   0/1     Init:ErrImagePull   0          114s   172.16.58.254   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>Pod未能运行成功，查找原因</p><pre><code class="highlight bash">$ kubectl describe pod my-apache-74b6d9f88b-lknsrName:             my-apache-74b6d9f88b-lknsrNamespace:        defaultPriority:         0Service Account:  my-apacheNode:             k8s-node02/192.168.6.141............Events:  Type     Reason     Age                    From               Message  ----     ------     ----                   ----               -------  Normal   Scheduled  6m39s                  default-scheduler  Successfully assigned default/my-apache-74b6d9f88b-lknsr to k8s-node02  Warning  Failed     5m51s (x2 over 6m21s)  kubelet            Failed to pull image <span class="string">&quot;docker.io/bitnami/apache:2.4.63-debian-12-r16&quot;</span>: Error response from daemon: Get <span class="string">&quot;https://registry-1.docker.io/v2/&quot;</span>: net/http: request canceled <span class="keyword">while</span> waiting <span class="keyword">for</span> connection (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)  Warning  Failed     5m10s                  kubelet            Failed to pull image <span class="string">&quot;docker.io/bitnami/apache:2.4.63-debian-12-r16&quot;</span>: Error response from daemon: Get <span class="string">&quot;https://registry-1.docker.io/v2/&quot;</span>: context deadline exceeded  Normal   Pulling    4m17s (x4 over 6m36s)  kubelet            Pulling image <span class="string">&quot;docker.io/bitnami/apache:2.4.63-debian-12-r16&quot;</span>  Warning  Failed     4m1s (x4 over 6m21s)   kubelet            Error: ErrImagePull  Warning  Failed     4m1s                   kubelet            Failed to pull image <span class="string">&quot;docker.io/bitnami/apache:2.4.63-debian-12-r16&quot;</span>: Error response from daemon: Get <span class="string">&quot;https://registry-1.docker.io/v2/&quot;</span>: context deadline exceeded (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)  Warning  Failed     3m46s (x6 over 6m20s)  kubelet            Error: ImagePullBackOff  Normal   BackOff    91s (x14 over 6m20s)   kubelet            Back-off pulling image <span class="string">&quot;docker.io/bitnami/apache:2.4.63-debian-12-r16&quot;</span></code></pre><p><strong>原因：镜像  docker.io&#x2F;bitnami&#x2F;apache:2.4.63-debian-12-r16 拉取失败，可以通过修改 chart 解压路径中的 value.yaml 文件，将镜像替换成国内的镜像即可。</strong></p><p>也可以添加国内的阿里云 chart 仓库，地址：<a href="https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts">https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</a> （chart包没有官网那么全），</p><p>还有<strong>微软的chart 仓库地址</strong>：<a href="http://mirror.azure.cn/kubernetes/charts/">http://mirror.azure.cn/kubernetes/charts/</a> （官网有的，它大多都有, <strong>推荐使用</strong>）</p><pre><code class="highlight bash">$ helm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts$ helm repo add ms http://mirror.azure.cn/kubernetes/charts/$ helm repo update$ helm search repo ms<span class="comment"># 显示 微软 提供的 Apache Helm chart 的默认配置文件（values.yaml）内容</span>$ helm show values ms/redis<span class="comment"># 在 Kubernetes 集群中安装 Bitnami 提供的 Apache Helm chart，并自动生成一个唯一的 release 名称</span>$ helm install ms/redis --generate-name</code></pre><h3 id="4-3-Chart-安装资源顺序"><a href="#4-3-Chart-安装资源顺序" class="headerlink" title="4.3 Chart 安装资源顺序"></a>4.3 Chart 安装资源顺序</h3><pre><code class="highlight plaintext">Namespace&gt;NetworkPolicy&gt;ResourceQuota&gt;LimitRange&gt;PodSecurityPolicy&gt;PodDisruptionBudget&gt;ServiceAccount&gt;Secret&gt;SecretList&gt;ConfigMap&gt;StorageClassPersistentVolume&gt;PersistentVolumeClaim&gt;CustomResourceDefinition&gt;ClusterRoleClusterRoleList&gt;ClusterRoleBinding&gt;ClusterRoleBindingList&gt;Role&gt;RoleListRoleBinding&gt;RoleBindingList&gt;Service&gt;DaemonSet&gt;Pod&gt;ReplicationController&gt;ReplicaSet&gt;Deployment&gt;HorizontalPodAutoscaler&gt;StatefulSet&gt;Job&gt;CronJob&gt;Ingress&gt;APIService</code></pre><!--Helm 客户端不会等到所有资源都运行才退出。许多 charts 需要大小超过 600M 的 Docker 镜像，可能需要很长时间才能安装到集群中。--><h3 id="4-4-安装过程中有两种方式传递配置数据"><a href="#4-4-安装过程中有两种方式传递配置数据" class="headerlink" title="4.4 安装过程中有两种方式传递配置数据"></a>4.4 安装过程中有两种方式传递配置数据</h3><ul><li><code>--values</code> (或 <code>-f</code>)：使用 YAML 文件覆盖配置。可以指定多次，优先使用最右边的文件</li><li><code>--set</code>：通过命令行的方式对指定项进行覆盖</li></ul><p>如果同时使用两种方式，则 <code>--set</code> 中的值会被合并到 <code>--values</code> 中，但是 <code>--set</code> 中的值优先级更高。在<code>--set</code> 中覆盖的内容会被被保存在 ConfigMap 中。可以通过 <code>helm get values &lt;release-name&gt;</code> 来查看指定 release 中 <code>--set</code> 设置的值。也可以通过运行 <code>helm upgrade</code> 并指定 <code>--reset-values</code> 字段来清除 <code>--set</code> 中设置的值</p><h4 id="4-4-1-set-的格式和限制"><a href="#4-4-1-set-的格式和限制" class="headerlink" title="4.4.1 --set 的格式和限制"></a>4.4.1 <code>--set</code> 的格式和限制</h4><p><code>--set</code> 选项使用0或多个 name&#x2F;value 对。最简单的用法类似于： <code>--set name=value</code> ，等价于如下 YAML 格式：</p><pre><code class="highlight yaml"><span class="attr">name:</span> <span class="string">value</span></code></pre><p>多个值使用逗号分割，因此 <code>--set a=b,c=d</code> 的 YAML 表示是：</p><pre><code class="highlight yaml"><span class="attr">a:</span> <span class="string">b</span><span class="attr">c:</span> <span class="string">d</span></code></pre><p>支持更复杂的表达式。例如，<code>--set outer.inner=value</code> 被转换成了：</p><pre><code class="highlight yaml"><span class="attr">outer:</span>  <span class="attr">inner:</span> <span class="string">value</span></code></pre><p>列表使用花括号（<code>&#123;&#125;</code>）来表示。例如，<code>--set name=&#123;a, b, c&#125;</code> 被转换成了：</p><pre><code class="highlight yaml"><span class="attr">name:</span>  <span class="bullet">-</span> <span class="string">a</span>  <span class="bullet">-</span> <span class="string">b</span>  <span class="bullet">-</span> <span class="string">c</span></code></pre><p>某些 name&#x2F;key 可以设置为 <code>null</code> 或者空数组，例如  <code>--set name=[],a=null</code>  </p><pre><code class="highlight yaml"><span class="attr">name:</span> []<span class="attr">a:</span> <span class="literal">null</span></code></pre><p>从 2.5.0 版本开始，可以使用数组下标的语法来访问列表中的元素。例如 <code>--set servers[0].port=80</code> 就变成了：</p><pre><code class="highlight yaml"><span class="attr">servers:</span>  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></code></pre><p>多个值也可以通过这种方式来设置。<code>--set servers[0].port=80,servers[0].host=example</code> 变成了：</p><pre><code class="highlight yaml"><span class="attr">servers:</span>  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>    <span class="attr">host:</span> <span class="string">example</span></code></pre><p>如果需要在 <code>--set</code> 中使用特殊字符，你可以使用反斜线来进行转义；<code>--set name=value1\,value2</code> 就变成了：</p><pre><code class="highlight yaml"><span class="attr">name:</span> <span class="string">&quot;value1,value2&quot;</span></code></pre><p>–set nodeSelector.”kubernetes.io&#x2F;role”&#x3D;master</p><pre><code class="highlight yaml"><span class="attr">nodeSelector:</span>  <span class="attr">kubernetes.io/role:</span> <span class="string">master</span></code></pre><h3 id="4-5-安装、升级、回滚时的有用选项"><a href="#4-5-安装、升级、回滚时的有用选项" class="headerlink" title="4.5 安装、升级、回滚时的有用选项"></a>4.5 安装、升级、回滚时的有用选项</h3><ul><li>–timeout：一个 Go duration 类型的值， 用来表示等待 Kubernetes 命令完成的超时时间，默认值为 5m0s。such as “300ms”, “-1.5h” or “2h45m”. Valid time units are “ns”, “us” (or “µs”), “ms”, “s”, “m”, “h”。</li><li>–wait：表示必须要等到所有的 Pods 都处于 ready 状态，PVC 都被绑定，Deployments 都至少拥有最小 ready 状态 Pods 个数（Desired 减去 maxUnavailable ），并且 Services 都具有 IP 地址（如果是 LoadBalancer， 则为 Ingress ），才会标记该 release 为成功。最长等待时间由 –timeout 值指定。如果达到超时时间，release 将被标记为 FAILED。注意：当 Deployment 的 replicas 被设置为1，但其滚动升级策略中的 maxUnavailable 没有被设置为0时，–wait 将返回就绪，因为已经满足了最小 ready Pod 数</li><li><code>--no-hooks</code>：不运行当前命令的钩子，即为安装此 chart 时的已定义的安装前或者安装后的动作</li><li>–recreate-pods：（仅适用于 <code>upgrade</code> 和 <code>rollback</code>）：这个参数会导致重建所有的 Pod（deployment 中的 Pod 除外）。（在 Helm 3 中已被废弃）</li></ul><h2 id="5-卸载Chart应用"><a href="#5-卸载Chart应用" class="headerlink" title="5. 卸载Chart应用"></a>5. 卸载Chart应用</h2><p>卸载一个已安装的 Release 实例</p><pre><code class="highlight bash"><span class="comment"># 查看当前运行的 release </span>$ helm listNAME            NAMESPACEREVISIONUPDATED                                STATUS  CHART         APP VERSIONchart-1750577584default  1       2025-06-22 15:33:04.623161176 +0800 CSTdeployedapache-11.3.162.4.63<span class="comment"># 卸载应用</span>$ helm uninstall chart-1750577584<span class="comment"># 再次查看 release ，应用已卸载</span>$ helm listNAMENAMESPACEREVISIONUPDATEDSTATUSCHARTAPP VERSION</code></pre><h1 id="六、案例-安装Nginx"><a href="#六、案例-安装Nginx" class="headerlink" title="六、案例-安装Nginx"></a>六、案例-安装Nginx</h1><h2 id="1-下载-Nginx-Chart-安装包"><a href="#1-下载-Nginx-Chart-安装包" class="headerlink" title="1. 下载 Nginx Chart 安装包"></a>1. 下载 Nginx Chart 安装包</h2><pre><code class="highlight bash"><span class="comment"># 搜索要下载的 Chart 版本</span>$ helm search repo bitnami/nginx --versionsNAME                            CHART VERSIONAPP VERSIONDESCRIPTION                                       bitnami/nginx                   20.1.3       1.28.0     NGINX Open Source is a web server that can be a...bitnami/nginx                   20.1.2       1.28.0     NGINX Open Source is a web server that can be a...<span class="comment"># 使用 pull 拉取Chart， 失败</span>$ helm pull bitnami/nginx --version 20.1.3Error: failed to <span class="keyword">do</span> request: Head <span class="string">&quot;https://registry-1.docker.io/v2/bitnamicharts/nginx/manifests/20.1.3&quot;</span>: dial tcp 199.59.148.202:443: i/o <span class="built_in">timeout</span><span class="comment"># 使用 wget 命令下载安装包，成功</span>$ wget https://charts.bitnami.com/bitnami/nginx-20.1.3.tgz</code></pre><h2 id="2-安装-Nginx-Chart"><a href="#2-安装-Nginx-Chart" class="headerlink" title="2. 安装 Nginx Chart"></a>2. 安装 Nginx Chart</h2><pre><code class="highlight bash"><span class="comment"># 执行命令，根据Chart压缩包创建实例，生成 svc、deployment、pod</span>$ helm install my-nginx nginx-20.1.3.tgz \--<span class="built_in">set</span> service.type=NodePort \--<span class="built_in">set</span> service.nodePorts.http=30003 \    --namespace default --create-namespace        <span class="comment"># --set service.type=NodePort  手动设置Service类型为NodePort,模板文件 values.yaml 中默认为 LoadBalance</span><span class="comment"># --set service.nodePorts.http=30003 手动设置NodePort端口，模板文件中默认为空，自动生成端口</span><span class="comment"># --namespace default --create-namespace 指定 Pod、SVC、Deployment 所在的工作空间，不存在则创建</span></code></pre><p> 由于模板文件中的镜像默认都从 docker hub 下载，国内存在网络限制，在执行下面的命令前，先将镜像下载下来，导入到集群的 Node 节点。</p><p>关于如下下载外网镜像，参考这篇博客：<a href="https://georgechan95.github.io/blog/b01d5c62.html">Docker配置网络代理实现外网镜像下载</a></p><p><strong>查看结果：</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 Release</span>$ helm listNAME    NAMESPACEREVISIONUPDATED                                STATUS  CHART       APP VERSIONmy-nginxdefault  1       2025-06-22 16:57:21.546051288 +0800 CSTdeployednginx-20.1.31.28.0<span class="comment"># 查看 SVC</span>$ kubectl get svc -o wideNAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE   SELECTORmy-nginx     NodePort    10.105.158.179   &lt;none&gt;        80:30003/TCP,443:31458/TCP   12m   app.kubernetes.io/instance=my-nginx,app.kubernetes.io/name=nginx<span class="comment"># 查看 Deploy</span>$ kubectl get deploy -o wideNAME       READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                                        SELECTORmy-nginx   1/1     1            1           12m   nginx        docker.io/bitnami/nginx:1.28.0-debian-12-r3   app.kubernetes.io/instance=my-nginx,app.kubernetes.io/name=nginx<span class="comment"># 查看 Pod</span>$ kubectl get pod -o wideNAME                        READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESmy-nginx-58cf875b74-tp8ct   1/1     Running   0          13m   172.16.58.223   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>浏览器访问 SVC</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/22/20250622-171105.png" alt="Helm 安装 Nginx"></p><h2 id="3-更新Chart"><a href="#3-更新Chart" class="headerlink" title="3. 更新Chart"></a>3. 更新Chart</h2><pre><code class="highlight bash"><span class="comment"># 更新 Realse ， 将Pod 副本数从 1 变成 3</span>$ helm upgrade my-nginx nginx-20.1.3.tgz --<span class="built_in">set</span> replicaCount=3<span class="comment"># 再次查看 Realse</span><span class="comment"># 版本号REVISION 更新了，从 1 变成了 2</span>$ helm listNAME    NAMESPACEREVISIONUPDATED                                STATUS  CHART       APP VERSIONmy-nginxdefault  2       2025-06-22 17:24:48.296877982 +0800 CSTdeployednginx-20.1.31.28.0<span class="comment"># 查看 Pod</span>$ kubectl get pods -o wideNAME                        READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESmy-nginx-58cf875b74-gszn4   1/1     Running   0          2m54s   172.16.58.208   k8s-node02   &lt;none&gt;           &lt;none&gt;my-nginx-58cf875b74-q76q6   1/1     Running   0          17s     172.16.58.210   k8s-node02   &lt;none&gt;           &lt;none&gt;my-nginx-58cf875b74-zgbtp   1/1     Running   0          2m42s   172.16.85.193   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h2 id="4-卸载Nginx"><a href="#4-卸载Nginx" class="headerlink" title="4. 卸载Nginx"></a>4. 卸载Nginx</h2><pre><code class="highlight bash">$ helm uninstall my-nginx</code></pre><h1 id="七、Helm-常用命令"><a href="#七、Helm-常用命令" class="headerlink" title="七、Helm 常用命令"></a>七、Helm 常用命令</h1><h2 id="1-Repository-相关命令"><a href="#1-Repository-相关命令" class="headerlink" title="1. Repository 相关命令"></a>1. Repository 相关命令</h2><p>见本文 <code>helm的使用 / Helm 仓库管理</code></p><h2 id="2-Chart-相关命令"><a href="#2-Chart-相关命令" class="headerlink" title="2. Chart 相关命令"></a>2. Chart 相关命令</h2><h3 id="2-1-helm-create"><a href="#2-1-helm-create" class="headerlink" title="2.1 helm create"></a>2.1 <code>helm create</code></h3><p>该命令用于创建一个新的 Chart 目录：</p><pre><code class="highlight bash">$ helm create demoCreating demo</code></pre><p>创建的 Chart 目录是下面这样的结构：</p><pre><code class="highlight bash">$ tree demodemo├── Chart.yaml├── charts├── templates│   ├── NOTES.txt│   ├── _helpers.tpl│   ├── deployment.yaml│   ├── hpa.yaml│   ├── ingress.yaml│   ├── service.yaml│   ├── serviceaccount.yaml│   └── tests│       └── test-connection.yaml└── values.yaml3 directories, 10 files</code></pre><h3 id="2-2-helm-package"><a href="#2-2-helm-package" class="headerlink" title="2.2 helm package"></a>2.2 <code>helm package</code></h3><p>将 Chart 目录（必须包含 <code>Chart.yaml</code> 文件）打包成 Chart 归档文件：</p><pre><code class="highlight bash">$ helm package demoSuccessfully packaged chart and saved it to: /opt/k8s/10/demo-0.1.0.tgz</code></pre><h3 id="2-3-helm-lint"><a href="#2-3-helm-lint" class="headerlink" title="2.3 helm lint"></a>2.3 <code>helm lint</code></h3><p>验证 Chart 是否存在问题：</p><pre><code class="highlight bash">$ helm lint ./demo==&gt; Linting ./demo[INFO] Chart.yaml: icon is recommended1 chart(s) linted, 0 chart(s) failed</code></pre><h3 id="2-4-helm-show"><a href="#2-4-helm-show" class="headerlink" title="2.4 helm show"></a>2.4 <code>helm show</code></h3><p>该命令用于显示 Chart 的基本信息，包括：</p><ul><li><code>helm show chart</code> - 显示 Chart 定义，实际上就是 <code>Chart.yaml</code> 文件的内容</li><li><code>helm show crds</code> - 显示 Chart 的 CRD</li><li><code>helm show readme</code> - 显示 Chart 的 <code>README.md</code> 文件中的内容</li><li><code>helm show values</code> - 显示 Chart 的 <code>values.yaml</code> 文件中的内容</li><li><code>helm show all</code> - 显示 Chart 的所有信息</li></ul><pre><code class="highlight bash">$ helm show chart demo-0.1.0.tgz$ helm show values demo-0.1.0.tgz</code></pre><h3 id="2-5-helm-pull"><a href="#2-5-helm-pull" class="headerlink" title="2.5 helm pull"></a>2.5 <code>helm pull</code></h3><p>从仓库中将 Chart 安装包下载到本地：</p><pre><code class="highlight bash">$ helm pull bitnami/nginx$ <span class="built_in">ls</span>nginx-13.2.23.tgz</code></pre><h3 id="2-6-helm-push"><a href="#2-6-helm-push" class="headerlink" title="2.6 helm push"></a>2.6 <code>helm push</code></h3><p>将 Chart 安装包推送到远程仓库：</p><pre><code class="highlight bash">$ helm push [chart] [remote]</code></pre><h2 id="3-Release-相关命令"><a href="#3-Release-相关命令" class="headerlink" title="3. Release 相关命令"></a>3. Release 相关命令</h2><h3 id="3-1-helm-install"><a href="#3-1-helm-install" class="headerlink" title="3.1 helm install"></a>3.1 <code>helm install</code></h3><p>将 Chart 安装到 Kubernetes 集群：</p><pre><code class="highlight bash">$ helm install my-nginx bitnami/nginx --version 20.1.3</code></pre><p>安装时可以通过 <code>--set</code> 选项修改配置参数：</p><pre><code class="highlight bash">$ helm install my-nginx bitnami/nginx --version 20.1.3 \    --<span class="built_in">set</span> service.ports.http=8080</code></pre><p>其中 <code>bitnami/nginx</code> 是要安装的 Chart，这种写法是最常用的格式，被称为 <code>Chart 引用</code>，一共有六种不同的 Chart 写法：</p><ul><li>通过 Chart 引用：<code>helm install my-nginx bitnami/nginx</code></li><li>通过 Chart 包：<code>helm install my-nginx ./nginx-13.2.23.tgz</code></li><li>通过未打包的 Chart 目录：<code>helm install my-nginx ./nginx</code></li><li>通过 Chart URL：<code>helm install my-nginx https://example.com/charts/nginx-13.2.23.tgz</code></li><li>通过仓库 URL 和 Chart 引用：<code>helm install --repo https://example.com/charts/ my-nginx nginx</code></li><li>通过 OCI 注册中心：<code>helm install my-nginx --version 13.2.23 oci://example.com/charts/nginx</code></li></ul><h3 id="3-2-helm-list"><a href="#3-2-helm-list" class="headerlink" title="3.2 helm list"></a>3.2 <code>helm list</code></h3><p>显示某个命名空间下的所有 Release：</p><pre><code class="highlight bash">$ helm list --namespace defaultNAME    NAMESPACEREVISIONUPDATED                                STATUS  CHART       APP VERSIONmy-nginxdefault  1       2025-06-22 17:50:26.273823328 +0800 CSTdeployednginx-20.1.31.28.0</code></pre><h3 id="3-3-helm-status"><a href="#3-3-helm-status" class="headerlink" title="3.3 helm status"></a>3.3 <code>helm status</code></h3><p>查询某个 Release 的状态信息：</p><pre><code class="highlight bash">$ helm status my-nginxNAME: my-nginxLAST DEPLOYED: Sun Jun 22 17:50:26 2025NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:CHART NAME: nginxCHART VERSION: 20.1.3APP VERSION: 1.28.0Did you know there are enterprise versions of the Bitnami catalog? For enhanced secure software supply chain features, unlimited pulls from Docker, LTS support, or application customization, see Bitnami Premium or Tanzu Application Catalog. See https://www.arrow.com/globalecs/na/vendors/bitnami <span class="keyword">for</span> more information.** Please be patient <span class="keyword">while</span> the chart is being deployed **NGINX can be accessed through the following DNS name from within your cluster:    my-nginx.default.svc.cluster.local (port 80)</code></pre><h3 id="3-4-helm-get"><a href="#3-4-helm-get" class="headerlink" title="3.4 helm get"></a>3.4 <code>helm get</code></h3><p>获取某个 Release 的扩展信息，包括：</p><ul><li><code>helm get hooks</code> - 获取 Release 关联的钩子信息</li><li><code>helm get manifest</code> - 获取 Release 的清单信息</li><li><code>helm get notes</code> - 获取 Release 的注释</li><li><code>helm get values</code> - 获取 Release 的 values 文件</li><li><code>helm get all</code> - 获取 Release 的所有信息</li></ul><pre><code class="highlight bash">$ helm get values my-nginxUSER-SUPPLIED VALUES:service:  nodePorts:    http: 30003  <span class="built_in">type</span>: NodePort</code></pre><h3 id="3-5-helm-upgrade"><a href="#3-5-helm-upgrade" class="headerlink" title="3.5 helm upgrade"></a>3.5 <code>helm upgrade</code></h3><p>将 Release 升级到新版本的 Chart：</p><pre><code class="highlight bash">$ helm upgrade my-nginx ./nginxRelease <span class="string">&quot;my-nginx&quot;</span> has been upgraded. Happy Helming!</code></pre><p>升级时可以通过 <code>--set</code> 选项修改配置参数：</p><pre><code class="highlight bash">$ helm upgrade my-nginx ./nginx \    --<span class="built_in">set</span> service.ports.http=8080</code></pre><h3 id="3-6-helm-history"><a href="#3-6-helm-history" class="headerlink" title="3.6 helm history"></a>3.6 <code>helm history</code></h3><p>查看某个 Release 的版本记录：</p><pre><code class="highlight bash">$ helm <span class="built_in">history</span> my-nginxREVISIONUPDATED                 STATUS    CHART       APP VERSIONDESCRIPTION     1       Sun Jun 22 17:50:26 2025supersedednginx-20.1.31.28.0     Install complete2       Sun Jun 22 17:55:25 2025deployed  nginx-20.1.31.28.0     Upgrade complete</code></pre><h3 id="3-7-helm-rollback"><a href="#3-7-helm-rollback" class="headerlink" title="3.7 helm rollback"></a>3.7 <code>helm rollback</code></h3><p>将 Release 回滚到某个版本：</p><pre><code class="highlight bash">$ helm rollback my-nginx 1Rollback was a success! Happy Helming!</code></pre><p>再查看版本记录可以看到多了一条记录：</p><pre><code class="highlight bash">$ helm <span class="built_in">history</span> my-nginxREVISIONUPDATED                 STATUS    CHART       APP VERSIONDESCRIPTION     1       Sun Jun 22 17:50:26 2025supersedednginx-20.1.31.28.0     Install complete2       Sun Jun 22 17:55:25 2025supersedednginx-20.1.31.28.0     Upgrade complete3       Sun Jun 22 17:56:48 2025deployed  nginx-20.1.31.28.0     Rollback to 1</code></pre><h3 id="3-8-helm-uninstall"><a href="#3-8-helm-uninstall" class="headerlink" title="3.8 helm uninstall"></a>3.8 <code>helm uninstall</code></h3><p>卸载 Release：</p><pre><code class="highlight bash">$ helm uninstall my-nginxrelease <span class="string">&quot;my-nginx&quot;</span> uninstalled</code></pre><h1 id="八、搭建-Chart-私有仓库"><a href="#八、搭建-Chart-私有仓库" class="headerlink" title="八、搭建 Chart 私有仓库"></a>八、搭建 Chart 私有仓库</h1><h2 id="1-创建一个-HTTP-Server-作为chart仓库"><a href="#1-创建一个-HTTP-Server-作为chart仓库" class="headerlink" title="1. 创建一个 HTTP Server 作为chart仓库"></a>1. 创建一个 HTTP Server 作为chart仓库</h2><pre><code class="highlight bash"><span class="comment"># 创建挂载目录</span>$ <span class="built_in">mkdir</span> -p /var/www/charts<span class="comment"># 拉取 httpd 镜像</span>$ docker pull httpd:2.4.63<span class="comment"># 启动容器</span>$ docker run -d -p 8899:80 --name=my-chart --restart=always -v /var/www:/usr/local/apache2/htdocs httpd:2.4.63</code></pre><p>浏览器访问 Chart 仓库</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/22/20250622-181042.png" alt="Chart 私有仓库"></p><p><strong>需要注意:</strong></p><ul><li><em>宿主机的&#x2F;var&#x2F;www目录需要存在,且有一定的访问权限。</em></li><li><em>容器内部的 httpd 配置不要和宿主机 8081 端口冲突。</em></li><li><em>可以添加-v宿主机日志目录:容器日志目录来收集日志。</em></li><li><em>可以设置时区等参数对容器进行定制。</em></li></ul><h2 id="2-Helm-Chart上传到私有仓库"><a href="#2-Helm-Chart上传到私有仓库" class="headerlink" title="2. Helm Chart上传到私有仓库"></a>2. Helm Chart上传到私有仓库</h2><p>这里为了测试方便，将前面案例中所使用的Chart 安装包：nginx-20.1.3.tgz 解压，然后打包上传到 Chart 私有仓库</p><pre><code class="highlight bash"><span class="comment"># 1.将 nginx 目录打包成tgz文件,用于发布。</span>$ helm package nginx/Successfully packaged chart and saved it to: /opt/software/nginx-20.1.3.tgz<span class="comment"># 2.创建文件夹作为chart仓库目录。</span>$ <span class="built_in">mkdir</span> myrepo<span class="comment"># 3. 将打包好的chart移动到仓库目录下。</span>$ <span class="built_in">mv</span> nginx-20.1.3.tgz myrepo/<span class="comment"># 4. 在myrepo目录生成index.yaml索引文件,用于仓库查询。</span>$ helm repo index myrepo --url http://192.168.6.203:8899/charts<span class="comment"># 5. 将index和chart复制到Web服务器目录下,提供下载。</span>$ <span class="built_in">cd</span> myrepo/$ scp index.yaml nginx-20.1.3.tgz /var/www/charts<span class="comment"># 6. 在本地Helm中添加这个chart仓库源,名为newrepo。</span>$ helm repo add newrepo http://192.168.6.203:8899/charts<span class="comment"># 7. 列出已知的仓库列表,确保newrepo添加成功。</span>$ helm repo list<span class="comment"># 8. 更新本地缓存的仓库index文件。</span>$ helm repo update<span class="comment"># 9. 在newrepo仓库中搜索 nginx 是否可用。</span>$ helm search repo newrepo/nginxNAME         CHART VERSIONAPP VERSIONDESCRIPTION                                       newrepo/nginx20.1.3       1.28.0     NGINX Open Source is a web server that can be a...</code></pre><h2 id="3-测试私有仓库"><a href="#3-测试私有仓库" class="headerlink" title="3. 测试私有仓库"></a>3. 测试私有仓库</h2><pre><code class="highlight bash"><span class="comment"># 使用本地仓库的Chart 安装Nginx</span>$ helm install newrepo/nginx --generate-name<span class="comment"># 查看Release</span>$ helm listNAME            NAMESPACEREVISIONUPDATED                                STATUS  CHART       APP VERSIONnginx-1750588514default  1       2025-06-22 18:35:14.639466957 +0800 CSTdeployednginx-20.1.31.28.0</code></pre><p>浏览器查看私有仓库</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/22/20250622-183645.png" alt="私有Chart仓库"></p><h1 id="九、自定义Chart"><a href="#九、自定义Chart" class="headerlink" title="九、自定义Chart"></a>九、自定义Chart</h1><h2 id="1-创建模板"><a href="#1-创建模板" class="headerlink" title="1. 创建模板"></a>1. 创建模板</h2><pre><code class="highlight bash"><span class="comment"># 创建chart模板</span>$ helm create myapp<span class="comment"># 查看模板目录结构</span>$ tree myapp/myapp/├── Chart.yaml├── charts├── templates│   ├── NOTES.txt│   ├── _helpers.tpl│   ├── deployment.yaml│   ├── hpa.yaml│   ├── ingress.yaml│   ├── service.yaml│   ├── serviceaccount.yaml│   └── tests│       └── test-connection.yaml└── values.yaml</code></pre><h2 id="2-删除多余的文件"><a href="#2-删除多余的文件" class="headerlink" title="2. 删除多余的文件"></a>2. 删除多余的文件</h2><pre><code class="highlight bash"><span class="comment"># 当前案例比较简单，暂时用不到这些文件，先删除</span>$ <span class="built_in">rm</span> -rf templates/_helpers.tpl templates/hpa.yaml templates/ingress.yaml templates/serviceaccount.yaml templates/tests/test-connection.yaml templates/NOTES.txt</code></pre><h2 id="3-service-yaml"><a href="#3-service-yaml" class="headerlink" title="3. service.yaml"></a>3. service.yaml</h2><pre><code class="highlight yaml"><span class="string">$</span> <span class="string">vim</span> <span class="string">service.yaml</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">myapp-test</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp-svc</span><span class="attr">spec:</span>  <span class="comment"># Service 类型，从 values.yaml 文件取</span>  <span class="attr">type:</span> &#123;&#123; <span class="string">.Values.service.type</span> &#125;&#125;  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> &#123;&#123; <span class="string">.Values.service.port</span> &#125;&#125; <span class="comment"># Service 端口，从 values.yaml 文件取</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">nodePort:</span> <span class="number">30003</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">myapp-test</span></code></pre><h2 id="4-deployment-yaml"><a href="#4-deployment-yaml" class="headerlink" title="4. deployment.yaml"></a>4. deployment.yaml</h2><pre><code class="highlight yaml"><span class="string">$</span> <span class="string">vim</span> <span class="string">deployment.yaml</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp-deploy</span>  <span class="attr">name:</span> <span class="string">myapp-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> &#123;&#123; <span class="string">.Values.replicaCount</span> &#125;&#125; <span class="comment"># Pod副本数，从 values.yaml 文件取</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp-test</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp-test</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> &#123;&#123; <span class="string">.Values.image.pullPolicy</span> &#125;&#125; <span class="comment"># 镜像拉取策略，从 values.yaml 文件取</span></code></pre><h2 id="5-values-yaml"><a href="#5-values-yaml" class="headerlink" title="5. values.yaml"></a>5. values.yaml</h2><pre><code class="highlight yaml"><span class="string">$</span> <span class="string">vim</span> <span class="string">values.yaml</span><span class="comment"># Pod副本数</span><span class="attr">replicaCount:</span> <span class="number">1</span><span class="attr">image:</span>  <span class="comment"># 镜像拉取策略</span>  <span class="attr">pullPolicy:</span> <span class="string">IfNotPresent</span><span class="attr">service:</span>  <span class="comment"># Service类型</span>  <span class="attr">type:</span> <span class="string">NodePort</span>  <span class="comment"># service端口</span>  <span class="attr">port:</span> <span class="number">80</span></code></pre><h2 id="6-Chart-yaml"><a href="#6-Chart-yaml" class="headerlink" title="6. Chart.yaml"></a>6. Chart.yaml</h2><pre><code class="highlight yaml"><span class="string">$</span> <span class="string">vim</span> <span class="string">Chart.yaml</span><span class="attr">apiVersion:</span> <span class="string">v2</span><span class="attr">name:</span> <span class="string">myapp</span><span class="attr">description:</span> <span class="string">A</span> <span class="string">Helm</span> <span class="string">chart</span> <span class="string">for</span> <span class="string">Kubernetes</span><span class="comment"># A chart can be either an &#x27;application&#x27; or a &#x27;library&#x27; chart.</span><span class="comment">#</span><span class="comment"># Application charts are a collection of templates that can be packaged into versioned archives</span><span class="comment"># to be deployed.</span><span class="comment">#</span><span class="comment"># Library charts provide useful utilities or functions for the chart developer. They&#x27;re included as</span><span class="comment"># a dependency of application charts to inject those utilities and functions into the rendering</span><span class="comment"># pipeline. Library charts do not define any templates and therefore cannot be deployed.</span><span class="attr">type:</span> <span class="string">application</span><span class="comment"># This is the chart version. This version number should be incremented each time you make changes</span><span class="comment"># to the chart and its templates, including the app version.</span><span class="comment"># Versions are expected to follow Semantic Versioning (https://semver.org/)</span><span class="attr">version:</span> <span class="number">0.1</span><span class="number">.0</span><span class="comment"># This is the version number of the application being deployed. This version number should be</span><span class="comment"># incremented each time you make changes to the application. Versions are not expected to</span><span class="comment"># follow Semantic Versioning. They should reflect the version the application is using.</span><span class="comment"># It is recommended to use it with quotes.</span><span class="attr">appVersion:</span> <span class="string">&quot;1.16.0&quot;</span></code></pre><h2 id="7-发布部署"><a href="#7-发布部署" class="headerlink" title="7. 发布部署"></a>7. 发布部署</h2><pre><code class="highlight bash">$ helm install myapp myapp/NAME: myappLAST DEPLOYED: Wed Jun 25 12:57:58 2025NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: None<span class="comment"># 查看部署的 Release</span>$ helm listNAME NAMESPACEREVISIONUPDATED                               STATUS  CHART      APP VERSIONmyappdefault  1       2025-06-25 12:57:58.07309733 +0800 CSTdeployedmyapp-0.1.01.16.0<span class="comment"># 查看 Service</span>$ kubectl get svc -o wideNAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE     SELECTORkubernetes   ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP        57d     &lt;none&gt;myapp-test   NodePort    10.108.147.243   &lt;none&gt;        80:30003/TCP   3m41s   app=myapp-test<span class="comment"># 查看 Deployment</span>$ kubectl get deploy -o wideNAME           READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES                     SELECTORmyapp-deploy   1/1     1            1           4m58s   myapp        wangyanglinux/myapp:v1.0   app=myapp-test<span class="comment"># 查看 Pod</span>$ kubectl get pod -o wideNAME                            READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESmyapp-deploy-7ff87cfb6c-nfff4   1/1     Running   0          5m29s   172.16.58.227   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>浏览器访问 Service</p><p><a href="http://192.168.6.139:30003/">http://192.168.6.139:30003/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/25/20250625-130414.png" alt="访问自定Chart"></p><h2 id="8-打包Chart，发布到私有仓库"><a href="#8-打包Chart，发布到私有仓库" class="headerlink" title="8. 打包Chart，发布到私有仓库"></a>8. 打包Chart，发布到私有仓库</h2><pre><code class="highlight bash"><span class="comment"># 1.将 myapp 目录打包成tgz文件,用于发布。</span>$ helm package myapp/Successfully packaged chart and saved it to: /opt/k8s/10/myapp-0.1.0.tgz<span class="comment"># 2.将打包好的压缩包移动到创建的私有仓库目录中（本文第八段有说明）</span>$ <span class="built_in">mv</span> myapp-0.1.0.tgz /opt/software/myrepo/<span class="comment"># 3. 在myrepo目录生成index.yaml索引文件,用于仓库查询。</span>$ $ helm repo index /opt/software/myrepo/ --url http://192.168.6.203:8899/charts<span class="comment"># 4. 将index和chart复制到Web服务器目录下,提供下载。</span>$ <span class="built_in">cd</span> /opt/software/myrepo/$ scp -r ./* root@192.168.6.203:/var/www/charts/<span class="comment"># 5. 在本地Helm中添加这个chart仓库源,名为newrepo。</span>$ helm repo add newrepo http://192.168.6.203:8899/charts<span class="comment"># 6. 列出已知的仓库列表,确保newrepo添加成功。</span>$ helm repo list<span class="comment"># 7. 更新本地缓存的仓库index文件。</span>$ helm repo update<span class="comment"># 8. 在newrepo仓库中搜索 nginx 是否可用。</span>$ helm search repo newrepo/myappNAME         CHART VERSIONAPP VERSIONDESCRIPTION                newrepo/myapp0.1.0        1.16.0     A Helm chart <span class="keyword">for</span> Kubernetes<span class="comment"># 9. 从私有仓库拉取chart，并安装到服务器</span>$ helm install newrepo/myapp --generate-nameNAME: myapp-1750829238LAST DEPLOYED: Wed Jun 25 13:27:18 2025NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: None<span class="comment"># 10. 卸载 Chart</span>$ helm uninstall myapp-1750829238release <span class="string">&quot;myapp-1750829238&quot;</span> uninstalled</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、引言&quot;&gt;&lt;a href=&quot;#一、引言&quot; class=&quot;headerlink&quot; title=&quot;一、引言&quot;&gt;&lt;/a&gt;一、引言&lt;/h1&gt;&lt;p&gt;没有使用 Helm 之前，在 Kubernetes 部署应用，我们要依次部署 deployment、service 等，步骤</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>009-Kubernetes 集群安全机制</title>
    <link href="https://georgechan95.github.io/blog/424f1119.html"/>
    <id>https://georgechan95.github.io/blog/424f1119.html</id>
    <published>2025-06-14T01:18:00.000Z</published>
    <updated>2025-06-19T02:30:21.990Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、K8S认证与授权"><a href="#一、K8S认证与授权" class="headerlink" title="一、K8S认证与授权"></a>一、K8S认证与授权</h1><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/14/20250614-104507.png" alt="K8S认证与授权"></p><h2 id="1-认证「Authentication」"><a href="#1-认证「Authentication」" class="headerlink" title="1. 认证「Authentication」"></a>1. 认证「Authentication」</h2><p>认证有如下几种方式：</p><p>1、HTTP Token认证：通过一个Token来识别合法用户。</p><p>HTTP Token的认证是用一个很长的特殊编码方式的并且难以被模仿的字符串来表达客户的一种方式。每一个Token对应一个用户名，存储在API Server能访问的文件中。当客户端发起API调用请求时，需要在HTTP Header里放入Token。</p><p>2、HTTP Base认证：通过用户名+密码的方式认证</p><p>用户名:密码用 base64 算法进行编码后的字符串放在 HTTP Request 中的 Heather Authorization 域里发送给服务端，服务端收到后进行解码，获取用户名和密码。</p><p>3、最严格的 HTTPS 证书认证：基于 CA 根证书签名的客户端身份认证方式</p><h2 id="2-授权「Authorization」"><a href="#2-授权「Authorization」" class="headerlink" title="2. 授权「Authorization」"></a>2. 授权「Authorization」</h2><p>认证只是确认通信的双方都是可信的，可以相互通信。而授权是确定请求方有哪些资源的权限。API Server 目前支持如下几种授权策略（通过 API Server 的启动参数  <code>--authorization-mode</code> 设置，在控制平面节点上，路径：<code>/etc/kubernetes/manifests/kube-apiserver.yaml</code> ）</p><ul><li><code>AlwaysDeny</code> ：表示拒绝所有请求。仅用于测试</li><li><code>AlwaysAllow</code> ：表示允许所有请求。如果有集群不需要授权流程，则可以采用该策略</li><li><code>Node</code> ：节点授权是一种特殊用途的授权模式，专门授权由 kubelet 发出的 API 请求</li><li><code>Webhook</code> ：是一种 HTTP 回调模式，允许使用远程 REST 端点管理授权</li><li><code>ABAC</code>：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制</li><li><strong>RBAC：基于角色的访问控制，默认使用该规则</strong></li></ul><h1 id="二、RBAC授权模式"><a href="#二、RBAC授权模式" class="headerlink" title="二、RBAC授权模式"></a>二、RBAC授权模式</h1><p>RBAC（Role-Based Access Control）基于角色的访问控制，在Kubernetes 1.5 中引入，现为默认标准。相对其他访问控制方式，拥有如下优势：</p><ul><li>对集群中的资源和非资源均拥有完整的覆盖</li><li>整个RBAC完全由几个 API 对象完成，同其他API对象一样，可以用 kubectl 或 API 进行操作</li><li>可以在运行时进行操作，无需重启API Server</li></ul><h2 id="1-RBAC-API-类型"><a href="#1-RBAC-API-类型" class="headerlink" title="1. RBAC API 类型"></a>1. RBAC API 类型</h2><p>RBAC API 所声明的四种顶级类型【Role、ClusterRole、RoleBinding 和 ClusterRoleBinding】。用户可以像与其他 API 资源交互一样，（通过 kubectl API 调用等方式）与这些资源交互。</p><h3 id="1-1-Role-和-ClusterRole"><a href="#1-1-Role-和-ClusterRole" class="headerlink" title="1.1 Role 和 ClusterRole"></a>1.1 Role 和 ClusterRole</h3><p>在 RBAC API 中，一个角色包含一组相关权限的规则。权限是纯粹累加的（不存在拒绝某操作的规则），即只能给权限累加，不存在给了XX权限，然后去掉XX01权限的情况。角色可以用 Role 来定义到某个命名空间（namespace）上， 或者用 ClusterRole 来定义到整个集群作用域（所有namespace）。</p><p>一个 Role 只可以用来对某一命名空间中的资源赋予访问权限。</p><p><strong>Role示例：</strong></p><p>定义到名称为 “default” 的命名空间，可以用来授予对该命名空间中的 Pods 的读取权限：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Role</span>  <span class="comment"># 资源类型为：角色</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-reader</span> <span class="comment"># 角色的名称</span>  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment"># 角色所属的命名空间</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 指定 API 组，空字符串 &quot;&quot; 表示 Kubernetes 核心 API 组（例如 pods、services 等资源属于核心组）。</span>    <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>] <span class="comment"># 指定规则适用的资源类型，这里是 pods（即 Pod 资源）。</span>    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>] <span class="comment"># 指定角色对Pod资源允许的操作，获取、监控、列出</span></code></pre><p>ClusterRole 可以授予的权限和 Role 相同，但是因为 ClusterRole 属于集群范围，所以它也可以授予以下访问权限：</p><ul><li>集群范围资源 （比如 nodes访问）</li><li>非资源端点（比如 “&#x2F;healthz” 访问）</li><li>跨命名空间访问的有名称空间作用域的资源（如 Pods），比如运行命令<code>kubectl get pods --all-namespaces</code> 时需要此能力</li></ul><p><strong>ClusterRole示例</strong></p><p>可用来对某特定命名空间下的 Secrets 的读取操作授权，或者跨所有名称空间执行授权（取决于它是如何绑定的）：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span> <span class="comment"># 资源类型</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">secret-reader</span> <span class="comment"># 集群角色的名称</span>  <span class="comment"># 此处的 &quot;namespace&quot; 被省略掉是因为 ClusterRoles 是没有命名空间的。</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 指定 API 组，空字符串 &quot;&quot; 表示 Kubernetes 核心 API 组（secrets 属于核心组）。</span>    <span class="attr">resources:</span> [<span class="string">&quot;secrets&quot;</span>] <span class="comment"># 指定规则适用的规则类型</span>    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]</code></pre><h3 id="1-2-RoleBinding-和-ClusterRoleBinding"><a href="#1-2-RoleBinding-和-ClusterRoleBinding" class="headerlink" title="1.2 RoleBinding 和 ClusterRoleBinding"></a>1.2 RoleBinding 和 ClusterRoleBinding</h3><p>角色绑定（RoleBinding）是将角色中定义的权限赋予一个用户或者一组用户。 它包含若干主体【subjects】（users、groups 或 service accounts）的列表和对这些主体所获得的角色引用。</p><p><strong>可以使用 RoleBinding 在指定的命名空间中执行授权，或者在集群范围的命名空间使用 ClusterRoleBinding 来执行授权。</strong></p><p>一个 RoleBinding 可以引用同一的命名空间中的 Role。</p><p><strong>RoleBinding示例</strong></p><p>将 “pod-reader” 角色授予在 “default” 命名空间中的用户 “jane”； 这样，用户 “jane” 就具有了读取 “default” 命名空间中 pods 的权限。</p><p>在下面的例子中，角色绑定使用 roleRef 将用户 “jane” 绑定到前文创建的角色 Role，其名称是 pod-reader。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">RoleBinding</span> <span class="comment"># 定义资源的类型为 RoleBinding，用于将一个角色（Role 或 ClusterRole）绑定到用户、组或服务账户</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">read-pods</span> <span class="comment"># RoleBinding 的名称</span>  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment"># 此 RoleBinding 作用于 default 命名空间，仅对该命名空间内的资源生效</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span> <span class="comment"># 主体类型为用户</span>    <span class="attr">name:</span> <span class="string">jane</span> <span class="comment"># 名称大小写敏感</span>    <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span> <span class="comment"># 指定主体所属的 API 组</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">Role</span> <span class="comment"># 引用的角色类型为 Role（命名空间级别的角色），而不是 ClusterRole（集群级别的角色）</span>  <span class="attr">name:</span> <span class="string">pod-reader</span> <span class="comment"># 引用的角色名称为 pod-reader，需要在 default 命名空间中存在</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span> <span class="comment"># 角色所属的 API 组</span></code></pre><p>roleRef 里的内容决定了实际创建绑定的方法。kind 可以是 Role 或 ClusterRole，name 是你要引用的 Role 或 ClusterRole 的名称。</p><p>RoleBinding 也可以引用 ClusterRole，这可以允许管理者在 整个集群中定义一组通用的角色，然后在多个命名空间中重用它们。（集群角色与角色绑定进行匹配后，就对集群角色进行了降维，绑定的用户将只能操作命名空间下的资源。）</p><p><strong>RoleBinding示例2</strong></p><p>下面的例子，RoleBinding 引用的是 ClusterRole， “dave” （subjects区分大小写）将只可以读取在”development” 名称空间（ RoleBinding 的命名空间）中的”secrets” 。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">RoleBinding</span> <span class="comment"># 定义资源的类型为 RoleBinding，用于将一个角色（Role 或 ClusterRole）绑定到用户、组或服务账户</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">read-secrets</span> <span class="comment"># RoleBinding 的名称</span>  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment"># 此 RoleBinding 作用于 default 命名空间，仅对该命名空间内的资源生效</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span> <span class="comment"># 主体类型为用户</span>    <span class="attr">name:</span> <span class="string">dave</span> <span class="comment"># 名称大小写敏感</span>    <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span> <span class="comment"># 指定主体所属的 API 组</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span> <span class="comment"># 引用的角色类型为 ClusterRole（集群级别的角色）,集群角色降维到命名空间</span>  <span class="attr">name:</span> <span class="string">secret-reader</span> <span class="comment"># 引用的角色名称为 secret-reader，需要在 default 命名空间中存在</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span> <span class="comment"># 角色所属的 API 组</span></code></pre><p>最后，ClusterRoleBinding 可用来在集群级别并对所有命名空间执行授权。</p><p><strong>ClusterRoleBinding示例</strong></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="comment"># 这个集群角色绑定允许 &quot;manager&quot; 组中的任何用户读取任意命名空间中 &quot;secrets&quot;s</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">read-secrets-global</span> <span class="comment"># 集群角色的名称</span>  <span class="comment"># 不需要定义 namespace，对所有名称空间有效</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span> <span class="comment"># 绑定的主体类型为 Group</span>    <span class="attr">name:</span> <span class="string">manager</span> <span class="comment"># 名称区分大小写</span>    <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">name:</span> <span class="string">secret-reader</span> <span class="comment"># 集群角色的名称，需要在集群中存在</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre><p><strong>当我们创建binding后，则不能修改binding所引用的Role或ClusterRole。尝试修改会导致验证错误；如果要改变binding的roleRef，那么应该删除该binding对象并且创建一个新的用来替换原来的。</strong></p><h2 id="2-资源引用-Referring-to-resources"><a href="#2-资源引用-Referring-to-resources" class="headerlink" title="2. 资源引用 Referring to resources"></a>2. 资源引用 Referring to resources</h2><p>Kubernetes集群内一些资源一般以其名称字符串来表示，这些字符串一般会在 API 的 URL 地址中出现；同时某些资源也会包含子资源，例如 pod 的 logs 资源就属于pods的子资源，API 中 URL 样例如下：</p><pre><code class="highlight plaintext">GET /api/v1/namespaces/&#123;namespace&#125;/pods/&#123;name&#125;/log</code></pre><p>在这种情况下，”pods” 是有名称空间的资源，而 “log” 是 pods 的子资源。在 RBAC 角色中，使用 “&#x2F;” 分隔资源和子资源。</p><p>允许一个主体（subject）要同时读取 pods 和 pod logs，你可以这么写：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">pod-and-pod-logs-reader</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>, <span class="string">&quot;pods/log&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>]</code></pre><p>对于某些请求，也可以通过 resourceNames 列表按名称引用资源。</p><p>例如：在指定时，可以将请求类型限制到资源的单个实例。限制只可以 “get” 和 “update” 到单个configmap，则可以这么写：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">configmap-updater</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 核心 API 组</span>    <span class="attr">resources:</span> [<span class="string">&quot;configmaps&quot;</span>] <span class="comment"># 可操作的资源类型为 Configmap</span>    <span class="attr">resourceNames:</span> [<span class="string">&quot;configmap-demo&quot;</span>] <span class="comment"># 可操作的具体是哪个 ConfigMap</span>    <span class="attr">verbs:</span> [<span class="string">&quot;update&quot;</span>, <span class="string">&quot;get&quot;</span>] <span class="comment"># 定义操作类型，只能 更新和读取</span></code></pre><p>需要注意的是，create 请求不能被 resourceName 限制，因为在鉴权时还不知道对象名称。 另一个例外是 deletecollection。</p><h2 id="3-主体引用-Referring-to-subjects"><a href="#3-主体引用-Referring-to-subjects" class="headerlink" title="3. 主体引用 Referring to subjects"></a>3. 主体引用 Referring to subjects</h2><p>RoleBinding 或 ClusterRoleBinding 绑定一个 role 到主体（subjects）。主体（subjects）可以是 groups，users 或 ServiceAccounts 。</p><p> Kubernetes将用户名表示为字符串。这些可以是：普通名称，比如 “alice” ；邮件风格的名字，比如 “<a href="mailto:&#98;&#x6f;&#x62;&#x40;&#101;&#120;&#97;&#109;&#x70;&#x6c;&#101;&#x2e;&#99;&#x6f;&#109;">&#98;&#x6f;&#x62;&#x40;&#101;&#120;&#97;&#109;&#x70;&#x6c;&#101;&#x2e;&#99;&#x6f;&#109;</a>” ；或表示为字符串的数字用户id。</p><p><strong>注意：前缀  <code>system:</code>  是保留给 Kubernetes 系统使用的，因此应该确保不会出现名称以 <code>system:</code>  开头的用户或组。除了这个特殊的前缀，RBAC 授权系统不要求用户名使用任何格式。</strong></p><p><strong>ServiceAccounts具有前缀为 <code>system:serviceaccount:</code>  的名称，属于具有前缀为 system:serviceaccounts: 的名称的组。</strong></p><h3 id="RoleBinding的示例"><a href="#RoleBinding的示例" class="headerlink" title="RoleBinding的示例"></a>RoleBinding的示例</h3><p>下面的示例只是展示 RoleBinding 中 subjects 的部分。</p><ul><li><p>用户的名称为 “<a href="mailto:&#x61;&#x6c;&#105;&#x63;&#101;&#64;&#101;&#120;&#x61;&#x6d;&#x70;&#x6c;&#x65;&#46;&#x63;&#111;&#x6d;">&#x61;&#x6c;&#105;&#x63;&#101;&#64;&#101;&#120;&#x61;&#x6d;&#x70;&#x6c;&#x65;&#46;&#x63;&#111;&#x6d;</a>” ：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span>  <span class="attr">name:</span> <span class="string">&quot;alice@example.com&quot;</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>组的名称为 “frontend-admins” ：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">&quot;frontend-admins&quot;</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>默认service account在 kube-system 命名空间中：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>  <span class="attr">name:</span> <span class="string">default</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span></code></pre><ul><li><p>查看 default 命名空间下的 ServiceAccount</p><pre><code class="highlight bash">$ kubectl get saNAME      SECRETS   AGEdefault   0         77d</code></pre></li></ul></li><li><p>在名称为 “qa” 命名空间中所有的服务账号：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:serviceaccounts:qa</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>在任意名称空间的所有service accounts：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:serviceaccounts</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>所有认证过的用户（版本 1.5+）：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:authenticated</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>所有未认证的用户（版本 1.5+）：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:unauthenticated</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>所有用户 （版本 1.5+）：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:authenticated</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:unauthenticated</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li></ul><h1 id="三、案例实操"><a href="#三、案例实操" class="headerlink" title="三、案例实操"></a>三、案例实操</h1><p><strong>创建一个用户只能管理 dev 名字空间</strong></p><h2 id="1-创建命名空间"><a href="#1-创建命名空间" class="headerlink" title="1. 创建命名空间"></a>1. 创建命名空间</h2><pre><code class="highlight bash"><span class="comment"># 创建 dev 名称空间</span>$ kubectl create namespace devnamespace/dev created<span class="comment"># 查看名称空间</span>$ kubectl get ns | grep devdev                Active   24s</code></pre><h2 id="2-创建证书"><a href="#2-创建证书" class="headerlink" title="2. 创建证书"></a>2. 创建证书</h2><p>在 master 节点操作，将证书创建在 <code>/etc/kubernetes/pki</code> 目录下， 该目录存放了 k8s 集群证书。</p><h3 id="2-1-创建证书描述文件"><a href="#2-1-创建证书描述文件" class="headerlink" title="2.1 创建证书描述文件"></a>2.1 创建证书描述文件</h3><pre><code class="highlight bash">vim /etc/kubernetes/pki/devuser.json<span class="comment"># 内容如下：</span>&#123;  <span class="string">&quot;CN&quot;</span>: <span class="string">&quot;devuser&quot;</span>,  <span class="string">&quot;hosts&quot;</span>: [],  <span class="string">&quot;key&quot;</span>: &#123;    <span class="string">&quot;algo&quot;</span>: <span class="string">&quot;rsa&quot;</span>,    <span class="string">&quot;size&quot;</span>: 2048  &#125;,  <span class="string">&quot;names&quot;</span>: [    &#123;      <span class="string">&quot;C&quot;</span>: <span class="string">&quot;CN&quot;</span>,      <span class="string">&quot;ST&quot;</span>: <span class="string">&quot;BeiJing&quot;</span>,      <span class="string">&quot;L&quot;</span>: <span class="string">&quot;BeiJing&quot;</span>,      <span class="string">&quot;O&quot;</span>: <span class="string">&quot;k8s&quot;</span>,      <span class="string">&quot;OU&quot;</span>: <span class="string">&quot;System&quot;</span>    &#125;  ]&#125;</code></pre><h3 id="2-2-下载证书生成工具"><a href="#2-2-下载证书生成工具" class="headerlink" title="2.2 下载证书生成工具"></a>2.2 下载证书生成工具</h3><pre><code class="highlight bash"><span class="comment"># 工具一</span>wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64<span class="built_in">mv</span> cfssl_linux-amd64 /usr/local/bin/cfssl<span class="comment"># 工具二</span>wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64<span class="built_in">mv</span> cfssljson_linux-amd64 /usr/local/bin/cfssljson<span class="comment"># 工具三</span>wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64<span class="built_in">mv</span> cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo<span class="comment"># 给生成工具授权</span><span class="built_in">chmod</span> a+x /usr/local/bin/cfssl*</code></pre><h3 id="2-3-生成证书"><a href="#2-3-生成证书" class="headerlink" title="2.3 生成证书"></a>2.3 生成证书</h3><pre><code class="highlight bash"><span class="comment"># 使用 cfssl 工具生成 Kubernetes 客户端证书，通常用于用户身份验证（如通过 kubectl 访问集群）</span>cfssl gencert -ca=/etc/kubernetes/pki/ca.crt -ca-key=/etc/kubernetes/pki/ca.key -profile=kubernetes /etc/kubernetes/pki/devuser.json | cfssljson -bare devuser</code></pre><p>命令解析：</p><ul><li>-ca&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt ： 指定 CA 的公钥证书文件路径</li><li>-ca-key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.key ：指定 CA 的私钥文件路径</li><li>-profile&#x3D;kubernetes ： 指定证书的配置文件中的一个 profile（指定导出的证书给谁用，这里就是 kubernetes ）</li><li>&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;devuser.json : 指定生成证书的 CSR（证书签名请求）配置文件路径。</li><li>cfssljson -bare devuser : cfssljson 是 cfssl 的辅助工具，用于解析 JSON 格式的证书数据并生成 PEM 格式的证书和私钥文件</li><li>-bare : 指定输出文件的基本名称，不添加默认后缀（如 -cert 或 -key）<ul><li>作用：生成的证书和私钥文件将以 devuser.pem（证书）和 devuser-key.pem（私钥）的形式保存，而不是 devuser-cert.pem 或 devuser-key.pem。</li></ul></li><li>devuser : 指定输出文件的前缀名称<ul><li>作用：生成的证书文件命名为 devuser.pem，私钥文件命名为 devuser-key.pem。</li></ul></li></ul><h3 id="2-4-声明环境变量：-Kubernetes-API-服务器的地址"><a href="#2-4-声明环境变量：-Kubernetes-API-服务器的地址" class="headerlink" title="2.4 声明环境变量： Kubernetes API 服务器的地址"></a>2.4 声明环境变量： Kubernetes API 服务器的地址</h3><pre><code class="highlight bash"><span class="comment"># 192.168.6.139 是master节点 API 服务器所在的主机地址</span><span class="comment"># 端口：6443 是 Kubernetes API 服务器的默认端口，用于处理客户端请求（如 kubectl）</span><span class="built_in">export</span> KUBE_APISERVER=<span class="string">&quot;https://192.168.6.139:6443&quot;</span></code></pre><h3 id="2-5-设置集群参数"><a href="#2-5-设置集群参数" class="headerlink" title="2.5 设置集群参数"></a>2.5 设置集群参数</h3><p>在指定的 kubeconfig 文件中添加或更新一个名为 kubernetes 的集群配置，包含 API 服务器地址和 CA 证书等信息</p><pre><code class="highlight bash">kubectl config set-cluster kubernetes \--certificate-authority=/etc/kubernetes/pki/ca.crt \--embed-certs=<span class="literal">true</span> \--server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \--kubeconfig=/etc/kubernetes/pki/devuser.kubeconfig</code></pre><p><strong>命令解析：</strong></p><ul><li><p><code>config set-cluster kubernetes</code> </p><p>设置或更新一个集群条目，kubernetes 是当前集群的名称，可以通过命令： </p><pre><code class="highlight bash">$ kubectl config get-clusters</code></pre><p>查看</p></li><li><p>–certificate-authority&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</p><p>指定集群的 CA（证书颁发机构）证书文件路径</p></li><li><p>–embed-certs&#x3D;true</p><p>指定是否将 CA 证书的内容嵌入到 kubeconfig 文件中，嵌入证书后，kubeconfig 文件是自包含的，无需依赖外部 ca.crt 文件，方便分发（如给开发人员使用）。</p></li><li><p>–server&#x3D;${KUBE_APISERVER}</p><p>指定 Kubernetes API 服务器的地址。</p></li><li><p>–kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;devuser.kubeconfig</p><p>将设置的内容保存到 devuser.kubeconfig 文件中，如果文件不存在，命令会创建新的 devuser.kubeconfig 文件。</p></li></ul><p>命令执行成功后，可以通过命令：</p><pre><code class="highlight bash">$ <span class="built_in">cat</span> /etc/kubernetes/pki/devuser.kubeconfig</code></pre><p>查看文件内容</p><h3 id="2-6-设置客户端认证参数"><a href="#2-6-设置客户端认证参数" class="headerlink" title="2.6 设置客户端认证参数"></a>2.6 设置客户端认证参数</h3><p>配置 Kubernetes 的 kubeconfig 文件，为用户 devuser 添加凭证信息</p><pre><code class="highlight bash">kubectl config set-credentials devuser \--client-certificate=/etc/kubernetes/pki/devuser.pem \--client-key=/etc/kubernetes/pki/devuser-key.pem \--embed-certs=<span class="literal">true</span> \--kubeconfig=/etc/kubernetes/pki/devuser.kubeconfig</code></pre><p><strong>命令解析：</strong></p><ul><li><p>config set-credentials</p><p>用于在 kubeconfig 文件中设置或更新用户（user）凭证信息</p></li><li><p>–client-certificate&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;devuser.pem</p><p>指定客户端证书文件的路径。此证书用于向 Kubernetes API 服务器证明用户 devuser 的身份。证书的 CN（Common Name，通常为 devuser）和 O（Organization，例如 system:masters）会影响 RBAC 权限。</p></li><li><p>–client-key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;devuser-key.pem</p><p>指定客户端私钥文件的路径，私钥用于签名客户端请求，与证书一起完成 TLS 身份验证。</p></li><li><p>–embed-certs&#x3D;true</p><p>指定是否将证书和私钥的内容嵌入到 kubeconfig 文件中。true 表示将 devuser.pem 和 devuser-key.pem 的内容（Base64 编码的 PEM 数据）写入 kubeconfig，而不是仅引用文件路径。</p></li><li><p>–kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;devuser.kubeconfig</p><p>将设置的内容保存到 devuser.kubeconfig 文件中</p></li></ul><h3 id="2-7-设置上下文参数"><a href="#2-7-设置上下文参数" class="headerlink" title="2.7 设置上下文参数"></a>2.7 设置上下文参数</h3><p>配置 Kubernetes 的 kubeconfig 文件，为用户 devuser 设置一个上下文（context），以便访问特定的集群和命名空间。</p><pre><code class="highlight bash">kubectl config set-context kubernetes \--cluster=kubernetes \--user=devuser \--namespace=dev \--kubeconfig=/etc/kubernetes/pki/devuser.kubeconfig</code></pre><p><strong>命令解析：</strong></p><ul><li><p>config set-context</p><p>kubectl config set-context 用于在 kubeconfig 文件中设置或更新一个上下文（context）。上下文定义了用户、集群和命名空间的组合，用于指定 kubectl 的操作环境。</p><p>kubernetes 是上下文的名称（可以自定义）。</p></li><li><p>–cluster&#x3D;kubernetes</p><p>指定上下文关联的集群名称，注意：集群名称必须与 kubeconfig 文件中 clusters 部分的 name 字段匹配</p></li><li><p>–user&#x3D;devuser</p><p>指定上下文关联的用户名称，注意：用户名称必须与 kubeconfig 文件中 users 部分的 name 字段匹配。</p></li><li><p>–namespace&#x3D;dev</p><p>指定上下文的默认命名空间，如果不指定 –namespace，默认使用 default 命名空间。确保 dev 命名空间存在（可用 kubectl get namespaces 检查）。</p></li></ul><h3 id="2-8-给用户授权"><a href="#2-8-给用户授权" class="headerlink" title="2.8 给用户授权"></a>2.8 给用户授权</h3><pre><code class="highlight bash">kubectl create rolebinding devuser-admin-binding --clusterrole=admin --user=devuser --namespace=dev<span class="comment"># 命令转换成资源清单</span>$ kubectl create rolebinding devuser-admin-binding --clusterrole=admin --user=devuser --namespace=dev --dry-run -o yamlW0614 17:49:28.687292 2342317 helpers.go:704] --dry-run is deprecated and can be replaced with --dry-run=client.apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata:  creationTimestamp: null  name: devuser-admin-binding  namespace: devroleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: adminsubjects:- apiGroup: rbac.authorization.k8s.io  kind: User  name: devuser</code></pre><p>命令解析：创建角色绑定（devuser-admin-binding），绑定到集群角色admin(系统默认存在的角色)， 绑定用户 devuser, 绑定到名称空间 dev。</p><h3 id="2-9-设置默认上下文"><a href="#2-9-设置默认上下文" class="headerlink" title="2.9 设置默认上下文"></a>2.9 设置默认上下文</h3><p>这条命令使用 kubectl config use-context 设置 Kubernetes 的 kubeconfig 文件中的默认上下文，以便 kubectl 使用指定的上下文进行操作。</p><p>在 devuser.kubeconfig 文件中将 current-context 设置为 kubernetes，使后续的 kubectl 命令使用该上下文的配置。</p><pre><code class="highlight bash">kubectl config use-context kubernetes --kubeconfig=/etc/kubernetes/pki/devuser.kubeconfig</code></pre><p>确保 kubectl 默认使用正确的集群（kubernetes）、用户（devuser）和命名空间（dev），无需每次手动指定 –kubeconfig 或 –context。</p><h3 id="2-10-测试-root-用户使用-devuser-kubeconfig-文件操作集群"><a href="#2-10-测试-root-用户使用-devuser-kubeconfig-文件操作集群" class="headerlink" title="2.10 测试 root 用户使用 devuser.kubeconfig 文件操作集群"></a>2.10 测试 root 用户使用 devuser.kubeconfig 文件操作集群</h3><pre><code class="highlight bash"><span class="comment"># 1. 将原有的kubeconfig 文件移除</span>$ <span class="built_in">mv</span> /root/.kube/config /root/<span class="comment"># 2. 将新建的 devuser.kubeconfig 放到 root 目录下</span>$ <span class="built_in">cp</span> -a /etc/kubernetes/pki/devuser.kubeconfig /root/.kube/config<span class="comment"># kubelet 命令</span>$ kubectl get podsNo resources found <span class="keyword">in</span> dev namespace.<span class="comment"># 创建 deploy</span>$ kubectl create deployment dev-deploy --image=wangyanglinux/myapp:v1.0deployment.apps/dev-deploy created$ kubectl get podsNAME                         READY   STATUS    RESTARTS   AGEdev-deploy-d7448d978-c8jkm   1/1     Running   0          10s</code></pre><h2 id="3-将-linux-用户与-k8s-用户绑定（非必须）"><a href="#3-将-linux-用户与-k8s-用户绑定（非必须）" class="headerlink" title="3. 将 linux 用户与 k8s 用户绑定（非必须）"></a>3. 将 linux 用户与 k8s 用户绑定（非必须）</h2><h3 id="3-1-创建-linux-用户"><a href="#3-1-创建-linux-用户" class="headerlink" title="3.1 创建 linux 用户"></a>3.1 创建 linux 用户</h3><pre><code class="highlight bash">$ useradd dev$ passwd dev</code></pre><h3 id="3-2-将-devuser-kubeconfig-文件放到新建用户的-家目录-中"><a href="#3-2-将-devuser-kubeconfig-文件放到新建用户的-家目录-中" class="headerlink" title="3.2 将 devuser.kubeconfig 文件放到新建用户的 家目录 中"></a>3.2 将 devuser.kubeconfig 文件放到新建用户的 家目录 中</h3><pre><code class="highlight bash"><span class="comment"># 创建文件目录</span>$ <span class="built_in">mkdir</span> /home/dev/.kube<span class="comment"># 将devuser.kubeconfig文件放到 dev 用户的家目录中</span>$ <span class="built_in">mv</span> /etc/kubernetes/pki/devuser.kubeconfig /home/dev/.kube/config<span class="comment"># 文件授权</span><span class="built_in">chown</span> -R dev:dev /home/dev/.kube</code></pre><h3 id="3-3-shell-使用-dev-用户登录测试"><a href="#3-3-shell-使用-dev-用户登录测试" class="headerlink" title="3.3 shell 使用 dev 用户登录测试"></a>3.3 shell 使用 dev 用户登录测试</h3><pre><code class="highlight bash">[dev@k8s-master01 ~]$ kubectl get podsNAME                         READY   STATUS    RESTARTS   AGEdev-deploy-d7448d978-c8jkm   1/1     Running   0          8m32s</code></pre><h1 id="四、补充"><a href="#四、补充" class="headerlink" title="四、补充"></a>四、补充</h1><h2 id="1-资源与角色类型的匹配"><a href="#1-资源与角色类型的匹配" class="headerlink" title="1. 资源与角色类型的匹配"></a>1. 资源与角色类型的匹配</h2><table><thead><tr><th>访问的资源</th><th>使用的角色类型</th><th>使用的绑定类型</th></tr></thead><tbody><tr><td>集群级别的资源（Namespace、Node、ClusterRole、ClusterRoleBinding、PersistentVolume (PV)、StorageClass 等）</td><td>ClusterRole</td><td>ClusterRoleBinding</td></tr><tr><td>非资源型URL（&#x2F;api、&#x2F;apis、&#x2F;apis&#x2F;<group>&#x2F;<version> 、&#x2F;healthz、&#x2F;livez、&#x2F;readyz、&#x2F;logs、&#x2F;metrics 等）</td><td>ClusterRole</td><td>ClusterRoleBinding</td></tr><tr><td>在任何命名空间中的资源（和跨所有命名空间的资源）</td><td>ClusterRole</td><td>ClusterRoleBinding</td></tr><tr><td>在具体命名空间中的资源（在多个命名空间中重用这个相同的ClusterRole)</td><td>ClusterRole</td><td>RoleBinding</td></tr><tr><td>在具体命名空间中的资源(Role必须在每个命名空间中定义好），例如：Pod、Deployment、ReplicaSet、StatefulSet、DaemonSet、Job、CronJob、Service、Ingress、ConfigMap、Secret、ServiceAccount、Role、RoleBinding、PersistentVolumeClaim (PVC)、NetworkPolicy、HorizontalPodAutoscaler (HPA)、Event、LimitRange、ResourceQuota</td><td>Role</td><td>RoleBinding</td></tr></tbody></table><h2 id="2-常见的预定义角色"><a href="#2-常见的预定义角色" class="headerlink" title="2. 常见的预定义角色"></a>2. 常见的预定义角色</h2><ul><li>view（ClusterRole）<ul><li>允许读取一个命名空间中的大多数资源， 除了Role、 RoleBinding 和 Secret</li></ul></li><li>edit（ClusterRole）<ul><li>允许读取和修改 Secret。 但是，它也不允许查看或修改 Role 和 RoleBinding, 这是为了防止权限扩散。</li></ul></li><li>admin（ClusterRole）<ul><li>一个命名空间中的资源的完全控制权是由 admin ClusterRole 赋予的。 有这个 ClusterRole 的主体可以读取和修改命名空间中的任何资源， 除了 ResourceQuota 和命名空间资源本身。 edit 和 admin ClusterRole  之间的主要区别是能否在命名空间中查看和修改 Role 和 RoleBinding。</li></ul></li><li>cluster-admin（ClusterRole）<ul><li>通过将 cluster-admin ClusterRole 赋给主体， 主体可以获得 Kubernetes 集群完全控制的权限</li></ul></li></ul><h1 id="五、准入控制"><a href="#五、准入控制" class="headerlink" title="五、准入控制"></a>五、准入控制</h1><p>Kubernetes（k8s）中的准入控制（Admission Control）是 Kubernetes API 服务器在处理请求（创建、更新、删除等）时，用于验证和修改资源对象的机制。它是 Kubernetes 扩展性和安全性的重要组成部分，允许管理员在资源对象被持久化到 etcd 之前对其进行检查或修改。准入控制通过准入控制器（Admission Controllers）和准入 webhook 实现。</p><h2 id="1-什么是准入控制？"><a href="#1-什么是准入控制？" class="headerlink" title="1. 什么是准入控制？"></a>1. 什么是准入控制？</h2><p>准入控制是 Kubernetes API 服务器在处理 API 请求时的一个阶段，位于 <strong>认证（Authentication）和授权（Authorization）</strong> 之后，但在对象持久化到 etcd 之前。它的主要作用是：</p><ul><li>验证（Validation）：检查请求是否符合特定的规则或策略（如资源配额、命名规范）。</li><li>修改（Mutation）：动态修改请求的资源对象（如自动添加标签、设置默认值）。</li><li>防止不符合策略的资源被创建或更新，确保集群的安全性、合规性和一致性。</li></ul><p>准入控制分为两个阶段：</p><ul><li>Mutating 阶段：修改资源对象的阶段，允许对请求的资源进行更改。</li><li>Validating 阶段：验证资源对象的阶段，决定是否允许请求通过。</li></ul><h2 id="2-准入控制的类型"><a href="#2-准入控制的类型" class="headerlink" title="2. 准入控制的类型"></a>2. 准入控制的类型</h2><p>Kubernetes 提供了两类准入控制机制：</p><h3 id="2-1-内置准入控制器（Admission-Controllers）"><a href="#2-1-内置准入控制器（Admission-Controllers）" class="headerlink" title="2.1 内置准入控制器（Admission Controllers）"></a>2.1 内置准入控制器（Admission Controllers）</h3><p>Kubernetes 提供了一系列内置的准入控制器，这些控制器是 API 服务器的静态插件，可以通过 API 服务器的启动参数 –enable-admission-plugins 启用或禁用。每个控制器负责特定的验证或修改逻辑。</p><p>常见的内置准入控制器包括：</p><ul><li><strong>NamespaceLifecycle</strong>：确保删除中的命名空间不能创建新资源，防止已删除命名空间的资源被访问。</li><li><strong>LimitRange</strong>：强制执行命名空间中的资源限制（如 CPU、内存）。</li><li><strong>ResourceQuota</strong>：确保命名空间的资源使用量不超过配额。</li><li><strong>PodSecurity</strong>：强制执行 Pod 安全策略（如限制特权容器）。</li><li><strong>DefaultStorageClass</strong>：为没有指定存储类的 PVC 设置默认 StorageClass。</li><li><strong>DefaultTolerationSeconds</strong>：为 Pod 设置默认的容忍时间（taint toleration）。</li><li><strong>MutatingAdmissionWebhook</strong>：调用外部 Mutating Webhook。</li><li><strong>ValidatingAdmissionWebhook</strong>：调用外部 Validating Webhook。</li><li><strong>NodeRestriction</strong>：限制 kubelet 能修改的资源，增强节点安全性。</li><li><strong>ImagePolicyWebhook</strong>：通过外部 webhook 验证容器镜像。</li><li><strong>ServiceAccount</strong>：自动为 Pod 分配 ServiceAccount。</li><li><strong>AlwaysPullImages</strong>：强制容器镜像总是拉取最新版本。</li></ul><h3 id="2-2-准入-Webhook（Admission-Webhooks）"><a href="#2-2-准入-Webhook（Admission-Webhooks）" class="headerlink" title="2.2 准入 Webhook（Admission Webhooks）"></a>2.2 准入 Webhook（Admission Webhooks）</h3><p>准入 webhook 是一种动态扩展机制，允许用户定义自定义的准入控制逻辑。Webhook 是一个外部 HTTP 服务，API 服务器会向其发送请求以验证或修改资源对象。Webhook 分为两类：</p><ul><li><strong>MutatingAdmissionWebhook</strong>：修改资源对象，例如添加标签、注入 sidecar 容器（如 Istio 的代理容器）。</li><li><strong>ValidatingAdmissionWebhook</strong>：验证资源对象，拒绝不符合策略的请求。</li></ul><p>Webhook 通常用于实现复杂的自定义逻辑，例如：</p><ul><li>强制执行组织的安全策略。</li><li>自动注入配置或 sidecar。</li><li>检查资源是否符合特定的合规性要求。</li></ul><h3 id="2-3-新引入的准入策略（Kubernetes-1-30-）"><a href="#2-3-新引入的准入策略（Kubernetes-1-30-）" class="headerlink" title="2.3 新引入的准入策略（Kubernetes 1.30+）"></a>2.3 新引入的准入策略（Kubernetes 1.30+）</h3><p>从 Kubernetes 1.30 开始，引入了 <code>ValidatingAdmissionPolicy</code> 和 <code>MutatingAdmissionPolicy</code>，作为一种更结构化的准入控制方式。这些策略使用 Common Expression Language (CEL) 定义规则，相比 webhook 更轻量且无需外部服务。它们是集群级别的资源，适合定义简单的验证或修改逻辑。</p><h2 id="3-准入控制的工作流程"><a href="#3-准入控制的工作流程" class="headerlink" title="3. 准入控制的工作流程"></a>3. 准入控制的工作流程</h2><p>当 Kubernetes API 服务器收到一个请求（如创建 Pod），会按照以下步骤处理：</p><ol><li><strong>认证（Authentication）</strong>：验证请求者的身份。</li><li><strong>授权（Authorization）</strong>：检查请求者是否有权限执行操作。</li><li><strong>准入控制（Admission Control）</strong>：<ul><li><strong>Mutating 阶段</strong>：按顺序调用所有启用的 Mutating 准入控制器和 Mutating Webhook，修改资源对象。</li><li><strong>Validating 阶段</strong>：按顺序调用所有启用的 Validating 准入控制器和 Validating Webhook，验证资源对象。</li><li>如果任一 Validating 控制器拒绝请求，请求失败并返回错误。</li></ul></li><li><strong>持久化</strong>：通过验证的资源对象被写入 etcd。</li></ol><p><strong>注意</strong>：</p><ul><li>Mutating 阶段先于 Validating 阶段执行。</li><li>准入控制器的执行顺序由 –enable-admission-plugins 参数指定。</li><li>如果任何 Validating 控制器返回拒绝，请求会被阻止。</li></ul><h2 id="4-常见用例"><a href="#4-常见用例" class="headerlink" title="4. 常见用例"></a>4. 常见用例</h2><p>准入控制在 Kubernetes 中有广泛的应用场景，包括但不限于：</p><ul><li><p><strong>安全性</strong>：</p><ul><li><p>使用 PodSecurity 限制特权容器或不安全的配置。</p></li><li><p>使用 ImagePolicyWebhook 限制 Pod 只能使用来自可信镜像仓库的镜像。</p></li></ul></li><li><p><strong>资源管理</strong>：</p><ul><li><p>使用 ResourceQuota 和 LimitRange 限制命名空间的资源使用。</p></li><li><p>使用 DefaultStorageClass 为 PVC 自动分配存储类。</p></li></ul></li><li><p><strong>自动化配置</strong>：</p><ul><li><p>使用 Mutating Webhook 自动为 Pod 注入 sidecar 容器（如日志收集代理）。</p></li><li><p>自动为资源添加标签或注释。</p></li></ul></li><li><p><strong>合规性</strong>：</p><ul><li><p>使用 Validating Webhook 确保资源符合组织策略（如强制使用特定的标签或命名规范）。</p></li><li><p>使用 ValidatingAdmissionPolicy 检查 Pod 是否满足安全合规要求。</p></li></ul></li><li><p><strong>服务网格</strong>：</p><ul><li>Istio 或 Linkerd 使用 Mutating Webhook 自动为 Pod 注入代理容器。</li></ul></li></ul><p>参考链接：</p><blockquote><p><a href="https://www.cnblogs.com/zhanglianghhh/p/14128332.html">https://www.cnblogs.com/zhanglianghhh/p/14128332.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、K8S认证与授权&quot;&gt;&lt;a href=&quot;#一、K8S认证与授权&quot; class=&quot;headerlink&quot; title=&quot;一、K8S认证与授权&quot;&gt;&lt;/a&gt;一、K8S认证与授权&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubuserconten</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
</feed>
