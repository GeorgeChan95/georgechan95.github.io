<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>George&#39;s Blog</title>
  
  <subtitle>个人邮箱：george_95@126.com</subtitle>
  <link href="https://georgechan95.github.io/atom.xml" rel="self"/>
  
  <link href="https://georgechan95.github.io/"/>
  <updated>2025-09-08T12:30:31.296Z</updated>
  <id>https://georgechan95.github.io/</id>
  
  <author>
    <name>George</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>002-安装Python开发环境</title>
    <link href="https://georgechan95.github.io/blog/7591dd09.html"/>
    <id>https://georgechan95.github.io/blog/7591dd09.html</id>
    <published>2025-09-08T12:22:00.000Z</published>
    <updated>2025-09-08T12:30:31.296Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、下载Python开发环境"><a href="#一、下载Python开发环境" class="headerlink" title="一、下载Python开发环境"></a>一、下载Python开发环境</h1><ul><li>官网：<a href="https://www.python.org/">https://www.python.org/</a></li><li>文档下载地址：<a href="https://www.python.org/doc/">https://www.python.org/doc/</a></li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/07/20250907-104643.png" alt="Python官网"></p><p>下载地址： <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></p><p>历史版本下载：<a href="https://www.python.org/downloads/windows/">https://www.python.org/downloads/windows/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/07/20250907-104733.png" alt="找到下载的Python版本"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/07/20250907-104943.png" alt="选择Window64位安装包"></p><h1 id="二、安装Python开发环境"><a href="#二、安装Python开发环境" class="headerlink" title="二、安装Python开发环境"></a>二、安装Python开发环境</h1><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201043.png" alt="选择自定义安装"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201244.png" alt="默认勾选全部选项，然后Next"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201528.png" alt="自定义安装路径，并为所有用户安装"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201506.png" alt="安装进行中"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201750.png" alt="安装完成"></p><h1 id="三、验证Python开发环境是否安装成功"><a href="#三、验证Python开发环境是否安装成功" class="headerlink" title="三、验证Python开发环境是否安装成功"></a>三、验证Python开发环境是否安装成功</h1><p>打开命令行，输入命令：</p><pre><code class="highlight powershell">C:\Users\kd&gt;pythonPython <span class="number">3.12</span>.<span class="number">0</span> (tags/v3.<span class="number">12.0</span>:<span class="number">0</span>fb18b0, Oct  <span class="number">2</span> <span class="number">2023</span>, <span class="number">13</span>:<span class="number">03</span>:<span class="number">39</span>) [<span class="type">MSC</span> <span class="type">v.1935</span> <span class="number">64</span> <span class="type">bit</span> (<span class="type">AMD64</span>)] on win32<span class="built_in">Type</span> <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> or <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.&gt;&gt;&gt;</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/09/08/20250908-201910.png" alt="image-20250908201909767"></p><p>成功打印了 Python 版本号，开发环境安装成功！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、下载Python开发环境&quot;&gt;&lt;a href=&quot;#一、下载Python开发环境&quot; class=&quot;headerlink&quot; title=&quot;一、下载Python开发环境&quot;&gt;&lt;/a&gt;一、下载Python开发环境&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;官网：&lt;a href=&quot;http</summary>
      
    
    
    
    <category term="Python" scheme="https://georgechan95.github.io/categories/Python/"/>
    
    
    <category term="Python" scheme="https://georgechan95.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>001-Python语言概述</title>
    <link href="https://georgechan95.github.io/blog/95026633.html"/>
    <id>https://georgechan95.github.io/blog/95026633.html</id>
    <published>2025-09-07T02:44:00.000Z</published>
    <updated>2025-09-08T12:30:31.294Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、Python-简介"><a href="#一、Python-简介" class="headerlink" title="一、Python 简介"></a>一、Python 简介</h1><p><em>Python 是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言。</em></p><p><em>Python 的设计具有很强的可读性，相比其他语言经常使用英文关键字，其他语言的一些标点符号，它具有比其他语言更有特色语法结构。</em></p><ul><li><strong>Python 是一种解释型语言：</strong> 这意味着开发过程中没有了编译这个环节。类似于PHP和Perl语言。</li><li><strong>Python 是交互式语言：</strong> 这意味着，您可以在一个 Python 提示符 <strong>&gt;&gt;&gt;</strong> 后直接执行代码。</li><li><strong>Python 是面向对象语言:</strong> 这意味着Python支持面向对象的风格或代码封装在对象的编程技术。</li><li><strong>Python 是初学者的语言：</strong>Python 对初级程序员而言，是一种伟大的语言，它支持广泛的应用程序开发，从简单的文字处理到 WWW 浏览器再到游戏。</li></ul><h1 id="二、Python-发展历史"><a href="#二、Python-发展历史" class="headerlink" title="二、Python 发展历史"></a>二、Python 发展历史</h1><p>Python 是由 Guido van Rossum 在八十年代末和九十年代初，在荷兰国家数学和计算机科学研究所设计出来的。</p><p>Python 本身也是由诸多其他语言发展而来的,这包括 ABC、Modula-3、C、C++、Algol-68、SmallTalk、Unix shell 和其他的脚本语言等等。</p><p>像 Perl 语言一样，Python 源代码同样遵循 GPL(GNU General Public License)协议。</p><p>现在 Python 是由一个核心开发团队在维护，Guido van Rossum 仍然占据着至关重要的作用，指导其进展。</p><p>Python 2.7 被确定为最后一个 Python 2.x 版本，它除了支持 Python 2.x 语法外，还支持部分 Python 3.1 语法。</p><h1 id="三、Python-特点"><a href="#三、Python-特点" class="headerlink" title="三、Python 特点"></a>三、Python 特点</h1><ul><li><strong>1.易于学习：</strong>Python 有相对较少的关键字，结构简单，和一个明确定义的语法，学习起来更加简单。</li><li><strong>2.易于阅读：</strong>Python 代码定义的更清晰。</li><li><strong>3.易于维护：</strong>Python的 成功在于它的源代码是相当容易维护的。</li><li><strong>4.一个广泛的标准库：</strong>Python 的最大的优势之一是丰富的库，跨平台的，在 UNIX、Windows 和 Mac 兼容很好。</li><li><strong>5.互动模式：</strong>互动模式的支持，您可以从终端输入执行代码并获得结果的语言，互动的测试和调试代码片段。</li><li><strong>6.可移植：</strong>基于其开放源代码的特性，Python 已经被移植（也就是使其工作）到许多平台。</li><li><strong>7.可扩展：</strong>如果你需要一段运行很快的关键代码，或者是想要编写一些不愿开放的算法，你可以使用 C 或 C++ 完成那部分程序，然后从你的 Python 程序中调用。</li><li><strong>8.数据库：</strong>Python 提供所有主要的商业数据库的接口。</li><li><strong>9.GUI 编程：</strong>Python 支持 GUI 可以创建和移植到许多系统调用。</li><li><strong>10.可嵌入:</strong> 你可以将 Python 嵌入到 C&#x2F;C++ 程序，让你的程序的用户获得”脚本化”的能力。</li></ul><p><strong>参考链接</strong></p><blockquote><p><a href="https://www.runoob.com/python/python-intro.html">https://www.runoob.com/python/python-intro.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、Python-简介&quot;&gt;&lt;a href=&quot;#一、Python-简介&quot; class=&quot;headerlink&quot; title=&quot;一、Python 简介&quot;&gt;&lt;/a&gt;一、Python 简介&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Python 是一个高层次的结合了解释性、编译性、互动性和面</summary>
      
    
    
    
    <category term="Python" scheme="https://georgechan95.github.io/categories/Python/"/>
    
    
    <category term="Python" scheme="https://georgechan95.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>021-K8S-安全参数</title>
    <link href="https://georgechan95.github.io/blog/e2c03adc.html"/>
    <id>https://georgechan95.github.io/blog/e2c03adc.html</id>
    <published>2025-08-23T06:43:00.000Z</published>
    <updated>2025-09-06T08:19:42.939Z</updated>
    
    <content type="html"><![CDATA[<p><strong>集群环境</strong></p><table><thead><tr><th>IP</th><th>Hostname</th><th>用途</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td><td>Master节点</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td><td>Node节点</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td><td>Node节点</td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td><td>Node节点</td></tr></tbody></table><h1 id="一、配置容器级别的安全控制"><a href="#一、配置容器级别的安全控制" class="headerlink" title="一、配置容器级别的安全控制"></a>一、配置容器级别的安全控制</h1><h2 id="1-共享主机网络"><a href="#1-共享主机网络" class="headerlink" title="1. 共享主机网络"></a>1. 共享主机网络</h2><p>通常情况下，Pod中的容器会使用 Kubernetes 网络插件提供的网络，这些插件确保了 Pod 之间的网络通信。然而，有时候可能需要 Pod 直接使用主机（节点）的网络，直接使用主机的IP地址和端口，可以通过在 Pod 的配置中设置 <code>hostNetwork: true</code> 来实现。</p><p>直接使用主机网络可以减少网络转发的开销，提高网络性能，但同时也需要注意Pod直接使用主机端口可能会存在部分冲突。</p><h3 id="1-1-案例"><a href="#1-1-案例" class="headerlink" title="1.1 案例"></a>1.1 案例</h3><p>资源清单：<code>host-network.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">nodeName:</span> <span class="string">k8s-master01</span> <span class="comment"># 选择 Pod 运行的节点的名字</span>      <span class="attr">hostNetwork:</span> <span class="literal">true</span> <span class="comment"># 主机共享网络</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f host-network.yaml<span class="comment"># 查看Pod详情</span>$ kubectl get pods -o wideNAME                     READY   STATUS    RESTARTS   AGE   IP            NODE           NOMINATED NODE   READINESS GATESnginx-76985c7d59-pzlpk   1/1     Running   0          11s   10.20.1.139   k8s-master01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 使用物理机IP访问Nginx</span>$ curl http://10.20.1.139:80&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="1-2-hostNetwork-使用注意事项"><a href="#1-2-hostNetwork-使用注意事项" class="headerlink" title="1.2 hostNetwork 使用注意事项"></a>1.2 hostNetwork 使用注意事项</h3><p>Pod 直接使用主机的网络会占用宿主机的端口，Pod 的 IP 就是宿主机的 IP，使用时需要考虑是否与主机上的端口冲突，因此一般情况下除非某个特定应用必须占用宿主机上的特定端口，否则不建议使用主机网络。</p><p>由于Pod使用主机网络，访问Pod需要直接通过节点端口，因此要 <strong>注意放通节点安全组端口</strong> ，否则会出现访问不通的情况。</p><p>另外由于占用主机端口，使用 Deployment 部署 hostNetwork 类型 Pod 时，要注意 <strong>Pod的副本数不要超过节点数量</strong> ，否则会导致一个节点上调度了多个Pod，Pod 启动时端口冲突无法创建。例如上面例子中的 nginx，如果服务数为 2，并部署在只有1个节点的集群上，就会有一个Pod无法创建，查询Pod日志会发现是由于端口占用导致 nginx 无法启动。</p><p><strong>请避免在同一个节点上调度多个使用主机网络的 Pod，否则在创建 ClusterIP 类型的 Service 访问 Pod 时，会出现访问 ClusterIP 不通的情况。</strong></p><h2 id="2-共享主机端口"><a href="#2-共享主机端口" class="headerlink" title="2. 共享主机端口"></a>2. 共享主机端口</h2><p>在 Kubernetes 中，hostPort 是一种用于将主机上的特定端口映射到运行在 Pod 内部容器的端口的配置选项。通过使用 hostPort，你可以在主机上暴露容器的服务，从而允许外部网络通过主机的 IP 地址和指定的端口访问容器内的应用程序。</p><h3 id="2-1-案例"><a href="#2-1-案例" class="headerlink" title="2.1 案例"></a>2.1 案例</h3><p>资源清单：<code>host-port.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">hostPort:</span> <span class="number">8080</span> <span class="comment"># 主机端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f host-port.yaml deployment.apps/nginx created<span class="comment"># 查看Pod运行情况</span>$ kubectl get pods -o wideNAME                    READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnginx-585b8dd6d-9tzl6   1/1     Running   0          8s    171.20.85.209   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 通过Pod运行节点的物理机IP和映射端口 8080 访问Nginx</span>$ curl 10.20.1.140:8080&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="2-2-hostPort-与-NodePort-的区别"><a href="#2-2-hostPort-与-NodePort-的区别" class="headerlink" title="2.2 hostPort 与 NodePort 的区别"></a>2.2 hostPort 与 NodePort 的区别</h3><p>hostPort 与 NodePort 的区别是，NodePort 服务默认是把请求转发到随机的一个运行的 Pod 上，而 hostPort 是直接转发到本 Node 上的指定 Pod。</p><table><thead><tr><th>特性</th><th>nodePort（Service）</th><th>hostPort（Pod）</th></tr></thead><tbody><tr><td>作用范围</td><td>集群所有节点</td><td>单个Pod所在节点</td></tr><tr><td>端口范围</td><td>默认30000-32767（可配置）</td><td>任意可用端口</td></tr><tr><td>安全性</td><td>推荐生产环境使用</td><td>存在端口冲突风险</td></tr><tr><td>负载均衡</td><td>自动负载均衡</td><td>需手动实现负载均衡</td></tr></tbody></table><h3 id="2-3-注意事项"><a href="#2-3-注意事项" class="headerlink" title="2.3 注意事项"></a>2.3 注意事项</h3><p>一个 Node 只能启动一个 hostPort，所以最初是用于把守护进程集（DaemonSets）部署到每个 Node (确保一个 Node 只有一个 hostPort )。如下图所示，3个 Node 上部署4个带 hostPort 的 Pod，会有一个不成功。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/23/20250823-162900.png" alt="每个Node节点只能运行一个 hostPort"></p><p>即便是3个 Node 上部署3个带 hostPort 的 Pod 滚动升级时也会有问题，所以使用 hostPort 的服务在升级的时候一定要保障先停掉旧版本的 Pod 实例再启动新版本的 Pod 实例。</p><h2 id="3-共享主机IPC和PID"><a href="#3-共享主机IPC和PID" class="headerlink" title="3. 共享主机IPC和PID"></a>3. 共享主机IPC和PID</h2><ul><li><p>PID</p><ul><li><p>当 Pod 的 hostPID 设置为 true 时，Pod 内的容器将与宿主机共享相同的 PID 命名空间。这意味着容器可以看到宿主机上运行的所有进程（通过 ps 命令等），并且可以与宿主机的进程进行交互（例如发送信号）。</p></li><li><p>使用场景：常用于需要监控或管理宿主机进程的场景，例如运行监控代理或安全工具。</p></li></ul></li><li><p>IPC</p><ul><li>当 Pod 的 hostIPC 设置为 true 时，Pod 内的容器将与宿主机共享相同的 IPC（进程间通信）命名空间，允许容器使用宿主机的 IPC 机制。这意味着容器内的进程可以直接访问宿主机的 IPC 资源（例如宿主机的共享内存、消息队列等），也可以与宿主机上的进程或其他共享同一 IPC 命名空间的容器进程进行通信。</li></ul></li></ul><h3 id="3-1-案例"><a href="#3-1-案例" class="headerlink" title="3.1 案例"></a>3.1 案例</h3><p>资源清单：<code>host-ipc-pid.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-ipc-pid</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx-ipc-pid</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx-ipc-pid</span>    <span class="attr">spec:</span>      <span class="attr">hostIPC:</span> <span class="literal">true</span> <span class="comment"># 主机共享 IPC 命名空间</span>      <span class="attr">hostPID:</span> <span class="literal">true</span> <span class="comment"># 主机共享 PID 命名空间</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Deployment</span>$ kubectl apply -f host-ipc-pid.yaml<span class="comment"># 查看Pod运行详情</span>$ kubectl get pods -o wideNAME                            READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnginx-ipc-pid-d9f877dbd-hq2vp   1/1     Running   0          14s   171.20.85.210   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 进入容器</span>$ kubectl <span class="built_in">exec</span> -it nginx-ipc-pid-d9f877dbd-hq2vp -- /bin/bash<span class="comment"># 在容器内查看进程，可以看到，把系统进程也一并打印出来了</span>root@nginx-ipc-pid-d9f877dbd-hq2vp:/<span class="comment"># ls -l /proc/</span>total 0drwxrwxrwt  2 root  root    40 Sep  6 02:19 acpi-r--r--r--  1 root  root     0 Sep  6 02:38 bootconfig-r--r--r--  1 root  root     0 Sep  6 02:38 buddyinfodr-xr-xr-x  4 root  root     0 Sep  6 02:19 bus-r--r--r--  1 root  root     0 Sep  6 02:38 cgroups-r--r--r--  1 root  root     0 Sep  6 02:38 cmdline-r--r--r--  1 root  root     0 Sep  6 02:38 consoles-r--r--r--  1 root  root     0 Sep  6 02:38 cpuinfo-r--r--r--  1 root  root     0 Sep  6 02:38 crypto-r--r--r--  1 root  root     0 Sep  6 02:38 devices-r--r--r--  1 root  root     0 Sep  6 02:38 diskstats-r--r--r--  1 root  root     0 Sep  6 02:38 dmadr-xr-xr-x  4 root  root     0 Sep  6 02:38 driverdr-xr-xr-x  3 root  root     0 Sep  6 02:38 dynamic_debug-r--r--r--  1 root  root     0 Sep  6 02:38 execdomains-r--r--r--  1 root  root     0 Sep  6 02:38 fb-r--r--r--  1 root  root     0 Sep  6 02:19 filesystemsdr-xr-xr-x  4 root  root     0 Sep  6 02:19 fs-r--r--r--  1 root  root     0 Sep  6 02:38 interrupts-r--r--r--  1 root  root     0 Sep  6 02:38 iomem-r--r--r--  1 root  root     0 Sep  6 02:38 ioportsdr-xr-xr-x 35 root  root     0 Sep  6 02:19 irq-r--r--r--  1 root  root     0 Sep  6 02:38 kallsymscrw-rw-rw-  1 root  root  1, 3 Sep  6 02:19 kcore-r--r--r--  1 root  root     0 Sep  6 02:38 key-userscrw-rw-rw-  1 root  root  1, 3 Sep  6 02:19 keys-r--------  1 root  root     0 Sep  6 02:38 kmsg-r--------  1 root  root     0 Sep  6 02:38 kpagecgroup-r--------  1 root  root     0 Sep  6 02:38 kpagecount-r--------  1 root  root     0 Sep  6 02:38 kpageflags-r--r--r--  1 root  root     0 Sep  6 02:38 loadavg-r--r--r--  1 root  root     0 Sep  6 02:38 locks-r--r--r--  1 root  root     0 Sep  6 02:38 mdstat-r--r--r--  1 root  root     0 Sep  6 02:38 meminfo-r--r--r--  1 root  root     0 Sep  6 02:38 misc-r--r--r--  1 root  root     0 Sep  6 02:38 moduleslrwxrwxrwx  1 root  root    11 Sep  6 02:38 mounts -&gt; self/mounts-rw-r--r--  1 root  root     0 Sep  6 02:38 mtrrlrwxrwxrwx  1 root  root     8 Sep  6 02:19 net -&gt; self/net-r--------  1 root  root     0 Sep  6 02:38 pagetypeinfo-r--r--r--  1 root  root     0 Sep  6 02:38 partitions-r--r--r--  1 root  root     0 Sep  6 02:38 schedstatdrwxrwxrwt  2 root  root    40 Sep  6 02:19 scsilrwxrwxrwx  1 root  root     0 Sep  6 02:19 self -&gt; 3214631-r--------  1 root  root     0 Sep  6 02:38 slabinfo-r--r--r--  1 root  root     0 Sep  6 02:38 softirqs-r--r--r--  1 root  root     0 Sep  6 02:38 <span class="built_in">stat</span>-r--r--r--  1 root  root     0 Sep  6 02:38 swapsdr-xr-xr-x  1 root  root     0 Sep  6 02:19 sys--w-------  1 root  root     0 Sep  6 02:19 sysrq-triggerdr-xr-xr-x  5 root  root     0 Sep  6 02:38 sysvipclrwxrwxrwx  1 root  root     0 Sep  6 02:19 thread-self -&gt; 3214631/task/3214631crw-rw-rw-  1 root  root  1, 3 Sep  6 02:19 timer_listdr-xr-xr-x  6 root  root     0 Sep  6 02:38 <span class="built_in">tty</span>-r--r--r--  1 root  root     0 Sep  6 02:38 <span class="built_in">uptime</span>-r--r--r--  1 root  root     0 Sep  6 02:38 version-r--------  1 root  root     0 Sep  6 02:38 vmallocinfo-r--r--r--  1 root  root     0 Sep  6 02:38 vmstat-r--r--r--  1 root  root     0 Sep  6 02:38 zoneinfo</code></pre><h3 id="3-2-Linux-Namespace-中的-IPC-是什么-？"><a href="#3-2-Linux-Namespace-中的-IPC-是什么-？" class="headerlink" title="3.2 Linux Namespace 中的 IPC 是什么 ？"></a>3.2 Linux Namespace 中的 IPC 是什么 ？</h3><ul><li>参考：<a href="https://www.cnblogs.com/Skybiubiu/p/17315019.html">https://www.cnblogs.com/Skybiubiu/p/17315019.html</a></li></ul><p>IPC (Inter-Process Communication) Namespace 是 Linux 容器隔离的一种命名空间，用于隔离进程间通信（IPC）资源，包括 System V IPC 和 POSIX IPC。</p><p>在 Linux 中，进程间通信机制可以使用不同的 IPC 方法。这些方法包括管道、套接字、消息队列、信号量和共享内存等。这些 IPC 机制可以在系统全局范围内使用，也可以在特定的命名空间内使用。</p><p>当一个容器启动时，如果该容器运行在它自己的 IPC Namespace 中，那么将为该容器分配一个独立的 IPC 句柄。这意味着该容器内部的进程和外部的进程将无法相互通信。</p><p>IPC Namespace 具有以下两个主要特性：</p><ul><li>隔离：IPC Namespace 可以将特定容器中的进程隔离并限制进程之间在 IPC 资源上的共享。这样就可以避免其他容器或主机干扰到该容器中的进程，或者该容器中的进程干扰到其他容器或主机。</li><li>共享：如果多个容器运行在同一个 IPC Namespace 中，它们将共享容器之间的 IPC 资源，这使得在同一 IPC Namespace 中的容器之间通信变得更加容易和高效。</li></ul><p>总的来说，IPC Namespace 可以有效地保护容器内的进程，避免不必要的干扰。同时，在多个容器需要通信时，将它们加入同一个 IPC Namespace 可以更好地共享资源，从而实现更好的协作和协同工作。</p><h1 id="二、配置pod的安全上下文"><a href="#二、配置pod的安全上下文" class="headerlink" title="二、配置pod的安全上下文"></a>二、配置pod的安全上下文</h1><p>针对于container级别的控制</p><h2 id="1-指定运行容器的用户"><a href="#1-指定运行容器的用户" class="headerlink" title="1. 指定运行容器的用户"></a>1. 指定运行容器的用户</h2><p>资源清单：<code>user-id-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">alpine-user-id</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">alpine-user-id</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">alpine-user-id</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alpine</span>          <span class="attr">image:</span> <span class="string">alpine:3.22.1</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">command:</span>  <span class="comment"># 容器启动命令</span>            <span class="bullet">-</span> <span class="string">/bin/sleep</span>            <span class="bullet">-</span> <span class="string">&quot;3600&quot;</span>          <span class="attr">securityContext:</span>            <span class="attr">runAsUser:</span> <span class="number">405</span> <span class="comment"># 运行用户 ID</span></code></pre><p><strong>运行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f user-id-pod.yaml<span class="comment"># 查看Pod</span>$ kubectl get podsNAME                              READY   STATUS    RESTARTS   AGEalpine-user-id-687f8f598b-dcj8f   1/1     Running   0          5m15s<span class="comment"># 进入容器，查看当前用户ID</span>$ kubectl <span class="built_in">exec</span> -it alpine-user-id-687f8f598b-dcj8f -- /bin/sh/ $ <span class="built_in">id</span>uid=405(guest) gid=100(<span class="built_in">users</span>) <span class="built_in">groups</span>=100(<span class="built_in">users</span>)</code></pre><h2 id="2-阻止容器以root用户运行"><a href="#2-阻止容器以root用户运行" class="headerlink" title="2. 阻止容器以root用户运行"></a>2. 阻止容器以root用户运行</h2><p>有的应用在容器中设置了运行用户，然后可能会有黑客上传一个以root用户运行的镜像到我们的镜像仓库。然后在容器中利用root用户<br>的权限，这样是很危险的，所以我们可以禁用容器中的root用户，让他不能以root用户启动容器</p><h3 id="2-1-创建一个非-Root-运行的-Nginx-镜像"><a href="#2-1-创建一个非-Root-运行的-Nginx-镜像" class="headerlink" title="2.1 创建一个非 Root 运行的 Nginx 镜像"></a>2.1 创建一个非 Root 运行的 Nginx 镜像</h3><p><strong>Dockerfile</strong></p><pre><code class="highlight dockerfile"><span class="keyword">FROM</span> nginx:<span class="number">1.29</span>.<span class="number">0</span>  <span class="comment"># 修改 Nginx 配置：移除 &#x27;user&#x27; 指令（避免权限警告），并将默认监听端口改为 8080</span><span class="keyword">RUN</span><span class="language-bash"> sed -i <span class="string">&#x27;/^user /d&#x27;</span> /etc/nginx/nginx.conf &amp;&amp; \</span><span class="language-bash">    sed -i <span class="string">&#x27;s/listen       80;/listen       8080;/&#x27;</span> /etc/nginx/conf.d/default.conf</span><span class="comment"># 创建必要的临时目录和 PID 文件，并调整权限给 nginx 用户</span><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> -p /var/cache/nginx/client_temp /var/cache/nginx/proxy_temp /var/cache/nginx/fastcgi_temp /var/cache/nginx/uwsgi_temp /var/cache/nginx/scgi_temp &amp;&amp; \</span><span class="language-bash">    <span class="built_in">chown</span> -R nginx:nginx /var/cache/nginx /var/log/nginx /etc/nginx/conf.d /var/run &amp;&amp; \</span><span class="language-bash">    <span class="built_in">chmod</span> -R 755 /var/cache/nginx /var/log/nginx /etc/nginx/conf.d /var/run &amp;&amp; \</span><span class="language-bash">    <span class="built_in">touch</span> /var/run/nginx.pid &amp;&amp; \</span><span class="language-bash">    <span class="built_in">chown</span> -R nginx:nginx /var/run/nginx.pid</span><span class="comment"># 切换到非 root 用户（使用镜像内置的 nginx 用户）</span><span class="keyword">USER</span> nginx<span class="comment"># 暴露端口（非特权端口）</span><span class="keyword">EXPOSE</span> <span class="number">8080</span><span class="comment"># 启动命令</span><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;nginx&quot;</span>, <span class="string">&quot;-g&quot;</span>, <span class="string">&quot;daemon off;&quot;</span>]</span></code></pre><p><strong>构建镜像</strong></p><pre><code class="highlight bash">docker build -t nginx-nonroot:1.0 .</code></pre><p><strong>测试镜像</strong></p><pre><code class="highlight bash"><span class="comment"># 运行 nginx-nonroot 容器</span>$ docker run -d -p 8080:8080 nginx-nonroot:1.0<span class="comment"># 访问 nginx-nonroot</span>$ curl http://localhost:8080&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;<span class="comment"># 查看当前nginx容器，启动命令的用户</span>nginx@b094f1470b19:/$ <span class="built_in">id</span>uid=101(nginx) gid=101(nginx) <span class="built_in">groups</span>=101(nginx)<span class="comment"># 查看Nginx容器内的所有用户，可以看到 101 对应的就是用户 nginx，也是 Dockerfile 中指定的用户</span>nginx@b094f1470b19:/$ <span class="built_in">cat</span> /etc/passwdroot:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologin<span class="built_in">sync</span>:x:4:65534:<span class="built_in">sync</span>:/bin:/bin/syncgames:x:5:60:games:/usr/games:/usr/sbin/nologinman:x:6:12:man:/var/cache/man:/usr/sbin/nologinlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologinmail:x:8:8:mail:/var/mail:/usr/sbin/nologinnews:x:9:9:news:/var/spool/news:/usr/sbin/nologinuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologinproxy:x:13:13:proxy:/bin:/usr/sbin/nologinwww-data:x:33:33:www-data:/var/www:/usr/sbin/nologinbackup:x:34:34:backup:/var/backups:/usr/sbin/nologinlist:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologinirc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin_apt:x:42:65534::/nonexistent:/usr/sbin/nologinnobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologinnginx:x:101:101:nginx user:/nonexistent:/bin/false</code></pre><h3 id="2-2-Pod-以非-root-用户运行"><a href="#2-2-Pod-以非-root-用户运行" class="headerlink" title="2.2 Pod 以非 root 用户运行"></a>2.2 Pod 以非 root 用户运行</h3><p>资源清单：<code>non-root-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">non-root-pod</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">non-root-pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">non-root-pod</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-nonroot</span>          <span class="attr">image:</span> <span class="string">nginx-nonroot:1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">runAsNonRoot:</span> <span class="literal">true</span> <span class="comment"># 以非root用户运行</span>            <span class="attr">runAsUser:</span> <span class="number">101</span> <span class="comment"># 运行用户 ID, 以非root用户运行，最好指定运行的用户id</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f non-root-pod.yaml<span class="comment"># 查看Pod详情</span>$ kubectl get pods -o wideNAME                            READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnon-root-pod-589bdf555b-c6925   1/1     Running   0          57s   171.20.85.214   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 进入Pod容器，查看当前容器运行的 User id</span>$ kubectl <span class="built_in">exec</span> -it non-root-pod-589bdf555b-c6925 -- /bin/bashnginx@non-root-pod-589bdf555b-c6925:/$ <span class="built_in">id</span>uid=101(nginx) gid=101(nginx) <span class="built_in">groups</span>=101(nginx)</code></pre><h3 id="2-3-使用特权模式启动容器"><a href="#2-3-使用特权模式启动容器" class="headerlink" title="2.3 使用特权模式启动容器"></a>2.3 使用特权模式启动容器</h3><p>使得容器内的进程以 root 用户运行，并具有宿主机的几乎所有权限（如访问所有设备、挂载文件系统、修改内核参数等）。</p><p>容器内的 root 用户几乎等同于宿主机的 root，具有访问宿主机设备（&#x2F;dev）、文件系统、内核功能等的权限。</p><p>注意：privileged: true 仅影响容器，而非整个 Pod。如果 Pod 有多个容器，需要为每个需要特权的容器单独设置。</p><p><strong>资源清单：</strong> <code>privileged-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">privileged-pod</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">privileged-pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">privileged-pod</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-privileged</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">true</span> <span class="comment"># 启用特权模式</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f privileged-pod.yaml<span class="comment"># 查看Pod详情</span>$ kubectl get pods -o wideNAME                              READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESprivileged-pod-86bdcd8565-lx5ff   1/1     Running   0          74s   171.20.85.216   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 进入Pod</span>$ kubectl <span class="built_in">exec</span> -it privileged-pod-86bdcd8565-lx5ff -- /bin/bash<span class="comment"># 查看运行容器的用户id</span>root@privileged-pod-86bdcd8565-lx5ff:/<span class="comment"># id</span>uid=0(root) gid=0(root) <span class="built_in">groups</span>=0(root)<span class="comment"># 查看 /dev 目录，容器内可以查看到宿主机所有的挂载设备</span>root@privileged-pod-86bdcd8565-lx5ff:/<span class="comment"># ls /dev</span>autofs dm-1   hidraw0 mcelog  ppp sda1   snd    tty0   tty15  tty21  tty28tty34  tty40  tty47  tty53  tty6   tty9     uinput vcs1  vcsa1  vcsu1  vga_arbiterbsg dma_heap  hpet mem ptmx sda2   sr0    tty1   tty16  tty22  tty29tty35  tty41  tty48  tty54  tty60  ttyS0    urandom vcs2  vcsa2  vcsu2  vhcibus dri   hwrng mqueue  pts sda3   stderr    tty10  tty17  tty23  tty3tty36  tty42  tty49  tty55  tty61  ttyS1    usbmon0 vcs3  vcsa3  vcsu3  vhost-netcore fb0   input net random  sg0   stdin    tty11  tty18  tty24  tty30tty37  tty43  tty5   tty56  tty62  ttyS2    usbmon1 vcs4  vcsa4  vcsu4  vhost-vsockcpu fd   kmsg null rfkill  sg1   stdout    tty12  tty19  tty25  tty31tty38  tty44  tty50  tty57  tty63  ttyS3    usbmon2 vcs5  vcsa5  vcsu5  vmcicpu_dma_latency  full   loop-control  nvram rtc0 shm   termination-log  tty13  tty2   tty26  tty32tty39  tty45  tty51  tty58  tty7   udmabuf  userfaultfd  vcs6  vcsa6  vcsu6  zerodm-0 fuse   mapper port sda snapshot  <span class="built_in">tty</span>    tty14  tty20  tty27  tty33tty4   tty46  tty52  tty59  tty8   uhid     vcs vcsa  vcsu   vfio</code></pre><h3 id="2-4-为容器-添加-禁用-linux-内核的功能"><a href="#2-4-为容器-添加-禁用-linux-内核的功能" class="headerlink" title="2.4 为容器 添加&#x2F;禁用 linux 内核的功能"></a>2.4 为容器 添加&#x2F;禁用 linux 内核的功能</h3><p>使用特权模式启动的容器被赋予了过大的权限，我们可以根据需求给予容器所需的 linux 内核的能力。</p><p>在 Kubernetes 中，可以通过配置 Pod 的 securityContext 来为容器添加或禁用 Linux 内核功能（Capabilities）。Linux Capabilities 是 Linux 内核提供的一种机制，将 root 用户的权限细分为多个独立的功能，允许以更精细的方式控制容器进程的权限，而不是简单地以 root 或非 root 用户运行。这种方式可以增强安全性，遵循最小权限原则。</p><p><strong>什么是 Linux Capabilities</strong></p><p>Linux Capabilities 是 Linux 内核将特权操作拆分成多个独立权限的机制，例如：</p><ul><li>CAP_SYS_ADMIN：允许执行高权限操作（如挂载文件系统、修改系统配置）。</li><li>CAP_NET_ADMIN：允许配置网络（如修改网络接口、设置防火墙规则）。</li><li>CAP_SYS_PTRACE：允许跟踪其他进程（结合 hostPID: true 可用于调试宿主机进程）。</li><li>CAP_CHOWN：允许更改文件的所有者。</li><li>完整 Capabilities 列表见 <a href="http://man7.org/linux/man-pages/man7/capabilities.7.html">Linux man page</a>。</li></ul><p>默认情况下：</p><ul><li>容器以非特权模式运行时，只有部分 Capabilities（例如 CAP_CHOWN、CAP_SETUID 等）。</li><li>特权模式（privileged: true）授予容器所有 Capabilities，等同于宿主机 root。</li><li>通过 securityContext.capabilities，可以显式添加（add）或禁用（drop）特定 Capabilities。</li></ul><p><strong>资源清单：</strong> <code>capabilities-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">capabilities-pod</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">capabilities-pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">capabilities-pod</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-capabilities</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">false</span> <span class="comment"># 禁用特权模式</span>            <span class="attr">capabilities:</span>              <span class="attr">add:</span>                <span class="bullet">-</span> <span class="string">NET_ADMIN</span> <span class="comment"># 添加网络管理能力</span>                <span class="bullet">-</span> <span class="string">SYS_PTRACE</span> <span class="comment"># 添加跟踪进程的能力（适用于 hostPID: true）</span>              <span class="attr">drop:</span><span class="comment">#                - CHOWN # 禁用更改文件所有者的能力（Nginx启动需要修改文件所有者，因此不能禁用）</span>                <span class="bullet">-</span> <span class="string">SYS_ADMIN</span> <span class="comment"># 禁用高危的系统管理能力</span></code></pre><p>注意：在linux中内核功能通常以CAP_开头，这里需要省略掉</p><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f capabilities-pod.yaml<span class="comment"># 查看Pod</span>$ kubectl get pods -wNAME                                READY   STATUS              RESTARTS   AGEcapabilities-pod-787896d744-p6ptf   0/1     ContainerCreating   0          12scapabilities-pod-787896d744-p6ptf   1/1     Running             0          13s</code></pre><h3 id="2-5-阻止对容器根文件系统的写入"><a href="#2-5-阻止对容器根文件系统的写入" class="headerlink" title="2.5 阻止对容器根文件系统的写入"></a>2.5 阻止对容器根文件系统的写入</h3><p><strong>资源清单：</strong><code>read-only-root-filesystem-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">read-only-root-filesystem-pod</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">read-only-root-filesystem-pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">read-only-root-filesystem-pod</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alpine</span>          <span class="attr">image:</span> <span class="string">alpine:3.22.1</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span> <span class="comment"># 只读根文件系统</span>          <span class="attr">command:</span>  <span class="comment"># 容器启动命令</span>            <span class="bullet">-</span> <span class="string">/bin/sleep</span>            <span class="bullet">-</span> <span class="string">&quot;3600&quot;</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">read-only-root-filesystem-pod</span> <span class="comment"># # 挂载了一个可写的 emptyDir 卷到 /volume 路径，允许容器写入数据</span>              <span class="attr">mountPath:</span> <span class="string">/volume</span>              <span class="attr">readOnly:</span> <span class="literal">false</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">read-only-root-filesystem-pod</span> <span class="comment"># 定义一个 emptyDir 卷，是一种临时存储卷，卷在 Pod 创建时分配，初始为空，生命周期与 Pod 绑定（Pod 删除时卷被销毁）</span>          <span class="attr">emptyDir:</span> &#123;&#125;</code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f read-only-root-filesystem-pod.yaml<span class="comment"># 查看Pod</span>$ kubectl get pods NAME                                             READY   STATUS    RESTARTS   AGEread-only-root-filesystem-pod-77bc855c7f-t9nsh   1/1     Running   0          39s<span class="comment"># 进入Pod容器</span>$ kubectl <span class="built_in">exec</span> -it read-only-root-filesystem-pod-77bc855c7f-t9nsh -- /bin/sh<span class="comment"># 在根路径下创建文件失败，因为 Pod 禁止了根路径下的文件写入</span>/ <span class="comment"># touch a.txt</span><span class="built_in">touch</span>: a.txt: Read-only file system<span class="comment"># 在挂载路径下创建文件</span>/ <span class="comment"># touch /volume/a.txt</span></code></pre><p><strong>readOnlyRootFilesystem: true</strong></p><p><strong>作用</strong>：将容器根文件系统（&#x2F;, 包括 &#x2F;etc、&#x2F;usr 等）设为只读。</p><p><strong>详情</strong>：</p><ul><li>容器无法在根文件系统上写入文件（如修改 &#x2F;etc&#x2F;passwd 或创建 &#x2F;tmp&#x2F;testfile），增强安全性。</li><li>防止恶意或意外修改关键文件，降低容器被攻击的风险。</li><li>影响：<ul><li>某些应用（如需要写日志或缓存到根文件系统的）可能失败，除非提供可写路径（如通过卷）。</li><li>在 alpine 镜像中，&#x2F;bin&#x2F;sleep 不需要写根文件系统，因此运行正常。</li></ul></li><li><strong>注意</strong>：与之前的 nginx:1.29.0 配置不同，Nginx 默认需要写日志（&#x2F;var&#x2F;log&#x2F;nginx）和缓存（&#x2F;var&#x2F;cache&#x2F;nginx），启用 readOnlyRootFilesystem: true 可能导致 Nginx 失败，除非将这些路径挂载到可写卷。</li></ul><p>如果想将此配置应用于 nginx:1.29.0，需添加多个可写卷：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-readonly</span><span class="attr">spec:</span>  <span class="attr">containers:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>    <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>    <span class="attr">securityContext:</span>      <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span>    <span class="attr">volumeMounts:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span>      <span class="attr">mountPath:</span> <span class="string">/var/log/nginx</span>      <span class="attr">readOnly:</span> <span class="literal">false</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cache-volume</span>      <span class="attr">mountPath:</span> <span class="string">/var/cache/nginx</span>      <span class="attr">readOnly:</span> <span class="literal">false</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run-volume</span>      <span class="attr">mountPath:</span> <span class="string">/var/run</span>      <span class="attr">readOnly:</span> <span class="literal">false</span>  <span class="attr">volumes:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span>    <span class="attr">emptyDir:</span> &#123;&#125;  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cache-volume</span>    <span class="attr">emptyDir:</span> &#123;&#125;  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run-volume</span>    <span class="attr">emptyDir:</span> &#123;&#125;</code></pre><h3 id="2-6-容器使用不同用户运行时共享存储卷"><a href="#2-6-容器使用不同用户运行时共享存储卷" class="headerlink" title="2.6  容器使用不同用户运行时共享存储卷"></a>2.6  容器使用不同用户运行时共享存储卷</h3><p>当一个 pod 中的两个容器都使用 root 用户运行时，他们之前可以互相读取对方的挂载卷。但是，当我们为每个容器配置其他的启动用户时，<br>可以会出现一些访问权限的问题。<br>在 kubernetes 中，可以为 pod 中的容器指定一个 supplemental 组，以允许他们无论通过哪个用户启动容器都可以共享文件。</p><pre><code class="highlight yaml"><span class="attr">spec:</span>  <span class="attr">securityContext:</span>    <span class="comment"># 用户组id设置为555，则创建存储卷时存储卷属于用户ID为555的用户组</span>    <span class="attr">fsGroup:</span> <span class="number">555</span>    <span class="comment"># 定义了某个用户所关联的额外的用户组</span>    <span class="attr">supplementalGroups:</span>      <span class="bullet">-</span> <span class="number">666</span>      <span class="bullet">-</span> <span class="number">777</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-A</span>      <span class="attr">image:</span> <span class="string">test-container</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">securityContext:</span>        <span class="attr">runAsUser:</span> <span class="number">01</span>      <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/volume</span>          <span class="attr">name:</span> <span class="string">test-volume</span>          <span class="attr">readOnly:</span> <span class="literal">false</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-B</span>      <span class="attr">image:</span> <span class="string">test-container</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">securityContext:</span>        <span class="attr">runAsUser:</span> <span class="number">02</span>      <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/volume</span>          <span class="attr">name:</span> <span class="string">test-volume</span>          <span class="attr">readOnly:</span> <span class="literal">false</span>  <span class="attr">volumes:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-volume</span>      <span class="attr">emptyDir:</span> &#123;&#125;</code></pre><p>在pod级别指定 fsGroup 与 supplementalGroups 属性，然后分别指定两个容器的启动用户为 01、02。然后在启动容器，在容器中执行<code>id</code>命令<br>可以查看容器的用户和用户组，然后就可以看到两个容器虽然用户不同，但是都属于“555、666、777”这三个组中。</p><h1 id="三、Pod-Security-Admission"><a href="#三、Pod-Security-Admission" class="headerlink" title="三、Pod Security Admission"></a>三、Pod Security Admission</h1><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h2 id="1-PodSecurityPolicy-概念（过时）"><a href="#1-PodSecurityPolicy-概念（过时）" class="headerlink" title="1. PodSecurityPolicy 概念（过时）"></a>1. PodSecurityPolicy 概念（过时）</h2><p>PodSecurityPolicy 在 kubernetes 中简称为 psp，主要定义了用户能否在 pod 中使用各种安全相关的特性。</p><p>当有人调用 api server创建pod时，PodSecurityPolicy 会拿到这个 pod 的信息与自己个规则做比较。如果符合规则，就运行其存入 etcd；否则会被拒绝。<br>因为是在创建 pod 时校验的，所以修改 psp，不会对已创建的 pod 采取措施。也可以设置默认值，就是用 psp 中配置的默认值替换掉 pod 中的值。</p><p>Pod Security Policy 是一个赋予集群管理员控制 Pod 安全规范的内置准入控制器，可以让管理人员控制Pod实例安全的诸多方面，例如禁止采用root权限、防止容器逃逸等等。Pod Security Policy 定义了一组 Pod 运行时必须遵循的条件及相关字段的默认值，Pod 必须满足这些条件才能被成功创建，Pod Security Policy 对象 Spec 包含以下字段也即是 Pod Security Policy 能够控制的方面：</p><table><thead><tr><th>控制的角度</th><th>字段名称</th></tr></thead><tbody><tr><td>运行特权容器</td><td>privileged</td></tr><tr><td>使用宿主名字空间</td><td>hostPID,hostIPC</td></tr><tr><td>使用宿主的网络和端口</td><td>hostNetwork, hostPorts</td></tr><tr><td>控制卷类型的使用</td><td>volumes</td></tr><tr><td>使用宿主文件系统</td><td>allowedHostPaths</td></tr><tr><td>允许使用特定的 FlexVolume 驱动</td><td>allowedFlexVolumes</td></tr><tr><td>分配拥有 Pod 卷的 FSGroup 账号</td><td>fsGroup</td></tr><tr><td>以只读方式访问根文件系统</td><td>readOnlyRootFilesystem</td></tr><tr><td>设置容器的用户和组 ID</td><td>runAsUser, runAsGroup, supplementalGroups</td></tr><tr><td>限制 root 账号特权级提升</td><td>allowPrivilegeEscalation, defaultAllowPrivilegeEscalation</td></tr><tr><td>Linux 功能（Capabilities）</td><td>defaultAddCapabilities, requiredDropCapabilities, allowedCapabilities</td></tr><tr><td>设置容器的 SELinux 上下文</td><td>seLinux</td></tr><tr><td>指定容器可以挂载的 proc 类型</td><td>allowedProcMountTypes</td></tr><tr><td>指定容器使用的 AppArmor 模版</td><td>annotations</td></tr><tr><td>指定容器使用的 seccomp 模版</td><td>annotations</td></tr><tr><td>指定容器使用的 sysctl 模版</td><td>forbiddenSysctls,allowedUnsafeSysctls</td></tr></tbody></table><p>其中AppArmor 和seccomp 需要通过给PodSecurityPolicy对象添加注解的方式设定：</p><pre><code class="highlight yaml"><span class="attr">seccomp.security.alpha.kubernetes.io/allowedProfileNames:</span> <span class="string">&#x27;docker/default&#x27;</span><span class="attr">seccomp.security.alpha.kubernetes.io/defaultProfileNames:</span> <span class="string">&#x27;docker/default&#x27;</span><span class="attr">apparmor.security.beta.kubernetes.io/allowedProfileNames:</span> <span class="string">&#x27;runtime/default&#x27;</span> <span class="attr">apparmor.security.beta.kubernetes.io/defaultProfileNames:</span> <span class="string">&#x27;runtime/default&#x27;</span></code></pre><p>Pod Security Policy是集群级别的资源，它的使用流程：</p><p><img src="https://img2022.cnblogs.com/blog/1669826/202204/1669826-20220406164525862-2082600217.png" alt="Pod Security Policy 使用流程"></p><p>由于需要创建 ClusterRole&#x2F;Role 和 ClusterRoleBinding&#x2F;RoleBinding 绑定服务账号来使用 PSP,这使得我们不能很容易的看出究竟使用了哪些 PSP,更难看出 Pod 的创建被哪些安全规则限制。</p><h2 id="2-关于-Pod-Security-Admission"><a href="#2-关于-Pod-Security-Admission" class="headerlink" title="2. 关于 Pod Security Admission"></a>2. 关于 Pod Security Admission</h2><p>通过对 PodSecurityPolicy 使用，应该也会发现它的问题，例如没有 dry-run 和审计模式、不方便开启和关闭等，并且使用起来也不那么清晰。种种缺陷造成的结果是 PodSecurityPolicy 在 Kubernetes v1.21 被标记为弃用，并且将在 v1.25中被移除，在 kubernets v1.22 中则增加了新特性 Pod Security Admission。</p><p>pod security admission 是 kubernetes 内置的一种准入控制器，在 kubernetes v1.23 版本中这一特性门是默认开启的，在v1.22中需要通过 kube-apiserver 参数 <code>--feature-gates=&quot;...,PodSecurity=true&quot;</code> 开启。在低于v1.22的 kuberntes 版本中也可以自行安装 Pod Security Admission Webhook。</p><p>Pod Security Admission 机制在易用性和灵活性上都有了很大提升，从使用角度有以下三点显著不同：</p><ul><li>可以在集群中默认开启，只要不设置约束条件就不会触发对 pod 的校验</li><li>只在命名空间级别生效，可以为不同命名空间通过添加标签的方式设置不同的安全限制</li><li>根据实践预设了三种安全等级，不需要由用户单独去设置每一项安全条件</li></ul><p>为了广泛的覆盖安全应用场景， Pod Security Standards渐进式的定义了三种不同的Pod安全标准策略：</p><table><thead><tr><th>Profile</th><th>描述</th></tr></thead><tbody><tr><td><strong>Privileged</strong></td><td>不受限制的策略，提供最大可能范围的权限许可。此策略允许已知的特权提升。</td></tr><tr><td><strong>Baseline</strong></td><td>限制性最弱的策略，禁止已知的策略提升。允许使用默认的（规定最少）Pod 配置。</td></tr><tr><td><strong>Restricted</strong></td><td>限制性非常强的策略，遵循当前的保护 Pod 的最佳实践。</td></tr></tbody></table><p>详细内容参见 <a href="https://kubernetes.io/docs/concepts/security/pod-security-standards">Pod Security Standards</a>。</p><h2 id="3-Pod-Security-Standards-实施方法"><a href="#3-Pod-Security-Standards-实施方法" class="headerlink" title="3. Pod Security Standards 实施方法"></a>3. Pod Security Standards 实施方法</h2><p>在kubernetes集群中开启了pod security admission特性门之后，就可以通过给namespace设置label的方式来实施Pod Security Standards。其中有三种设定模式可选用：</p><table><thead><tr><th align="left">Mode</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left"><strong>enforce</strong></td><td align="left">违反安全标准策略的 Pod 将被拒绝。</td></tr><tr><td align="left"><strong>audit</strong></td><td align="left">违反安全标准策略触发向审计日志中记录的事件添加审计注释，但其他行为被允许。</td></tr><tr><td align="left"><strong>warn</strong></td><td align="left">违反安全标准策略将触发面向用户的警告，但其他行为被允许。</td></tr></tbody></table><p>label设置模板解释：</p><pre><code class="highlight bash"><span class="comment"># 设定模式及安全标准策略等级</span><span class="comment"># MODE必须是 `enforce`, `audit`或`warn`其中之一。</span><span class="comment"># LEVEL必须是`privileged`, `baseline`或 `restricted`其中之一</span>pod-security.kubernetes.io/&lt;MODE&gt;: &lt;LEVEL&gt;<span class="comment"># 此选项是非必填的，用来锁定使用哪个版本的的安全标准</span><span class="comment"># MODE必须是 `enforce`, `audit`或`warn`其中之一。</span><span class="comment"># VERSION必须是一个有效的kubernetes minor version(例如v1.23)，或者 `latest`</span>pod-security.kubernetes.io/&lt;MODE&gt;-version: &lt;VERSION&gt;</code></pre><p>一个 namesapce 可以设定任意种模式或者不同的模式设定不同的安全标准策略。</p><p>通过准入控制器配置文件，可以为pod security admission设置默认配置：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apiserver.config.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">AdmissionConfiguration</span> <span class="comment"># 准入控制</span><span class="attr">plugins:</span><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PodSecurity</span>  <span class="attr">configuration:</span>    <span class="attr">apiVersion:</span> <span class="string">pod-security.admission.config.k8s.io/v1beta1</span>    <span class="attr">kind:</span> <span class="string">PodSecurityConfiguration</span>    <span class="comment"># Defaults applied when a mode label is not set.</span>    <span class="comment">#</span>    <span class="comment"># Level label values must be one of:</span>    <span class="comment"># - &quot;privileged&quot; (default)</span>    <span class="comment"># - &quot;baseline&quot;</span>    <span class="comment"># - &quot;restricted&quot;</span>    <span class="comment">#</span>    <span class="comment"># Version label values must be one of:</span>    <span class="comment"># - &quot;latest&quot; (default) </span>    <span class="comment"># - specific version like &quot;v1.23&quot;</span>    <span class="attr">defaults:</span> <span class="comment"># 默认执行最宽松的检验策略</span>      <span class="attr">enforce:</span> <span class="string">&quot;privileged&quot;</span>      <span class="attr">enforce-version:</span> <span class="string">&quot;latest&quot;</span> <span class="comment"># latest 表示使用最新的 PSS 版本（基于集群版本，例如 Kubernetes 1.25 可能是 v1.25）</span>      <span class="attr">audit:</span> <span class="string">&quot;privileged&quot;</span>      <span class="attr">audit-version:</span> <span class="string">&quot;latest&quot;</span>      <span class="attr">warn:</span> <span class="string">&quot;privileged&quot;</span>      <span class="attr">warn-version:</span> <span class="string">&quot;latest&quot;</span>    <span class="attr">exemptions:</span>      <span class="comment"># 指定免除检查的认证用户名，空数组表示没有用户豁免，所有用户创建的 Pod 都受策略约束。</span>      <span class="attr">usernames:</span> []      <span class="comment"># 指定免除检查的 RuntimeClass 名称。空数组表示没有 RuntimeClass 豁免，适用于所有运行时（如 containerd、CRI-O）</span>      <span class="attr">runtimeClassNames:</span> []      <span class="comment"># 指定免除检查的命名空间</span>      <span class="attr">namespaces:</span> []</code></pre><p>pod security admission 可以从 username，runtimeClassName，namespace 三个维度对pod进行安全标准检查的豁免。</p><h2 id="4-Pod-Security-Standards实施演示"><a href="#4-Pod-Security-Standards实施演示" class="headerlink" title="4. Pod Security Standards实施演示"></a>4. Pod Security Standards实施演示</h2><ul><li>环境: kubernetes v1.29</li></ul><p>运行时的容器面临很多攻击风险，例如容器逃逸，从容器发起资源耗尽型攻击。</p><h3 id="4-1-Baseline策略"><a href="#4-1-Baseline策略" class="headerlink" title="4.1 Baseline策略"></a>4.1 Baseline策略</h3><p>Baseline策略目标是应用于常见的容器化应用，禁止已知的特权提升，在官方的介绍中此策略针对的是应用运维人员和非关键性应用开发人员，在该策略中包括：</p><p>必须禁止共享宿主机命名空间、禁止容器特权、 限制Linux能力、禁止hostPath卷、限制宿主机端口、设定AppArmor、SElinux、Seccomp、Sysctls等。</p><p><strong>下面演示设定Baseline策略。</strong></p><p>违反Baseline策略存在的风险：</p><ul><li>特权容器可以看到宿主机设备</li><li>挂载procfs后可以看到宿主机进程，打破进程隔离</li><li>可以打破网络隔离</li><li>挂载运行时socket后可以不受限制的与运行时通信</li></ul><p>等等以上风险都可能导致容器逃逸。</p><ol><li><p>创建名为my-baseline-namespace的namespace，并设定enforce和warn两种模式都对应Baseline等级的Pod安全标准策略：</p><p>资源清单：<code>my-baseline-namespace.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span> <span class="comment"># 命名空间的 API 版本（固定为 v1）</span><span class="attr">kind:</span> <span class="string">Namespace</span> <span class="comment"># 资源类型：命名空间（用于隔离集群资源）</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-baseline-namespace</span> <span class="comment"># 命名空间名称，Pod 将在此命名空间内运行</span>  <span class="attr">labels:</span> <span class="comment"># 核心：通过标签配置 Pod 安全策略（PSA 规则）</span>    <span class="comment"># 强制实施 Baseline 级别的安全标准，所有在该命名空间创建的 Pod 必须符合此标准，否则会被拒绝创建。</span>    <span class="comment"># Baseline 标准核心约束（Kubernetes 官方定义）：</span>      <span class="comment"># - 禁止特权容器（privileged: true）。</span>      <span class="comment"># - 禁止已知的特权升级路径（如 allowPrivilegeEscalation: true 且 runAsUser: 0）。</span>      <span class="comment"># - 允许默认的（相对宽松的）Pod 配置（如允许使用主机网络 hostNetwork、主机 PID hostPID、主机 IPC hostIPC 等，这也是与更严格的 Restricted 级别的主要区别）</span>    <span class="attr">pod-security.kubernetes.io/enforce:</span> <span class="string">baseline</span>    <span class="comment"># 指定 enforce 规则所使用的 Kubernetes 版本（此处为 v1.29）， 这确保了 PSA 规则仅在指定的 Kubernetes 版本下生效，避免与未来版本的 Kubernetes 发生冲突。</span>    <span class="attr">pod-security.kubernetes.io/enforce-version:</span> <span class="string">v1.29</span>    <span class="comment"># 当 Pod 不符合 Baseline 标准时，不阻止创建，但会生成警告信息（通过 API 响应或事件日志）。</span>    <span class="attr">pod-security.kubernetes.io/warn:</span> <span class="string">baseline</span>    <span class="comment"># 指定 warn 规则所使用的 Kubernetes 版本，与 enforce-version 保持一致（v1.29），确保警告规则与强制规则基于相同的标准定义</span>    <span class="attr">pod-security.kubernetes.io/warn-version:</span> <span class="string">v1.29</span><span class="comment"># 当同时指定 enforce: baseline 和 warn: baseline 时，Pod 创建流程如下：</span><span class="comment"># - 先检查 enforce 规则：</span><span class="comment">#   若 Pod 完全符合 baseline 标准 → 允许创建，进入下一步。</span><span class="comment">#   若 Pod 违反 baseline 核心约束（如特权容器、特权升级等）→ 直接拒绝创建，流程终止。</span><span class="comment"># - 再检查 warn 规则（仅当 enforce 允许创建时）：</span><span class="comment">#   若 Pod 存在潜在风险（如使用了不推荐但未被 enforce 禁止的配置）→ 生成警告信息（如 Warning: Pod violates PodSecurity &quot;baseline:v1.29&quot;）。</span><span class="comment">#   若 Pod 完全符合 baseline 标准 → 无警告，Pod 正常运行。</span></code></pre><p><strong>执行资源清单：</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f my-baseline-namespace.yaml <span class="comment"># 查看名称空间</span>$ kubectl get nsNAME                    STATUS   AGEkube-node-lease         Active   40dkube-public             Active   40dkube-system             Active   40dmy-baseline-namespace   Active   4snetwork                 Active   37d</code></pre></li><li><p>创建pod</p><ul><li><p>创建一个违反baseline策略的pod</p><p>资源清单：<code>fail-hostnamespaces.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">my-baseline-namespace</span>  <span class="attr">name:</span> <span class="string">fail-hostnamespaces</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">fail-hostnamespaces</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">fail-hostnamespaces</span>    <span class="attr">spec:</span>      <span class="attr">hostPID:</span> <span class="literal">true</span> <span class="comment"># 与主机共享PID</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">true</span> <span class="comment"># 启用特权模式</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 提示 容器创建异常</span>$ kubectl apply -f fail-hostnamespaces.yaml Warning: would violate PodSecurity <span class="string">&quot;baseline:v1.29&quot;</span>: host namespaces (hostPID=<span class="literal">true</span>), privileged (container <span class="string">&quot;nginx&quot;</span> must not <span class="built_in">set</span> securityContext.privileged=<span class="literal">true</span>)deployment.apps/fail-hostnamespaces created<span class="comment"># 只有Deploy，Pod创建失败</span>$ kubectl get deployment -n my-baseline-namespaceNAME                  READY   UP-TO-DATE   AVAILABLE   AGEfail-hostnamespaces   0/1     0            0           16s</code></pre></li><li><p>创建不违反 baseline 策略的 pod，设定 Pod 的 hostPID&#x3D;false，securityContext.privileged&#x3D;false</p><p>资源清单：<code>success-hostnamespaces.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">my-baseline-namespace</span>  <span class="attr">name:</span> <span class="string">success-hostnamespaces</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">fail-hostnamespaces</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">fail-hostnamespaces</span>    <span class="attr">spec:</span>      <span class="attr">hostPID:</span> <span class="literal">false</span> <span class="comment"># 不与主机共享PID</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">false</span> <span class="comment"># 禁用特权模式</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 创建Pod</span>$ kubectl apply -f success-hostnamespaces.yaml<span class="comment"># Pod成功启动</span>$ kubectl get pods -n my-baseline-namespaceNAME                                      READY   STATUS    RESTARTS   AGEsuccess-hostnamespaces-759ccb9dcd-x9cp6   1/1     Running   0          12s</code></pre></li></ul></li></ol><h3 id="4-2-Restricted策略"><a href="#4-2-Restricted策略" class="headerlink" title="4.2 Restricted策略"></a>4.2 Restricted策略</h3><p>Restricted 策略目标是实施当前保护 Pod 的最佳实践，在官方介绍中此策略主要针对运维人员和安全性很重要的应用开发人员，以及不太被信任的用户。该策略包含所有的 baseline 策略的内容，额外增加： 限制可以通过 PersistentVolumes 定义的非核心卷类型、禁止（通过 SetUID 或 SetGID 文件模式）获得特权提升、必须要求容器以非 root 用户运行、Containers 不可以将 runAsUser 设置为 0、 容器组必须弃用 ALL capabilities 并且只允许添加 NET_BIND_SERVICE 能力。</p><p>restricted 策略进一步的限制在容器内获取 root 权限，linux内核功能。例如针对 kubernetes 网络的中间人攻击需要拥有Linux系统的 CAP_NET_RAW 权限来发送ARP包。</p><ol><li><p>创建名为 my-restricted-namespace 的 namespace，并设定 enforce 和 warn 两种模式都对应 Restricted 等级的 Pod 安全标准策略：</p><p>资源清单：<code>my-restricted-namespace.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span> <span class="comment"># 命名空间的 API 版本（固定为 v1）</span><span class="attr">kind:</span> <span class="string">Namespace</span> <span class="comment"># 资源类型：命名空间（用于隔离集群资源）</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-restricted-namespace</span> <span class="comment"># 命名空间名称，Pod 将在此命名空间内运行</span>  <span class="attr">labels:</span> <span class="comment"># 核心：通过标签配置 Pod 安全策略（PSA 规则）</span>    <span class="comment"># 强制实施 Baseline 级别的安全标准，所有在该命名空间创建的 Pod 必须符合此标准，否则会被拒绝创建。</span>    <span class="attr">pod-security.kubernetes.io/enforce:</span> <span class="string">restricted</span>    <span class="comment"># 指定 enforce 规则所使用的 Kubernetes 版本（此处为 v1.29）， 这确保了 PSA 规则仅在指定的 Kubernetes 版本下生效，避免与未来版本的 Kubernetes 发生冲突。</span>    <span class="attr">pod-security.kubernetes.io/enforce-version:</span> <span class="string">v1.29</span>    <span class="comment"># 当 Pod 不符合 Restricted 标准时，不阻止创建，但会生成警告信息（通过 API 响应或事件日志）。</span>    <span class="attr">pod-security.kubernetes.io/warn:</span> <span class="string">restricted</span>    <span class="comment"># 指定 warn 规则所使用的 Kubernetes 版本，与 enforce-version 保持一致（v1.29），确保警告规则与强制规则基于相同的标准定义</span>    <span class="attr">pod-security.kubernetes.io/warn-version:</span> <span class="string">v1.29</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 创建名称空间</span>$ kubectl apply -f my-restricted-namespace.yaml namespace/my-restricted-namespace created<span class="comment"># 查看</span>$ kubectl get ns | grep restrictedmy-restricted-namespace   Active   12s</code></pre></li><li><p>创建pod</p><ul><li><p>创建一个违反 Restricted 策略的 pod</p><p>资源清单：<code>fail-restricted-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">my-restricted-namespace</span>  <span class="attr">name:</span> <span class="string">fail-restricted</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">fail-restricted</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">fail-restricted</span>    <span class="attr">spec:</span>      <span class="attr">hostPID:</span> <span class="literal">true</span> <span class="comment"># 与主机共享PID</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alpine</span>          <span class="attr">image:</span> <span class="string">alpine:3.22.1</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">command:</span> <span class="comment"># 容器启动命令</span>            <span class="bullet">-</span> <span class="string">/bin/sleep</span>            <span class="bullet">-</span> <span class="string">&quot;3600&quot;</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">true</span> <span class="comment"># 启用特权模式</span></code></pre><p>执行资源清单</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，提示异常</span>$ kubectl apply -f fail-restricted-pod.yaml Warning: would violate PodSecurity <span class="string">&quot;restricted:v1.29&quot;</span>: host namespaces (hostPID=<span class="literal">true</span>), privileged (container <span class="string">&quot;alpine&quot;</span> must not <span class="built_in">set</span> securityContext.privileged=<span class="literal">true</span>), allowPrivilegeEscalation != <span class="literal">false</span> (container <span class="string">&quot;alpine&quot;</span> must <span class="built_in">set</span> securityContext.allowPrivilegeEscalation=<span class="literal">false</span>), unrestricted capabilities (container <span class="string">&quot;alpine&quot;</span> must <span class="built_in">set</span> securityContext.capabilities.drop=[<span class="string">&quot;ALL&quot;</span>]), runAsNonRoot != <span class="literal">true</span> (pod or container <span class="string">&quot;alpine&quot;</span> must <span class="built_in">set</span> securityContext.runAsNonRoot=<span class="literal">true</span>), seccompProfile (pod or container <span class="string">&quot;alpine&quot;</span> must <span class="built_in">set</span> securityContext.seccompProfile.<span class="built_in">type</span> to <span class="string">&quot;RuntimeDefault&quot;</span> or <span class="string">&quot;Localhost&quot;</span>)deployment.apps/fail-restricted created<span class="comment"># 查看 Deploy，Pod未启动</span>$ kubectl get deployment -n my-restricted-namespaceNAME              READY   UP-TO-DATE   AVAILABLE   AGEfail-restricted   0/1     0            0           53s$ kubectl get pods -n my-restricted-namespaceNo resources found <span class="keyword">in</span> my-restricted-namespace namespace.</code></pre></li><li><p>创建不违反 Restricted 策略的 pod，设定 Pod 的 securityContext.runAsNonRoot&#x3D;true，Drop 所有 linux 能力。</p><p>资源清单：<code>success-restricted-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">my-restricted-namespace</span>  <span class="attr">name:</span> <span class="string">success-restricted</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">success-restricted</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">success-restricted</span>    <span class="attr">spec:</span>      <span class="attr">hostPID:</span> <span class="literal">false</span> <span class="comment"># 不与主机共享PID</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-nonroot</span>          <span class="attr">image:</span> <span class="string">nginx-nonroot:1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="comment"># 容器级别的安全上下文</span>          <span class="attr">securityContext:</span>            <span class="comment"># 以非root启动</span>            <span class="attr">runAsNonRoot:</span> <span class="literal">true</span>            <span class="comment"># 运行容器的用户ID</span>            <span class="attr">runAsUser:</span> <span class="number">101</span>            <span class="comment"># 不允许权限提升</span>            <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span>            <span class="comment"># 禁用所有能力</span>            <span class="attr">capabilities:</span>              <span class="attr">drop:</span>                <span class="bullet">-</span> <span class="string">ALL</span>      <span class="comment"># Pod级别的安全上下文</span>      <span class="attr">securityContext:</span>        <span class="comment"># 不允许以root启动</span>        <span class="attr">runAsNonRoot:</span> <span class="literal">true</span>        <span class="comment"># 不允许使用默认的seccomp profile</span>        <span class="attr">seccompProfile:</span>          <span class="attr">type:</span> <span class="string">RuntimeDefault</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f success-restricted-pod.yaml deployment.apps/success-restricted created<span class="comment"># 查看Pod 已成功运行</span>$ kubectl get deployment -n my-restricted-namespaceNAME                 READY   UP-TO-DATE   AVAILABLE   AGEsuccess-restricted   1/1     1            1           28s</code></pre></li></ul></li></ol><h1 id="四、pod-security-admission当前局限性"><a href="#四、pod-security-admission当前局限性" class="headerlink" title="四、pod security admission当前局限性"></a>四、pod security admission当前局限性</h1><p>如果你的集群中已经配置PodSecurityPolicy，考虑把它们迁移到pod security admission是需要一定的工作量的。</p><p>首先需要考虑当前的pod security admission是否适合你的集群，目前它旨在满足开箱即用的最常见的安全需求，与PSP相比它存在以下差异：</p><ul><li>pod security admission 只是对 pod 进行安全标准的检查，不支持对 pod 进行修改，不能为 pod 设置默认的安全配置。</li><li>pod security admission 只支持官方定义的三种安全标准策略，不支持灵活的自定义安全标准策略。这使得不能完全将 PSP 规则迁移到 pod security admission，需要进行具体的安全规则考量。</li><li>pod security admission 不像 PSP 一样可以与具体的用户进行绑定，只支持豁免特定的用户或者 RuntimeClass 及 namespace。</li></ul><p><strong>参考链接</strong></p><blockquote><p><a href="https://support.huaweicloud.com/usermanual-cce/cce_10_0402.html">https://support.huaweicloud.com/usermanual-cce/cce_10_0402.html</a></p><p><a href="https://www.cnblogs.com/zhangmingcheng/p/17640118.html">https://www.cnblogs.com/zhangmingcheng/p/17640118.html</a></p><p><a href="https://www.cnblogs.com/bocloud/p/16107335.html">https://www.cnblogs.com/bocloud/p/16107335.html</a></p><p><a href="https://waynerv.com/posts/enable-pod-security-policy-for-cluster/">https://waynerv.com/posts/enable-pod-security-policy-for-cluster/</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;集群环境&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;Hostname&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;10.20.1.139&lt;/td&gt;
</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>020-K8S-审计</title>
    <link href="https://georgechan95.github.io/blog/88f4f580.html"/>
    <id>https://georgechan95.github.io/blog/88f4f580.html</id>
    <published>2025-08-10T06:43:00.000Z</published>
    <updated>2025-08-11T02:54:19.657Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h1><p>Kubernetes 审计（Auditing） 功能提供了与安全相关的、按时间顺序排列的记录集， 记录每个用户、使用 Kubernetes API 的应用以及控制面自身引发的活动（所有访问kube-apiserver服务的客户端）。</p><p>审计功能使得集群管理员能够回答以下问题：</p><ul><li>发生了什么？</li><li>什么时候发生的？</li><li>谁触发的？</li><li>活动发生在哪个（些）对象上？</li><li>在哪观察到的？</li><li>它从哪触发的？</li><li>活动的后续处理行为是什么？</li></ul><p>这对平台管理者来说十分重要，能够回答一些在故障时候出现的问题。哪个用户，从哪个ip上，发起了什么请求。如删除了一个命名空间，导致这个命名空间下的所有pod被回收，对故障进行复盘。</p><p>Kubernetes 审计功能由 kube-apiserver 服务提供。每个请求在不同执行阶段都会生成审计事件；这些审计事件会根据特定策略被预处理并写入后端。策略确定要记录的内容，当前的后端支持日志文件和 webhook。</p><p>每个请求都可被记录其相关的 <strong>阶段（stage）</strong>。已定义的阶段有：</p><ul><li><code>RequestReceived</code> - 此阶段对应审计处理器接收到请求后，并且在委托给处理器处理之前生成的事件。</li><li><code>ResponseStarted</code> - 在响应消息的头部发送后，响应消息体发送前生成的事件。 只有长时间运行的请求（例如 watch）才会生成这个阶段。</li><li><code>ResponseComplete</code> - 当响应消息体完成并且没有更多数据需要传输的时候。</li><li><code>Panic</code> - 当 panic 发生时生成。</li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-152540.png" alt="审计的4个阶段"></p><p>审计日志记录功能会增加 API server 的内存消耗，因为需要为每个请求存储审计所需的某些上下文。 此外，内存消耗取决于审计日志记录的配置。</p><p>Kubernetes 审计是一种监控和记录 Kubernetes 集群中资源操作的方法，用于确保集群的安全性和符合性。通过审计，管理员可以跟踪对集群资源的访问和修改，以便在发生安全事件时进行调查和响应。Kubernetes 提供了审计日志记录的框架，允许管理员自定义审计策略，以确定哪些资源操作应该被记录。</p><h1 id="二、审计策略简介"><a href="#二、审计策略简介" class="headerlink" title="二、审计策略简介"></a>二、审计策略简介</h1><p>审计策略定义了关于应记录哪些事件以及应包含哪些数据的规则。 审计策略对象结构定义在 <code>audit.k8s.io</code> API 组。 处理事件时，将按顺序与规则列表进行比较。第一个匹配规则设置事件的审计级别（Audit Level），<strong>审计级别（Audit Level）可以理解为记录什么？</strong> 已定义的审计级别有：</p><ul><li>None - 符合这条规则的日志将不会记录。</li><li>Metadata - 记录请求的元数据（请求的用户、时间戳、资源、动词等等）， 但是不记录请求或者响应的消息体。</li><li>Request - 记录事件的元数据和请求的消息体，但是不记录响应的消息体。 这不适用于非资源类型的请求。</li><li>RequestResponse - 记录事件的元数据，请求和响应的消息体。这不适用于非资源类型的请求。</li></ul><p>你可以使用 <code>--audit-policy-file</code> 标志将包含策略的文件传递给 <code>kube-apiserver</code>。 如果不设置该标志，则不记录事件。 注意 <code>rules</code> 字段 <strong>必须</strong> 在审计策略文件中提供。没有（0）规则的策略将被视为非法配置。</p><p>审计策略定义了哪些资源操作应该被审计以及审计记录的格式。在 Kubernetes 中，审计策略通过 Admission Controllers 实现，可以通过 Webhook 的方式进行集成。审计策略可以根据资源的类型、操作的类型和用户身份等信息进行过滤，以满足不同场景下的审计需求。</p><h1 id="三、启用审计"><a href="#三、启用审计" class="headerlink" title="三、启用审计"></a>三、启用审计</h1><h2 id="1-创建审计策略文件"><a href="#1-创建审计策略文件" class="headerlink" title="1. 创建审计策略文件"></a>1. 创建审计策略文件</h2><pre><code class="highlight bash"><span class="comment"># 创建文件夹，用于存放审计日志策略文件，和日志文件</span>$ <span class="built_in">mkdir</span> /etc/kubernetes/audit-policy /etc/kubernetes/audit-logs<span class="comment"># 编辑审计策略（仅是示例）</span>$ <span class="built_in">cat</span> /etc/kubernetes/audit-policy/policy.yamlapiVersion: audit.k8s.io/v1kind: Policyrules:  <span class="comment"># 设置机密资源的审计日志级别为Metadata</span>  - level: Metadata    resources:      - group: <span class="string">&quot;&quot;</span>        resources: [<span class="string">&quot;pods&quot;</span>]    namespaces: [<span class="string">&quot;default&quot;</span>]             <span class="comment"># 默认就是default命名空间</span>  <span class="comment"># 设置节点的审计日志级别为RequestResponse</span>  - level: RequestResponse    userGroups: [<span class="string">&quot;system:nodes&quot;</span>]  <span class="comment"># 对于其他内容，不要记录任何内容</span>  - level: None</code></pre><h2 id="2-添加审计日志"><a href="#2-添加审计日志" class="headerlink" title="2. 添加审计日志"></a>2. 添加审计日志</h2><p>审计日志参数如下：</p><ul><li>–audit-log-path 指定用来写入审计事件的日志文件路径。不指定此标志会禁用日志后端。- 意味着标准化</li><li>–audit-log-maxage 定义保留旧审计日志文件的最大天数</li><li>–audit-log-maxbackup 定义要保留的审计日志文件的最大数量</li><li>–audit-log-maxsize 定义审计日志文件轮转之前的最大大小（兆字节）</li></ul><pre><code class="highlight yaml"><span class="comment"># 修改 kube-apiserver.yaml，添加添加审计日志配置</span><span class="string">$</span> <span class="string">vim</span> <span class="string">/etc/kubernetes/manifests/kube-apiserver.yaml</span><span class="comment"># 配置审计日志参数</span><span class="attr">spec:</span>  <span class="attr">containers:</span>  <span class="bullet">-</span> <span class="attr">command:</span>    <span class="bullet">-</span> <span class="string">--audit-policy-file=/etc/kubernetes/audit-policy/policy.yaml</span><span class="comment"># 审计策略文件</span>    <span class="bullet">-</span> <span class="string">--audit-log-path=/etc/kubernetes/audit-logs/audit.log</span><span class="comment"># 审计日志文件</span>    <span class="bullet">-</span> <span class="string">--audit-log-maxsize=10</span><span class="comment"># 单个日志最大 10MB</span>    <span class="bullet">-</span> <span class="string">--audit-log-maxbackup=20</span><span class="comment"># 最多保留20个日志文件</span><span class="comment"># 挂载存储卷，将审计策略文件和日志文件挂载到容器内的指定路径</span><span class="attr">volumeMounts:</span><span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/kubernetes/audit-policy/policy.yaml</span>  <span class="attr">name:</span> <span class="string">audit-policy</span>  <span class="attr">readOnly:</span> <span class="literal">true</span><span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/kubernetes/audit-logs</span>  <span class="attr">name:</span> <span class="string">audit-logs</span>  <span class="attr">readOnly:</span> <span class="literal">false</span><span class="comment"># 声明挂载卷</span>  <span class="attr">volumes:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">audit-policy</span>    <span class="attr">hostPath:</span>      <span class="attr">path:</span> <span class="string">/etc/kubernetes/audit-policy/policy.yaml</span>      <span class="attr">type:</span> <span class="string">File</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">audit-logs</span>    <span class="attr">hostPath:</span>      <span class="attr">path:</span> <span class="string">/etc/kubernetes/audit-logs</span>      <span class="attr">type:</span> <span class="string">DirectoryOrCreate</span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-155941.png" alt="配置审计日志参数"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-160013.png" alt="挂载存储卷"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-160042.png" alt="声明挂载卷"></p><p>保存 kube-apiserver.yaml 文件后，等待生效（为了保险起见也可以重启 kubelet ）。</p><pre><code class="highlight bash">$ systemctl daemon-reload$ systemctl restart kubelet</code></pre><h2 id="3-查看审计日志"><a href="#3-查看审计日志" class="headerlink" title="3. 查看审计日志"></a>3. 查看审计日志</h2><h3 id="3-1-创建测试-Pod"><a href="#3-1-创建测试-Pod" class="headerlink" title="3.1 创建测试 Pod"></a>3.1 创建测试 Pod</h3><pre><code class="highlight bash">$ kubectl run audit-demo --image=nginx:1.29.0 --image-pull-policy=IfNotPresent</code></pre><h3 id="3-2-查看日志"><a href="#3-2-查看日志" class="headerlink" title="3.2 查看日志"></a>3.2 查看日志</h3><pre><code class="highlight bash">$ <span class="built_in">tail</span> -1000f /etc/kubernetes/audit-logs/audit.log | grep audit-demo -A 10&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;Metadata&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;3943a216-8452-45d9-a127-6ab2e58e4fa0&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;RequestReceived&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/api/v1/namespaces/default/pods/audit-demo&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;get&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:serviceaccount:kube-system:calico-cni-plugin&quot;</span>,<span class="string">&quot;uid&quot;</span>:<span class="string">&quot;3d9a2a4d-8207-4e57-ae9e-23e4e1a943be&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:serviceaccounts&quot;</span>,<span class="string">&quot;system:serviceaccounts:kube-system&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.140&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;calico/v0.0.0 (linux/amd64) kubernetes/<span class="variable">$Format</span>&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;pods&quot;</span>,<span class="string">&quot;namespace&quot;</span>:<span class="string">&quot;default&quot;</span>,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;audit-demo&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.977141Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.977141Z&quot;</span>&#125;&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;Metadata&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;3943a216-8452-45d9-a127-6ab2e58e4fa0&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;ResponseComplete&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/api/v1/namespaces/default/pods/audit-demo&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;get&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:serviceaccount:kube-system:calico-cni-plugin&quot;</span>,<span class="string">&quot;uid&quot;</span>:<span class="string">&quot;3d9a2a4d-8207-4e57-ae9e-23e4e1a943be&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:serviceaccounts&quot;</span>,<span class="string">&quot;system:serviceaccounts:kube-system&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.140&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;calico/v0.0.0 (linux/amd64) kubernetes/<span class="variable">$Format</span>&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;pods&quot;</span>,<span class="string">&quot;namespace&quot;</span>:<span class="string">&quot;default&quot;</span>,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;audit-demo&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;responseStatus&quot;</span>:&#123;<span class="string">&quot;metadata&quot;</span>:&#123;&#125;,<span class="string">&quot;code&quot;</span>:200&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.977141Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.979410Z&quot;</span>,<span class="string">&quot;annotations&quot;</span>:&#123;<span class="string">&quot;authorization.k8s.io/decision&quot;</span>:<span class="string">&quot;allow&quot;</span>,<span class="string">&quot;authorization.k8s.io/reason&quot;</span>:<span class="string">&quot;RBAC: allowed by ClusterRoleBinding \&quot;calico-cni-plugin\&quot; of ClusterRole \&quot;calico-cni-plugin\&quot; to ServiceAccount \&quot;calico-cni-plugin/kube-system\&quot;&quot;</span>&#125;&#125;&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;Metadata&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;8c1f6ae3-edb9-41cf-a73a-633ad406d270&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;RequestReceived&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/api/v1/namespaces/default/pods/audit-demo&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;get&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:serviceaccount:kube-system:calico-cni-plugin&quot;</span>,<span class="string">&quot;uid&quot;</span>:<span class="string">&quot;3d9a2a4d-8207-4e57-ae9e-23e4e1a943be&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:serviceaccounts&quot;</span>,<span class="string">&quot;system:serviceaccounts:kube-system&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.140&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;calico/v0.0.0 (linux/amd64) kubernetes/<span class="variable">$Format</span>&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;pods&quot;</span>,<span class="string">&quot;namespace&quot;</span>:<span class="string">&quot;default&quot;</span>,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;audit-demo&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.984952Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-10T08:05:13.984952Z&quot;</span>&#125;</code></pre><h3 id="3-3-日志解析"><a href="#3-3-日志解析" class="headerlink" title="3.3 日志解析"></a>3.3 日志解析</h3><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-161933.png" alt="审计日志解析"></p><h1 id="四、审计策略案例实践"><a href="#四、审计策略案例实践" class="headerlink" title="四、审计策略案例实践"></a>四、审计策略案例实践</h1><pre><code class="highlight bash"><span class="comment"># 创建命名空间</span>$ kubectl create ns auditnamespace/audit created$ kubectl get ns | grep auditaudit             Active   11m</code></pre><h2 id="1-只记录-audit-命名空间里的日志"><a href="#1-只记录-audit-命名空间里的日志" class="headerlink" title="1. 只记录 audit 命名空间里的日志"></a>1. 只记录 audit 命名空间里的日志</h2><p>修改审计策略，现在配置只记录某个命名空间里的审计日志，namespaces: [“audit”] 表示只记录 audit 命名空间里的日志。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">omitStages:</span>                     <span class="comment"># 记录审计阶段为：ResponseStarted</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span>             <span class="comment"># 设置机密资源的审计日志级别为Metadata</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]       <span class="comment"># 只记录该命名空间的日志</span></code></pre><p>重启 kubelet , 让策略生效</p><pre><code class="highlight bash">$ systemctl daemon-reload &amp;&amp; systemctl restart kubelet</code></pre><p>清空 <code>audit.log</code></p><pre><code class="highlight bash">$ &gt; /etc/kubernetes/audit-logs/audit.log</code></pre><p>查看审计日志，只记录了audit 命名空间的操作，default 命名空间的操作没有记录。</p><pre><code class="highlight bash">$ <span class="built_in">tail</span> -100f /etc/kubernetes/audit-logs/audit.log&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;RequestResponse&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;2205c680-4877-4498-b40f-459b2779afa8&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;ResponseComplete&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/apis/node.k8s.io/v1/runtimeclasses?allowWatchBookmarks=true\u0026resourceVersion=2798746\u0026timeout=9m18s\u0026timeoutSeconds=558\u0026watch=true&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;watch&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:node:k8s-master01&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:nodes&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.139&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;kubelet/v1.29.15 (linux/amd64) kubernetes/0d0f172&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;runtimeclasses&quot;</span>,<span class="string">&quot;apiGroup&quot;</span>:<span class="string">&quot;node.k8s.io&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;responseStatus&quot;</span>:&#123;<span class="string">&quot;metadata&quot;</span>:&#123;&#125;,<span class="string">&quot;code&quot;</span>:200&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:06:30.212676Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:08:29.706126Z&quot;</span>,<span class="string">&quot;annotations&quot;</span>:&#123;<span class="string">&quot;authorization.k8s.io/decision&quot;</span>:<span class="string">&quot;allow&quot;</span>,<span class="string">&quot;authorization.k8s.io/reason&quot;</span>:<span class="string">&quot;&quot;</span>&#125;&#125;&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;RequestResponse&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;4a54a59a-fa98-43e7-a004-f14b9d4bd6eb&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;ResponseComplete&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/api/v1/nodes?allowWatchBookmarks=true\u0026fieldSelector=metadata.name%3Dk8s-master01\u0026resourceVersion=2798755\u0026timeout=6m45s\u0026timeoutSeconds=405\u0026watch=true&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;watch&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:node:k8s-master01&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:nodes&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.139&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;kubelet/v1.29.15 (linux/amd64) kubernetes/0d0f172&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;nodes&quot;</span>,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;k8s-master01&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;responseStatus&quot;</span>:&#123;<span class="string">&quot;metadata&quot;</span>:&#123;&#125;,<span class="string">&quot;code&quot;</span>:200&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:06:31.945964Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:08:29.706028Z&quot;</span>,<span class="string">&quot;annotations&quot;</span>:&#123;<span class="string">&quot;authorization.k8s.io/decision&quot;</span>:<span class="string">&quot;allow&quot;</span>,<span class="string">&quot;authorization.k8s.io/reason&quot;</span>:<span class="string">&quot;&quot;</span>&#125;&#125;&#123;<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Event&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;audit.k8s.io/v1&quot;</span>,<span class="string">&quot;level&quot;</span>:<span class="string">&quot;RequestResponse&quot;</span>,<span class="string">&quot;auditID&quot;</span>:<span class="string">&quot;9dcf6bb7-51f5-45d0-a7b6-f352e455c736&quot;</span>,<span class="string">&quot;stage&quot;</span>:<span class="string">&quot;ResponseComplete&quot;</span>,<span class="string">&quot;requestURI&quot;</span>:<span class="string">&quot;/api/v1/services?allowWatchBookmarks=true\u0026resourceVersion=2798746\u0026timeout=8m41s\u0026timeoutSeconds=521\u0026watch=true&quot;</span>,<span class="string">&quot;verb&quot;</span>:<span class="string">&quot;watch&quot;</span>,<span class="string">&quot;user&quot;</span>:&#123;<span class="string">&quot;username&quot;</span>:<span class="string">&quot;system:node:k8s-master01&quot;</span>,<span class="string">&quot;groups&quot;</span>:[<span class="string">&quot;system:nodes&quot;</span>,<span class="string">&quot;system:authenticated&quot;</span>]&#125;,<span class="string">&quot;sourceIPs&quot;</span>:[<span class="string">&quot;10.20.1.139&quot;</span>],<span class="string">&quot;userAgent&quot;</span>:<span class="string">&quot;kubelet/v1.29.15 (linux/amd64) kubernetes/0d0f172&quot;</span>,<span class="string">&quot;objectRef&quot;</span>:&#123;<span class="string">&quot;resource&quot;</span>:<span class="string">&quot;services&quot;</span>,<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>&#125;,<span class="string">&quot;responseStatus&quot;</span>:&#123;<span class="string">&quot;metadata&quot;</span>:&#123;&#125;,<span class="string">&quot;code&quot;</span>:200&#125;,<span class="string">&quot;requestReceivedTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:06:29.952827Z&quot;</span>,<span class="string">&quot;stageTimestamp&quot;</span>:<span class="string">&quot;2025-08-11T02:08:29.706023Z&quot;</span>,<span class="string">&quot;annotations&quot;</span>:&#123;<span class="string">&quot;authorization.k8s.io/decision&quot;</span>:<span class="string">&quot;allow&quot;</span>,<span class="string">&quot;authorization.k8s.io/reason&quot;</span>:<span class="string">&quot;&quot;</span>&#125;&#125;</code></pre><h2 id="2-只记录-audit-命名空间的-pods-操作日志"><a href="#2-只记录-audit-命名空间的-pods-操作日志" class="headerlink" title="2. 只记录 audit 命名空间的 pods 操作日志"></a>2. 只记录 audit 命名空间的 pods 操作日志</h2><p>修改审计策略，该审计策略表示只记录 audit 命名空间的 pods 操作</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span>     <span class="comment"># 只记录audit命名空间的pods操作日志</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">omitStages:</span>                     <span class="comment"># 记录审计阶段为：ResponseStarted</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span>             <span class="comment"># 设置机密资源的审计日志级别为Metadata</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>        <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]       <span class="comment"># 只记录该命名空间的日志</span></code></pre><h2 id="3-只记录-audit-命名空间的-pods-services-deployments-操作日志"><a href="#3-只记录-audit-命名空间的-pods-services-deployments-操作日志" class="headerlink" title="3. 只记录 audit 命名空间的 pods,services,deployments 操作日志"></a>3. 只记录 audit 命名空间的 pods,services,deployments 操作日志</h2><p>编辑审计策略文件，表示只记录 audit 命名空间的 pods,services,deployments 操作，因为 deployments 的 apiVersion 的父级为 apps，所以需要 group: “apps” 。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span>     <span class="comment"># 只记录audit命名空间的pods,services,deployments操作日志</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">omitStages:</span>                     <span class="comment"># 记录审计阶段为：ResponseStarted</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span>             <span class="comment"># 设置机密资源的审计日志级别为Metadata</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>        <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>,<span class="string">&quot;services&quot;</span>]      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;apps&quot;</span>        <span class="attr">resources:</span> [<span class="string">&quot;deployments&quot;</span>]    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]       <span class="comment"># 只记录该命名空间的日志</span></code></pre><h2 id="4-只记录-audit-命名空间的-pods-操作-审计级别为-RequestResponse"><a href="#4-只记录-audit-命名空间的-pods-操作-审计级别为-RequestResponse" class="headerlink" title="4. 只记录 audit 命名空间的 pods 操作,审计级别为 RequestResponse"></a>4. 只记录 audit 命名空间的 pods 操作,审计级别为 RequestResponse</h2><p>编辑审计策略文件，表示只记录 audit 命名空间的 pods 操作,审计级别为 RequestResponse，记录事件的元数据，请求和响应的消息体。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span>     <span class="comment"># 只记录audit命名空间的pods,services,deployments操作日志</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">omitStages:</span>                     <span class="comment"># 记录审计阶段为：ResponseStarted</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">RequestResponse</span>             <span class="comment"># 设置机密资源的审计日志级别为 RequestResponse</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>        <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]       <span class="comment"># 只记录该命名空间的日志</span></code></pre><h2 id="5-只记录-audit-命名空间下的-dev-用户的-pods-操作，其他用户操作不记录"><a href="#5-只记录-audit-命名空间下的-dev-用户的-pods-操作，其他用户操作不记录" class="headerlink" title="5. 只记录 audit 命名空间下的 dev 用户的 pods 操作，其他用户操作不记录"></a>5. 只记录 audit 命名空间下的 dev 用户的 pods 操作，其他用户操作不记录</h2><p>参考：<a href="https://georgechan95.github.io/blog/424f1119.html">https://georgechan95.github.io/blog/424f1119.html</a></p><p>编辑审计策略文件，设置审计策略：只记录 audit 命名空间下的 george 用户的 pods 操作，其他用户的操作不记录。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span>     <span class="comment"># 只记录audit命名空间的pods,services,deployments操作日志</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">omitStages:</span>                     <span class="comment"># 记录审计阶段为：ResponseStarted</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span>             <span class="comment"># 设置机密资源的审计日志级别为 Metadata</span>    <span class="attr">users:</span> [<span class="string">&quot;george&quot;</span>]           <span class="comment"># 只记录 george 用户的操作</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>        <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]       <span class="comment"># 只记录该命名空间的日志</span></code></pre><h2 id="6-rules-规则是从上往下匹配的，第一条规则已经匹配了，第二条就不匹配了"><a href="#6-rules-规则是从上往下匹配的，第一条规则已经匹配了，第二条就不匹配了" class="headerlink" title="6. rules 规则是从上往下匹配的，第一条规则已经匹配了，第二条就不匹配了"></a>6. rules 规则是从上往下匹配的，第一条规则已经匹配了，第二条就不匹配了</h2><p>编辑审计策略文件，有两条策略，一条是：apiVersion 为 group: “” 的操作不记录日志，另外一条是：只记录 audit 命名空间下 george 用户的 pod 操作。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1</span> <span class="comment"># This is required.</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="comment"># Don&#x27;t generate audit events for all requests in RequestReceived stage.</span><span class="attr">omitStages:</span>  <span class="bullet">-</span> <span class="string">&quot;ResponseStarted&quot;</span><span class="attr">rules:</span>  <span class="comment"># apiVersion为 group: &quot;&quot; 的操作不记录日志</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">None</span>    <span class="attr">resources:</span>    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>  <span class="comment"># 只记录 audit 命名空间下 george 用户的 pod 操作</span>  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span>    <span class="attr">users:</span> [<span class="string">&quot;george&quot;</span>]    <span class="attr">resources:</span>    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">&quot;&quot;</span>      <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]    <span class="attr">namespaces:</span> [<span class="string">&quot;audit&quot;</span>]</code></pre><p>查看审计日志，可以发现在客户端使用 george 用户查询 pod 和使用管理员用户查看 pod 都没有生成审计日志，rules 规则是从上往下匹配的，第一条规则已经匹配了，第二条就不匹配了。</p><h2 id="7-在-Metadata-级别为所有请求生成日志"><a href="#7-在-Metadata-级别为所有请求生成日志" class="headerlink" title="7. 在 Metadata 级别为所有请求生成日志"></a>7. 在 Metadata 级别为所有请求生成日志</h2><p>编辑审计策略文件，在 Metadata 级别为所有请求生成日志。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1beta1</span><span class="attr">kind:</span> <span class="string">Policy</span><span class="attr">rules:</span><span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span></code></pre><h1 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h1><p>实施审计策略可以帮助管理员监控和记录集群中的资源操作，确保集群的安全性和符合性。通过启用审计 Admission Controller 和配置相应的审计策略，我们可以灵活地控制审计记录的格式和范围。</p><p><strong>参考链接</strong></p><blockquote><p><a href="https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/audit/">https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/audit/</a></p><p><a href="https://kubernetes.io/zh-cn/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Event">https://kubernetes.io/zh-cn/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Event</a></p><p><a href="https://www.cnblogs.com/renshengdezheli/p/18266120">https://www.cnblogs.com/renshengdezheli/p/18266120</a></p><p><a href="https://www.cnblogs.com/tencent-cloud-native/p/14097545.html">https://www.cnblogs.com/tencent-cloud-native/p/14097545.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、概述&quot;&gt;&lt;a href=&quot;#一、概述&quot; class=&quot;headerlink&quot; title=&quot;一、概述&quot;&gt;&lt;/a&gt;一、概述&lt;/h1&gt;&lt;p&gt;Kubernetes 审计（Auditing） 功能提供了与安全相关的、按时间顺序排列的记录集， 记录每个用户、使用 Kub</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>019-K8S-kubectl端口转发</title>
    <link href="https://georgechan95.github.io/blog/9bea6e2e.html"/>
    <id>https://georgechan95.github.io/blog/9bea6e2e.html</id>
    <published>2025-08-04T15:02:00.000Z</published>
    <updated>2025-08-10T04:05:16.107Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h1><p>在 Kubernetes 集群中，所有资源都运行在私有网络空间（通常使用 CNI 插件构建 overlay 网络），这带来了以下调试难题：</p><ul><li>Pod 使用动态 IP 地址（生命周期短暂）</li><li>Service 的 ClusterIP 仅在集群内部可达</li><li>生产环境通常禁用 NodePort 等暴露方式</li></ul><p>针对上述的几种情况，我们就可以使用 <code>kubectl port-forward</code>来满足需求。</p><h2 id="1-port-forward-介绍"><a href="#1-port-forward-介绍" class="headerlink" title="1. port-forward 介绍"></a>1. port-forward 介绍</h2><p><code>kubectl port-forward</code> 是 Kubernetes 命令行工具 kubectl 提供的一个功能，用于在本地主机和 Kubernetes 集群中的 Pod 之间建立端口转发。</p><p>当你运行 kubectl port-forward 命令时，它会将本地主机上的一个端口与 Kubernetes 集群中的一个 Pod 的端口进行绑定。这样，在本地主机上监听的端口上收到的流量将被转发到 Pod 的端口上，反之亦然。</p><p>这个功能在开发和调试应用程序时非常有用。以下是一些 <code>kubectl port-forward</code>的常见用途和好处：</p><ul><li><strong>访问远程 Pod 的本地服务</strong>: 你可以将 Pod 的端口转发到本地主机，从而能够直接访问 Pod 上运行的服务。例如，你可以将一个运行在 Kubernetes 集群中的数据库 Pod 的端口转发到本地，以便在本地开发环境中连接和测试数据库。</li><li><strong>调试和日志记录</strong>: 通过将 Pod 的端口转发到本地，你可以使用本地工具来调试和监视在 Kubernetes 中运行的应用程序。你可以使用本地的调试器、日志记录工具或其他开发工具来检查应用程序的状态、调试问题或查看日志。</li><li><strong>绕过 Kubernetes 服务和负载均衡器</strong>: 有时候，你可能想直接访问运行在 Kubernetes 中的应用程序，而不经过 Kubernetes 的服务发现和负载均衡机制。通过将 Pod 的端口转发到本地，你可以绕过这些机制，直接连接到应用程序。</li></ul><p><strong>端口转发优势</strong></p><table><thead><tr><th><strong>特性</strong></th><th><strong>kubectl port-forward</strong></th><th><strong>NodePort</strong></th><th><strong>Ingress</strong></th></tr></thead><tbody><tr><td>无需修改资源配置</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>临时性访问</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>支持TCP&#x2F;UDP</td><td><strong>TCP</strong></td><td>✓</td><td><strong>HTTP&#x2F;HTTPS only</strong></td></tr><tr><td>网络策略穿透</td><td>✓</td><td>✗</td><td>✗</td></tr></tbody></table><p><strong>注意：<code>kubectl port-forward</code> 目前仅支持 <code>TCP</code> 端口的转发，对 <code>UDP</code> 协议的支持正在 <code>GitHub</code> 的 <code>Issue</code> Port-forward for UDP 中进行跟踪。</strong></p><h2 id="2-安装-socat"><a href="#2-安装-socat" class="headerlink" title="2. 安装 socat"></a>2. 安装 socat</h2><p>kubectl port-forward 命令依赖 socat 来处理本地端口与 Kubernetes Pod 之间的 TCP 连接转发。如果 socat 未安装，命令会无法执行转发操作，导致连接丢失（”lost connection to pod”）。</p><p><strong>Pod 运行的每个节点都需要安装</strong></p><pre><code class="highlight bash"><span class="comment"># Linux（例如 Ubuntu/Debian）：</span>sudo apt updatesudo apt install socat<span class="comment"># Linux（例如 CentOS/RHEL/Fedora）</span>sudo yum install socat<span class="comment"># dnf 系统</span>sudo dnf install socat<span class="comment"># macOS（使用 Homebrew）</span>brew install socat</code></pre><h1 id="二、kubectl-port-forward-命令概述"><a href="#二、kubectl-port-forward-命令概述" class="headerlink" title="二、kubectl port-forward 命令概述"></a>二、kubectl port-forward 命令概述</h1><h2 id="1-基本语法"><a href="#1-基本语法" class="headerlink" title="1. 基本语法"></a>1. 基本语法</h2><pre><code class="highlight bash">kubectl port-forward &lt;pod-name&gt; [local-port:]pod-port [-n namespace]  kubectl port-forward deployment/&lt;deployment-name&gt; [local-port:]pod-port [-n namespace]kubectl port-forward replicaset/&lt;replicaset-name&gt; [local-port:]pod-port [-n namespace]kubectl port-forward service/&lt;service-name&gt; [local-port:]pod-port [-n namespace]</code></pre><p><strong>核心参数说明</strong></p><pre><code class="highlight plaintext">-n, --namespace string       指定命名空间（默认default）--address stringArray        绑定地址（默认为127.0.0.1）， 0.0.0.0 表示所有ip都能连接访问--pod-running-timeout duration 等待Pod运行的最长时间</code></pre><h2 id="2-多资源类型支持"><a href="#2-多资源类型支持" class="headerlink" title="2. 多资源类型支持"></a>2. 多资源类型支持</h2><pre><code class="highlight bash"><span class="comment"># Pod 转发（直接访问指定Pod）</span>kubectl port-forward pod/nginx 8080:80 <span class="comment"># Deployment 转发（自动选择最新Pod）</span>kubectl port-forward deployment/nginx 8080:80 <span class="comment"># Service 转发（自动选择后端Pod）</span>kubectl port-forward svc/mysql 3306:3306 <span class="comment"># StatefulSet 转发（指定序号Pod）</span>kubectl port-forward pod/redis-1 6379:6379</code></pre><h2 id="3-高级转发模式"><a href="#3-高级转发模式" class="headerlink" title="3. 高级转发模式"></a>3. 高级转发模式</h2><h3 id="3-1-多端口转发"><a href="#3-1-多端口转发" class="headerlink" title="3.1 多端口转发"></a>3.1 多端口转发</h3><pre><code class="highlight bash">kubectl port-forward pod/nginx 8080:80 8443:443</code></pre><h3 id="3-2-后台运行"><a href="#3-2-后台运行" class="headerlink" title="3.2 后台运行"></a>3.2 后台运行</h3><pre><code class="highlight bash"><span class="comment"># 使用 nohup 防止终端关闭后进程终止</span><span class="built_in">nohup</span> kubectl port-forward pod/nginx 8080:80 &gt; portforward.log 2&gt;&amp;1 &lt; /dev/null &amp;</code></pre><p><strong>命令解析</strong></p><p>这个命令用于在后台运行 Kubernetes 的 kubectl port-forward 操作，将本地端口（8080）上的流量转发到 Kubernetes 中名为 nginx 的 Pod 的端口（80）。它通过 nohup 确保进程在终端关闭后继续运行，将输出重定向到日志文件，并将进程与终端分离。</p><ul><li><p>**<code>nohup</code>**：作用：nohup（no hang-up，意为“无挂起”）是一个 Unix 工具，用于让进程在用户退出终端或关闭会话后继续运行。通常，当终端会话关闭时，进程会收到 SIGHUP（挂起信号）而终止，而 nohup 可以防止进程因收到此信号而停止。</p></li><li><p>**<code>&gt; portforward.log</code>**：作用：将命令的标准输出（stdout）重定向到文件 portforward.log 中。</p><ul><li>kubectl port-forward 的输出（例如连接信息或日志）会被写入到当前目录下的 portforward.log 文件，而不是显示在终端上。</li><li>如果 portforward.log 文件已存在，&gt; 会覆盖原有内容（若想追加而不是覆盖，可以用 &gt;&gt;）。</li></ul></li><li><p>**<code>2&gt;&amp;1</code>**：作用：将标准错误（stderr）重定向到标准输出（stdout）。</p><p>在 Unix&#x2F;Linux 中，进程有三个标准文件描述符</p><ul><li>0：标准输入（stdin）</li><li>1：标准输出（stdout）</li><li>2：标准错误（stderr）</li></ul><p>2&gt;&amp;1 表示将标准错误（2）重定向到标准输出（1）的同一个目标。结合前面的 <code>&gt; portforward.log</code>，这意味着标准错误和标准输出都会被写入到 portforward.log 文件中。</p></li><li><p><strong><code>&lt; /dev/null</code></strong> ：将标准输入（stdin）重定向到 &#x2F;dev&#x2F;null。</p><ul><li><code>/dev/null</code> 是一个特殊的 Unix 文件，任何写入其中的数据都会被丢弃，读取时则返回空。</li><li><code>&lt; /dev/null</code> 表示将命令的标准输入设置为 &#x2F;dev&#x2F;null，意味着命令不会从终端读取任何输入。</li></ul></li><li><p><strong><code>&amp;</code></strong> ：将命令放入后台运行</p><ul><li><p><code>&amp;</code> 使整个命令在后台执行，终端会立即返回提示符，允许用户继续执行其他命令。</p></li><li><p>结合 <code>nohup</code>，这确保进程不仅在后台运行，而且在终端关闭后也不会终止。</p></li></ul></li></ul><p><strong>关闭后台进程</strong></p><pre><code class="highlight bash"><span class="comment"># 查找进程</span>ps aux | grep kubectl输出示例：user     12345  0.1  0.2 123456 7890 ?  S    04:00   0:00 kubectl port-forward pod/nginx 8080:80<span class="comment"># 杀死进程</span><span class="built_in">kill</span> -9 &lt;PID&gt;</code></pre><h1 id="三、案例实操"><a href="#三、案例实操" class="headerlink" title="三、案例实操"></a>三、案例实操</h1><h2 id="1-创建-Pod"><a href="#1-创建-Pod" class="headerlink" title="1. 创建 Pod"></a>1. 创建 Pod</h2><pre><code class="highlight bash"><span class="comment"># 创建一个nginx deployment</span>$ kubectl create deployment nginx-deployment --image=nginx:1.29.0 --replicas=3<span class="comment"># 查看Deployment</span>$ kubectl get deployment -o wideNAME               READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTORnginx-deployment   2/3     3            2           14s   nginx        nginx:1.29.0   app=nginx-deployment<span class="comment"># 查看Pod</span>$ kubectl get pods -o wideNAME                               READY   STATUS         RESTARTS   AGE    IP               NODE         NOMINATED NODE   READINESS GATESnginx-deployment-95cff5589-5jldt   1/1     Running        0          108s   171.20.58.206    k8s-node02   &lt;none&gt;           &lt;none&gt;nginx-deployment-95cff5589-b7klr   1/1     Running        0          108s   171.20.85.206    k8s-node01   &lt;none&gt;           &lt;none&gt;nginx-deployment-95cff5589-jctfz   0/1     ErrImagePull   0          108s   171.20.135.129   k8s-node03   &lt;none&gt;           &lt;none&gt;</code></pre><h2 id="2-本地访问pod"><a href="#2-本地访问pod" class="headerlink" title="2. 本地访问pod"></a>2. 本地访问pod</h2><pre><code class="highlight bash"><span class="comment"># 本地访问 Pod 正常</span>$ curl http://171.20.58.206:80&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="3-使用端口转发"><a href="#3-使用端口转发" class="headerlink" title="3. 使用端口转发"></a>3. 使用端口转发</h2><p><strong>仅本地访问</strong></p><pre><code class="highlight bash"><span class="comment"># 前台运行端口转发，此时转发的地址默认是 127.0.0.1，仅本地可以访问</span>$ kubectl port-forward deployment/nginx-deployment 30080:80 -n defaultForwarding from 127.0.0.1:30080 -&gt; 80Forwarding from [::1]:30080 -&gt; 80<span class="comment"># 新开终端，通过转发的端口 30080 访问 pod</span>$ curl 127.0.0.1:30080&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><p><strong>不限制访问IP</strong></p><pre><code class="highlight bash"><span class="comment"># 前台运行端口转发，所有IP可以访问</span>$ kubectl port-forward deployment/nginx-deployment 30080:80 -n default --address=0.0.0.0Forwarding from 0.0.0.0:30080 -&gt; 80</code></pre><p>浏览器，通过转发端口访问 nginx</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/10/20250810-120031.png" alt="浏览器通过转发端口访问"></p><h1 id="四、故障排查与最佳实践"><a href="#四、故障排查与最佳实践" class="headerlink" title="四、故障排查与最佳实践"></a>四、故障排查与最佳实践</h1><h2 id="1-常见错误解决方案"><a href="#1-常见错误解决方案" class="headerlink" title="1. 常见错误解决方案"></a>1. 常见错误解决方案</h2><table><thead><tr><th><strong>错误现象</strong></th><th><strong>可能原因</strong></th><th><strong>解决方案</strong></th></tr></thead><tbody><tr><td><code>unable to do port forwarding: pod not found</code></td><td>Pod未启动</td><td>检查Pod状态：<code>kubectl describe pod/[name]</code></td></tr><tr><td><code>error: listen tcp 127.0.0.1:8080: bind: address already in use</code></td><td>端口冲突</td><td>更换端口或杀死占用进程：<code>lsof -i :8080</code></td></tr><tr><td><code>error: timed out waiting for the condition</code></td><td>Pod启动超时</td><td>增加超时参数：<code>--pod-running-timeout=5m</code></td></tr></tbody></table><h2 id="2-性能优化技巧"><a href="#2-性能优化技巧" class="headerlink" title="2. 性能优化技巧"></a>2. 性能优化技巧</h2><p><strong>批量转发：同时转发多个相关端口</strong></p><pre><code class="highlight bash">kubectl port-forward deployment/nginx-deployment 80:80 443:443</code></pre><p><strong>保持连接：使用工具自动重连</strong></p><pre><code class="highlight bash"><span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span> kubectl port-forward svc/redis 6379:6379; <span class="keyword">done</span></code></pre><p><strong>网络诊断：开启详细日志</strong></p><pre><code class="highlight bash">kubectl port-forward -v=9 pod/nginx 8080:80</code></pre><p><strong>参考链接</strong></p><blockquote><p><a href="https://blog.csdn.net/J56793/article/details/145400712">https://blog.csdn.net/J56793/article/details/145400712</a></p><p><a href="https://feisky.gitbooks.io/kubernetes/content/practice/portforward.html">https://feisky.gitbooks.io/kubernetes/content/practice/portforward.html</a></p><p><a href="https://www.cnblogs.com/waldron/p/17927449.html">https://www.cnblogs.com/waldron/p/17927449.html</a></p><p><a href="https://chanjarster.github.io/post/k8s/kubectl-port-forward/">https://chanjarster.github.io/post/k8s/kubectl-port-forward/</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、概述&quot;&gt;&lt;a href=&quot;#一、概述&quot; class=&quot;headerlink&quot; title=&quot;一、概述&quot;&gt;&lt;/a&gt;一、概述&lt;/h1&gt;&lt;p&gt;在 Kubernetes 集群中，所有资源都运行在私有网络空间（通常使用 CNI 插件构建 overlay 网络），这带来了</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>018-K8S-临时容器</title>
    <link href="https://georgechan95.github.io/blog/af9812e0.html"/>
    <id>https://georgechan95.github.io/blog/af9812e0.html</id>
    <published>2025-08-03T14:01:00.000Z</published>
    <updated>2025-08-05T13:24:18.989Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、了解临时容器"><a href="#一、了解临时容器" class="headerlink" title="一、了解临时容器"></a>一、了解临时容器</h1><p>临时容器：一种特殊的容器，该容器在现有 Pod 中临时运行，以便完成用户发起的操作，例如故障排查。 你会使用临时容器来检查服务，而不是用它来构建应用程序</p><p>Pods 是 Kubernetes 应用程序的基本构建块。由于 pod 是一次性且可替换的，因此一旦 Pod 创建，就无法将容器加入到 Pod 中。取而代之的是，通常使用 Deployments 以受控的方式来删除并替换 Pod。</p><p>有时有必要检查现有 Pod 的状态，例如，对于难以复现的故障进行排查。在这些场景中，可以在现有 Pod 中运行临时容器来检查其状态并运行任意命令。</p><h2 id="1-什么是临时容器？"><a href="#1-什么是临时容器？" class="headerlink" title="1.  什么是临时容器？"></a>1.  什么是临时容器？</h2><p>临时容器与其他容器的不同之处在于，它们缺少对资源或执行的保证，并且永远不会自动重启，因此不适用于构建应用程序。临时容器使用与常规容器相同的 <code>ContainerSpec</code> 段进行描述，但许多字段是不相容且不允许的。</p><ul><li>临时容器没有端口配置，因此像 <code>ports</code>，<code>livenessProbe</code>，<code>readinessProbe</code> 这样的字段是不允许的。</li><li>Pod 资源分配是不可变的，因此 <code>resources</code> 配置是不允许的。</li></ul><p>临时容器是使用 API 中的一种特殊的 <code>ephemeralcontainers</code> 处理器进行创建的， 而不是直接添加到 <code>pod.spec</code> 段，因此无法使用 kubectl edit 来添加一个临时容器。与常规容器一样，将临时容器添加到 Pod 后，将不能更改或删除临时容器</p><h2 id="2-临时容器的用途"><a href="#2-临时容器的用途" class="headerlink" title="2. 临时容器的用途"></a>2. 临时容器的用途</h2><p>当由于容器崩溃或容器镜像不包含调试工具而导致 kubectl exec 无用时， 临时容器对于交互式故障排查很有用。尤其是，Distroless 镜像 允许用户部署最小的容器镜像，从而减少攻击面并减少故障和漏洞的暴露。 由于 distroless 镜像不包含 Shell 或任何的调试工具，因此很难单独使用 kubectl exec 命令进行故障排查。使用临时容器时，启用 进程名字空间共享 很有帮助，可以查看其他容器中的进程</p><p><a href="https://github.com/GoogleContainerTools/distroless">https://github.com/GoogleContainerTools/distroless</a></p><h1 id="二、使用临时容器"><a href="#二、使用临时容器" class="headerlink" title="二、使用临时容器"></a>二、使用临时容器</h1><h2 id="1-给运行中的-Pod-增加临时容器"><a href="#1-给运行中的-Pod-增加临时容器" class="headerlink" title="1. 给运行中的 Pod 增加临时容器"></a>1. 给运行中的 Pod 增加临时容器</h2><p>使用 <code>kubectl debug</code> 命令来给正在运行中的 Pod 增加一个临时容器</p><pre><code class="highlight bash"><span class="comment"># 1.启动一个普通的Pod</span>kubectl run demo --image=nginx:1.29.0 --restart=Never<span class="comment"># 2.给运行中的Pod demo 增加临时容器（不创建新的pod，仅调试运行中的pod）</span>kubectl debug -it demo --image=yauritux/busybox-curl:latest --target=demo --image-pull-policy=IfNotPresent</code></pre><p><strong>命令解析</strong></p><ul><li><p><code>kubectl debug</code> 是 Kubernetes 提供的一个调试工具，用于诊断 Pod 的问题</p></li><li><p><code>-it</code> 表示以交互模式（interactive 和 terminal）运行，允许用户进入调试容器的终端。</p></li><li><p><code>demo</code> 指定了要调试的 Pod 的名称</p></li><li><p><code>yauritux/busybox-curl:latest</code> 指定调试容器使用的镜像，这是带 curl 工具的 busybox</p></li><li><p><code>--target=demo</code> 指定调试的目标是 demo Pod</p></li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/05/20250805-171442.png" alt="创建临时容器"></p><p><strong>查看POD</strong></p><pre><code class="highlight bash"><span class="comment"># 增加临时容器，-it会自动进入pod</span>[root@k8s-master01 ~]$ kubectl debug -it demo --image=yauritux/busybox-curl:latest --target=demo --image-pull-policy=IfNotPresentTargeting container <span class="string">&quot;demo&quot;</span>. If you don<span class="string">&#x27;t see processes from this container it may be because the container runtime doesn&#x27;</span>t support this feature.Defaulting debug container name to debugger-rq9mr.If you don<span class="string">&#x27;t see a command prompt, try pressing enter.</span><span class="string"></span><span class="string"></span><span class="string"># 在pod 内 访问 nginx</span><span class="string">/home # curl localhost</span><span class="string">&lt;!DOCTYPE html&gt;</span><span class="string">&lt;html&gt;</span><span class="string">&lt;body&gt;</span><span class="string">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span><span class="string">&lt;/body&gt;</span><span class="string">&lt;/html&gt;</span><span class="string"></span><span class="string"></span><span class="string"># 新起一个终端，查看 Pod， READY 1/1 可以看出 Pod 内部只有一个容器</span><span class="string">$ kubectl get pods -o wide</span><span class="string">NAME   READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><span class="string">demo   1/1     Running   0          99m   171.20.85.201   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><span class="string"></span><span class="string"></span><span class="string"># 查看 Pod 详情，里面就有临时容器</span><span class="string">$ kubectl get pod demo -o yaml</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">......</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">  # 主容器</span><span class="string">  - image: nginx:1.29.0</span><span class="string">    imagePullPolicy: IfNotPresent</span><span class="string">    ......</span><span class="string">  dnsPolicy: ClusterFirst</span><span class="string">  enableServiceLinks: true</span><span class="string">  ephemeralContainers:</span><span class="string">  - image: yauritux/busybox-curl:latest</span><span class="string">    imagePullPolicy: IfNotPresent</span><span class="string">    name: debugger-4rrx4</span><span class="string">    ......</span><span class="string">  nodeName: k8s-node01</span><span class="string">  preemptionPolicy: PreemptLowerPriority</span><span class="string">  priority: 0</span><span class="string">  restartPolicy: Never</span><span class="string">  ......</span><span class="string">status:</span><span class="string">  conditions:</span><span class="string">  ......</span><span class="string">  ephemeralContainerStatuses:</span><span class="string">  - containerID: docker://ea0f00240984545badc309b3f23617b924200ad9851f979dfdf83d559ad669e2</span><span class="string">    image: yauritux/busybox-curl:latest</span><span class="string">    imageID: docker://sha256:cda3fcfbc75d9cd4624dc403fd5f54f2e49b84874e4cf8d01a56f0e2db6c72e6</span><span class="string">    lastState: &#123;&#125;</span><span class="string">    name: debugger-4rrx4</span><span class="string">    ready: false</span><span class="string">    restartCount: 0</span><span class="string">    state:</span><span class="string">      running:</span><span class="string">        startedAt: &quot;2025-08-05T11:15:27Z&quot;</span><span class="string">  hostIP: 10.20.1.140</span><span class="string">  hostIPs:</span><span class="string">  - ip: 10.20.1.140</span><span class="string">  phase: Running</span><span class="string">  podIP: 171.20.85.202</span><span class="string">  podIPs:</span><span class="string">  - ip: 171.20.85.202</span><span class="string">  qosClass: BestEffort</span><span class="string">  startTime: &quot;2025-08-05T11:14:39Z&quot;</span></code></pre><p><strong>总结：这种方式调试 pod 不会创建新的 pod，只在原有的 pod 中增加临时容器。</strong></p><h2 id="2-通过-Pod-副本调试"><a href="#2-通过-Pod-副本调试" class="headerlink" title="2. 通过 Pod 副本调试"></a>2. 通过 Pod 副本调试</h2><p><strong>在添加新的容器时创建 Pod 副本</strong></p><p>当应用程序正在运行但其表现不符合预期时，你会希望在 Pod 中添加额外的调试工具， 这时添加新容器是很有用的</p><pre><code class="highlight bash"><span class="comment"># 1.启动一个普通的Pod</span>$ kubectl run myapp --image=busybox:1.31.1 --restart=Never -- <span class="built_in">sleep</span> 1d<span class="comment"># 2.建立 myapp 的一个名为 myapp-debug 的副本， 新增了一个用于调试的 Ubuntu 容器</span>$ kubectl debug myapp -it --image=ubuntu:20.04 --share-processes --copy-to=myapp-debug<span class="comment"># 如果你没有使用 --container 指定新的容器名，kubectl debug 会自动生成的。</span><span class="comment"># 默认情况下，-i 标志使 kubectl debug 附加到新容器上。 你可以通过指定 --attach=false 来防止这种情况</span><span class="comment"># --share-processes 允许在此 Pod 中的其他容器中查看该容器的进程。 </span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/05/20250805-204430.png" alt="添加新的容器时创建 Pod 副本"></p><p><strong>查看POD</strong></p><pre><code class="highlight bash"><span class="comment"># 创建新的pod myapp-debug, 使用镜像 ubuntu:20.04, 与 myapp 共享进程</span>$ kubectl debug myapp -it --image=ubuntu:20.04 --share-processes --copy-to=myapp-debugDefaulting debug container name to debugger-8hjcc.If you don<span class="string">&#x27;t see a command prompt, try pressing enter.</span><span class="string"># 查看进程</span><span class="string">root@myapp-debug:/# ps aux  </span><span class="string">USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><span class="string">65535          1  0.0  0.0   1028     4 ?        Ss   12:41   0:00 /pause</span><span class="string">root           7  0.0  0.0   1296     4 ?        Ss   12:42   0:00 sleep 1d # busybox 进程</span><span class="string">root          13  0.0  0.0   4116  3532 pts/0    Ss   12:42   0:00 /bin/bash</span><span class="string">root          24  0.0  0.0   5900  2852 pts/0    R+   12:50   0:00 ps aux</span><span class="string"></span><span class="string"></span><span class="string"># 新起shell终端，查看Pod</span><span class="string"># 新建了一个 pod myapp-debug, READY 2/2 表示里面有两个容器（busybox 和 ubuntu）</span><span class="string">$ kubectl get pods -o wide</span><span class="string">NAME          READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES</span><span class="string">myapp         1/1     Running   0          3m50s   171.20.85.203   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><span class="string">myapp-debug   2/2     Running   0          3m35s   171.20.85.204   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><span class="string"></span><span class="string"></span><span class="string"># 查看新建的 Pod 详情</span><span class="string">$ kubectl get pod myapp-debug -o yaml</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">  ......</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">  # 第一个容器 busybox</span><span class="string">  - args:</span><span class="string">    - sleep</span><span class="string">    - 1d</span><span class="string">    image: busybox:1.31.1</span><span class="string">    imagePullPolicy: IfNotPresent</span><span class="string">    name: myapp</span><span class="string">    resources: &#123;&#125;</span><span class="string">    terminationMessagePath: /dev/termination-log</span><span class="string">    terminationMessagePolicy: File</span><span class="string">    volumeMounts:</span><span class="string">    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount</span><span class="string">      name: kube-api-access-hmf9b</span><span class="string">      readOnly: true</span><span class="string">  # 第二个容器 ubuntu</span><span class="string">  - image: ubuntu:20.04</span><span class="string">    imagePullPolicy: IfNotPresent</span><span class="string">    name: debugger-8hjcc</span><span class="string">    resources: &#123;&#125;</span><span class="string">    stdin: true</span><span class="string">    terminationMessagePath: /dev/termination-log</span><span class="string">    terminationMessagePolicy: File</span><span class="string">    tty: true</span><span class="string">    volumeMounts:</span><span class="string">    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount</span><span class="string">      name: kube-api-access-hmf9b</span><span class="string">      readOnly: true</span><span class="string">  dnsPolicy: ClusterFirst</span><span class="string">  containerStatuses:</span><span class="string">  ......</span></code></pre><h2 id="3-在改变-Pod-命令时创建-Pod-副本"><a href="#3-在改变-Pod-命令时创建-Pod-副本" class="headerlink" title="3. 在改变 Pod 命令时创建 Pod 副本"></a>3. 在改变 Pod 命令时创建 Pod 副本</h2><p>有时更改容器的命令很有用，例如添加调试标志或因为应用崩溃</p><pre><code class="highlight bash"><span class="comment"># 1.启动pod，执行命令 false</span><span class="comment"># false 是 busybox 默认命令之一，执行后容器会退出</span>$ kubectl run --image=busybox:1.31.1 myapp -- <span class="literal">false</span><span class="comment"># 2.使用 kubectl debug 命令创建该 Pod 的一个副本， 在该副本中命令改变为交互式 shell：</span>$ kubectl debug myapp -it --copy-to=myapp-debug --container=myapp -- sh<span class="comment"># 要更改指定容器的命令，你必须用 --container 命令指定容器的名字， 否则 kubectl debug 将建立一个新的容器运行你指定的命令</span><span class="comment"># 默认情况下，标志 -i 使 kubectl debug 附加到容器。 你可通过指定 --attach=false 来防止这种情况</span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/05/20250805-211440.png" alt="改变 Pod 命令时创建 Pod 副本"></p><p><strong>查看Pod</strong></p><pre><code class="highlight bash"><span class="comment"># 使用 kubectl debug 命令创建该 Pod 的一个副本， 在该副本中命令为 sh</span>$ kubectl debug myapp -it --copy-to=myapp-debug --container=myapp -- shIf you don<span class="string">&#x27;t see a command prompt, try pressing enter.</span><span class="string"># 查看进程</span><span class="string">/ # ps aux</span><span class="string">PID   USER     TIME  COMMAND</span><span class="string">    1 root      0:00 sh # 此为pod执行的进程命令：sh</span><span class="string">    7 root      0:00 ps aux</span><span class="string">/ # </span><span class="string"></span><span class="string"></span><span class="string"># 新起shell终端，查看Pod,myapp-debug 为复制的pod，修改了shell，成功运行。</span><span class="string">$ kubectl get pods -o wide</span><span class="string">NAME          READY   STATUS             RESTARTS      AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><span class="string">myapp         0/1     CrashLoopBackOff   2 (16s ago)   41s   171.20.85.205   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><span class="string">myapp-debug   1/1     Running            0             22s   171.20.58.205   k8s-node02   &lt;none&gt;           &lt;none&gt;</span></code></pre><h2 id="4-在同一个节点上创建-pod-进行调试"><a href="#4-在同一个节点上创建-pod-进行调试" class="headerlink" title="4. 在同一个节点上创建 pod 进行调试"></a>4. 在同一个节点上创建 pod 进行调试</h2><p>如果这些方法都不起作用，你可以找到运行 Pod 的节点，然后创建一个 Pod 运行在该节点上。 你可以通过 <code>kubectl debug</code> 在节点上创建一个交互式 Shell</p><pre><code class="highlight bash">kubectl debug node/mynode -it --image=ubuntu<span class="comment"># kubectl debug 基于节点的名字自动生成新的 Pod 的名字</span><span class="comment"># 节点的根文件系统会被挂载在 /host。</span><span class="comment"># 新的调试容器运行在主机 IPC 名字空间、主机网络名字空间以及主机 PID 名字空间内， Pod 没有特权，因此读取某些进程信息可能会失败，并且 chroot /host 也会失败</span><span class="comment"># 如果你需要一个特权 Pod，需要手动创建</span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/08/05/20250805-212317.png" alt="在同一个节点上创建 pod 进行调试"></p><p><strong>测试</strong></p><pre><code class="highlight bash"><span class="comment"># 会在 Kubernetes 集群的 k8s-node01 节点上启动一个临时的调试容器，使用 ubuntu:20.04 镜像</span>$ kubectl debug node/k8s-node01 -it --image=ubuntu:20.04Creating debugging pod node-debugger-k8s-node01-5zhwj with container debugger on node k8s-node01.If you don<span class="string">&#x27;t see a command prompt, try pressing enter.</span><span class="string"></span><span class="string"># 查看物理机内存</span><span class="string">root@k8s-node01:/# free -m</span><span class="string">              total        used        free      shared  buff/cache   available</span><span class="string">Mem:           7671         864        4760         154        2047        6381</span><span class="string">Swap:             0           0           0</span><span class="string"></span><span class="string"># 查看目录机目录</span><span class="string">root@k8s-node01:/# cd /host/opt/images/</span><span class="string">root@k8s-node01:/host/opt/images# ls</span><span class="string">all-in-one.tar       defaultbackend-amd64-1.5.tar </span></code></pre><p><strong>常用场景</strong></p><p><code>kubectl debug node/</code> 常用于以下场景：</p><ul><li><strong>检查节点文件系统</strong>：<ul><li>检查节点上的日志文件（比如 &#x2F;var&#x2F;log）。</li><li>查看 Kubernetes 相关文件（比如 &#x2F;etc&#x2F;kubernetes 或 &#x2F;var&#x2F;lib&#x2F;kubelet）。</li></ul></li><li><strong>诊断网络问题</strong>：<ul><li>检查节点的网络配置（比如 ifconfig、ip addr）。</li><li>测试网络连通性（比如 ping、curl）。</li></ul></li><li><strong>检查进程或资源</strong>：<ul><li>查看节点上的运行进程（ps aux）。</li><li>检查磁盘使用情况（df -h）或内存状态（free -m）。</li></ul></li><li><strong>调试 Kubernetes 组件</strong>：<ul><li>检查 kubelet、containerd 或 Docker 的状态。</li><li>验证节点的 CRI（容器运行时接口）配置。</li></ul></li></ul><p><strong>参考链接</strong></p><blockquote><p><a href="http://kubernetes.hankbook.cn/pods/ephemeral-containers.html">http://kubernetes.hankbook.cn/pods/ephemeral-containers.html</a></p><p><a href="https://cloudmessage.top/archives/k8s-lin-shi-rong-qi-guan-fang-diao-shi-ji-zhi">https://cloudmessage.top/archives/k8s-lin-shi-rong-qi-guan-fang-diao-shi-ji-zhi</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、了解临时容器&quot;&gt;&lt;a href=&quot;#一、了解临时容器&quot; class=&quot;headerlink&quot; title=&quot;一、了解临时容器&quot;&gt;&lt;/a&gt;一、了解临时容器&lt;/h1&gt;&lt;p&gt;临时容器：一种特殊的容器，该容器在现有 Pod 中临时运行，以便完成用户发起的操作，例如故障</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>017-K8S-网络策略NetworkPolicy</title>
    <link href="https://georgechan95.github.io/blog/99657768.html"/>
    <id>https://georgechan95.github.io/blog/99657768.html</id>
    <published>2025-07-28T13:33:00.000Z</published>
    <updated>2025-08-05T06:53:48.526Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、网络策略-NetworkPolicy-简介"><a href="#一、网络策略-NetworkPolicy-简介" class="headerlink" title="一、网络策略(NetworkPolicy)简介"></a>一、网络策略(NetworkPolicy)简介</h1><h2 id="1-概念解析"><a href="#1-概念解析" class="headerlink" title="1. 概念解析"></a>1. 概念解析</h2><p>如果你希望在 IP 地址或端口层面（OSI 第 3 层或第 4 层）控制网络流量， 则你可以考虑为集群中特定应用使用 Kubernetes 网络策略（NetworkPolicy）</p><p>Kubernetes 网络策略(NetworkPolicy)是一个资源对象，主要用于定义Pod之间的流量控制，其实现了一个基于标签的选择器模型，允许管理员通过网络策略规则限制对Pod的流量访问。</p><p>网络策略(NetworkPolicy)是以Pod为单位进行授权的，因此，只有当所有的Pod都通过了网络策略时，才能够接收到其他Pod发送的流量。这种方式极大提高了网络的安全性。</p><p>Pod 是通过如下三个标识符的组合来辩识是否可以通讯：</p><ul><li>其他被允许的 Pods（例外：Pod 无法阻塞对自身的访问）</li><li>被允许的名字空间</li><li>IP 组块 [ ipBlock ]（例外：与 Pod 运行所在的节点的通信总是被允许的， 无论 Pod 或节点的 IP 地址）</li></ul><h2 id="2-前置条件"><a href="#2-前置条件" class="headerlink" title="2. 前置条件"></a>2. 前置条件</h2><p>网络策略通过 网络插件 来实现。 要使用网络策略，你必须使用支持 NetworkPolicy 的网络解决方案。 创建一个 NetworkPolicy 资源对象而没有控制器来使它生效的话，是没有任何作用的</p><ul><li>Calico （当前使用此网络插件）</li><li>Antrea</li><li>Cilium</li><li>Kube-router</li><li>Romana</li><li>Weave 网络</li></ul><h2 id="3-隔离默认策略"><a href="#3-隔离默认策略" class="headerlink" title="3. 隔离默认策略"></a>3. 隔离默认策略</h2><ul><li>出口的隔离<ul><li>默认情况下，一个 Pod 的出口是非隔离的，即所有外向连接都是被允许的</li></ul></li><li>入口的隔离<ul><li>默认情况下，一个 Pod 对入口是非隔离的，即所有入站连接都是被允许的</li></ul></li></ul><h2 id="4-特别说明"><a href="#4-特别说明" class="headerlink" title="4. 特别说明"></a>4. 特别说明</h2><p>网络策略是相加的，所以不会产生冲突。如果策略适用于 Pod 某一特定方向的流量， Pod 在对应方向所允许的连接是适用的网络策略所允许的集合。 因此，评估的顺序不影响策略的结果。</p><p>要允许从源 Pod 到目的 Pod 的连接，源 Pod 的出口策略和目的 Pod 的入口策略都需要允许连接。 如果任何一方不允许连接，建立连接将会失败。</p><h1 id="二、创建-pod-和-svc"><a href="#二、创建-pod-和-svc" class="headerlink" title="二、创建 pod 和 svc"></a>二、创建 pod 和 svc</h1><p>基于 Nginx 镜像创建Pod，用于后续实验测试。</p><pre><code class="highlight bash"><span class="comment"># 创建工作空间，演示的Pod创建在此工作空间内</span>$ kubectl create ns network<span class="comment"># 切换工作空间到 network， 切换后续所有操作默认再次工作空间内（此操作非必须）</span>$ kubectl config set-context --current --namespace=network<span class="comment"># 查看当前所在工作空间</span>$ kubectl config view --minify<span class="comment"># 创建两个nginx pod用于测试使用</span>kubectl run web1 --image=nginx:1.29.0 --labels=app=web,<span class="built_in">env</span>=prod --image-pull-policy=IfNotPresent -n network --expose --port 80kubectl run web2 --image=nginx:1.29.0 --labels=app=web,<span class="built_in">env</span>=<span class="built_in">test</span> --image-pull-policy=IfNotPresent -n network --expose --port 80<span class="comment"># 查看Pod</span>$ kubectl get pods -o wide -n networkNAME   READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESweb1   1/1     Running   0          65s   171.20.85.196   k8s-node01   &lt;none&gt;           &lt;none&gt;web2   1/1     Running   0          30s   171.20.85.197   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 Service</span>$ kubectl get svc -o wide -n networkNAME   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE   SELECTORweb1   ClusterIP   10.110.3.181    &lt;none&gt;        80/TCP    70s   app=web,<span class="built_in">env</span>=prodweb2   ClusterIP   10.100.184.48   &lt;none&gt;        80/TCP    35s   app=web,<span class="built_in">env</span>=<span class="built_in">test</span><span class="comment"># 修改nginx的首页文件index.html，用于区分两个pod</span>$ kubectl <span class="built_in">exec</span> -it web1 -- sh -c <span class="string">&quot;echo web1 &gt; /usr/share/nginx/html/index.html&quot;</span>$ kubectl <span class="built_in">exec</span> -it web2 -- sh -c <span class="string">&quot;echo web2 &gt; /usr/share/nginx/html/index.html&quot;</span><span class="comment"># 访问Pod，测试首页是否改变</span>$ curl 171.20.85.196web1$ curl 171.20.85.197web2</code></pre><h1 id="三、未添加网络策略，访问Pod"><a href="#三、未添加网络策略，访问Pod" class="headerlink" title="三、未添加网络策略，访问Pod"></a>三、未添加网络策略，访问Pod</h1><p>查看当前命名空间下的 NetworkPolicy，当前没有网络策略。</p><pre><code class="highlight bash">$ kubectl get networkpolicy -n networkNo resources found <span class="keyword">in</span> network namespace.</code></pre><p>新建一个临时 Pod， 用于访问 web1 和 web2。在没有网络策略的情况下，临时 Pod 可以访问 web1 和 web2</p><pre><code class="highlight bash"><span class="comment"># 创建临时Pod，推出容器时自动删除该pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=<span class="built_in">env</span>=prod --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh<span class="comment"># 由于临时 Pod 与 web1 不在同一个 名称空间，因此访问Service需要添加 名称空间</span>/home <span class="comment"># curl web1.network</span>web1/home <span class="comment"># curl web1.network.svc.cluster.local</span>web1/home <span class="comment"># curl web2.network</span>web2</code></pre><p>修改Nginx Pod 的 Service 类型为 LoadBalance ，让浏览器可以访问 Nginx。</p><pre><code class="highlight bash"><span class="comment"># 修改 Service 类型</span>$ kubectl patch svc web1 -n network -p <span class="string">&#x27;&#123;&quot;spec&quot;:&#123;&quot;type&quot;:&quot;LoadBalancer&quot;&#125;&#125;&#x27;</span>$ kubectl patch svc web2 -n network -p <span class="string">&#x27;&#123;&quot;spec&quot;:&#123;&quot;type&quot;:&quot;LoadBalancer&quot;&#125;&#125;&#x27;</span><span class="comment"># 查看 Service</span>$ kubectl get svc -o wideNAME   TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTORweb1   LoadBalancer   10.110.3.181    &lt;pending&gt;     80:31193/TCP   30m   app=web,<span class="built_in">env</span>=prodweb2   LoadBalancer   10.100.184.48   &lt;pending&gt;     80:30826/TCP   29m   app=web,<span class="built_in">env</span>=<span class="built_in">test</span></code></pre><p>测试浏览器访问 Service</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/31/20250731-142153.png" alt="访问web1"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/31/20250731-142217.png" alt="访问web2"></p><p><strong>结论：未添加网络策略，外界可以随意访问 pod。这是不安全的。</strong></p><h1 id="四、Pod-添加网络策略"><a href="#四、Pod-添加网络策略" class="headerlink" title="四、Pod 添加网络策略"></a>四、Pod 添加网络策略</h1><p>网络策略 NetworkPolicy 是一种以应用为中心的结构，允许你设置如何允许 Pod 与网络上的各类网络“实体” 通信。 说白了，网络策略本质上就是建立一个防火墙，控制入站和出站流量。</p><p>网络策略通过 CNI(Containernetworking Interface) 网络插件来实现。 要使用网络策略，你必须使用支持 NetworkPolicy 的网络解决方案。 创建一个 NetworkPolicy 资源对象而没有控制器来使它生效的话，是没有任何作用的。此kubernetes集群使用的网络插件是Calico，Calico支持网络策略，大家熟知的Flannel是不支持网络策略的。</p><p>Pod 有两种隔离: 出口的隔离和入口的隔离，即出站（Egress）和入站（Ingress）。</p><p><strong>为了允许两个 Pods 之间的网络数据流，源端 Pod 上的出站（Egress）规则和 目标端 Pod 上的入站（Ingress）规则都需要允许该流量。 如果源端的出站（Egress）规则或目标端的入站（Ingress）规则拒绝该流量， 则流量将被拒绝。</strong></p><h2 id="1-入站网络策略"><a href="#1-入站网络策略" class="headerlink" title="1. 入站网络策略"></a>1. 入站网络策略</h2><p>下面的 yaml 文件是一个标准的网络策略：</p><ul><li>PodSelector : 指定被此 NetworkPolicy 影响的 Pod。此处匹配 Label 为 “role&#x3D;db” 的 Pod。</li><li>PolicyTypes: 规定所需的网络策略类型。此处包括 Ingress 和 Egress。</li><li>Ingress: 定义允许从指定来源（IP 地址范围、命名空间 或 Pod）和端口接收流量的规则。此处仅允许 TCP 流量访问端口 6379。</li><li>Egress: 定义允许发送到指定目标（IP 地址范围）和端口的流量的规则。此处仅允许 TCP 流量发送到端口 5978 的目标 IP 地址范围为 10.0.0.0&#x2F;24</li></ul><p>资源清单：<code>networkpolicy-example.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span>    <span class="comment"># networking.k8s.io/v1 是 NetworkPolicy 资源的标准 API</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span>                <span class="comment"># 资源所在名称空间，该 NetworkPolicy 只能作用于该名称空间下的Pod</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">role:</span> <span class="string">db</span>                      <span class="comment"># 当前网络策略作用于 network 名称空间下，具有标签 role: db 的 Pod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>                         <span class="comment"># 控制入站流量</span>  <span class="bullet">-</span> <span class="string">Egress</span>                          <span class="comment"># 控制出站流量</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">ipBlock:</span>            <span class="comment">#cidr: 0.0.0.0/0表示允许所有客户端可以访问</span>            <span class="attr">cidr:</span> <span class="number">172.17</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span>     <span class="comment"># 允许来自 IP 范围 172.17.0.0 到 172.17.255.255 的流量</span>            <span class="attr">except:</span>              <span class="bullet">-</span> <span class="number">172.17</span><span class="number">.1</span><span class="number">.0</span><span class="string">/24</span>       <span class="comment"># 排除子范围 172.17.1.0 到 172.17.1.255，即这部分 IP 被禁止。</span>        <span class="bullet">-</span> <span class="attr">namespaceSelector:</span>            <span class="attr">matchLabels:</span>              <span class="attr">project:</span> <span class="string">myproject</span>    <span class="comment"># 允许来自具有标签 project=myproject 的命名空间中的所有 Pod 发起的流量。</span>        <span class="bullet">-</span> <span class="attr">podSelector:</span>            <span class="attr">matchLabels:</span>              <span class="attr">role:</span> <span class="string">frontend</span>        <span class="comment"># 允许 【同一命名】 空间内具有标签 role=frontend 的 Pod 发起的流量。</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">6379</span>                <span class="comment"># 只允许上述来源访问 role=db Pod 的 TCP 6379 端口</span>  <span class="attr">egress:</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">ipBlock:</span>            <span class="attr">cidr:</span> <span class="number">10.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">/24</span>       <span class="comment"># 允许 role=db Pod 访问 IP 范围 10.0.0.0 到 10.0.0.255 的目标</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">5978</span>                <span class="comment"># 只允许访问目标的 TCP 5978 端口</span></code></pre><h3 id="1-1-入站网络策略-pod标签选择器"><a href="#1-1-入站网络策略-pod标签选择器" class="headerlink" title="1.1 入站网络策略-pod标签选择器"></a>1.1 入站网络策略-pod标签选择器</h3><p><strong>查看 pod 标签</strong></p><pre><code class="highlight bash"><span class="comment"># 查看pod</span>$ kubectl get pod -o wide -n network --show-labelsNAME   READY   STATUS    RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATES   LABELSweb1   1/1     Running   0          128m   171.20.85.196   k8s-node01   &lt;none&gt;           &lt;none&gt;            app=web,<span class="built_in">env</span>=prodweb2   1/1     Running   0          128m   171.20.85.197   k8s-node01   &lt;none&gt;           &lt;none&gt;            app=web,<span class="built_in">env</span>=<span class="built_in">test</span><span class="comment"># 查看Service</span>$ kubectl get svc -n network -o wideNAME   TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE    SELECTORweb1   LoadBalancer   10.110.3.181    &lt;pending&gt;     80:31193/TCP   146m   app=web,<span class="built_in">env</span>=prodweb2   LoadBalancer   10.100.184.48   &lt;pending&gt;     80:30826/TCP   146m   app=web,<span class="built_in">env</span>=<span class="built_in">test</span></code></pre><h4 id="1-1-1-案例1"><a href="#1-1-1-案例1" class="headerlink" title="1.1.1 案例1"></a>1.1.1 案例1</h4><p>编写网络策略规则，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，仅仅允许当前命名空间(network)内标签为 role&#x3D;podclient 的 pod可以访问 web1的80端口(TCP)。</p><p><strong>资源清单：</strong><code>network-policy-pod-selector.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">podSelector:</span>        <span class="comment"># 仅当前命名空间内，具有标签 role: podclient 的 Pod 可以访问 web1</span>            <span class="attr">matchLabels:</span>              <span class="attr">role:</span> <span class="string">podclient</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">80</span>            <span class="comment"># web1 只开放80端口</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-pod-selector.yaml<span class="comment"># 查看 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       28s</code></pre><p>**测试1：使用浏览器访问 web1 **</p><p>浏览器没有Pod标签，因此访问 web1 失败</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/31/20250731-162205.png" alt="浏览器访问 web1"></p><p><strong>测试2：没有 role&#x3D;podclient 标签的临时pod，访问web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod，不添加标签</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --image-pull-policy=IfNotPresent -n network -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 Service 失败，因为没有 role=podclient 标签，无法通过网络策略</span>/home <span class="comment"># curl web1</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out<span class="comment"># 访问 web2 Service 成功，因为 web2 无网络策略限制</span>/home <span class="comment"># curl web2</span>web2</code></pre><p><strong>测试3：具有 role&#x3D;podclient 标签，但Pod不在 network 名称空间，访问web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 default 名称空间创建临时Pod，添加标签 role=podclient</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=role=podclient --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 Service 失败，虽然pod1具有标签 role=podclient，但由于网络策略限制了与web1必须在同一名称空间，因此访问失败</span>/home <span class="comment"># curl web1.network</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out<span class="comment"># 访问 web2 Service 成功，因为 web2 无网络策略限制</span>/home <span class="comment"># curl web2.network</span>web2</code></pre><p><strong>测试4：具有 role&#x3D;podclient 标签，且Pod在 network 名称空间</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod，添加标签 role=podclient</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=role=podclient --image-pull-policy=IfNotPresent -n network -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 成功</span>/home <span class="comment"># curl web1</span>web1</code></pre><h3 id="1-2-入站网络策略-namespaceSelector命名空间选择器"><a href="#1-2-入站网络策略-namespaceSelector命名空间选择器" class="headerlink" title="1.2 入站网络策略-namespaceSelector命名空间选择器"></a>1.2 入站网络策略-namespaceSelector命名空间选择器</h3><p><strong>查看命名空间的标签</strong></p><pre><code class="highlight bash">$ kubectl get ns --show-labelsNAME              STATUS   AGE     LABELSdefault           Active   4d      kubernetes.io/metadata.name=defaultkube-node-lease   Active   4d      kubernetes.io/metadata.name=kube-node-leasekube-public       Active   4d      kubernetes.io/metadata.name=kube-publickube-system       Active   4d      kubernetes.io/metadata.name=kube-systemnetwork           Active   177m    kubernetes.io/metadata.name=network</code></pre><p><strong>给命名空间打标签</strong></p><p>给 default 命名空间打 name&#x3D;default 标签</p><pre><code class="highlight bash"><span class="comment"># 给 default 命名空间打标签</span>$ kubectl label ns default name=defaultnamespace/default labeled<span class="comment"># 查看命名空间标签</span>$ kubectl get ns --show-labels | grep defaultdefault           Active   4d      kubernetes.io/metadata.name=default,name=default</code></pre><h4 id="1-2-1-案例1"><a href="#1-2-1-案例1" class="headerlink" title="1.2.1 案例1"></a>1.2.1 案例1</h4><p>定义通过 namespaceSelector 命名空间来控制的入站网络策略，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，允许标签为 <code>name: default</code> 的 namespace下的所有 pod 可以访问 web1 的 80 端口(TCP)。</p><p><strong>资源清单：</strong> <code>network-policy-namespace-selector.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">namespaceSelector:</span>            <span class="attr">matchLabels:</span>      <span class="comment"># 具有 name=default 标签的命名空间下所有的pod，可以访问web1的80端口</span>              <span class="attr">name:</span> <span class="string">default</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">80</span>            <span class="comment"># web1 只开放80端口</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-namespace-selector.yaml<span class="comment"># 查看 network 命名空间下的 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       113s</code></pre><p><strong>测试1：在没有 name&#x3D;default 标签的名称空间下创建Pod，访问 web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --image-pull-policy=IfNotPresent -n network -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 失败，network 命名空间没有 name=default 标签，无法通过网络策略</span>/home <span class="comment"># curl web1</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out<span class="comment"># 访问 web2 成功，web2 无网络策略限制</span>/home <span class="comment"># curl web2</span>web2</code></pre><p><strong>测试2： 在具有 name&#x3D;default 标签的名称空间下创建Pod，访问 web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 成功，default 命名空间具有 name=default 标签，通过了网络策略</span>/home <span class="comment"># curl web1.network</span>web1</code></pre><h4 id="1-2-2-案例2"><a href="#1-2-2-案例2" class="headerlink" title="1.2.2 案例2"></a>1.2.2 案例2</h4><p>修改网络策略，设置只允许 default 命名空间里的特定 pod 能访问，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，允许标签为name: default 的 namespace下的标签为 role: podclient 的 pod 可以访问 web1 的80端口(TCP)。</p><p><strong>资源清单：</strong><code>network-policy-namespace-pod-selector.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">namespaceSelector:</span>            <span class="attr">matchLabels:</span>      <span class="comment"># 具有 name=default 标签的命名空间下的pod</span>              <span class="attr">name:</span> <span class="string">default</span>          <span class="attr">podSelector:</span>            <span class="attr">matchLabels:</span>      <span class="comment"># 在具有 name=default 标签的命名空间基础上，还需要具有 role=podclient 标签的pod</span>              <span class="attr">role:</span> <span class="string">podclient</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">80</span>            <span class="comment"># web1 只开放80端口</span></code></pre><p><strong>注意：</strong> podSelector 前面没有 - ，因此 namespaceSelector 和 podSelector 这两个条件是 <strong>并集关系</strong>，需要同时满足。</p><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-namespace-pod-selector.yaml networkpolicy.networking.k8s.io/my-network-policy created<span class="comment"># 查看 network 名称空间下的 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       11s</code></pre><p><strong>测试1：在没有 name&#x3D;default 标签的名称空间下，创建具有标签 role&#x3D;podclient 的 Pod，访问 web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=role=podclient --image-pull-policy=IfNotPresent -n network -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 失败，network 命名空间没有 name=default 标签，无法通过网络策略</span>/home <span class="comment"># curl web1</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out<span class="comment"># 访问 web2 成功，web2 无网络策略限制</span>/home <span class="comment"># curl web2</span>web2</code></pre><p><strong>测试2： 在具有 name&#x3D;default 标签的名称空间下，创建没有标签 role&#x3D;podclient 的 Pod，访问 web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 失败，虽然 default 命名空间具有 name=default 标签，但 pod1 没有标签 role=podclient，无法通过了网络策略</span>/home <span class="comment"># curl web1.network</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out</code></pre><p><strong>测试3： 在具有 name&#x3D;default 标签的名称空间下，创建具有标签 role&#x3D;podclient 的 Pod，访问 web1</strong></p><pre><code class="highlight bash"><span class="comment"># 在 network 名称空间创建临时Pod</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --image-pull-policy=IfNotPresent --labels=role=podclient -n default -it --<span class="built_in">rm</span> -- sh<span class="comment"># 访问 web1 成功，pod1 同时满足了在具有 name=default 标签的 default 命名空间下，且具有标签 role=podclient，通过了网络策略</span>/home <span class="comment"># curl web1.network</span>web1</code></pre><h3 id="1-3-入站网络策略-IP地址控制"><a href="#1-3-入站网络策略-IP地址控制" class="headerlink" title="1.3 入站网络策略-IP地址控制"></a>1.3 入站网络策略-IP地址控制</h3><h4 id="1-3-1-案例1"><a href="#1-3-1-案例1" class="headerlink" title="1.3.1 案例1"></a>1.3.1 案例1</h4><p>定义通过IP地址来控制的入站网络策略，如下网络策略的功能为：把名为my-network-policy的网络策略应用到 web1，只允许 171.20.10.0&#x2F;24 这个网段的pod可以访问 web1 的80端口(TCP)。</p><p><strong>资源清单：</strong><code>network-policy-ipBlock.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">ipBlock:</span>            <span class="attr">cidr:</span> <span class="number">171.20</span><span class="number">.10</span><span class="number">.0</span><span class="string">/24</span>    <span class="comment"># 只允许 171.20.10.0/24 这个网段的pod可以访问 web1 的80端口(TCP)</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">80</span>            <span class="comment"># web1 只开放80端口</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-ipBlock.yaml<span class="comment"># 查看 network 名称空间的 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       35s</code></pre><p><strong>测试1：创建Pod，固定IP地址，访问web1</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 Pod Ip地址范围</span>$ calicoctl get ippoolNAME                  CIDR            SELECTOR   default-ipv4-ippool   171.20.0.0/16   all()<span class="comment"># 创建 171.20.10.0/24 这个网段的pod</span>$ kubectl create -f - &lt;&lt;<span class="string">EOF</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">  labels:</span><span class="string">    app: pod</span><span class="string">  annotations:</span><span class="string">    &quot;cni.projectcalico.org/ipAddrs&quot;: &quot;[\&quot;171.20.10.27\&quot;]&quot;</span><span class="string">  name: pod1</span><span class="string">  namespace: default</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">    - image: nginx:1.29.0</span><span class="string">      imagePullPolicy: IfNotPresent</span><span class="string">      name: pod1</span><span class="string">EOF</span><span class="comment"># 创建非 171.20.10.0/24 这个网段的pod</span>$ kubectl create -f - &lt;&lt;<span class="string">EOF</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">  labels:</span><span class="string">    app: pod</span><span class="string">  annotations:</span><span class="string">    &quot;cni.projectcalico.org/ipAddrs&quot;: &quot;[\&quot;171.20.20.57\&quot;]&quot;</span><span class="string">  name: pod2</span><span class="string">  namespace: default</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">    - image: nginx:1.29.0</span><span class="string">      imagePullPolicy: IfNotPresent</span><span class="string">      name: pod2</span><span class="string">EOF</span><span class="comment"># 查看创建 Pod 的IP地址</span>$ kubectl get pods -o wide -n defaultNAME   READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATESpod1   1/1     Running   0          24s   171.20.10.27   k8s-node02   &lt;none&gt;           &lt;none&gt;pod2   1/1     Running   0          16s   171.20.20.57   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># pod1 访问 web1 成功，pod1 ip 为 171.20.10.27，在 171.20.10.0/24 网段内，可通过网络策略</span>$ kubectl <span class="built_in">exec</span> -it pod1 -n default -- sh -c <span class="string">&quot;curl web1.network&quot;</span>web1<span class="comment"># pod2 访问 web1 失败，pod2 ip 为 171.20.20.57，不在 171.20.10.0/24 网段内，无法通过网络策略</span>$ kubectl <span class="built_in">exec</span> -it pod2 -n default -- sh -c <span class="string">&quot;curl web1.network&quot;</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out</code></pre><h4 id="1-3-2-案例2"><a href="#1-3-2-案例2" class="headerlink" title="1.3.2 案例2"></a>1.3.2 案例2</h4><p>修改网络策略，设置只允许 171.20.10.0&#x2F;24 这个网段的进行访问，但是 171.20.10.10 不可以访问，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，只允许 171.20.10.0&#x2F;24 这个网段的 pod 可以访问 web1 的80端口(TCP)，但是 171.20.10.10 这个IP的 pod 不可以访问 web1 的80端口(TCP)</p><p><strong>资源清单：</strong> <code>network-policy-ipBlock-except.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="attr">ingress:</span>    <span class="bullet">-</span> <span class="attr">from:</span>        <span class="bullet">-</span> <span class="attr">ipBlock:</span>            <span class="attr">cidr:</span> <span class="number">171.20</span><span class="number">.10</span><span class="number">.0</span><span class="string">/24</span>    <span class="comment"># 只允许 171.20.10.0/24 这个网段的pod可以访问 web1 的80端口(TCP)、</span>            <span class="attr">except:</span>              <span class="bullet">-</span> <span class="number">171.20</span><span class="number">.10</span><span class="number">.10</span><span class="string">/32</span>        <span class="comment"># 排除单个ip</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">80</span>            <span class="comment"># web1 只开放80端口</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-ipBlock-except.yaml<span class="comment"># 查询 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       42s</code></pre><p><strong>测试1：创建Pod，固定IP地址，访问web1</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 Pod Ip地址范围</span>$ calicoctl get ippoolNAME                  CIDR            SELECTOR   default-ipv4-ippool   171.20.0.0/16   all()<span class="comment"># 创建 171.20.10.0/24 这个网段的pod</span>$ kubectl create -f - &lt;&lt;<span class="string">EOF</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">  labels:</span><span class="string">    app: pod</span><span class="string">  annotations:</span><span class="string">    &quot;cni.projectcalico.org/ipAddrs&quot;: &quot;[\&quot;171.20.10.27\&quot;]&quot;</span><span class="string">  name: pod1</span><span class="string">  namespace: default</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">    - image: nginx:1.29.0</span><span class="string">      imagePullPolicy: IfNotPresent</span><span class="string">      name: pod1</span><span class="string">EOF</span><span class="comment"># 创建非 171.20.10.0/24 这个网段的pod</span>$ kubectl create -f - &lt;&lt;<span class="string">EOF</span><span class="string">apiVersion: v1</span><span class="string">kind: Pod</span><span class="string">metadata:</span><span class="string">  labels:</span><span class="string">    app: pod</span><span class="string">  annotations:</span><span class="string">    &quot;cni.projectcalico.org/ipAddrs&quot;: &quot;[\&quot;171.20.10.10\&quot;]&quot;</span><span class="string">  name: pod2</span><span class="string">  namespace: default</span><span class="string">spec:</span><span class="string">  containers:</span><span class="string">    - image: nginx:1.29.0</span><span class="string">      imagePullPolicy: IfNotPresent</span><span class="string">      name: pod2</span><span class="string">EOF</span><span class="comment"># 查看创建 Pod 的IP地址</span>$ kubectl get pods -o wide -n defaultNAME   READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATESpod1   1/1     Running   0          24s   171.20.10.27   k8s-node02   &lt;none&gt;           &lt;none&gt;pod2   1/1     Running   0          16s   171.20.20.10   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># pod1 访问 web1 成功，pod1 ip 为 171.20.10.27，在 171.20.10.0/24 网段内，可通过网络策略</span>$ kubectl <span class="built_in">exec</span> -it pod1 -n default -- sh -c <span class="string">&quot;curl web1.network&quot;</span>web1<span class="comment"># pod2 访问 web1 失败，pod2 ip 为 171.20.10.10，被 NetworkPolicy except 排除在外，无法通过网络策略</span>$ kubectl <span class="built_in">exec</span> -it pod2 -n default -- sh -c <span class="string">&quot;curl web1.network&quot;</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out</code></pre><h2 id="2-出站网络策略"><a href="#2-出站网络策略" class="headerlink" title="2. 出站网络策略"></a>2. 出站网络策略</h2><p><strong>创建 web3</strong></p><pre><code class="highlight bash"><span class="comment"># 创建web3用于测试使用</span>$ kubectl run web3 --image=nginx:1.29.0 --labels=app=web,<span class="built_in">env</span>=dev --image-pull-policy=IfNotPresent -n network --expose --port 80<span class="comment"># 查看Pod</span>$ $ kubectl get pods -o wide -n networkNAME   READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESweb1   1/1     Running   0          6h26m   171.20.85.196   k8s-node01   &lt;none&gt;           &lt;none&gt;web2   1/1     Running   0          6h26m   171.20.85.197   k8s-node01   &lt;none&gt;           &lt;none&gt;web3   1/1     Running   0          5s      171.20.10.0     k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 Service</span>$ $ kubectl get pods -o wide -n network --show-labelsNAME   READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES   LABELSweb1   1/1     Running   0          6h27m   171.20.85.196   k8s-node01   &lt;none&gt;           &lt;none&gt;            app=web,<span class="built_in">env</span>=prodweb2   1/1     Running   0          6h26m   171.20.85.197   k8s-node01   &lt;none&gt;           &lt;none&gt;            app=web,<span class="built_in">env</span>=<span class="built_in">test</span>web3   1/1     Running   0          35s     171.20.10.0     k8s-node02   &lt;none&gt;           &lt;none&gt;            app=web,<span class="built_in">env</span>=dev<span class="comment"># 修改nginx的首页文件index.html，用于区分pod</span>$ kubectl <span class="built_in">exec</span> -it web3 -- sh -c <span class="string">&quot;echo web3 &gt; /usr/share/nginx/html/index.html&quot;</span><span class="comment"># 访问Pod，测试首页是否改变</span>$ curl 171.20.10.0web3</code></pre><h3 id="2-1-出站网络策略-pod标签选择器"><a href="#2-1-出站网络策略-pod标签选择器" class="headerlink" title="2.1 出站网络策略-pod标签选择器"></a>2.1 出站网络策略-pod标签选择器</h3><h4 id="2-1-1-案例1"><a href="#2-1-1-案例1" class="headerlink" title="2.1.1 案例1"></a>2.1.1 案例1</h4><p>定义通过 pod 标签选择器来控制的出站网络策略，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，web1只能访问当前命名空间标签为 test: pod3的pod的80端口(TCP)</p><p><strong>资源清单：</strong><code>network-policy-pod-selector.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span>  <span class="attr">egress:</span>                   <span class="comment"># 出站网络策略</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">podSelector:</span>            <span class="attr">matchLabels:</span>    <span class="comment"># 只能访问标签为 env: dev 的Pod</span>              <span class="attr">env:</span> <span class="string">dev</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>     <span class="comment"># 只能访问端口 80，且协议为TCP</span>          <span class="attr">port:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-pod-selector.yaml<span class="comment"># 查询 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       85s</code></pre><p><strong>测试出站网络策略</strong></p><p>进入 web1 , 访问 web2 和 web3</p><pre><code class="highlight bash"><span class="comment"># web1 直接访问 web3 的ip是成功的，因为满足的出站策略</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl 171.20.10.0&quot;</span>web3<span class="comment"># web1 直接访问 web2 的ip失败了，因为 出站策略里，限制了访问的pod，不包含 pod2</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl 171.20.85.197&quot;</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out<span class="comment"># web1 访问 web3 svc 失败，原因为：如果想通过svc访问 pod,pod 需要去kube-dns那里查询 svc 的IP地址，但是现在 web1 没有 kube-dns 的访问权限</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl web3.network&quot;</span>curl: (6) Could not resolve host: web3.network</code></pre><p>web1 访问 web3 svc 失败，原因为：如果想通过svc访问 pod,pod 需要去kube-dns那里查询 svc 的IP地址，但是现在 web1 没有 kube-dns 的访问权限</p><h3 id="2-2-出站网络策略-pod标签选择器和-namespaceSelector-命名空间选择器"><a href="#2-2-出站网络策略-pod标签选择器和-namespaceSelector-命名空间选择器" class="headerlink" title="2.2 出站网络策略-pod标签选择器和 namespaceSelector 命名空间选择器"></a>2.2 出站网络策略-pod标签选择器和 namespaceSelector 命名空间选择器</h3><h4 id="2-2-1-案例1"><a href="#2-2-1-案例1" class="headerlink" title="2.2.1 案例1"></a>2.2.1 案例1</h4><p>修改网络策略，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，web1 能访问 kube-system 命名空间下的所有 pod 和当前命名空间下标签为 env: dev 的 pod，访问端口为 80 和 53。</p><p><strong>查看命名空间 kube-system 的标签</strong></p><pre><code class="highlight bash">$ kubectl get ns --show-labels | grep kube-systemkube-system       Active   4d4h    kubernetes.io/metadata.name=kube-system</code></pre><p><strong>资源清单：</strong> <code>network-policy-pod-namespace.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span>  <span class="attr">egress:</span>                   <span class="comment"># 出站网络策略</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">namespaceSelector:</span>      <span class="comment"># 标签为 kubernetes.io/metadata.name: kube-system 下的所有pod，web1 都能访问</span>            <span class="attr">matchLabels:</span>              <span class="attr">kubernetes.io/metadata.name:</span> <span class="string">kube-system</span>        <span class="bullet">-</span> <span class="attr">podSelector:</span>            <span class="attr">matchLabels:</span>          <span class="comment"># 并且能访问标签为 env: dev 的Pod（web3）</span>              <span class="attr">env:</span> <span class="string">dev</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>           <span class="comment"># 能访问端口 80，且协议为TCP</span>          <span class="attr">port:</span> <span class="number">80</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">UDP</span>           <span class="comment"># 能访问端口 53，且协议为UDP</span>          <span class="attr">port:</span> <span class="number">53</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-pod-namespace.yaml<span class="comment"># 查询 NetworkPolicy</span>$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       85s</code></pre><p><strong>测试出站网络策略</strong></p><p>进入 web1 , 访问 web2 和 web3</p><pre><code class="highlight bash"><span class="comment"># web1 直接访问 web3 svc成功，因为满足的出站策略，且 web1 具有 kube-dns 访问权限，因此可以解析域名</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl web3.network&quot;</span>web3<span class="comment"># web1 直接访问 web2 的ip失败了，因为 出站策略里，限制了访问的pod，不包含 pod2</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl web2.network&quot;</span>curl: (28) Failed to connect to web1 port 80 after 133895 ms: Operation timed out</code></pre><h3 id="2-3-优化出站网络策略"><a href="#2-3-优化出站网络策略" class="headerlink" title="2.3 优化出站网络策略"></a>2.3 优化出站网络策略</h3><p>上面的案例存在问题：web1可以访问标签为 <code>env: dev</code> 的 pod 的 80端口 和 53端口, 而 web3 只有 80端口，53 端口属于 kube-system 名称空间下的 coredns pod.</p><h4 id="2-3-1-案例1"><a href="#2-3-1-案例1" class="headerlink" title="2.3.1 案例1"></a>2.3.1 案例1</h4><p>修改网络策略，如下网络策略的功能为：把名为 my-network-policy 的网络策略应用到 web1，web1能访问 kube-system 命名空间下的所有 pod 的53端口，web1能访问当前命名空间下标签为 <code>env: dev</code> 的pod的80端口。</p><p><strong>资源清单：</strong><code>network-policy-pod-namespace2.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-network-policy</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span>  <span class="attr">egress:</span>                   <span class="comment"># 出站网络策略</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">namespaceSelector:</span>      <span class="comment"># 标签为 kubernetes.io/metadata.name: kube-system 下的所有 pod，web1 都能访问</span>            <span class="attr">matchLabels:</span>              <span class="attr">kubernetes.io/metadata.name:</span> <span class="string">kube-system</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">UDP</span>           <span class="comment"># 能访问端口 53，且协议为UDP</span>          <span class="attr">port:</span> <span class="number">53</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">podSelector:</span>            <span class="attr">matchLabels:</span> <span class="comment"># 并且能访问标签为 env: dev 的Pod（web3）</span>              <span class="attr">env:</span> <span class="string">dev</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="comment"># 能访问端口 80，且协议为TCP</span>          <span class="attr">port:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 NetworkPolicy</span>$ kubectl apply -f network-policy-pod-namespace2.yaml$ kubectl get networkpolicy -n networkNAME                POD-SELECTOR   AGEmy-network-policy   <span class="built_in">env</span>=prod       26m</code></pre><p><strong>测试出站网络策略</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 coredns Pod</span>$ kubectl get pods -n kube-system -o wide | grep corednscoredns-5f98f8d567-72vc7                   1/1     Running   0               4d16h   171.20.58.192   k8s-node02     &lt;none&gt;           &lt;none&gt;coredns-5f98f8d567-cv75d                   1/1     Running   0               4d16h   171.20.85.192   k8s-node01     &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 coredns Service</span>$ kubectl get service -n kube-system -o wide | grep kube-dnskube-dns       ClusterIP   10.96.0.10       &lt;none&gt;        53/UDP,53/TCP,9153/TCP   4d16h   k8s-app=kube-dns<span class="comment"># 测试 pod1 访问 coredns Service 53 端口，成功</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=<span class="built_in">env</span>=prod --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh/home <span class="comment"># telnet kube-dns.kube-system 53</span>Connected to kube-dns.kube-system<span class="comment"># 测试 web1 访问 web3 80 端口，成功</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl web3.network&quot;</span>web3</code></pre><h3 id="2-4-出站网络策略-指定端口范围"><a href="#2-4-出站网络策略-指定端口范围" class="headerlink" title="2.4 出站网络策略-指定端口范围"></a>2.4 出站网络策略-指定端口范围</h3><p>在Kubernetes v1.22 版本，出了个新特性，在编写 NetworkPolicy 时，你可以针对一个端口范围而不是某个固定端口。这一目的可以通过使用 endPort 字段来实现，如下例所示：</p><p><strong>资源清单：</strong> <code>network-policy-ipBlock.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">multi-port-egress</span>  <span class="attr">namespace:</span> <span class="string">network</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 匹配作用的 Pod 标签</span>      <span class="attr">env:</span> <span class="string">prod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span>  <span class="attr">egress:</span>                   <span class="comment"># 出站网络策略</span>    <span class="bullet">-</span> <span class="attr">to:</span>        <span class="bullet">-</span> <span class="attr">ipBlock:</span>            <span class="attr">cidr:</span> <span class="number">171.20</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span>    <span class="comment"># 只允许 171.20.0.0/16 这个网段的pod可以访问</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">port:</span> <span class="number">53</span>                  <span class="comment"># 可以访问 53-80 之间的端口</span>          <span class="attr">endPort:</span> <span class="number">80</span></code></pre><p>上面的规则允许名字空间 network 中所有带有标签 env: prod 的 Pod 使用 TCP 协议 与 171.20.0.0&#x2F;16 范围内的 IP 通信，只要目标端口介于 53 和 80 之间就可以。</p><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f network-policy-ipBlock.yaml</code></pre><p><strong>测试出站网络策略</strong></p><pre><code class="highlight bash"><span class="comment"># 测试 pod1 访问 coredns Service 53 端口，成功</span>$ kubectl run pod1 --image=yauritux/busybox-curl:latest --labels=<span class="built_in">env</span>=prod --image-pull-policy=IfNotPresent -n default -it --<span class="built_in">rm</span> -- sh/home <span class="comment"># telnet kube-dns.kube-system 53</span>Connected to kube-dns.kube-system<span class="comment"># 测试 web1 访问 web3 80 端口，成功</span>$ kubectl <span class="built_in">exec</span> -it web1 -n network -- bash -c <span class="string">&quot;curl web3.network&quot;</span>web3</code></pre><p><strong>使用endPort字段时存在以下限制</strong>：</p><ul><li>作为一种 Beta 阶段的特性，<strong>端口范围设定默认是被启用的</strong>。要在整个集群 范围内禁止使用 endPort 字段，你需要为 API 服务器设置 -feature-gates&#x3D;NetworkPolicyEndPort&#x3D;false,… 以禁用 NetworkPolicyEndPort 特性。</li><li>endPort 字段必须等于或者大于 port 字段的值。</li><li>port，endPort 两个字段的设置值都只能是数字。</li></ul><p><strong>注意</strong>：你的集群所使用的 CNI 网络插件 必须支持在 NetworkPolicy 规约中使用 endPort 字段。 如果你的网络插件 不支持 endPort 字段，而你指定了一个包含 endPort 字段的 NetworkPolicy， 策略只对单个 port 字段生效。</p><h1 id="五、默认网络策略"><a href="#五、默认网络策略" class="headerlink" title="五、默认网络策略"></a>五、默认网络策略</h1><h2 id="1-默认拒绝所有入站流量"><a href="#1-默认拒绝所有入站流量" class="headerlink" title="1. 默认拒绝所有入站流量"></a>1. 默认拒绝所有入站流量</h2><p>可以通过创建<strong>选择所有容器</strong>但不允许任何进入这些容器的入站流量的 NetworkPolicy 来为命名空间创建 “default” 隔离策略。这样可以确保即使容器没有选择其他任何 NetworkPolicy，也仍然可以被隔离。 此策略不会更改默认的出口隔离行为。</p><p>默认拒绝所有入站流量，网络策略如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">default-deny-ingress</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span> &#123;&#125;<span class="comment"># 空选择器（&#123;&#125;）表示匹配default命名空间下所有Pod</span>  <span class="attr">policyTypes:</span><span class="comment"># 定义入站流量</span>  <span class="bullet">-</span> <span class="string">Ingress</span>  <span class="comment"># 没有 ingress 规则，意味着拒绝所有入站流量</span></code></pre><h2 id="2-默认允许所有入站流量"><a href="#2-默认允许所有入站流量" class="headerlink" title="2. 默认允许所有入站流量"></a>2. 默认允许所有入站流量</h2><p>如果要允许所有流量进入某个命名空间中的所有 Pod（即使添加了导致某些 Pod 被视为 “隔离”的策略），则可以创建一个策略来明确允许该名字空间中的所有流量。</p><p>默认允许所有入站流量，网络策略如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">allow-all-ingress</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span> &#123;&#125;<span class="comment"># 空选择器（&#123;&#125;）表示匹配default命名空间下所有Pod</span>  <span class="attr">ingress:</span>  <span class="bullet">-</span> &#123;&#125;<span class="comment"># 空规则（&#123;&#125;）表示允许所有入站流量。</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span><span class="comment"># 控制入站流量（从外部或集群内其他 Pod 访问目标 Pod）</span></code></pre><h2 id="3-默认拒绝所有出站流量"><a href="#3-默认拒绝所有出站流量" class="headerlink" title="3. 默认拒绝所有出站流量"></a>3. 默认拒绝所有出站流量</h2><p>可以通过创建选择所有容器但不允许来自这些容器的任何出站流量的 NetworkPolicy 来为名字空间创建 “default” egress 隔离策略。<br>此策略可以确保即使没有被其他任何 NetworkPolicy 选择的 Pod 也不会被允许流出流量。 此策略不会更改默认的入站流量隔离行为。</p><p>默认拒绝所有出站流量，网络策略如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">default-deny-egress</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span> &#123;&#125;<span class="comment"># 空选择器（&#123;&#125;）表示匹配default命名空间下所有Pod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span><span class="comment"># 控制出站流量（Pod 访问其他 Pod、Service 或外部网络）</span>  <span class="comment"># 没有 egress 规则，意味着拒绝所有出站流量</span></code></pre><h2 id="4-默认允许所有出站流量"><a href="#4-默认允许所有出站流量" class="headerlink" title="4. 默认允许所有出站流量"></a>4. 默认允许所有出站流量</h2><p>如果要允许来自名字空间中所有 Pod 的所有流量（即使添加了导致某些 Pod 被视为“隔离”的策略）， 则可以创建一个策略，该策略明确允许该名字空间中的所有出站流量。</p><p>默认允许所有出站流量，网络策略如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">allow-all-egress</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span> &#123;&#125;<span class="comment"># 空选择器（&#123;&#125;）表示匹配default命名空间下所有Pod</span>  <span class="attr">egress:</span>  <span class="bullet">-</span> &#123;&#125;<span class="comment"># 空规则（&#123;&#125;）表示允许所有出站流量。</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Egress</span><span class="comment"># 控制出站流量（Pod 访问其他 Pod、Service 或外部网络）</span></code></pre><h2 id="5-默认拒绝所有入口和所有出站流量"><a href="#5-默认拒绝所有入口和所有出站流量" class="headerlink" title="5. 默认拒绝所有入口和所有出站流量"></a>5. 默认拒绝所有入口和所有出站流量</h2><p>你可以为名字空间创建“默认”策略，以通过在该名字空间中创建以下 NetworkPolicy 来阻止所有入站和出站流量。<br>此策略可以确保即使没有被其他任何 NetworkPolicy 选择的 Pod 也不会被 允许入站或出站流量。</p><p>默认拒绝所有入口和所有出站流量，网络策略如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">NetworkPolicy</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">default-deny-all</span><span class="attr">spec:</span>  <span class="attr">podSelector:</span> &#123;&#125;<span class="comment"># 空选择器（&#123;&#125;）表示匹配default命名空间下所有Pod</span>  <span class="attr">policyTypes:</span>  <span class="bullet">-</span> <span class="string">Ingress</span><span class="comment"># 控制入站流量（从外部或集群内其他 Pod 访问目标 Pod）</span>  <span class="bullet">-</span> <span class="string">Egress</span><span class="comment"># 控制出站流量（Pod 访问其他 Pod、Service 或外部网络）</span>  <span class="comment"># 没有 egress 规则，意味着拒绝所有出站流量</span>  <span class="comment"># 没有 ingress 规则，意味着拒绝所有入站流量</span></code></pre><h1 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h1><p>网络策略(NetworkPolicy)是 Kubernetes 集群中一个非常重要的安全控制措施，可以帮助我们保护 Kubernetes集群的网络安全。</p><p>通过网络策略(NetworkPolicy)示例，展示了如何使用网络策略( NetworkPolicy )来限制Pod之间的流量访问。</p><p>在 Kubernetes 集群中使用网络策略( NetworkPolicy )可以提高网络的安全性，但也需要注意以下几点：</p><ul><li>应该避免创建过于复杂的网络策略(NetworkPolicy)，因为这可能会导致网络通信中断或延迟。</li><li>在创建网络策略(NetworkPolicy)前，需要确保已仔细检查其规则，并确认这些规则符合预期。</li><li>当修改或删除一个网络策略(NetworkPolicy)时，需要确保所有Pod都能够正常通信。</li></ul><p><strong>通过网络策略（至少目前还）无法完成的工作</strong></p><ul><li>强制集群内部流量经过某公用网关（这种场景最好通过服务网格或其他代理来实现）</li><li>与 TLS 相关的场景（考虑使用服务网格或者 Ingress 控制器）</li><li>特定于节点的策略（你可以使用 CIDR 来表达这一需求不过你无法使用节点在 Kubernetes 中的其他标识信息来辩识目标节点）；</li><li>基于名字来选择服务来选择目标 Pod 或名字空间</li><li>基于名字来选择服务来选择目标 Pod 或名字空间</li><li>实现适用于所有名字空间或 Pods 的默认策略（某些第三方 Kubernetes 发行版本或项目可以做到这点）；</li><li>高级的策略查询或者可达性相关工具；</li><li>生成网络安全事件日志的能力（例如，被阻塞或接收的连接请求）；</li><li>显式地拒绝策略的能力（目前，NetworkPolicy 的模型默认采用拒绝操作， 其唯一的能力是添加允许策略）；</li><li>禁止本地回路或指向宿主的网络流量（Pod 目前无法阻塞 localhost 访问， 它们也无法禁止来自所在节点的访问请求）；</li></ul><p><strong>参考链接</strong></p><blockquote><p><a href="https://www.cnblogs.com/renshengdezheli/p/17479289.html">https://www.cnblogs.com/renshengdezheli/p/17479289.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、网络策略-NetworkPolicy-简介&quot;&gt;&lt;a href=&quot;#一、网络策略-NetworkPolicy-简介&quot; class=&quot;headerlink&quot; title=&quot;一、网络策略(NetworkPolicy)简介&quot;&gt;&lt;/a&gt;一、网络策略(NetworkPol</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Pod" scheme="https://georgechan95.github.io/tags/Pod/"/>
    
  </entry>
  
  <entry>
    <title>016-K8S-固定Pod IP地址，基于Calico插件</title>
    <link href="https://georgechan95.github.io/blog/c9536d9e.html"/>
    <id>https://georgechan95.github.io/blog/c9536d9e.html</id>
    <published>2025-07-26T05:35:00.000Z</published>
    <updated>2025-07-28T03:11:50.871Z</updated>
    
    <content type="html"><![CDATA[<p><strong>需求：</strong></p><p>在某种情况下，创建 Pod 时主动给它分配IP地址，并要求即使重启Pod IP地址也不变。</p><p>这里演示 Calico 网络插件环境中，如何给 Pod 分配固定的 IP 地址。</p><h1 id="一、确认环境"><a href="#一、确认环境" class="headerlink" title="一、确认环境"></a>一、确认环境</h1><h2 id="1-修改-calico-配置文件"><a href="#1-修改-calico-配置文件" class="headerlink" title="1. 修改 calico 配置文件"></a>1. 修改 calico 配置文件</h2><p>修改配置文件 <code>vim /etc/cni/net.d/10-calico.conflist</code> ，将 <code>ipam</code> 类型修改为 <code>calico-ipam</code></p><pre><code class="highlight bash">$ vim /etc/cni/net.d/10-calico.conflist<span class="string">&quot;ipam&quot;</span>: &#123;          <span class="string">&quot;type&quot;</span>: <span class="string">&quot;calico-ipam&quot;</span>&#125;</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/26/20250726-135737.png" alt="image-20250726135707385"></p><h2 id="2-安装-calicoctl-工具"><a href="#2-安装-calicoctl-工具" class="headerlink" title="2. 安装 calicoctl 工具"></a>2. 安装 calicoctl 工具</h2><p>二进制方式安装 calicoctl 工具，版本号选择 Calico 相同的版本，这里是 3.26.3</p><h3 id="2-1-安装-calicoctl"><a href="#2-1-安装-calicoctl" class="headerlink" title="2.1 安装 calicoctl"></a>2.1 安装 calicoctl</h3><pre><code class="highlight bash"><span class="comment"># 下载 calicoctl 二进制包</span>$ wget https://github.com/projectcalico/calico/releases/download/v3.26.3/calicoctl-linux-amd64<span class="comment"># 将二进制包放到指定目录</span>$ <span class="built_in">mv</span> calicoctl-linux-amd64 /usr/local/bin/calicoctl<span class="comment"># 授权</span>$ <span class="built_in">chmod</span> +x /usr/local/bin/calicoctl<span class="comment"># 永久设置环境变量</span>calicoctl get ippool --show-ip-allocations</code></pre><h3 id="2-2-配置-calicoctl"><a href="#2-2-配置-calicoctl" class="headerlink" title="2.2 配置 calicoctl"></a>2.2 配置 calicoctl</h3><p>calicoctl 通过读写 calico 的数据存储系统（ datastore ）进行查看或者其他各类管理操作，通常，它需要提供认证信息经由相应的数据存储完成认证。在使用<code>Kubernetes API</code> 数据存储时，需要使用类似 kubectl 的认证信息完成认证。它可以通过环境变量声明的 <code>DATASTORE_TYPE</code> 和 <code>KUBECONFIG</code> 接入集群，例如以下命令格式运行 calicoctl ：</p><pre><code class="highlight bash"><span class="comment"># 临时设置环境变量</span>$ <span class="built_in">export</span> CALICO_DATASTORE_TYPE=kubernetes$ <span class="built_in">export</span> CALICO_KUBECONFIG=~/.kube/config<span class="comment"># 测试</span>$ calicoctl get nodesNAME           k8s-master01   k8s-node01     k8s-node02     k8s-node03</code></pre><p>也可以直接将认证信息等保存于配置文件中，calicoctl 默认加载 <code>/etc/calico/calicoctl.cfg</code> 配置文件读取配置信息，如下所示：</p><pre><code class="highlight bash">$ <span class="built_in">cat</span> /etc/calico/calicoctl.cfg apiVersion: projectcalico.org/v3kind: CalicoAPIConfigmetadata:spec:  datastoreType: <span class="string">&quot;kubernetes&quot;</span>         kubeconfig: <span class="string">&quot;/root/.kube/config&quot;</span></code></pre><h2 id="3-查看-calico-的-CIDR-地址范围"><a href="#3-查看-calico-的-CIDR-地址范围" class="headerlink" title="3. 查看 calico 的 CIDR 地址范围"></a>3. 查看 calico 的 CIDR 地址范围</h2><pre><code class="highlight bash">$ calicoctl get ippoolNAME                  CIDR            SELECTOR   default-ipv4-ippool   171.20.0.0/16   all()</code></pre><h2 id="4-创建-Pod"><a href="#4-创建-Pod" class="headerlink" title="4. 创建 Pod"></a>4. 创建 Pod</h2><p>在 CIDR 地址范围内给 Pod 设定一个 IP 地址。</p><p>IP 地址范围：171.20.0.0 到 171.20.255.255</p><h3 id="4-1-直接创建-Pod"><a href="#4-1-直接创建-Pod" class="headerlink" title="4.1 直接创建 Pod"></a>4.1 直接创建 Pod</h3><p>资源清单1：<code>fixed-pod-ip.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">annotations:</span>    <span class="comment"># 设置Pod固定ip地址</span>    <span class="attr">&quot;cni.projectcalico.org/ipAddrs&quot;:</span> <span class="string">&quot;[\&quot;171.20.45.27\&quot;]&quot;</span>  <span class="attr">name:</span> <span class="string">fixed-pod-ip</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">name:</span> <span class="string">nginx</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f fixed-pod-ip.yaml<span class="comment"># 查看Pod，使用的正是分配的IP</span>$ kubectl get pods -o wide -wNAME           READY   STATUS              RESTARTS   AGE   IP       NODE         NOMINATED NODE   READINESS GATESfixed-pod-ip   0/1     ContainerCreating   0          3s    &lt;none&gt;   k8s-node01   &lt;none&gt;           &lt;none&gt;fixed-pod-ip   0/1     ContainerCreating   0          3s    &lt;none&gt;   k8s-node01   &lt;none&gt;           &lt;none&gt;fixed-pod-ip   1/1     Running             0          7s    171.20.45.27   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 测试访问</span>$ curl http://171.20.45.27:80&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="4-2-创建-Deployment"><a href="#4-2-创建-Deployment" class="headerlink" title="4.2 创建 Deployment"></a>4.2 创建 Deployment</h3><p>资源清单：<code>fixed-deploy-ip.yaml</code></p><pre><code class="highlight bash">apiVersion: apps/v1kind: Deploymentmetadata:  name: fixed-deploy-ip  labels:    app: my-deployspec:  selector:    matchLabels:      app: fixed-deploy  template:    metadata:      labels:        app: fixed-deploy      annotations:        <span class="comment"># 设置Pod固定ip地址</span>        <span class="string">&quot;cni.projectcalico.org/ipAddrs&quot;</span>: <span class="string">&quot;[\&quot;171.20.42.65\&quot;]&quot;</span>    spec:      containers:        - image: nginx:1.29.0          imagePullPolicy: IfNotPresent          name: nginx</code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f fixed-deploy-ip.yaml<span class="comment"># Pod使用Ip为手动分配的IP</span>$ kubectl get pods -o wideNAME                               READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATESfixed-deploy-ip-6fcf56c75b-tk6nb   1/1     Running   0          78s   171.20.42.65   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 删除Pod，重新生成Pod</span>$ kubectl delete pod fixed-deploy-ip-6fcf56c75b-tk6nb<span class="comment"># 新的Pod ip 依旧是手动分配的IP</span>$ kubectl get pods -o wide -wNAME                               READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATESfixed-deploy-ip-6fcf56c75b-25pxm   1/1     Running   0          11s   171.20.42.65   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p><strong>注意：</strong> 使用 Deployment 自动分配IP， replicas 副本数必须是1，多个Pod会存在IP冲突问题，如下：</p><pre><code class="highlight yaml"><span class="string">$</span> <span class="string">kubectl</span> <span class="string">describe</span> <span class="string">pod</span> <span class="string">fixed-deploy-ip-6fcf56c75b-cgksd</span><span class="attr">Name:</span>             <span class="string">fixed-deploy-ip-6fcf56c75b-cgksd</span><span class="attr">Namespace:</span>        <span class="string">default</span><span class="attr">Priority:</span>         <span class="number">0</span><span class="attr">Service Account:</span>  <span class="string">default</span><span class="attr">Node:</span>             <span class="string">k8s-node01/10.20.1.140</span><span class="attr">Start Time:</span>       <span class="string">Mon,</span> <span class="number">28</span> <span class="string">Jul</span> <span class="number">2025 10:59:27</span> <span class="string">+0800</span><span class="attr">Labels:</span>           <span class="string">app=fixed-deploy</span>                  <span class="string">pod-template-hash=6fcf56c75b</span><span class="attr">Annotations:      cni.projectcalico.org/ipAddrs:</span> [<span class="string">&quot;171.20.42.65&quot;</span>]                  <span class="attr">cni.projectcalico.org/podIP:</span>                   <span class="attr">cni.projectcalico.org/podIPs:</span> <span class="attr">Status:</span>           <span class="string">Pending</span><span class="attr">IP:</span>               <span class="attr">IPs:</span>              <span class="string">&lt;none&gt;</span><span class="attr">Controlled By:</span>    <span class="string">ReplicaSet/fixed-deploy-ip-6fcf56c75b</span><span class="attr">Containers:</span>  <span class="attr">nginx:</span>    <span class="attr">Container ID:</span>       <span class="attr">Image:</span>          <span class="string">nginx:1.29.0</span>    <span class="attr">Image ID:</span>           <span class="attr">Port:</span>           <span class="string">&lt;none&gt;</span>    <span class="attr">Host Port:</span>      <span class="string">&lt;none&gt;</span>    <span class="attr">State:</span>          <span class="string">Waiting</span>      <span class="attr">Reason:</span>       <span class="string">ContainerCreating</span>    <span class="attr">Ready:</span>          <span class="literal">False</span>    <span class="attr">Restart Count:</span>  <span class="number">0</span>    <span class="attr">Environment:</span>    <span class="string">&lt;none&gt;</span>    <span class="attr">Mounts:</span>      <span class="string">/var/run/secrets/kubernetes.io/serviceaccount</span> <span class="string">from</span> <span class="string">kube-api-access-dd6zw</span> <span class="string">(ro)</span><span class="attr">Conditions:</span>  <span class="string">Type</span>                        <span class="string">Status</span>  <span class="string">PodReadyToStartContainers</span>   <span class="literal">False</span>   <span class="string">Initialized</span>                 <span class="literal">True</span>   <span class="string">Ready</span>                       <span class="literal">False</span>   <span class="string">ContainersReady</span>             <span class="literal">False</span>   <span class="string">PodScheduled</span>                <span class="literal">True</span> <span class="attr">Volumes:</span>  <span class="attr">kube-api-access-dd6zw:</span>    <span class="attr">Type:</span>                    <span class="string">Projected</span> <span class="string">(a</span> <span class="string">volume</span> <span class="string">that</span> <span class="string">contains</span> <span class="string">injected</span> <span class="string">data</span> <span class="string">from</span> <span class="string">multiple</span> <span class="string">sources)</span>    <span class="attr">TokenExpirationSeconds:</span>  <span class="number">3607</span>    <span class="attr">ConfigMapName:</span>           <span class="string">kube-root-ca.crt</span>    <span class="attr">ConfigMapOptional:</span>       <span class="string">&lt;nil&gt;</span>    <span class="attr">DownwardAPI:</span>             <span class="literal">true</span><span class="attr">QoS Class:</span>                   <span class="string">BestEffort</span><span class="attr">Node-Selectors:</span>              <span class="string">&lt;none&gt;</span><span class="attr">Tolerations:</span>                 <span class="string">node.kubernetes.io/not-ready:NoExecute</span> <span class="string">op=Exists</span> <span class="string">for</span> <span class="string">300s</span>                             <span class="string">node.kubernetes.io/unreachable:NoExecute</span> <span class="string">op=Exists</span> <span class="string">for</span> <span class="string">300s</span><span class="attr">Events:</span>  <span class="string">Type</span>     <span class="string">Reason</span>                  <span class="string">Age</span>               <span class="string">From</span>               <span class="string">Message</span>  <span class="string">----</span>     <span class="string">------</span>                  <span class="string">----</span>              <span class="string">----</span>               <span class="string">-------</span>  <span class="string">Normal</span>   <span class="string">Scheduled</span>               <span class="string">28s</span>               <span class="string">default-scheduler</span>  <span class="string">Successfully</span> <span class="string">assigned</span> <span class="string">default/fixed-deploy-ip-6fcf56c75b-cgksd</span> <span class="string">to</span> <span class="string">k8s-node01</span>  <span class="attr">Warning  FailedCreatePodSandBox  24s               kubelet            Failed to create pod sandbox: rpc error:</span> <span class="string">code</span> <span class="string">=</span> <span class="string">Unknown</span> <span class="string">desc</span> <span class="string">=</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">sandbox</span> <span class="string">container</span> <span class="string">&quot;f1b3f4fc77eeca1672a1ddd935bdbda2d7a1dbd237a5be89b7422a56a315dc0a&quot;</span> <span class="string">network</span> <span class="string">for</span> <span class="string">pod</span> <span class="attr">&quot;fixed-deploy-ip-6fcf56c75b-cgksd&quot;:</span> <span class="string">networkPlugin</span> <span class="string">cni</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">pod</span> <span class="string">&quot;fixed-deploy-ip-6fcf56c75b-cgksd_default&quot;</span> <span class="attr">network:</span> <span class="string">plugin</span> <span class="string">type=&quot;calico&quot;</span> <span class="string">failed</span> <span class="string">(add):</span> <span class="attr">error getting IP from IPAM: resource already exists:</span> <span class="number">171.20</span><span class="number">.42</span><span class="number">.65</span>  <span class="attr">Warning  FailedCreatePodSandBox  20s               kubelet            Failed to create pod sandbox: rpc error:</span> <span class="string">code</span> <span class="string">=</span> <span class="string">Unknown</span> <span class="string">desc</span> <span class="string">=</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">sandbox</span> <span class="string">container</span> <span class="string">&quot;bf2d21340a820b55b1f202d2f89f68d42523859dacd1e1c9a5d757e814fc34b4&quot;</span> <span class="string">network</span> <span class="string">for</span> <span class="string">pod</span> <span class="attr">&quot;fixed-deploy-ip-6fcf56c75b-cgksd&quot;:</span> <span class="string">networkPlugin</span> <span class="string">cni</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">pod</span> <span class="string">&quot;fixed-deploy-ip-6fcf56c75b-cgksd_default&quot;</span> <span class="attr">network:</span> <span class="string">plugin</span> <span class="string">type=&quot;calico&quot;</span> <span class="string">failed</span> <span class="string">(add):</span> <span class="attr">error getting IP from IPAM: resource already exists:</span> <span class="number">171.20</span><span class="number">.42</span><span class="number">.65</span>  <span class="attr">Warning  FailedCreatePodSandBox  16s               kubelet            Failed to create pod sandbox: rpc error:</span> <span class="string">code</span> <span class="string">=</span> <span class="string">Unknown</span> <span class="string">desc</span> <span class="string">=</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">sandbox</span> <span class="string">container</span> <span class="string">&quot;230660cce4caaf260bfb2079479d8885aa19059441759246db3ef8ac5f93ba6c&quot;</span> <span class="string">network</span> <span class="string">for</span> <span class="string">pod</span> <span class="attr">&quot;fixed-deploy-ip-6fcf56c75b-cgksd&quot;:</span> <span class="string">networkPlugin</span> <span class="string">cni</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">pod</span> <span class="string">&quot;fixed-deploy-ip-6fcf56c75b-cgksd_default&quot;</span> <span class="attr">network:</span> <span class="string">plugin</span> <span class="string">type=&quot;calico&quot;</span> <span class="string">failed</span> <span class="string">(add):</span> <span class="attr">error getting IP from IPAM: resource already exists:</span> <span class="number">171.20</span><span class="number">.42</span><span class="number">.65</span>  <span class="attr">Warning  FailedCreatePodSandBox  11s               kubelet            Failed to create pod sandbox: rpc error:</span> <span class="string">code</span> <span class="string">=</span> <span class="string">Unknown</span> <span class="string">desc</span> <span class="string">=</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">sandbox</span> <span class="string">container</span> <span class="string">&quot;7b28648e2799adc7c5e73f5038279586ac36226f157349ae8054b0048953f41c&quot;</span> <span class="string">network</span> <span class="string">for</span> <span class="string">pod</span> <span class="attr">&quot;fixed-deploy-ip-6fcf56c75b-cgksd&quot;:</span> <span class="string">networkPlugin</span> <span class="string">cni</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">pod</span> <span class="string">&quot;fixed-deploy-ip-6fcf56c75b-cgksd_default&quot;</span> <span class="attr">network:</span> <span class="string">plugin</span> <span class="string">type=&quot;calico&quot;</span> <span class="string">failed</span> <span class="string">(add):</span> <span class="attr">error getting IP from IPAM: resource already exists:</span> <span class="number">171.20</span><span class="number">.42</span><span class="number">.65</span>  <span class="attr">Warning  FailedCreatePodSandBox  5s                kubelet            Failed to create pod sandbox: rpc error:</span> <span class="string">code</span> <span class="string">=</span> <span class="string">Unknown</span> <span class="string">desc</span> <span class="string">=</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">sandbox</span> <span class="string">container</span> <span class="string">&quot;2eed3030e3bfecbc5668a1621454a26dfd67688c5d152e638c86b58baa66b826&quot;</span> <span class="string">network</span> <span class="string">for</span> <span class="string">pod</span> <span class="attr">&quot;fixed-deploy-ip-6fcf56c75b-cgksd&quot;:</span> <span class="string">networkPlugin</span> <span class="string">cni</span> <span class="string">failed</span> <span class="string">to</span> <span class="string">set</span> <span class="string">up</span> <span class="string">pod</span> <span class="string">&quot;fixed-deploy-ip-6fcf56c75b-cgksd_default&quot;</span> <span class="attr">network:</span> <span class="string">plugin</span> <span class="string">type=&quot;calico&quot;</span> <span class="string">failed</span> <span class="string">(add):</span> <span class="attr">error getting IP from IPAM: resource already exists:</span> <span class="number">171.20</span><span class="number">.42</span><span class="number">.65</span></code></pre><h2 id="5-手动释放IP"><a href="#5-手动释放IP" class="headerlink" title="5. 手动释放IP"></a>5. 手动释放IP</h2><p>在使用过程中可能会遇到 IP 没有释放等问题导致 pod 启动失败，导致这种原因可能是 pod 被删除后，使用的 IP 地址未被释放，所以需要使用以下命令对地址池的 IP 进行释放，才能够被 pod 重新使用</p><pre><code class="highlight bash">$ calicoctl ipam release --ip 171.20.42.65</code></pre><p><strong>参考链接</strong></p><blockquote><p><a href="https://blog.csdn.net/weixin_48711696/article/details/136049633?csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%22136049633%22,%22source%22:%22weixin_48711696%22%7D">https://blog.csdn.net/weixin_48711696/article/details/136049633?csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%22136049633%22,%22source%22:%22weixin_48711696%22%7D</a></p><p><a href="https://blog.csdn.net/weixin_48711696/article/details/135749305">https://blog.csdn.net/weixin_48711696/article/details/135749305</a></p><p><a href="https://www.cnblogs.com/chuanzhang053/p/17584488.html">https://www.cnblogs.com/chuanzhang053/p/17584488.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;需求：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在某种情况下，创建 Pod 时主动给它分配IP地址，并要求即使重启Pod IP地址也不变。&lt;/p&gt;
&lt;p&gt;这里演示 Calico 网络插件环境中，如何给 Pod 分配固定的 IP 地址。&lt;/p&gt;
&lt;h1 id=&quot;一、确</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Pod" scheme="https://georgechan95.github.io/tags/Pod/"/>
    
  </entry>
  
  <entry>
    <title>015-K8S-Prometheus部署及监控告警</title>
    <link href="https://georgechan95.github.io/blog/e62b8338.html"/>
    <id>https://georgechan95.github.io/blog/e62b8338.html</id>
    <published>2025-07-19T08:39:00.000Z</published>
    <updated>2025-07-24T13:06:41.589Z</updated>
    
    <content type="html"><![CDATA[<p><strong>概要：</strong></p><p>简述 Loki 相关组件原理，并演示两种使用 Loki 监控Pod日志的部署方式：<strong>使用 yaml 资源清单部署</strong> 和 <strong>使用 Helm 部署</strong></p><p><strong>集群环境</strong></p><table><thead><tr><th>IP</th><th>Hostname</th><th>用途</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td><td>Master节点</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td><td>Node节点</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td><td>Node节点</td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td><td>Node节点</td></tr></tbody></table><h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>对于 Kubernetes 集群本身的监控也是非常重要的，我们需要时时刻刻了解集群的运行状态。</p><p>对于集群的监控一般我们需要考虑以下几个方面：</p><ul><li>Kubernetes 节点的监控：比如节点的 cpu、load、disk、memory 等指标</li><li>内部系统组件的状态：比如 kube-scheduler、kube-controller-manager、kubedns&#x2F;coredns 等组件的详细运行状态</li><li>编排级的 metrics：比如 Deployment 的状态、资源请求、调度和 API 延迟等数据指标</li></ul><p>Kubernetes 集群的监控方案目前主要有以下几种方案：</p><ul><li><p>cAdvisor : 是一个轻量级的容器监控工具，用于收集容器运行时的资源使用情况（如 CPU、内存、磁盘、网络等）以及性能统计数据。</p><ul><li><p>作用</p><ul><li>提供容器级别的资源使用和性能指标。</li><li>暴露这些指标，供其他监控工具（如 Metrics Server 或 Prometheus）采集。</li><li>内置于 Kubernetes 的 <strong>Kubelet</strong> 中，自动为集群中的每个节点收集容器数据。</li></ul></li><li><p>特点</p><ul><li><p><strong>轻量级</strong>：资源占用低，适合在每个节点运行。</p></li><li><p><strong>实时性</strong>：提供实时的容器性能数据。</p></li><li><p><strong>原生支持</strong>：在 Kubernetes 中默认集成到 Kubelet，无需单独部署。</p></li><li><p><strong>开放接口</strong>：通过 HTTP API 暴露指标，易于集成到其他监控系统。</p></li></ul></li></ul></li><li><p>metrics-server : 是一个轻量级的、可扩展的组件，用于从 Kubernetes 集群中的节点和 Pod 收集资源使用情况（如 CPU 和内存）的指标数据，并通过 Kubernetes API 提供这些数据。</p><ul><li><p>作用</p><ul><li>提供实时的资源使用指标，供用户或工具（如 kubectl、HPA）查询。</li><li>支持基于资源使用情况的自动扩展决策。</li><li>替代了早期的 Heapster（已废弃），是 Kubernetes 生态系统中默认的监控数据收集工具。</li></ul></li><li><p>特点</p><ul><li><p>轻量级：Metrics Server 只存储内存中的瞬时数据，不持久化历史数据。</p></li><li><p>高效：通过 Kubernetes API 聚合层提供指标，易于集成。</p></li><li><p>可扩展：支持与更复杂的监控系统（如 Prometheus）集成。</p></li></ul></li></ul></li><li><p>kube-state-metrics : 是一个服务，通过 Kubernetes API 收集集群中资源对象（如 Pod、Deployment、Service 等）的状态和元数据，并以 Prometheus 兼容的格式通过 HTTP 端点暴露这些指标。</p><ul><li><p>作用：</p><ul><li>提供 Kubernetes 资源对象的状态信息（如 Pod 运行状态、Deployment 副本数等）。</li><li>补充 cAdvisor 和 node_exporter 的功能，专注于 Kubernetes 对象的元数据而非系统或容器级资源使用。</li><li>支持 Prometheus 抓取数据，用于监控、告警和可视化。</li></ul></li><li><p>特点：</p><ul><li><p><strong>轻量级</strong>：以单一 Deployment 运行，资源占用低。</p></li><li><p><strong>专注于状态</strong>：提供资源对象的元数据和状态（如 Pod 是否 Running、Job 是否完成）。</p></li><li><p><strong>Prometheus 集成</strong>：通过 &#x2F;metrics 端点暴露数据，易于与 Prometheus 和 Grafana 集成。</p></li><li><p><strong>动态更新</strong>：实时监听 Kubernetes API 的资源变化。</p></li></ul></li></ul></li><li><p>node_exporter : 一个 Prometheus 导出器（exporter），专门用于收集主机（节点）的系统级指标，如 CPU、内存、磁盘、网络、文件系统等，并以 Prometheus 兼容的格式通过 HTTP 端点暴露这些指标。</p><ul><li><strong>作用</strong>：<ul><li>提供节点级别的详细系统监控数据，弥补 Kubernetes Metrics Server 和 cAdvisor 的局限性（后者主要聚焦于容器指标）。</li><li>支持 Prometheus 抓取指标，用于长期存储、分析和可视化。</li><li>广泛用于 Kubernetes 集群、裸机或虚拟机环境的监控。</li></ul></li><li><strong>特点</strong>：<ul><li><strong>轻量级</strong>：资源占用低，适合在每个节点运行。</li><li><strong>模块化</strong>：支持多种收集器（collector），可按需启用或禁用。</li><li><strong>跨平台</strong>：主要支持 Linux，也支持部分 Unix 系统（如 macOS、FreeBSD）。</li><li><strong>Prometheus 集成</strong>：通过标准化的 &#x2F;metrics 端点暴露数据，易于与 Prometheus 和 Grafana 集成。</li></ul></li></ul></li></ul><p>不过 kube-state-metrics 和 metrics-server 之间还是有很大不同的，二者的主要区别如下：</p><ul><li>kube-state-metrics 主要关注的是业务相关的一些元数据，比如 Deployment、Pod、副本状态等</li><li>metrics-server 主要关注的是<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/resource-metrics-api.md">资源度量 API</a> 的实现，比如 CPU、文件描述符、内存、请求延时等指标</li></ul><h1 id="二、部署-StorageClass"><a href="#二、部署-StorageClass" class="headerlink" title="二、部署 StorageClass"></a>二、部署 StorageClass</h1><h2 id="1-安装NFS"><a href="#1-安装NFS" class="headerlink" title="1. 安装NFS"></a>1. 安装NFS</h2><p>安装 NFS,配置存储卷自动分配 PV，用于持久化日志数据。</p><p>这里选用 k8s-master (10.20.1.139) 作为 nfs 服务端，其它节点作为 nfs 客户端</p><h3 id="1-1-安装-NFS-服务"><a href="#1-1-安装-NFS-服务" class="headerlink" title="1.1 安装 NFS 服务"></a>1.1 安装 NFS 服务</h3><blockquote><p>master节点、node01、node02、node03 节点都需要安装执行</p></blockquote><pre><code class="highlight bash">$ yum install -y nfs-utils rpcbind</code></pre><h3 id="1-2-创建共享目录"><a href="#1-2-创建共享目录" class="headerlink" title="1.2 创建共享目录"></a>1.2 创建共享目录</h3><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash"><span class="comment"># 创建 共享目录</span>$ <span class="built_in">mkdir</span> -p /root/data/prometheus/<span class="comment"># 目录提权</span><span class="built_in">chmod</span> 777 /root/data/prometheus/<span class="comment"># 变更用户组</span><span class="built_in">chown</span> nobody /root/data/prometheus/</code></pre><h3 id="1-3-编辑共享目录读写配置"><a href="#1-3-编辑共享目录读写配置" class="headerlink" title="1.3 编辑共享目录读写配置"></a>1.3 编辑共享目录读写配置</h3><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash">$ vim /etc/exports/root/data     10.20.1.0/24(rw,fsid=0,no_root_squash)/root/data/prometheus       10.20.1.0/24(rw,no_root_squash,no_all_squash,no_subtree_check,<span class="built_in">sync</span>)</code></pre><p>这里使用的是 NFS4 服务，上面的配置表示 10.20.1.0&#x2F;24 网段的 ip 都可以与 nfs 主服务器共享 <code>/root/data/prometheus</code> 目录内容</p><h3 id="1-4-启动NFS服务"><a href="#1-4-启动NFS服务" class="headerlink" title="1.4 启动NFS服务"></a>1.4 启动NFS服务</h3><blockquote><p>集群内所有节点都需要操作</p></blockquote><pre><code class="highlight bash"> <span class="comment"># 启动服务</span>$ systemctl start rpcbind$ systemctl restart nfs-server.service<span class="comment"># 设置开机自启</span>$ systemctl <span class="built_in">enable</span> rpcbind$ systemctl <span class="built_in">enable</span> nfs-server.service</code></pre><h3 id="1-5-测试-NFS-目录挂载"><a href="#1-5-测试-NFS-目录挂载" class="headerlink" title="1.5 测试 NFS 目录挂载"></a>1.5 测试 NFS 目录挂载</h3><pre><code class="highlight bash"><span class="comment"># NFS 客户端执行：创建目录</span>$ <span class="built_in">mkdir</span> /data/test1<span class="comment"># NFS 客户端执行：挂载目录到NFS服务端</span>$ mount -t nfs4 10.20.1.139:/prometheus /data/test1<span class="comment"># NFS 客户端执行：查看挂载结果</span>$ mount | grep /data/test110.20.1.139:/prometheus on /data/test1 <span class="built_in">type</span> nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.1.141,local_lock=none,addr=10.20.1.139)<span class="comment"># NFS 客户端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;this is client&quot;</span> &gt; /data/test1/a.txt<span class="comment"># NFS 服务端执行：查看数据， 结论：客户端数据已写入服务端挂载目录</span>$ <span class="built_in">cat</span> /root/data/prometheus/a.txt this is client<span class="comment"># NFS 服务端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;This is Server&quot;</span> &gt;&gt; /root/data/prometheus/a.txt<span class="comment"># NFS 客户端执行：查看数据， 结论：服务端数据已写入客户端挂载目录</span>$ <span class="built_in">cat</span> /data/test1/a.txtthis is clientThis is Server</code></pre><p><strong>取消挂载</strong></p><pre><code class="highlight bash"><span class="comment"># 取消挂载</span>umount /data/test1<span class="comment"># 如果取消挂载出现报错，例如：</span>$ umount /data/test1umount.nfs4: /data/test1: device is busy<span class="comment"># 查看目录占用进程</span>$ fuser -m /data/test1/data/test1:         32679c<span class="comment"># kill 进程</span>$ <span class="built_in">kill</span> -9 32679<span class="comment"># 方式二：强制卸载</span>umount -l /data/test1</code></pre><h2 id="2-创建-StorageClass"><a href="#2-创建-StorageClass" class="headerlink" title="2. 创建 StorageClass"></a>2. 创建 StorageClass</h2><p>资源清单：<code>prometheus-storage.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.存储类</span><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">StorageClass</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">prometheus-storage</span>  <span class="attr">name:</span> <span class="string">prometheus-storage</span><span class="comment"># provisioner: nfs-provisioner</span><span class="attr">provisioner:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定动态配置器，NFS 子目录外部配置器</span><span class="attr">parameters:</span>  <span class="attr">pathPattern:</span> <span class="string">$&#123;.PVC.namespace&#125;/$&#123;.PVC.name&#125;</span> <span class="comment"># 动态生成的 NFS 路径，格式为 &lt;PVC 命名空间&gt;/&lt;PVC 名称&gt;，例如 loki-storageclass/test-claim。</span>  <span class="attr">archiveOnDelete:</span> <span class="string">&quot;true&quot;</span> <span class="comment">##删除 pv,pv内容是否备份</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">prometheus-storage</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 指定使用的 ServiceAccountName</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span>          <span class="attr">image:</span> <span class="string">k8s.dockerproxy.com/sig-storage/nfs-subdir-external-provisioner:v4.0.2</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 挂载的卷名称，与 volumes 部分定义的卷对应</span>              <span class="attr">mountPath:</span> <span class="string">/persistentvolumes</span> <span class="comment"># 将 NFS 卷挂载到容器内的 /persistentvolumes 路径，供容器读写 NFS 共享数据。</span>          <span class="attr">env:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PROVISIONER_NAME</span>              <span class="attr">value:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定配置器名称，与 StorageClass 保持一致</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_SERVER</span>              <span class="attr">value:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_PATH</span>              <span class="attr">value:</span> <span class="string">/root/data/prometheus</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 定义一个名为 nfs-client-root 的 NFS 卷，连接到 NFS 服务器的指定地址和路径</span>          <span class="attr">nfs:</span>            <span class="attr">server:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="attr">path:</span> <span class="string">/root/data/prometheus</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">nodeSelector:</span> <span class="comment"># 指定Pod运行的节点</span>        <span class="attr">kubernetes.io/hostname:</span> <span class="string">k8s-node01</span>      <span class="comment"># nodeName: k8s-node01 # 指定 Pod 运行在 k8s-node01 节点上</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4.服务账户</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># SA 的名称</span>  <span class="attr">namespace:</span> <span class="string">prometheus-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 5.集群角色</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;nodes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumeclaims&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;storage.k8s.io&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;storageclasses&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;events&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># 6.集群角色绑定</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-nfs-client-provisioner</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定类型 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># ServiceAccount 的名称</span>    <span class="attr">namespace:</span> <span class="string">prometheus-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span> <span class="comment"># 绑定的角色类型</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span> <span class="comment"># 集群角色名称 nfs-client-provisioner-runner</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 角色</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称，表明它与 NFS 客户端存储提供者的领导者选举（leader election）机制相关。</span>  <span class="attr">namespace:</span> <span class="string">prometheus-storage</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 空字符串表示核心 API 组（core API group），包含 Kubernetes 的基本资源，如 endpoints。</span>    <span class="attr">resources:</span> [<span class="string">&quot;endpoints&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># SA角色绑定</span><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-leader-locking-nfs-client-provisioner</span>  <span class="attr">namespace:</span> <span class="string">prometheus-storage</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定资源类型为 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 绑定的ServiceAccount 名称</span>    <span class="attr">namespace:</span> <span class="string">prometheus-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">Role</span> <span class="comment"># 绑定角色（loki-storage名称空间的角色）</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 创建 StorageClass</span>$ kubectl apply -f prometheus-storage.yaml<span class="comment"># 查看 StorageClass</span>$ kubectl get StorageClassNAME                 PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGEloki-storage         k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  5d21hnfs-client           k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  6d5hprometheus-storage   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  11m<span class="comment"># 查看 Pod</span>$ kubectl get pods -n prometheus-storage -o wideNAME                                      READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESnfs-client-provisioner-6cb79b9755-7q2t4   1/1     Running   0          11m   192.168.85.207   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h1 id="三、部署-Prometheus"><a href="#三、部署-Prometheus" class="headerlink" title="三、部署 Prometheus"></a>三、部署 Prometheus</h1><h2 id="1-创建命名空间"><a href="#1-创建命名空间" class="headerlink" title="1. 创建命名空间"></a>1. 创建命名空间</h2><p>资源清单：<code>kube-ops.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">kube-ops</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f kube-ops.yaml<span class="comment"># 查看命名空间</span>$ kubectl get namespace | grep kube-opskube-ops             Active   50s</code></pre><h2 id="2-创建Prometheus-ConfigMap"><a href="#2-创建Prometheus-ConfigMap" class="headerlink" title="2. 创建Prometheus ConfigMap"></a>2. 创建Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]</code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 查看 ConfigMap</span>$ kubectl get cm -n kube-opsNAME                DATA   AGEkube-root-ca.crt    1      32mprometheus-config   1      38s</code></pre><h2 id="3-部署-Prometheus"><a href="#3-部署-Prometheus" class="headerlink" title="3. 部署 Prometheus"></a>3. 部署 Prometheus</h2><p>资源清单：<code>prometheus.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 定义 PVC</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">storageClassName:</span> <span class="string">prometheus-storage</span>  <span class="comment"># 指定使用的 StorageClass</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteMany</span>                     <span class="comment"># 存储卷可以被多个节点（Node）以读写模式同时挂载</span>  <span class="attr">resources:</span>    <span class="attr">requests:</span>      <span class="attr">storage:</span> <span class="string">10Gi</span>                     <span class="comment"># 定义 PVC 请求的资源量，这里特指存储容量</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 创建 SA</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 集群角色</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span>      <span class="bullet">-</span> <span class="string">&quot;&quot;</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="string">nodes</span>      <span class="bullet">-</span> <span class="string">services</span>      <span class="bullet">-</span> <span class="string">endpoints</span>      <span class="bullet">-</span> <span class="string">pods</span>      <span class="bullet">-</span> <span class="string">nodes/proxy</span>    <span class="attr">verbs:</span>      <span class="bullet">-</span> <span class="string">get</span>      <span class="bullet">-</span> <span class="string">list</span>      <span class="bullet">-</span> <span class="string">watch</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span>      <span class="bullet">-</span> <span class="string">&quot;&quot;</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="string">configmaps</span>      <span class="bullet">-</span> <span class="string">nodes/metrics</span>    <span class="attr">verbs:</span>      <span class="bullet">-</span> <span class="string">get</span>  <span class="bullet">-</span> <span class="attr">nonResourceURLs:</span>      <span class="bullet">-</span> <span class="string">/metrics</span>    <span class="attr">verbs:</span>      <span class="bullet">-</span> <span class="string">get</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 集群角色绑定</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span><span class="attr">roleRef:</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">name:</span> <span class="string">prometheus</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>    <span class="attr">name:</span> <span class="string">prometheus</span>    <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="meta">---</span><span class="meta"></span><span class="comment"># Deployment</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">prometheus</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>               <span class="comment"># Pod 副本数为1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">prometheus</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">prometheus</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">prometheus</span>    <span class="comment"># 指定 Pod 使用的 Kubernetes 服务账号（ServiceAccount）为 prometheus</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">prometheus</span>          <span class="attr">image:</span> <span class="string">prom/prometheus:v2.4.3</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&quot;/bin/prometheus&quot;</span>         <span class="comment"># 指定容器启动时运行的命令为 /bin/prometheus，这是 Prometheus 的主可执行文件</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">&quot;--config.file=/etc/prometheus/prometheus.yml&quot;</span>    <span class="comment"># 指定 Prometheus 的配置文件路径为 /etc/prometheus/prometheus.yml，这个文件由 ConfigMap（prometheus-config）提供，挂载到容器内</span>            <span class="bullet">-</span> <span class="string">&quot;--storage.tsdb.path=/prometheus&quot;</span>                 <span class="comment"># 指定 Prometheus 时间序列数据库（TSDB）的存储路径为 /prometheus，这个路径由 PVC（prometheus）提供，持久化存储数据</span>            <span class="bullet">-</span> <span class="string">&quot;--storage.tsdb.retention=24h&quot;</span>                    <span class="comment"># 设置数据保留时间为 24 小时，意味着 Prometheus 只保留最近 24 小时的监控数据，旧数据将被删除。生产环境建议 15-30天</span>            <span class="bullet">-</span> <span class="string">&quot;--web.enable-admin-api&quot;</span>                          <span class="comment"># 启用 Prometheus 的 Admin HTTP API，允许执行管理操作（如删除时间序列）</span>            <span class="bullet">-</span> <span class="string">&quot;--web.enable-lifecycle&quot;</span>                          <span class="comment"># 启用生命周期 API，支持通过 HTTP 请求（如 localhost:9090/-/reload）动态重新加载配置文件。</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9090</span>       <span class="comment"># 指定 Prometheus 监听端口，用于提供 Web UI 和 API</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>              <span class="attr">name:</span> <span class="string">http</span>          <span class="attr">volumeMounts:</span>                 <span class="comment"># 定义容器内的挂载点，将卷挂载到指定路径</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/prometheus&quot;</span>  <span class="comment"># 将名为 data 的卷挂载到容器内的 /prometheus 路径，用于存储 TSDB 数据</span>              <span class="attr">subPath:</span> <span class="string">prometheus</span>       <span class="comment"># 表示使用卷中的子路径 prometheus，避免覆盖整个卷的其他内容</span>              <span class="attr">name:</span> <span class="string">data</span>                <span class="comment"># 卷由 PVC（prometheus）提供</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/etc/prometheus&quot;</span>      <span class="comment"># 将名为 config-volume 的卷挂载到容器内的 /etc/prometheus 路径，用于存储配置文件</span>              <span class="attr">name:</span> <span class="string">config-volume</span>               <span class="comment"># 由 ConfigMap（prometheus-config）提供</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="string">100m</span>                 <span class="comment"># 请求 100 毫核（0.1 CPU 核心），表示容器需要的最小 CPU 资源</span>              <span class="attr">memory:</span> <span class="string">512Mi</span>             <span class="comment"># 请求 512 MiB 内存，表示容器需要的最小内存</span>            <span class="attr">limits:</span>              <span class="attr">cpu:</span> <span class="string">100m</span>                 <span class="comment"># 限制容器最多使用 100 毫核 CPU，防止过量占用</span>              <span class="attr">memory:</span> <span class="string">512Mi</span>             <span class="comment"># 限制容器最多使用 512 MiB 内存，防止内存溢出</span>      <span class="attr">securityContext:</span>                  <span class="comment"># 定义 Pod 的安全上下文，控制容器运行时的权限</span>        <span class="attr">runAsUser:</span> <span class="number">0</span>                    <span class="comment"># 指定容器以用户 ID 0（即 root 用户）运行</span>      <span class="attr">volumes:</span>                          <span class="comment"># 定义 Pod 使用的卷，供容器挂载</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span>          <span class="attr">persistentVolumeClaim:</span>        <span class="comment"># 指定挂载的PVC</span>            <span class="attr">claimName:</span> <span class="string">prometheus</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span>          <span class="attr">configMap:</span>                    <span class="comment"># 指定挂载的 configMap</span>            <span class="attr">name:</span> <span class="string">prometheus-config</span><span class="meta">---</span><span class="meta"></span><span class="comment"># Service</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">prometheus</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">prometheus</span>  <span class="attr">type:</span> <span class="string">NodePort</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web-prometheus</span>  <span class="comment"># 端口名称</span>      <span class="attr">port:</span> <span class="number">9090</span>            <span class="comment"># service 对外端口 9090</span>      <span class="attr">targetPort:</span> <span class="string">http</span>      <span class="comment"># 内部名为 http 的端口 （9090）</span><span class="meta">---</span><span class="meta"></span><span class="comment"># Ingress， 安装参考：https://georgechan95.github.io/blog/6436eaf1.html</span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-ui</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span>           <span class="comment"># 指定 Ingress 控制器为 nginx，由 Nginx Ingress Controller 处理</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">my.prometheus.com</span>       <span class="comment"># 定义一个基于域名 my.prometheus.com 的路由规则</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">prometheus</span>    <span class="comment"># 流量转发到 kube-ops 命名空间中的 prometheus 服务</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">9090</span>            <span class="attr">path:</span> <span class="string">/</span>                 <span class="comment"># 匹配根路径 / 及所有以 / 开头的子路径（如 /graph, /api/v1）</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f prometheus.yaml<span class="comment"># 查看PVC</span>$ kubectl get pvc -n kube-opsNAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS         VOLUMEATTRIBUTESCLASS   AGEprometheus   Bound    pvc-b85318bf-0ef5-449f-ab40-200238200e10   10Gi       RWX            prometheus-storage   &lt;<span class="built_in">unset</span>&gt;                 3h15m<span class="comment"># 查看 ServiceAccount</span>$ kubectl get serviceaccount -n kube-opsNAME         SECRETS   AGEdefault      0         4h4mprometheus   0         3h11m<span class="comment"># 查看 Deployment</span>$ kubectl get deploy -n kube-opsNAME         READY   UP-TO-DATE   AVAILABLE   AGEprometheus   1/1     1            1           125m<span class="comment"># 查看 Pods</span>$ kubectl get pods -n kube-opsNAME                          READY   STATUS    RESTARTS   AGEprometheus-844847f5c7-7gwck   1/1     Running   0          125m<span class="comment"># 查看 Service</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   18m<span class="comment"># 查看 Ingress</span>$ kubectl get ingress -n kube-opsNAME            CLASS   HOSTS               ADDRESS   PORTS   AGEprometheus-ui   nginx   my.prometheus.com             80      9m56s</code></pre><p><strong>添加Host域名映射</strong></p><pre><code class="highlight plaintext">10.20.1.140 my.prometheus.com</code></pre><p><strong>浏览器访问 Prometheus</strong></p><p><a href="http://my.prometheus.com/">http://my.prometheus.com/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/22/20250722-193045.png" alt="Prometheus"></p><h1 id="四、配置-Prometheus-抓取-Ingress-Nginx-指标"><a href="#四、配置-Prometheus-抓取-Ingress-Nginx-指标" class="headerlink" title="四、配置 Prometheus 抓取 Ingress-Nginx 指标"></a>四、配置 Prometheus 抓取 Ingress-Nginx 指标</h1><h2 id="1、开启-Ingress-nginx-监听端口"><a href="#1、开启-Ingress-nginx-监听端口" class="headerlink" title="1、开启 Ingress-nginx 监听端口"></a>1、开启 Ingress-nginx 监听端口</h2><p>这里的 ingress-nginx 使用的是 helm 安装的，安装过程见：<a href="https://georgechan95.github.io/blog/6436eaf1.html">https://georgechan95.github.io/blog/6436eaf1.html</a></p><p>开启 Ingress-nginx 指标监听端口，默认：10254</p><p><strong>编辑 <code>value.yaml</code></strong></p><pre><code class="highlight yaml"><span class="attr">metrics:</span>  <span class="attr">port:</span> <span class="number">10254</span>  <span class="attr">portName:</span> <span class="string">metrics</span>  <span class="comment"># if this port is changed, change healthz-port: in extraArgs: accordingly</span>  <span class="attr">enabled:</span> <span class="literal">true</span></code></pre><p><strong>更新 Ingress-Nginx</strong></p><pre><code class="highlight bash">$ helm upgrade ingress-nginx -n ingress-nginx -f values.yaml .</code></pre><h2 id="2-修改-Prometheus-ConfigMap"><a href="#2-修改-Prometheus-ConfigMap" class="headerlink" title="2. 修改 Prometheus ConfigMap"></a>2. 修改 Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]</code></pre><p>重新执行资源清单</p><p>方式一：</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f prometheus-cm.yaml$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   111m<span class="comment"># 请求uri，重新加载</span>curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p>方式二：</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 查看 prometheus pod</span>$ kubectl get pods -n kube-opsNAME                          READY   STATUS    RESTARTS   AGEprometheus-844847f5c7-7gwck   1/1     Running   0          3h29m<span class="comment"># 杀死重启Pod，重新加载 ConfigMap</span>$ kubectl delete pod prometheus-844847f5c7-7gwck -n kube-opspod <span class="string">&quot;prometheus-844847f5c7-7gwck&quot;</span> deleted</code></pre><p>再次从浏览器查看 Prometheus </p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/22/20250722-205857.png" alt="抓取 Ingress-Nginx 指标"></p><h1 id="五、创建-node-exporter，监控节点资源"><a href="#五、创建-node-exporter，监控节点资源" class="headerlink" title="五、创建 node_exporter，监控节点资源"></a>五、创建 node_exporter，监控节点资源</h1><p>node_exporter 就是抓取用于采集服务器节点的各种运行指标，目前 node_exporter 支持几乎所有常见的监控点，比如 conntrack，cpu，diskstats，filesystem，loadavg，meminfo，netstat 等，详细的监控点列表可以参考其 <a href="https://github.com/prometheus/node_exporter">Node_Exporter</a></p><p><strong>说明：</strong></p><p>在 Kubernetes 下，Promethues 通过与 Kubernetes API 集成，目前主要支持5中服务发现模式，分别是：Node、Service、Pod、Endpoints、Ingress</p><p>通过指定 <code>kubernetes_sd_configs</code> 的模式为 <code>node</code>，Prometheus 就会自动从 Kubernetes 中发现所有的 node 节点并作为当前 job 监控的目标实例，发现的节点 <code>/metrics</code> 接口是默认的 kubelet 的 HTTP 接口</p><p>prometheus 去发现 Node 模式的服务的时候，访问的端口默认是<strong>10250</strong>，而现在该端口下面已经没有了<code>/metrics</code>指标数据了，现在 kubelet 只读的数据接口统一通过 <strong>10255</strong> 端口进行暴露了，所以我们应该去替换掉这里的端口，但是我们是要替换成 <strong>10255</strong> 端口吗？不是的，因为我们是要去配置上面通过<code>node-exporter</code>抓取到的节点指标数据，而我们上面是不是指定了 <code>hostNetwork=true</code> ，所以在每个节点上就会绑定一个端口 <strong>9100</strong>，所以我们应该将这里的 <strong>10250</strong> 替换成 <strong>9100</strong></p><p>这里我们就需要使用到 Prometheus 提供的<code>relabel_configs</code>中的<code>replace</code>能力了，relabel 可以在 Prometheus 采集数据之前，通过Target 实例的 Metadata 信息，动态重新写入 Label 的值。除此之外，我们还能根据 Target 实例的 Metadata 信息选择是否采集或者忽略该 Target 实例</p><p>添加了一个 action 为<code>labelmap</code>，正则表达式是<code>__meta_kubernetes_node_label_(.+)</code>的配置，这里的意思就是表达式中匹配都的数据也添加到指标数据的 Label 标签中去。</p><p>对于 kubernetes_sd_configs 下面可用的标签如下： 可用元标签：</p><ul><li>__meta_kubernetes_node_name：节点对象的名称</li><li><em>_meta_kubernetes_node_label</em>：节点对象中的每个标签</li><li><em>_meta_kubernetes_node_annotation</em>：来自节点对象的每个注释</li><li><em>_meta_kubernetes_node_address</em>：每个节点地址类型的第一个地址（如果存在） *</li></ul><blockquote><p>关于 kubernets_sd_configs 更多信息可以查看官方文档：<a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#">kubernetes_sd_config</a></p></blockquote><p>Kubernetes 1.11+ 版本以后，kubelet 就移除了 10255 端口， metrics 接口又回到了 10250 端口，所以这里不需要替换端口，但是需要使用 https 的协议</p><h2 id="1-部署-node-exporter"><a href="#1-部署-node-exporter" class="headerlink" title="1. 部署 node-exporter"></a>1. 部署 node-exporter</h2><p>资源清单：<code>prometheus-node-exporter.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">DaemonSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">node-exporter</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">name:</span> <span class="string">node-exporter</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">name:</span> <span class="string">node-exporter</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">name:</span> <span class="string">node-exporter</span>    <span class="attr">spec:</span>      <span class="attr">hostPID:</span> <span class="literal">true</span>                         <span class="comment"># 允许 Pod 使用主机节点的 PID 命名空间, Node Exporter 需要访问主机的 /proc 文件系统以收集进程相关指标（如 CPU、内存使用情况），因此需要 hostPID: true</span>      <span class="attr">hostIPC:</span> <span class="literal">true</span>                         <span class="comment"># 允许 Pod 使用主机节点的 IPC（进程间通信）命名空间，这通常用于访问主机的共享内存或其他 IPC 机制，但在 Node Exporter 中可能不是必需，建议评估是否需要以降低安全风险。</span>      <span class="attr">hostNetwork:</span> <span class="literal">true</span>                     <span class="comment"># Pod 使用主机节点的网络命名空间，直接绑定到主机的网络接口和端口，Node Exporter 的端口（9100）将直接绑定到主机网络，便于 Prometheus 抓取节点的指标（如通过节点 IP:9100）</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">node-exporter</span>          <span class="attr">image:</span> <span class="string">prom/node-exporter:v0.16.0</span>   <span class="comment"># Node Exporter 收集主机系统的指标（如 CPU、内存、磁盘、文件系统等）并通过 HTTP 端点（默认 /metrics）暴露</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9100</span>             <span class="comment"># Node Exporter 监听 9100 端口，暴露 Prometheus 格式的指标端点（默认 /metrics）</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="number">0.15</span>                       <span class="comment"># 请求 0.15 CPU 核心（150 毫核），表示 Node Exporter 的最小 CPU 需求</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">true</span>                  <span class="comment"># 容器以特权模式运行，拥有对主机的广泛访问权限</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">--path.procfs</span>                   <span class="comment"># 指定进程文件系统路径为 /host/proc，映射到主机的 /proc，用于收集进程、CPU、内存等指标</span>            <span class="bullet">-</span> <span class="string">/host/proc</span>            <span class="bullet">-</span> <span class="string">--path.sysfs</span>                    <span class="comment"># 指定系统文件系统路径为 /host/sys，映射到主机的 /sys，用于收集硬件相关指标（如设备信息）</span>            <span class="bullet">-</span> <span class="string">/host/sys</span>            <span class="bullet">-</span> <span class="string">--collector.filesystem.ignored-mount-points</span>   <span class="comment"># 配置文件系统收集器，忽略以 /sys, /proc, /dev, /host, /etc 开头的挂载点，防止收集容器内部或无关的文件系统指标，专注于主机文件系统</span>            <span class="bullet">-</span> <span class="string">&#x27;&quot;^/(sys|proc|dev|host|etc)($|/)&quot;&#x27;</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dev</span>              <span class="attr">mountPath:</span> <span class="string">/host/dev</span>      <span class="comment"># 挂载主机的 /dev 到容器内的 /host/dev</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">proc</span>              <span class="attr">mountPath:</span> <span class="string">/host/proc</span>     <span class="comment"># 挂载主机的 /proc 到 /host/proc</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sys</span>              <span class="attr">mountPath:</span> <span class="string">/host/sys</span>      <span class="comment"># 挂载主机的 /sys 到 /host/sys</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">rootfs</span>              <span class="attr">mountPath:</span> <span class="string">/rootfs</span>        <span class="comment"># 挂载主机的根文件系统（/）到 /rootfs</span>      <span class="attr">tolerations:</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;node-role.kubernetes.io/control-plane&quot;</span>    <span class="comment"># 允许 Pod 调度到带有 node-role.kubernetes.io/control-plane 污点的节点</span>          <span class="attr">operator:</span> <span class="string">Exists</span>          <span class="attr">effect:</span> <span class="string">NoSchedule</span>      <span class="attr">volumes:</span>                          <span class="comment"># 定义 Pod 使用的卷，映射主机文件系统到容器</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">proc</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/proc</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dev</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/dev</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sys</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/sys</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">rootfs</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 node-exporter</span>$ kubectl apply -f prometheus-node-exporter.yaml<span class="comment"># 查看 Pod</span>$ kubectl get pods -n kube-opsNAME                          READY   STATUS    RESTARTS   AGEnode-exporter-d85s5           1/1     Running   0          165mnode-exporter-gmwln           1/1     Running   0          165mnode-exporter-kjdm9           1/1     Running   0          165mnode-exporter-vg29l           1/1     Running   0          165mprometheus-844847f5c7-2zvbn   1/1     Running   0          17h</code></pre><h2 id="2-修改-Prometheus-ConfigMap-1"><a href="#2-修改-Prometheus-ConfigMap-1" class="headerlink" title="2. 修改 Prometheus ConfigMap"></a>2. 修改 Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span></code></pre><p><strong>重新执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行更新 ConfigMap 资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 等待一会，待ConfigMap更新后，执行请求，让 Prometheus 配置热更新</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   18h$ curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p>再次从浏览器查看 Prometheus 控制台，发现 node_exporter 和 kubelet 已被监听</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-141026.png" alt="node_exporter 和 kubelet"></p><h1 id="六、使用-cAdvisor-监控容器资源指标"><a href="#六、使用-cAdvisor-监控容器资源指标" class="headerlink" title="六、使用 cAdvisor 监控容器资源指标"></a>六、使用 cAdvisor 监控容器资源指标</h1><p>说到容器监控我们自然会想到 <code>cAdvisor</code>，我们前面也说过<code>cAdvisor</code>已经内置在了 kubelet 组件之中，所以我们不需要单独去安装，<code>cAdvisor</code> 的数据路径为<code>/api/v1/nodes/&lt;node&gt;/proxy/metrics</code>，同样我们这里使用 node 的服务发现模式，因为每一个节点下面都有 kubelet</p><h2 id="1-修改-Prometheus-ConfigMap"><a href="#1-修改-Prometheus-ConfigMap" class="headerlink" title="1. 修改 Prometheus ConfigMap"></a>1. 修改 Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-cadvisor&#x27;</span>                                         <span class="comment"># 抓取任务名称为 kubernetes-cadvisor，用于监控 Kubernetes 节点的 cAdvisor 指标</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                           <span class="comment"># 指定使用 HTTPS 协议访问目标（Kubernetes API 服务器的 443 端口）</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Pod 内部的服务账号卷挂载的 CA 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌</span>      <span class="attr">relabel_configs:</span>                                              <span class="comment"># 定义标签重写规则，修改服务发现的目标地址和路径</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                                          <span class="comment"># 规则1：将节点的标签（如 kubernetes.io/hostname）映射到 Prometheus 指标标签 </span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span>                   <span class="comment"># 规则2：将抓取目标地址设置为 kubernetes.default.svc:443，即 Kubernetes API 服务器的 ClusterIP 服务（默认命名空间 default，端口 443）</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]              <span class="comment"># 规则3：使用节点名称（__meta_kubernetes_node_name，如 node01）动态构造指标路径</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span></code></pre><p><strong>重新执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行更新 ConfigMap 资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 等待一会，待ConfigMap更新后，执行请求，让 Prometheus 配置热更新</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   18h$ curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p>再次从浏览器查看 Prometheus 控制台，发现 cAdvisor 已被监听</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-150843.png" alt="Prometheus 监听 cAdvisor"></p><h1 id="七、Prometheus-监控-kube-apiserver"><a href="#七、Prometheus-监控-kube-apiserver" class="headerlink" title="七、Prometheus 监控 kube-apiserver"></a>七、Prometheus 监控 kube-apiserver</h1><p><code>kube-apiserver</code> 监听在节点的 6443 端口，通过以下配置可以使 Prometheus 读取 <code>kube-apiserver</code> 的指标数据</p><h2 id="1-修改-Prometheus-ConfigMap-1"><a href="#1-修改-Prometheus-ConfigMap-1" class="headerlink" title="1. 修改 Prometheus ConfigMap"></a>1. 修改 Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-cadvisor&#x27;</span>                                         <span class="comment"># 抓取任务名称为 kubernetes-cadvisor，用于监控 Kubernetes 节点的 cAdvisor 指标</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                           <span class="comment"># 指定使用 HTTPS 协议访问目标（Kubernetes API 服务器的 443 端口）</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Pod 内部的服务账号卷挂载的 CA 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌</span>      <span class="attr">relabel_configs:</span>                                              <span class="comment"># 定义标签重写规则，修改服务发现的目标地址和路径</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                                          <span class="comment"># 规则1：将节点的标签（如 kubernetes.io/hostname）映射到 Prometheus 指标标签 </span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span>                   <span class="comment"># 规则2：将抓取目标地址设置为 kubernetes.default.svc:443，即 Kubernetes API 服务器的 ClusterIP 服务（默认命名空间 default，端口 443）</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]              <span class="comment"># 规则3：使用节点名称（__meta_kubernetes_node_name，如 node01）动态构造指标路径</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-apiservers&#x27;</span>                             <span class="comment"># 抓取任务名称为 kubernetes-apiservers，用于监控 Kubernetes API 服务器的指标，包括请求速率、延迟、错误率等（如 apiserver_request_total, apiserver_request_duration_seconds）</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                                           <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中的所有 Endpoints 对象</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                 <span class="comment"># Kubernetes API 服务器默认通过 HTTPS（端口 443）暴露 /metrics 端点</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Prometheus Pod 内部的服务账号卷挂载的 CA 证书（位于 /var/run/secrets/kubernetes.io/serviceaccount/ca.crt）验证 API 服务器的 TLS 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌（位于 /var/run/secrets/kubernetes.io/serviceaccount/token）进行身份验证</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>, <span class="string">__meta_kubernetes_service_name</span>, <span class="string">__meta_kubernetes_endpoint_port_name</span>]    <span class="comment"># 断点所在的名称空间，断点所在的 Service， 断点端口名称</span>          <span class="attr">action:</span> <span class="string">keep</span>                      <span class="comment"># 仅保留匹配正则表达式的端点，未匹配的端点被丢弃。</span>          <span class="attr">regex:</span> <span class="string">default;kubernetes;https</span>   <span class="comment"># 确保 Prometheus 只抓取 default 命名空间中 kubernetes 服务的 HTTPS 端点（即 API 服务器的 /metrics）</span></code></pre><p><strong>重新执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行更新 ConfigMap 资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 等待一会，待ConfigMap更新后，执行请求，让 Prometheus 配置热更新</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   18h$ curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p>再次从浏览器查看 Prometheus 控制台，发现 apiServer 已被监听</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-155007.png" alt="Prometheus 监听 apiServer"></p><h1 id="八、Prometheus-通过-Service-监控服务"><a href="#八、Prometheus-通过-Service-监控服务" class="headerlink" title="八、Prometheus 通过 Service 监控服务"></a>八、Prometheus 通过 Service 监控服务</h1><h2 id="1-修改-Prometheus-ConfigMap-2"><a href="#1-修改-Prometheus-ConfigMap-2" class="headerlink" title="1. 修改 Prometheus ConfigMap"></a>1. 修改 Prometheus ConfigMap</h2><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-cadvisor&#x27;</span>                                         <span class="comment"># 抓取任务名称为 kubernetes-cadvisor，用于监控 Kubernetes 节点的 cAdvisor 指标</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                           <span class="comment"># 指定使用 HTTPS 协议访问目标（Kubernetes API 服务器的 443 端口）</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Pod 内部的服务账号卷挂载的 CA 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌</span>      <span class="attr">relabel_configs:</span>                                              <span class="comment"># 定义标签重写规则，修改服务发现的目标地址和路径</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                                          <span class="comment"># 规则1：将节点的标签（如 kubernetes.io/hostname）映射到 Prometheus 指标标签 </span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span>                   <span class="comment"># 规则2：将抓取目标地址设置为 kubernetes.default.svc:443，即 Kubernetes API 服务器的 ClusterIP 服务（默认命名空间 default，端口 443）</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]              <span class="comment"># 规则3：使用节点名称（__meta_kubernetes_node_name，如 node01）动态构造指标路径</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-apiservers&#x27;</span>                             <span class="comment"># 抓取任务名称为 kubernetes-apiservers，用于监控 Kubernetes API 服务器的指标，包括请求速率、延迟、错误率等（如 apiserver_request_total, apiserver_request_duration_seconds）</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                                           <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中的所有 Endpoints 对象</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                 <span class="comment"># Kubernetes API 服务器默认通过 HTTPS（端口 443）暴露 /metrics 端点</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Prometheus Pod 内部的服务账号卷挂载的 CA 证书（位于 /var/run/secrets/kubernetes.io/serviceaccount/ca.crt）验证 API 服务器的 TLS 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌（位于 /var/run/secrets/kubernetes.io/serviceaccount/token）进行身份验证</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>, <span class="string">__meta_kubernetes_service_name</span>, <span class="string">__meta_kubernetes_endpoint_port_name</span>]    <span class="comment"># 断点所在的名称空间，断点所在的 Service， 断点端口名称</span>          <span class="attr">action:</span> <span class="string">keep</span>                      <span class="comment"># 仅保留匹配正则表达式的端点，未匹配的端点被丢弃。</span>          <span class="attr">regex:</span> <span class="string">default;kubernetes;https</span>   <span class="comment"># 确保 Prometheus 只抓取 default 命名空间中 kubernetes 服务的 HTTPS 端点（即 API 服务器的 /metrics）</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-service-endpoints&#x27;</span>        <span class="comment"># 抓取任务名称为 kubernetes-service-endpoints，用于监控 Kubernetes Service 的 Endpoints 指标。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                             <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中所有 Service 的 Endpoints 对象</span>      <span class="attr">relabel_configs:</span>                                <span class="comment"># 定义标签重写规则，过滤和配置服务发现的目标，确保只抓取符合条件的 Service Endpoints</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scrape</span>]          <span class="attr">action:</span> <span class="string">keep</span>                                <span class="comment"># 仅保留注解 prometheus.io/scrape: &quot;true&quot; 的 Service Endpoints，未匹配的被丢弃</span>          <span class="attr">regex:</span> <span class="literal">true</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scheme</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将匹配的值替换到 __scheme__ 标签，决定抓取协议（http 或 https），允许 Service 指定是否通过 HTTPS 抓取指标，适用于需要安全连接的场景</span>          <span class="attr">target_label:</span> <span class="string">__scheme__</span>          <span class="attr">regex:</span> <span class="string">(https?)</span>                             <span class="comment"># 匹配 http 或 https，若注解未设置，默认使用 http</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_path</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 检查 Service 的注解 prometheus.io/path，将匹配的值替换到 __metrics_path__ 标签，指定指标端点的路径</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>, <span class="string">__meta_kubernetes_service_annotation_prometheus_io_port</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将地址和端口组合替换到 __address__ 标签，允许 Service 指定抓取端口（如 prometheus.io/port: &quot;8080&quot;），覆盖 Endpoints 的默认端口</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">regex:</span> <span class="string">([^:]+)(?::\d+)?;(\d+)</span>          <span class="attr">replacement:</span> <span class="string">$1:$2</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                            <span class="comment"># 将 Service 的标签（如 app=my-app）映射到 Prometheus 指标标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_service_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>]      <span class="comment"># 将 Service 的命名空间（__meta_kubernetes_namespace）写入指标标签 kubernetes_namespace</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_namespace</span>                  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_name</span>]   <span class="comment"># 将 Service 名称（__meta_kubernetes_service_name）写入指标标签 kubernetes_name</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_name</span></code></pre><p><strong>重新执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行更新 ConfigMap 资源清单</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment"># 等待一会，待ConfigMap更新后，执行请求，让 Prometheus 配置热更新</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP   18h$ curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p>再次从浏览器查看 Prometheus 控制台，发现 Service 已被监听</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-163620.png" alt="Prometheus 监听 Service"></p><h1 id="九、部署-kube-state-metrics，并使用-Prometheus-监控"><a href="#九、部署-kube-state-metrics，并使用-Prometheus-监控" class="headerlink" title="九、部署 kube-state-metrics，并使用 Prometheus 监控"></a>九、部署 kube-state-metrics，并使用 Prometheus 监控</h1><h2 id="1-部署-kube-state-metrics"><a href="#1-部署-kube-state-metrics" class="headerlink" title="1. 部署 kube-state-metrics"></a>1. 部署 kube-state-metrics</h2><pre><code class="highlight bash"><span class="comment"># 克隆 kube-state-metrics 仓库代码</span>git <span class="built_in">clone</span> https://github.com/kubernetes/kube-state-metrics.git<span class="comment"># 克隆后，进入资源清单目录</span><span class="built_in">cd</span> kube-state-metrics/examples/standard<span class="comment"># 修改 service.yaml</span>$ vim service.yaml<span class="comment"># 添加 annotations 信息，用于被prometheus发现</span>metadata:  annotations:    prometheus.io/scrape: <span class="string">&#x27;true&#x27;</span>    prometheus.io/port: <span class="string">&quot;8080&quot;</span><span class="comment"># 执行所有资源清单，注意：这里是 -k 不是 -f</span>$ kubectl apply -k .</code></pre><p><strong>查看部署资源</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 Service</span>$ kubectl get pods -n kube-system | grep kube-state-metricskube-state-metrics-54c8f8787f-6jnp5        1/1     Running   0              107s<span class="comment"># 查看 Pod</span>$ kubectl get svc -n kube-system | grep kube-state-metricskube-state-metrics   ClusterIP   None            &lt;none&gt;        8080/TCP,8081/TCP        119s</code></pre><p>部署完成后，等待一会，等待 Prometheus 抓取 kube-state-metrics 指标信息。</p><p>在浏览器查看 Prometheus ，kube-state-metrics 信息已经被成功抓取。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-195227.png" alt="Prometheus 监听 kube-state-metrics"></p><h1 id="十、部署-Grafana"><a href="#十、部署-Grafana" class="headerlink" title="十、部署 Grafana"></a>十、部署 Grafana</h1><p>用于展示 Prometheus 抓取保存的指标数据</p><p>资源清单：<code>prometheus-grafana.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.声明 PVC ，使用 StorageClass 动态创建PV</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-pvc</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">resources:</span>    <span class="attr">requests:</span>      <span class="attr">storage:</span> <span class="string">5Gi</span>  <span class="attr">storageClassName:</span> <span class="string">prometheus-storage</span> <span class="comment"># 使用 StorageClass 动态创建PV</span>  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.创建Deployment</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">name:</span> <span class="string">grafana</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">grafana</span>    <span class="attr">spec:</span>      <span class="attr">securityContext:</span>        <span class="attr">fsGroup:</span> <span class="number">472</span>        <span class="attr">supplementalGroups:</span>          <span class="bullet">-</span> <span class="number">0</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grafana</span>          <span class="attr">image:</span> <span class="string">grafana/grafana:8.3.5</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">env:</span>                                    <span class="comment"># 设置grafana初始华用户名和密码</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GF_SECURITY_ADMIN_USER</span>              <span class="attr">value:</span> <span class="string">admin</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GF_SECURITY_ADMIN_PASSWORD</span>              <span class="attr">value:</span> <span class="string">admin</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3000</span>              <span class="attr">name:</span> <span class="string">http-grafana</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">readinessProbe:</span>                         <span class="comment"># 就绪探测</span>            <span class="attr">failureThreshold:</span> <span class="number">10</span>            <span class="attr">httpGet:</span>              <span class="attr">path:</span> <span class="string">/api/health</span>              <span class="attr">port:</span> <span class="number">3000</span>              <span class="attr">scheme:</span> <span class="string">HTTP</span>            <span class="attr">initialDelaySeconds:</span> <span class="number">60</span>               <span class="comment"># 延迟 60秒探测，等待job执行完成</span>            <span class="attr">periodSeconds:</span> <span class="number">10</span>            <span class="attr">successThreshold:</span> <span class="number">1</span>            <span class="attr">timeoutSeconds:</span> <span class="number">30</span>          <span class="attr">livenessProbe:</span>                          <span class="comment"># 存活探测</span>            <span class="attr">failureThreshold:</span> <span class="number">3</span>            <span class="attr">httpGet:</span>              <span class="attr">path:</span> <span class="string">/api/health</span>              <span class="attr">port:</span> <span class="number">3000</span>              <span class="attr">scheme:</span> <span class="string">HTTP</span>            <span class="attr">periodSeconds:</span> <span class="number">10</span>            <span class="attr">successThreshold:</span> <span class="number">1</span>            <span class="attr">timeoutSeconds:</span> <span class="number">1</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="string">500m</span>              <span class="attr">memory:</span> <span class="string">1024Mi</span>            <span class="attr">limits:</span>              <span class="attr">cpu:</span> <span class="string">1000m</span>              <span class="attr">memory:</span> <span class="string">2048Mi</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/lib/grafana</span>              <span class="attr">subPath:</span> <span class="string">grafana</span>              <span class="attr">name:</span> <span class="string">grafana-pv</span>          <span class="attr">securityContext:</span>                  <span class="comment"># 容器以用户id 472 运行</span>            <span class="attr">runAsUser:</span> <span class="number">472</span>      <span class="attr">volumes:</span>                              <span class="comment"># 挂载容器卷</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grafana-pv</span>          <span class="attr">persistentVolumeClaim:</span>            <span class="attr">claimName:</span> <span class="string">grafana-pvc</span>          <span class="comment"># 使用声明的PVC，通过 StorageClass 动态创建PV</span>      <span class="attr">nodeSelector:</span> <span class="comment"># 指定Pod运行的节点</span>        <span class="attr">kubernetes.io/hostname:</span> <span class="string">k8s-node02</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.创建Service</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">3000</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="string">http-grafana</span>      <span class="attr">nodePort:</span> <span class="number">30339</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">type:</span> <span class="string">NodePort</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 创建 job，调整 grafana 挂载目录权限</span><span class="attr">apiVersion:</span> <span class="string">batch/v1</span><span class="attr">kind:</span> <span class="string">Job</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-chown</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">spec:</span>  <span class="attr">template:</span>    <span class="attr">spec:</span>      <span class="attr">restartPolicy:</span> <span class="string">Never</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grafana-chown</span>          <span class="attr">command:</span> [<span class="string">&quot;chown&quot;</span>, <span class="string">&quot;-R&quot;</span>, <span class="string">&quot;472:472&quot;</span>, <span class="string">&quot;/var/lib/grafana&quot;</span>]          <span class="attr">image:</span> <span class="string">busybox:1.37.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">storage</span>              <span class="attr">subPath:</span> <span class="string">grafana</span>              <span class="attr">mountPath:</span> <span class="string">/var/lib/grafana</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">storage</span>          <span class="attr">persistentVolumeClaim:</span>            <span class="attr">claimName:</span> <span class="string">grafana-pvc</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4.创建 Ingress</span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-ui</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">grafana</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span>       <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">prom.grafana.com</span>    <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 prom.grafana.com 的流量。客户端必须通过该域名访问</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>             <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>    <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">grafana</span>   <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">3000</span>  <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f prometheus-grafana.yaml<span class="comment"># 查看 NFS Server 挂载目录权限</span>$ <span class="built_in">cd</span> /root/data/prometheus/kube-ops/grafana-pvc/$ lltotal 0drwxrwxrwx 6 472 472 77 Jul 23 20:19 grafana<span class="comment"># 查看 Service</span>$ kubectl get svc -n kube-ops | grep grafanagrafana      NodePort   10.109.7.30      &lt;none&gt;        3000:30339/TCP   8m33s<span class="comment"># 查看 Pod</span>$ kubectl get pods -n kube-ops | grep grafanagrafana-b85d687cc-gtrhh       1/1     Running     0          8m41sgrafana-chown-z55rs           0/1     Completed   0          8m41s<span class="comment"># 查看 Job</span>$ kubectl get job -n kube-ops | grep grafanagrafana-chown   1/1           4s         8m50s</code></pre><p><strong>添加 Host 域名映射</strong></p><pre><code class="highlight plaintext">10.20.1.140 prom.grafana.com</code></pre><p><strong>浏览器访问 Grafana</strong></p><p><a href="http://prom.grafana.com/">http://prom.grafana.com/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-204348.png" alt="浏览器访问 Grafana"></p><p>用户名&#x2F;密码：admin&#x2F;admin</p><p><strong>添加Prometheus数据源</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-204501.png" alt="添加Prometheus数据"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-204521.png" alt="添加Prometheus数据源"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/23/20250723-204708.png" alt="配置数据源"></p><p><strong>导入监控配置Json文件</strong></p><p>文件内容如下</p><pre><code class="highlight json"><span class="punctuation">&#123;</span><span class="attr">&quot;__inputs&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;DS_PROMETHEUS&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="string">&quot;prometheus&quot;</span><span class="punctuation">,</span><span class="attr">&quot;description&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;datasource&quot;</span><span class="punctuation">,</span><span class="attr">&quot;pluginId&quot;</span><span class="punctuation">:</span><span class="string">&quot;prometheus&quot;</span><span class="punctuation">,</span><span class="attr">&quot;pluginName&quot;</span><span class="punctuation">:</span><span class="string">&quot;Prometheus&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;__requires&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;grafana&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;grafana&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Grafana&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;5.3.4&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;panel&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;5.0.0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;datasource&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;prometheus&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Prometheus&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;5.0.0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;panel&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;5.0.0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;annotations&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;list&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;builtIn&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;-- Grafana --&quot;</span><span class="punctuation">,</span><span class="attr">&quot;enable&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;hide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;iconColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(0, 211, 255, 1)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Annotations &amp; Alerts&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;dashboard&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;editable&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;gnetId&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;graphTooltip&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;panels&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">40</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Kubernetes 指标&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;row&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">38</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;alignAsTable&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;hideEmpty&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;rightSide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(apiserver_request_total[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;一分钟平均&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(apiserver_request_total[5m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;五分钟平均&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;ApiServer 每分钟请求数&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;cacheTimeout&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;colorBackground&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colorValue&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colors&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;#299c46&quot;</span><span class="punctuation">,</span><span class="string">&quot;rgba(237, 129, 40, 0.89)&quot;</span><span class="punctuation">,</span><span class="string">&quot;#d44a3a&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;gauge&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;maxValue&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;minValue&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdLabels&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdMarkers&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">32</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;mappingType&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;mappingTypes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;value to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;range to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;maxDataPoints&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;connected&quot;</span><span class="punctuation">,</span><span class="attr">&quot;nullText&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;postfix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;postfixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;rangeMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;sparkline&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;fillColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(31, 118, 189, 0.18)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;full&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;lineColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgb(31, 120, 193)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;tableColumn&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;kubelet_active_pods&#123;beta_kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,beta_kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;,instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;,job=\\&quot;</span>kubernetes-kubelet\\<span class="string">&quot;,kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,kubernetes_io_hostname=\\&quot;</span>k8s-master01\\<span class="string">&quot;,kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;,static=\\&quot;</span>\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01 节点 Pod 总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;80%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;op&quot;</span><span class="punctuation">:</span><span class="string">&quot;=&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;valueName&quot;</span><span class="punctuation">:</span><span class="string">&quot;avg&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;cacheTimeout&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;colorBackground&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colorValue&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colors&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;#299c46&quot;</span><span class="punctuation">,</span><span class="string">&quot;rgba(237, 129, 40, 0.89)&quot;</span><span class="punctuation">,</span><span class="string">&quot;#d44a3a&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;gauge&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;maxValue&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;minValue&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdLabels&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdMarkers&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">12</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">34</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;mappingType&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;mappingTypes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;value to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;range to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;maxDataPoints&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;connected&quot;</span><span class="punctuation">,</span><span class="attr">&quot;nullText&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;postfix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;postfixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;rangeMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;sparkline&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;fillColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(31, 118, 189, 0.18)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;full&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;lineColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgb(31, 120, 193)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;tableColumn&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;kubelet_active_pods&#123;kubernetes_io_hostname=\\&quot;</span>k8s-node01\\<span class="string">&quot;,static=\\&quot;</span>\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01 节点 Pod 总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;80%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;op&quot;</span><span class="punctuation">:</span><span class="string">&quot;=&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;valueName&quot;</span><span class="punctuation">:</span><span class="string">&quot;avg&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;cacheTimeout&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;colorBackground&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colorValue&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colors&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;#299c46&quot;</span><span class="punctuation">,</span><span class="string">&quot;rgba(237, 129, 40, 0.89)&quot;</span><span class="punctuation">,</span><span class="string">&quot;#d44a3a&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;gauge&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;maxValue&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;minValue&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdLabels&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdMarkers&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">16</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">36</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;mappingType&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;mappingTypes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;value to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;range to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;maxDataPoints&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;connected&quot;</span><span class="punctuation">,</span><span class="attr">&quot;nullText&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;postfix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;postfixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;rangeMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;sparkline&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;fillColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(31, 118, 189, 0.18)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;full&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;lineColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgb(31, 120, 193)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;tableColumn&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;kubelet_active_pods&#123;kubernetes_io_hostname=\\&quot;</span>k8s-node02\\<span class="string">&quot;,static=\\&quot;</span>\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02 节点 Pod 总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;80%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;op&quot;</span><span class="punctuation">:</span><span class="string">&quot;=&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;valueName&quot;</span><span class="punctuation">:</span><span class="string">&quot;avg&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;collapsed&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;panels&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Kubernetes 物理机&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;row&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;decimals&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">9</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;alignAsTable&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;hideEmpty&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;rightSide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;100 * (1 - avg by (instance) (rate(node_cpu_seconds_total&#123;mode=\\&quot;</span>idle\\<span class="string">&quot;, instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125;[1m])))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;hide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;100 * (1 - avg by (instance) (rate(node_cpu_seconds_total&#123;mode=\\&quot;</span>idle\\<span class="string">&quot;, instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125;[1m])))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;hide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;100 * (1 - avg by (instance) (rate(node_cpu_seconds_total&#123;mode=\\&quot;</span>idle\\<span class="string">&quot;, instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125;[1m])))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;hide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;C&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;CPU 使用量（百分比）&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;current&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">9</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;alignAsTable&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;hideEmpty&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;rightSide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;(node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125; - (node_memory_MemFree_bytes&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125; + node_memory_Buffers_bytes&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125; + node_memory_Cached_bytes&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125;)) / node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125; * 100&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01 节点&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;(node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125; - (node_memory_MemFree_bytes&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125; + node_memory_Buffers_bytes&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125; + node_memory_Cached_bytes&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125;)) / node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125; * 100&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01 节点&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;(node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125; - (node_memory_MemFree_bytes&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125; + node_memory_Buffers_bytes&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125; + node_memory_Cached_bytes&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125;)) / node_memory_MemTotal_bytes&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125; * 100&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;hide&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02 节点&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;C&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;内存使用量（百分比）&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;current&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;decimals&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">16</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">9</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">18</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;node_filesystem_avail_bytes&#123;device=\\&quot;</span>/dev/mapper/rl-root\\<span class="string">&quot;,mountpoint=\\&quot;</span>/rootfs\\<span class="string">&quot;,instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;node_filesystem_avail_bytes&#123;device=\\&quot;</span>/dev/mapper/rl-root\\<span class="string">&quot;,mountpoint=\\&quot;</span>/rootfs\\<span class="string">&quot;,instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;node_filesystem_avail_bytes&#123;device=\\&quot;</span>/dev/mapper/rl-root\\<span class="string">&quot;,mountpoint=\\&quot;</span>/rootfs\\<span class="string">&quot;,instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;C&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;存储空间剩余量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;current&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;bytes&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">15</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">12</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_receive_bytes_total&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01 下行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_transmit_bytes_total&#123;instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Master01 上行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_receive_bytes_total&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01  下行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;C&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_transmit_bytes_total&#123;instance=\\&quot;</span>k8s-node01\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node01 上行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;D&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_receive_bytes_total&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02 下行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;E&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(rate(node_network_transmit_bytes_total&#123;instance=\\&quot;</span>k8s-node02\\<span class="string">&quot;&#125;[1m]))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;Node02 上行&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;F&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;网络 IO&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;collapsed&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">21</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">16</span><span class="punctuation">,</span><span class="attr">&quot;panels&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;repeat&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Pod&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;row&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">22</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">20</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;100 *  (sum(rate(container_cpu_usage_seconds_total&#123;namespace=\\&quot;</span>kube-system\\<span class="string">&quot;, pod=\\&quot;</span>kube-apiserver-k8s-master01\\<span class="string">&quot;&#125;[1m])) by (namespace, pod))&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;apiServer&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Pod  CPU 使用量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">7</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">22</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">22</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;sum(container_memory_usage_bytes&#123;namespace=\\&quot;</span>kube-system\\<span class="string">&quot;, pod=\\&quot;</span>kube-apiserver-k8s-master01\\<span class="string">&quot;&#125;) by (namespace, pod)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;apiServer&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Pod 内存使用量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;bytes&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;collapsed&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">29</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;panels&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Ingress-Nginx&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;row&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;cacheTimeout&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;colorBackground&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colorValue&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colors&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;#299c46&quot;</span><span class="punctuation">,</span><span class="string">&quot;rgba(237, 129, 40, 0.89)&quot;</span><span class="punctuation">,</span><span class="string">&quot;#d44a3a&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;gauge&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;maxValue&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;minValue&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdLabels&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdMarkers&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">30</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">28</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;mappingType&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;mappingTypes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;value to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;range to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;maxDataPoints&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;connected&quot;</span><span class="punctuation">,</span><span class="attr">&quot;nullText&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;postfix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;postfixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;rangeMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;sparkline&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;fillColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(31, 118, 189, 0.18)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;full&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;lineColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgb(31, 120, 193)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;tableColumn&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;nginx_ingress_controller_success&#123;job=\\&quot;</span>ingressnginx12\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;node01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;node01 节点 Nginx-ingress 重载次数&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;80%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;op&quot;</span><span class="punctuation">:</span><span class="string">&quot;=&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;valueName&quot;</span><span class="punctuation">:</span><span class="string">&quot;avg&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;cacheTimeout&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;colorBackground&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colorValue&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;colors&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;#299c46&quot;</span><span class="punctuation">,</span><span class="string">&quot;rgba(237, 129, 40, 0.89)&quot;</span><span class="punctuation">,</span><span class="string">&quot;#d44a3a&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;none&quot;</span><span class="punctuation">,</span><span class="attr">&quot;gauge&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;maxValue&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;minValue&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdLabels&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;thresholdMarkers&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">30</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">30</span><span class="punctuation">,</span><span class="attr">&quot;interval&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;mappingType&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;mappingTypes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;value to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;range to text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;maxDataPoints&quot;</span><span class="punctuation">:</span><span class="number">100</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;connected&quot;</span><span class="punctuation">,</span><span class="attr">&quot;nullText&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;postfix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;postfixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefix&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;prefixFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;50%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;rangeMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;sparkline&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;fillColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgba(31, 118, 189, 0.18)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;full&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;lineColor&quot;</span><span class="punctuation">:</span><span class="string">&quot;rgb(31, 120, 193)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;tableColumn&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;nginx_ingress_controller_success&#123;job=\\&quot;</span>ingressnginx13\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;node02 节点 Nginx-ingress 重载次数&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;singlestat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueFontSize&quot;</span><span class="punctuation">:</span><span class="string">&quot;80%&quot;</span><span class="punctuation">,</span><span class="attr">&quot;valueMaps&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;op&quot;</span><span class="punctuation">:</span><span class="string">&quot;=&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;N/A&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;valueName&quot;</span><span class="punctuation">:</span><span class="string">&quot;avg&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">8</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">32</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;nginx_ingress_controller_nginx_process_requests_total&#123;controller_class=\\&quot;</span>k8s.io/ingress-nginx\\<span class="string">&quot;,controller_namespace=\\&quot;</span>ingress\\<span class="string">&quot;,controller_pod=\\&quot;</span>ingress-nginx-controller-c5h6j\\<span class="string">&quot;,instance=\\&quot;</span><span class="number">192.168</span><span class="number">.10</span><span class="number">.12</span><span class="punctuation">:</span><span class="number">10254</span>\\<span class="string">&quot;,job=\\&quot;</span>ingressnginx12\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;node01&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;nginx_ingress_controller_nginx_process_requests_total&#123;controller_class=\\&quot;</span>k8s.io/ingress-nginx\\<span class="string">&quot;,controller_namespace=\\&quot;</span>ingress\\<span class="string">&quot;,controller_pod=\\&quot;</span>ingress-nginx-controller-c5h6j\\<span class="string">&quot;,instance=\\&quot;</span><span class="number">192.168</span><span class="number">.10</span><span class="number">.12</span><span class="punctuation">:</span><span class="number">10254</span>\\<span class="string">&quot;,job=\\&quot;</span>ingressnginx12\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;node02&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Ingress-Nginx 请求量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;collapsed&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">37</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;panels&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;NFS-StorageClass&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;row&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;aliasColors&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;bars&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;dashLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;dashes&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;datasource&quot;</span><span class="punctuation">:</span><span class="string">&quot;$&#123;DS_PROMETHEUS&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fill&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;gridPos&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span><span class="number">6</span><span class="punctuation">,</span><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span><span class="number">24</span><span class="punctuation">,</span><span class="attr">&quot;x&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;y&quot;</span><span class="punctuation">:</span><span class="number">38</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">14</span><span class="punctuation">,</span><span class="attr">&quot;legend&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;avg&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;current&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;total&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;lines&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;linewidth&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;links&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;nullPointMode&quot;</span><span class="punctuation">:</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span><span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;pointradius&quot;</span><span class="punctuation">:</span><span class="number">5</span><span class="punctuation">,</span><span class="attr">&quot;points&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;renderer&quot;</span><span class="punctuation">:</span><span class="string">&quot;flot&quot;</span><span class="punctuation">,</span><span class="attr">&quot;seriesOverrides&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;spaceLength&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span><span class="attr">&quot;stack&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;steppedLine&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;targets&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;node_nfsd_disk_bytes_read_total&#123;beta_kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,beta_kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;,instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;,job=\\&quot;</span>kubernetes-nodes\\<span class="string">&quot;,kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,kubernetes_io_hostname=\\&quot;</span>k8s-master01\\<span class="string">&quot;,kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;读取总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;A&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;expr&quot;</span><span class="punctuation">:</span><span class="string">&quot;node_nfsd_disk_bytes_written_total&#123;beta_kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,beta_kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;,instance=\\&quot;</span>k8s-master01\\<span class="string">&quot;,job=\\&quot;</span>kubernetes-nodes\\<span class="string">&quot;,kubernetes_io_arch=\\&quot;</span>amd64\\<span class="string">&quot;,kubernetes_io_hostname=\\&quot;</span>k8s-master01\\<span class="string">&quot;,kubernetes_io_os=\\&quot;</span>linux\\<span class="string">&quot;&#125;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;time_series&quot;</span><span class="punctuation">,</span><span class="attr">&quot;intervalFactor&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;legendFormat&quot;</span><span class="punctuation">:</span><span class="string">&quot;写入总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;refId&quot;</span><span class="punctuation">:</span><span class="string">&quot;B&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;thresholds&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;timeFrom&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;timeShift&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;NFS storageClass 读取文件总量&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tooltip&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;shared&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;value_type&quot;</span><span class="punctuation">:</span><span class="string">&quot;individual&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;graph&quot;</span><span class="punctuation">,</span><span class="attr">&quot;xaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;buckets&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span><span class="string">&quot;time&quot;</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span><span class="attr">&quot;values&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;yaxes&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;decbytes&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;format&quot;</span><span class="punctuation">:</span><span class="string">&quot;short&quot;</span><span class="punctuation">,</span><span class="attr">&quot;label&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;logBase&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;max&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;min&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span><span class="attr">&quot;show&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;yaxis&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;align&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;alignLevel&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;refresh&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;schemaVersion&quot;</span><span class="punctuation">:</span><span class="number">16</span><span class="punctuation">,</span><span class="attr">&quot;style&quot;</span><span class="punctuation">:</span><span class="string">&quot;dark&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tags&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;templating&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;list&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;time&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span><span class="string">&quot;now-6h&quot;</span><span class="punctuation">,</span><span class="attr">&quot;to&quot;</span><span class="punctuation">:</span><span class="string">&quot;now&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;timepicker&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;refresh_intervals&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;5s&quot;</span><span class="punctuation">,</span><span class="string">&quot;10s&quot;</span><span class="punctuation">,</span><span class="string">&quot;30s&quot;</span><span class="punctuation">,</span><span class="string">&quot;1m&quot;</span><span class="punctuation">,</span><span class="string">&quot;5m&quot;</span><span class="punctuation">,</span><span class="string">&quot;15m&quot;</span><span class="punctuation">,</span><span class="string">&quot;30m&quot;</span><span class="punctuation">,</span><span class="string">&quot;1h&quot;</span><span class="punctuation">,</span><span class="string">&quot;2h&quot;</span><span class="punctuation">,</span><span class="string">&quot;1d&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;time_options&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;5m&quot;</span><span class="punctuation">,</span><span class="string">&quot;15m&quot;</span><span class="punctuation">,</span><span class="string">&quot;1h&quot;</span><span class="punctuation">,</span><span class="string">&quot;6h&quot;</span><span class="punctuation">,</span><span class="string">&quot;12h&quot;</span><span class="punctuation">,</span><span class="string">&quot;24h&quot;</span><span class="punctuation">,</span><span class="string">&quot;2d&quot;</span><span class="punctuation">,</span><span class="string">&quot;7d&quot;</span><span class="punctuation">,</span><span class="string">&quot;30d&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;timezone&quot;</span><span class="punctuation">:</span><span class="string">&quot;&quot;</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Kubernetes 监控&quot;</span><span class="punctuation">,</span><span class="attr">&quot;uid&quot;</span><span class="punctuation">:</span><span class="string">&quot;Lwdu47xIk&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="number">33</span><span class="punctuation">&#125;</span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-082411.png" alt="导入监控配置Json文件"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-082434.png" alt="选择json文件"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-082630.png" alt="点击导入"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-082736.png" alt="查看监控指标"></p><h1 id="十一、监控-metrics-server"><a href="#十一、监控-metrics-server" class="headerlink" title="十一、监控 metrics.server"></a>十一、监控 metrics.server</h1><p>从 Kubernetes v1.8 开始，资源使用情况的监控可以通过 Metrics API 的形式获取，例如容器 CPU 和内存使用率。这些度量可以由用户直接访问（例如，通过使用 kubectl top 命令），或者由集群中的控制器（例如，Horizontal Pod Autoscaler）使用来进行决策，具体的组件为 Metrics Server，用来替换之前的 heapster，heapster 从 1.11 开始逐渐被废弃。</p><p>Metrics-Server 是集群核心监控数据的聚合器。通俗地说，它存储了集群中各节点的监控数据，并且提供了 API 以供分析和使用。Metrics-Server 作为一个 Deployment 对象默认部署在 Kubernetes 集群中。不过准确地说，它是 Deployment，Service，ClusterRole，ClusterRoleBinding，APIService，RoleBinding 等资源对象的综合体。</p><pre><code class="highlight bash"><span class="comment"># https://github.com/kubernetes-sigs/metrics-server</span>https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.7.0/components.yaml</code></pre><p>当前 K8S 版本 1.29.0 ，使用 Metrics Server 版本 0.7.0.</p><p>下载后的资源清单稍作修改，<strong>跳过 Kubelet TLS 验证</strong></p><p><code>components.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>    <span class="attr">rbac.authorization.k8s.io/aggregate-to-admin:</span> <span class="string">&quot;true&quot;</span>    <span class="attr">rbac.authorization.k8s.io/aggregate-to-edit:</span> <span class="string">&quot;true&quot;</span>    <span class="attr">rbac.authorization.k8s.io/aggregate-to-view:</span> <span class="string">&quot;true&quot;</span>  <span class="attr">name:</span> <span class="string">system:aggregated-metrics-reader</span><span class="attr">rules:</span><span class="bullet">-</span> <span class="attr">apiGroups:</span>  <span class="bullet">-</span> <span class="string">metrics.k8s.io</span>  <span class="attr">resources:</span>  <span class="bullet">-</span> <span class="string">pods</span>  <span class="bullet">-</span> <span class="string">nodes</span>  <span class="attr">verbs:</span>  <span class="bullet">-</span> <span class="string">get</span>  <span class="bullet">-</span> <span class="string">list</span>  <span class="bullet">-</span> <span class="string">watch</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">system:metrics-server</span><span class="attr">rules:</span><span class="bullet">-</span> <span class="attr">apiGroups:</span>  <span class="bullet">-</span> <span class="string">&quot;&quot;</span>  <span class="attr">resources:</span>  <span class="bullet">-</span> <span class="string">nodes/metrics</span>  <span class="attr">verbs:</span>  <span class="bullet">-</span> <span class="string">get</span><span class="bullet">-</span> <span class="attr">apiGroups:</span>  <span class="bullet">-</span> <span class="string">&quot;&quot;</span>  <span class="attr">resources:</span>  <span class="bullet">-</span> <span class="string">pods</span>  <span class="bullet">-</span> <span class="string">nodes</span>  <span class="attr">verbs:</span>  <span class="bullet">-</span> <span class="string">get</span>  <span class="bullet">-</span> <span class="string">list</span>  <span class="bullet">-</span> <span class="string">watch</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server-auth-reader</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="attr">roleRef:</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">Role</span>  <span class="attr">name:</span> <span class="string">extension-apiserver-authentication-reader</span><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server:system:auth-delegator</span><span class="attr">roleRef:</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">name:</span> <span class="string">system:auth-delegator</span><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">system:metrics-server</span><span class="attr">roleRef:</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">name:</span> <span class="string">system:metrics-server</span><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="attr">spec:</span>  <span class="attr">ports:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https</span>    <span class="attr">port:</span> <span class="number">443</span>    <span class="attr">protocol:</span> <span class="string">TCP</span>    <span class="attr">targetPort:</span> <span class="string">https</span>  <span class="attr">selector:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">metrics-server</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">strategy:</span>    <span class="attr">rollingUpdate:</span>      <span class="attr">maxUnavailable:</span> <span class="number">0</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>      <span class="bullet">-</span> <span class="attr">args:</span>        <span class="bullet">-</span> <span class="string">--cert-dir=/tmp</span>        <span class="bullet">-</span> <span class="string">--secure-port=10250</span>        <span class="bullet">-</span> <span class="string">--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span>        <span class="bullet">-</span> <span class="string">--kubelet-use-node-status-port</span>        <span class="bullet">-</span> <span class="string">--kubelet-insecure-tls</span>  <span class="comment"># 跳过 Kubelet TLS 验证</span>        <span class="bullet">-</span> <span class="string">--metric-resolution=15s</span>        <span class="attr">image:</span> <span class="string">registry.k8s.io/metrics-server/metrics-server:v0.7.0</span>        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>        <span class="attr">livenessProbe:</span>          <span class="attr">failureThreshold:</span> <span class="number">3</span>          <span class="attr">httpGet:</span>            <span class="attr">path:</span> <span class="string">/livez</span>            <span class="attr">port:</span> <span class="string">https</span>            <span class="attr">scheme:</span> <span class="string">HTTPS</span>          <span class="attr">periodSeconds:</span> <span class="number">10</span>        <span class="attr">name:</span> <span class="string">metrics-server</span>        <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">10250</span>          <span class="attr">name:</span> <span class="string">https</span>          <span class="attr">protocol:</span> <span class="string">TCP</span>        <span class="attr">readinessProbe:</span>          <span class="attr">failureThreshold:</span> <span class="number">3</span>          <span class="attr">httpGet:</span>            <span class="attr">path:</span> <span class="string">/readyz</span>            <span class="attr">port:</span> <span class="string">https</span>            <span class="attr">scheme:</span> <span class="string">HTTPS</span>          <span class="attr">initialDelaySeconds:</span> <span class="number">20</span>          <span class="attr">periodSeconds:</span> <span class="number">10</span>        <span class="attr">resources:</span>          <span class="attr">requests:</span>            <span class="attr">cpu:</span> <span class="string">100m</span>            <span class="attr">memory:</span> <span class="string">200Mi</span>        <span class="attr">securityContext:</span>          <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span>          <span class="attr">capabilities:</span>            <span class="attr">drop:</span>            <span class="bullet">-</span> <span class="string">ALL</span>          <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span>          <span class="attr">runAsNonRoot:</span> <span class="literal">true</span>          <span class="attr">runAsUser:</span> <span class="number">1000</span>          <span class="attr">seccompProfile:</span>            <span class="attr">type:</span> <span class="string">RuntimeDefault</span>        <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/tmp</span>          <span class="attr">name:</span> <span class="string">tmp-dir</span>      <span class="attr">nodeSelector:</span>        <span class="attr">kubernetes.io/os:</span> <span class="string">linux</span>      <span class="attr">priorityClassName:</span> <span class="string">system-cluster-critical</span>      <span class="attr">serviceAccountName:</span> <span class="string">metrics-server</span>      <span class="attr">volumes:</span>      <span class="bullet">-</span> <span class="attr">emptyDir:</span> &#123;&#125;        <span class="attr">name:</span> <span class="string">tmp-dir</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">apiregistration.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">APIService</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">metrics-server</span>  <span class="attr">name:</span> <span class="string">v1beta1.metrics.k8s.io</span><span class="attr">spec:</span>  <span class="attr">group:</span> <span class="string">metrics.k8s.io</span>  <span class="attr">groupPriorityMinimum:</span> <span class="number">100</span>  <span class="attr">insecureSkipTLSVerify:</span> <span class="literal">true</span>  <span class="attr">service:</span>    <span class="attr">name:</span> <span class="string">metrics-server</span>    <span class="attr">namespace:</span> <span class="string">kube-system</span>  <span class="attr">version:</span> <span class="string">v1beta1</span>  <span class="attr">versionPriority:</span> <span class="number">100</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，部署 metrics-server</span>$ kubectl apply -f components.yaml<span class="comment"># 查看 Pod</span>$ kubectl get pod -n kube-system  -o wide -w | grep metrics-server metrics-server-56cfc8b678-b77wb            1/1     Running   0               59s   192.168.85.217   k8s-node01     &lt;none&gt;           &lt;none&gt;</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-104820.png" alt="metric-server 监控数据原理"></p><h1 id="十二、alertmanager-部署"><a href="#十二、alertmanager-部署" class="headerlink" title="十二、alertmanager 部署"></a>十二、alertmanager 部署</h1><h2 id="1-创建-alertmanager-配置文件"><a href="#1-创建-alertmanager-配置文件" class="headerlink" title="1. 创建 alertmanager 配置文件"></a>1. 创建 alertmanager 配置文件</h2><p>资源清单：<code>alertmanager-conf.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">alert-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">config.yml:</span> <span class="string">|-</span><span class="string">    global:</span><span class="string">      # 定义告警在没有新触发的情况下被标记为已解决（resolved）的时间，设置为 5 分钟。</span><span class="string">      resolve_timeout: 5m</span><span class="string">      # 配置邮件发送信息</span><span class="string">      smtp_smarthost: &#x27;smtp.163.com:25&#x27;             # 指定 SMTP 服务器地址和端口，用于发送邮件通知</span><span class="string">      smtp_from: &#x27;18326088610@163.com&#x27;              # 邮件发送者的地址，显示为发件人（From 字段）</span><span class="string">      smtp_auth_username: &#x27;18326088610@163.com&#x27;     # SMTP 认证用户名，与发件人地址一致</span><span class="string">      smtp_auth_password: &#x27;xxxxxxxxxxxxxxxx&#x27;        # SMTP 认证密码，通常是 163 邮箱的授权码（非登录密码）</span><span class="string">      smtp_hello: &#x27;163.com&#x27;                         # SMTP 客户端在与服务器建立连接时发送的 HELO/EHLO 域名，设置为 163.com</span><span class="string">      smtp_require_tls: false                       # 禁用 TLS 加密，邮件通过明文传输（端口 25 通常不加密）</span><span class="string">    route:    # 定义告警的路由策略，决定如何分组、处理和分发告警</span><span class="string">      # 这里的标签列表是接收到报警信息后的重新分组标签，例如，接收到的报警信息里面有许多具有 cluster=A 和 alertname=LatncyHigh 这样的标签的报警信息将会批量被聚合到一个分组里面</span><span class="string">      group_by: [&#x27;alertname&#x27;, &#x27;cluster&#x27;]</span><span class="string">      # 当一个新的报警分组被创建后，需要等待至少group_wait时间来初始化通知，这种方式可以确保您能有足够的时间为同一分组来获取多个警报，然后一起触发这个报警信息。</span><span class="string">      group_wait: 30s</span><span class="string">      # 当第一个报警发送后，等待&#x27;group_interval&#x27;时间来发送新的一组报警信息。</span><span class="string">      group_interval: 5m</span><span class="string">      # 如果一个报警信息已经发送成功了，等待&#x27;repeat_interval&#x27;时间来重新发送他们</span><span class="string">      repeat_interval: 5m</span><span class="string">      # 默认的receiver：如果一个报警没有被一个route匹配，则发送给默认的接收器</span><span class="string">      receiver: default</span><span class="string">      # 上面所有的属性都由所有子路由继承，并且可以在每个子路由上进行覆盖。</span><span class="string">      routes:</span><span class="string">        - receiver: email   # 匹配子路由的告警发送到 email 接收器</span><span class="string">          group_wait: 10s   # 子路由覆盖父路由的 group_wait，仅等待 10 秒发送通知</span><span class="string">          match:</span><span class="string">            team: node      # 仅匹配带有标签 team=node 的告警（如 Prometheus 规则中定义的 HighNodeCPU 告警）</span><span class="string">    receivers:              # 定义告警通知的接收器，指定通知方式和目标</span><span class="string">      - name: &#x27;default&#x27;</span><span class="string">        email_configs:</span><span class="string">          - to: &#x27;george_95@126.com&#x27;     # 告警邮件发送到 george_95@126.com</span><span class="string">            send_resolved: true         # 当告警解决时，发送“已恢复”通知邮件</span><span class="string">      - name: &#x27;email&#x27;                   # 自定义接收器，处理匹配 team: node 的告警</span><span class="string">        email_configs:</span><span class="string">          - to: &#x27;george_95@126.com&#x27;     # 告警邮件发送到 george_95@126.com</span><span class="string">            send_resolved: true         # 当告警解决时，发送“已恢复”通知邮件</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f alertmanager-conf.yaml</code></pre><h2 id="2-修改-Prometheus-ConfigMap-2"><a href="#2-修改-Prometheus-ConfigMap-2" class="headerlink" title="2. 修改 Prometheus ConfigMap"></a>2. 修改 Prometheus ConfigMap</h2><p><code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">rules.yml:</span> <span class="string">|</span>          <span class="comment"># 配置Prometheus告警规则，内存使用超过 20% 就告警</span>    <span class="attr">groups:</span>      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-rule</span>        <span class="attr">rules:</span>          <span class="bullet">-</span> <span class="attr">alert:</span> <span class="string">NodeMemoryUsage</span>            <span class="attr">expr:</span> <span class="string">(node_memory_MemTotal_bytes</span> <span class="bullet">-</span> <span class="string">(node_memory_MemFree_bytes</span> <span class="string">+</span> <span class="string">node_memory_Buffers_bytes</span> <span class="string">+</span> <span class="string">node_memory_Cached_bytes))</span> <span class="string">/</span> <span class="string">node_memory_MemTotal_bytes</span> <span class="string">*</span> <span class="number">100</span> <span class="string">&gt;</span> <span class="number">20</span>            <span class="attr">for:</span> <span class="string">2m</span>       <span class="comment"># 告警条件需持续满足 2 分钟（2m）才会触发</span>            <span class="attr">labels:</span>       <span class="comment"># 为告警添加标签 team=node，用于路由和分组</span>              <span class="attr">team:</span> <span class="string">node</span>            <span class="attr">annotations:</span>  <span class="comment"># 提供告警的附加信息，显示在通知（如邮件）中</span>              <span class="attr">summary:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>: High Memory usage detected&quot;</span>              <span class="attr">description:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>: Memory usage is above 20% (current value is: <span class="template-variable">&#123;&#123; $value &#125;&#125;</span>&quot;</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-cadvisor&#x27;</span>                                         <span class="comment"># 抓取任务名称为 kubernetes-cadvisor，用于监控 Kubernetes 节点的 cAdvisor 指标</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                           <span class="comment"># 指定使用 HTTPS 协议访问目标（Kubernetes API 服务器的 443 端口）</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Pod 内部的服务账号卷挂载的 CA 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌</span>      <span class="attr">relabel_configs:</span>                                              <span class="comment"># 定义标签重写规则，修改服务发现的目标地址和路径</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                                          <span class="comment"># 规则1：将节点的标签（如 kubernetes.io/hostname）映射到 Prometheus 指标标签 </span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span>                   <span class="comment"># 规则2：将抓取目标地址设置为 kubernetes.default.svc:443，即 Kubernetes API 服务器的 ClusterIP 服务（默认命名空间 default，端口 443）</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]              <span class="comment"># 规则3：使用节点名称（__meta_kubernetes_node_name，如 node01）动态构造指标路径</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-apiservers&#x27;</span>                             <span class="comment"># 抓取任务名称为 kubernetes-apiservers，用于监控 Kubernetes API 服务器的指标，包括请求速率、延迟、错误率等（如 apiserver_request_total, apiserver_request_duration_seconds）</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                                           <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中的所有 Endpoints 对象</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                 <span class="comment"># Kubernetes API 服务器默认通过 HTTPS（端口 443）暴露 /metrics 端点</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Prometheus Pod 内部的服务账号卷挂载的 CA 证书（位于 /var/run/secrets/kubernetes.io/serviceaccount/ca.crt）验证 API 服务器的 TLS 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌（位于 /var/run/secrets/kubernetes.io/serviceaccount/token）进行身份验证</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>, <span class="string">__meta_kubernetes_service_name</span>, <span class="string">__meta_kubernetes_endpoint_port_name</span>]    <span class="comment"># 断点所在的名称空间，断点所在的 Service， 断点端口名称</span>          <span class="attr">action:</span> <span class="string">keep</span>                      <span class="comment"># 仅保留匹配正则表达式的端点，未匹配的端点被丢弃。</span>          <span class="attr">regex:</span> <span class="string">default;kubernetes;https</span>   <span class="comment"># 确保 Prometheus 只抓取 default 命名空间中 kubernetes 服务的 HTTPS 端点（即 API 服务器的 /metrics）</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-service-endpoints&#x27;</span>        <span class="comment"># 抓取任务名称为 kubernetes-service-endpoints，用于监控 Kubernetes Service 的 Endpoints 指标。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                             <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中所有 Service 的 Endpoints 对象</span>      <span class="attr">relabel_configs:</span>                                <span class="comment"># 定义标签重写规则，过滤和配置服务发现的目标，确保只抓取符合条件的 Service Endpoints</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scrape</span>]          <span class="attr">action:</span> <span class="string">keep</span>                                <span class="comment"># 仅保留注解 prometheus.io/scrape: &quot;true&quot; 的 Service Endpoints，未匹配的被丢弃</span>          <span class="attr">regex:</span> <span class="literal">true</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scheme</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将匹配的值替换到 __scheme__ 标签，决定抓取协议（http 或 https），允许 Service 指定是否通过 HTTPS 抓取指标，适用于需要安全连接的场景</span>          <span class="attr">target_label:</span> <span class="string">__scheme__</span>          <span class="attr">regex:</span> <span class="string">(https?)</span>                             <span class="comment"># 匹配 http 或 https，若注解未设置，默认使用 http</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_path</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 检查 Service 的注解 prometheus.io/path，将匹配的值替换到 __metrics_path__ 标签，指定指标端点的路径</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>, <span class="string">__meta_kubernetes_service_annotation_prometheus_io_port</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将地址和端口组合替换到 __address__ 标签，允许 Service 指定抓取端口（如 prometheus.io/port: &quot;8080&quot;），覆盖 Endpoints 的默认端口</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">regex:</span> <span class="string">([^:]+)(?::\d+)?;(\d+)</span>          <span class="attr">replacement:</span> <span class="string">$1:$2</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                            <span class="comment"># 将 Service 的标签（如 app=my-app）映射到 Prometheus 指标标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_service_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>]      <span class="comment"># 将 Service 的命名空间（__meta_kubernetes_namespace）写入指标标签 kubernetes_namespace</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_namespace</span>                  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_name</span>]   <span class="comment"># 将 Service 名称（__meta_kubernetes_service_name）写入指标标签 kubernetes_name</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_name</span>              <span class="attr">alerting:</span>               <span class="comment"># 定义 Prometheus 与 Alertmanager 的连接，用于发送告警</span>      <span class="attr">alertmanagers:</span>        <span class="comment"># 指定 Alertmanager 实例的地址</span>        <span class="bullet">-</span> <span class="attr">static_configs:</span>            <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&quot;prometheus.kube-ops.svc.cluster.local:9093&quot;</span>]   <span class="comment"># &lt;service-name&gt;.&lt;namespace&gt;.svc.&lt;cluster-domain&gt;，注意 这里Service名称是 prometheus</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f prometheus-cm.yaml</code></pre><h2 id="3-修改-Prometheus-Service"><a href="#3-修改-Prometheus-Service" class="headerlink" title="3. 修改 Prometheus Service"></a>3. 修改 Prometheus Service</h2><p>资源清单：<code>prometheus.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># Service</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">prometheus</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">prometheus</span>  <span class="attr">type:</span> <span class="string">NodePort</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="comment"># 端口名称</span>      <span class="attr">port:</span> <span class="number">9090</span>            <span class="comment"># service 对外端口 9090</span>      <span class="attr">targetPort:</span> <span class="number">9090</span>      <span class="comment"># 内部名为 http 的端口 （9090）</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alertmanager</span>    <span class="comment"># altermanager 端口配置</span>      <span class="attr">port:</span> <span class="number">9093</span>      <span class="attr">targetPort:</span> <span class="number">9093</span></code></pre><h2 id="4-合并-altermanager-至-prometheus-deploy-文件"><a href="#4-合并-altermanager-至-prometheus-deploy-文件" class="headerlink" title="4. 合并 altermanager 至 prometheus deploy 文件"></a>4. 合并 altermanager 至 prometheus deploy 文件</h2><p>资源清单：<code>prometheus.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">prometheus</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>               <span class="comment"># Pod 副本数为1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">prometheus</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">prometheus</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">prometheus</span>    <span class="comment"># 指定 Pod 使用的 Kubernetes 服务账号（ServiceAccount）为 prometheus</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alertmanager</span>          <span class="attr">image:</span> <span class="string">prom/alertmanager:v0.28.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">&quot;--config.file=/etc/alertmanager/config.yml&quot;</span>            <span class="bullet">-</span> <span class="string">&quot;--storage.path=/alertmanager/data&quot;</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9093</span>              <span class="attr">name:</span> <span class="string">alertmanager</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/etc/alertmanager&quot;</span>              <span class="attr">name:</span> <span class="string">alertcfg</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="string">300m</span>              <span class="attr">memory:</span> <span class="string">512Mi</span>            <span class="attr">limits:</span>              <span class="attr">cpu:</span> <span class="string">300m</span>              <span class="attr">memory:</span> <span class="string">512Mi</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">prometheus</span>          <span class="attr">image:</span> <span class="string">prom/prometheus:v2.54.1</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&quot;/bin/prometheus&quot;</span>         <span class="comment"># 指定容器启动时运行的命令为 /bin/prometheus，这是 Prometheus 的主可执行文件</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">&quot;--config.file=/etc/prometheus/prometheus.yml&quot;</span>    <span class="comment"># 指定 Prometheus 的配置文件路径为 /etc/prometheus/prometheus.yml，这个文件由 ConfigMap（prometheus-config）提供，挂载到容器内</span>            <span class="bullet">-</span> <span class="string">&quot;--storage.tsdb.path=/prometheus&quot;</span>                 <span class="comment"># 指定 Prometheus 时间序列数据库（TSDB）的存储路径为 /prometheus，这个路径由 PVC（prometheus）提供，持久化存储数据</span>            <span class="bullet">-</span> <span class="string">&quot;--storage.tsdb.retention=24h&quot;</span>                    <span class="comment"># 设置数据保留时间为 24 小时，意味着 Prometheus 只保留最近 24 小时的监控数据，旧数据将被删除。生产环境建议 15-30天</span>            <span class="bullet">-</span> <span class="string">&quot;--web.enable-admin-api&quot;</span>                          <span class="comment"># 启用 Prometheus 的 Admin HTTP API，允许执行管理操作（如删除时间序列）</span>            <span class="bullet">-</span> <span class="string">&quot;--web.enable-lifecycle&quot;</span>                          <span class="comment"># 启用生命周期 API，支持通过 HTTP 请求（如 localhost:9090/-/reload）动态重新加载配置文件。</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9090</span>       <span class="comment"># 指定 Prometheus 监听端口，用于提供 Web UI 和 API</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>              <span class="attr">name:</span> <span class="string">http</span>          <span class="attr">volumeMounts:</span>                 <span class="comment"># 定义容器内的挂载点，将卷挂载到指定路径</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/prometheus&quot;</span>  <span class="comment"># 将名为 data 的卷挂载到容器内的 /prometheus 路径，用于存储 TSDB 数据</span>              <span class="attr">subPath:</span> <span class="string">prometheus</span>       <span class="comment"># 表示使用卷中的子路径 prometheus，避免覆盖整个卷的其他内容</span>              <span class="attr">name:</span> <span class="string">data</span>                <span class="comment"># 卷由 PVC（prometheus）提供</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/etc/prometheus&quot;</span>      <span class="comment"># 将名为 config-volume 的卷挂载到容器内的 /etc/prometheus 路径，用于存储配置文件</span>              <span class="attr">name:</span> <span class="string">config-volume</span>               <span class="comment"># 由 ConfigMap（prometheus-config）提供</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="string">500m</span>                 <span class="comment"># 请求 100 毫核（0.1 CPU 核心），表示容器需要的最小 CPU 资源</span>              <span class="attr">memory:</span> <span class="string">1024Mi</span>             <span class="comment"># 请求 512 MiB 内存，表示容器需要的最小内存</span>            <span class="attr">limits:</span>              <span class="attr">cpu:</span> <span class="string">500m</span>                 <span class="comment"># 限制容器最多使用 100 毫核 CPU，防止过量占用</span>              <span class="attr">memory:</span> <span class="string">1024Mi</span>             <span class="comment"># 限制容器最多使用 512 MiB 内存，防止内存溢出</span>      <span class="attr">securityContext:</span>                  <span class="comment"># 定义 Pod 的安全上下文，控制容器运行时的权限</span>        <span class="attr">runAsUser:</span> <span class="number">0</span>                    <span class="comment"># 指定容器以用户 ID 0（即 root 用户）运行</span>      <span class="attr">volumes:</span>                          <span class="comment"># 定义 Pod 使用的卷，供容器挂载</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span>          <span class="attr">persistentVolumeClaim:</span>        <span class="comment"># 指定挂载的PVC</span>            <span class="attr">claimName:</span> <span class="string">prometheus</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span>          <span class="attr">configMap:</span>                    <span class="comment"># 指定挂载的 configMap</span>            <span class="attr">name:</span> <span class="string">prometheus-config</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">alertcfg</span>                <span class="comment"># 挂载AlertManager ConfigMap</span>          <span class="attr">configMap:</span>            <span class="attr">name:</span> <span class="string">alert-config</span></code></pre><p>这里要注意 prometheus 和 alertmanager 不能太旧，否则无法适配当前的 SMTP 协议。</p><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，重新加载 Service 和 Deployment</span>$ kubectl apply -f prometheus.yaml</code></pre><h2 id="5-添加报警演示"><a href="#5-添加报警演示" class="headerlink" title="5. 添加报警演示"></a>5. 添加报警演示</h2><p>修改 Prometheus ConfigMap，添加监控 <strong>内存使用量</strong></p><p>资源清单：<code>prometheus-cm.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">prometheus-config</span>  <span class="attr">namespace:</span> <span class="string">kube-ops</span><span class="attr">data:</span>  <span class="attr">rules.yml:</span> <span class="string">|</span>          <span class="comment"># 配置Prometheus告警规则，内存使用超过 20% 就告警</span>    <span class="attr">groups:</span>      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-rule</span>        <span class="attr">rules:</span>          <span class="bullet">-</span> <span class="attr">alert:</span> <span class="string">NodeMemoryUsage</span>            <span class="attr">expr:</span> <span class="string">(node_memory_MemTotal_bytes</span> <span class="bullet">-</span> <span class="string">(node_memory_MemFree_bytes</span> <span class="string">+</span> <span class="string">node_memory_Buffers_bytes</span> <span class="string">+</span> <span class="string">node_memory_Cached_bytes))</span> <span class="string">/</span> <span class="string">node_memory_MemTotal_bytes</span> <span class="string">*</span> <span class="number">100</span> <span class="string">&gt;</span> <span class="number">20</span>            <span class="attr">for:</span> <span class="string">2m</span>       <span class="comment"># 告警条件需持续满足 2 分钟（2m）才会触发</span>            <span class="attr">labels:</span>       <span class="comment"># 为告警添加标签 team=node，用于路由和分组</span>              <span class="attr">team:</span> <span class="string">node</span>            <span class="attr">annotations:</span>  <span class="comment"># 提供告警的附加信息，显示在通知（如邮件）中</span>              <span class="attr">summary:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>: High Memory usage detected&quot;</span>              <span class="attr">description:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123;$labels.instance&#125;&#125;</span>: Memory usage is above 20% (current value is: <span class="template-variable">&#123;&#123; $value &#125;&#125;</span>&quot;</span>  <span class="attr">prometheus.yml:</span> <span class="string">|</span>           <span class="comment"># 使用 | 表示 YAML 中的多行文本</span>    <span class="attr">global:</span>                   <span class="comment"># 定义 Prometheus 的全局配置，适用于所有抓取任务（除非在具体任务中被覆盖）</span>      <span class="attr">scrape_interval:</span> <span class="string">15s</span>    <span class="comment"># 表示 prometheus 抓取指标数据的频率，默认是 15s</span>      <span class="attr">scrape_timeout:</span> <span class="string">15s</span>     <span class="comment"># 表示 prometheus 抓取指标数据的超时时间，默认是 15s</span>    <span class="attr">scrape_configs:</span>    <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;prometheus&#x27;</span>  <span class="comment"># 定义任务名，这里监控 prometheus 自身</span>      <span class="attr">static_configs:</span>      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9090&#x27;</span>]            <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx140&#x27;</span>         <span class="comment"># 10.20.1.140 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.140:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx141&#x27;</span>         <span class="comment"># 10.20.1.141 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.141:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;ingressnginx142&#x27;</span>         <span class="comment"># 10.20.1.142 Ingress-nginx 指标数据抓取</span>      <span class="attr">static_configs:</span>        <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;10.20.1.142:10254&#x27;</span>]              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-nodes&#x27;</span>        <span class="comment"># 基于Node自动发现节点，并抓取指标信息。Node Exporter：提供系统级指标，适合监控节点的硬件和操作系统状态（如磁盘 I/O、网络流量）。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>]    <span class="comment"># 默认抓取节点的 Kubelet 端点（端口 10250，/metrics），但这里通过 relabel_configs 修改为 Node Exporter 的端口（9100）</span>          <span class="attr">regex:</span> <span class="string">&#x27;(.*):10250&#x27;</span>          <span class="attr">replacement:</span> <span class="string">&#x27;$&#123;1&#125;:9100&#x27;</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">action:</span> <span class="string">replace</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-kubelet&#x27;</span>      <span class="comment"># 基于Node发现，从 Kubelet 抓取指标信息。Kubelet：提供 Kubernetes 特定指标，如 Pod 运行状态、Kubelet 的健康状况和 API 请求统计。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># k8s 自动为pod挂载的证书文件路径,在pod内部</span>        <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># k8s 自动为pod挂载的token文件路径，在pod内部</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>                            <span class="comment"># 将 Kubernetes 节点的标签（__meta_kubernetes_node_label_&lt;key&gt;）映射为 Prometheus 指标的标签</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-cadvisor&#x27;</span>                                         <span class="comment"># 抓取任务名称为 kubernetes-cadvisor，用于监控 Kubernetes 节点的 cAdvisor 指标</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                           <span class="comment"># 指定使用 HTTPS 协议访问目标（Kubernetes API 服务器的 443 端口）</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Pod 内部的服务账号卷挂载的 CA 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌</span>      <span class="attr">relabel_configs:</span>                                              <span class="comment"># 定义标签重写规则，修改服务发现的目标地址和路径</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                                          <span class="comment"># 规则1：将节点的标签（如 kubernetes.io/hostname）映射到 Prometheus 指标标签 </span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span>                   <span class="comment"># 规则2：将抓取目标地址设置为 kubernetes.default.svc:443，即 Kubernetes API 服务器的 ClusterIP 服务（默认命名空间 default，端口 443）</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]              <span class="comment"># 规则3：使用节点名称（__meta_kubernetes_node_name，如 node01）动态构造指标路径</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-apiservers&#x27;</span>                             <span class="comment"># 抓取任务名称为 kubernetes-apiservers，用于监控 Kubernetes API 服务器的指标，包括请求速率、延迟、错误率等（如 apiserver_request_total, apiserver_request_duration_seconds）</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                                           <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中的所有 Endpoints 对象</span>      <span class="attr">scheme:</span> <span class="string">https</span>                                                 <span class="comment"># Kubernetes API 服务器默认通过 HTTPS（端口 443）暴露 /metrics 端点</span>      <span class="attr">tls_config:</span>        <span class="attr">ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span>         <span class="comment"># 使用 Prometheus Pod 内部的服务账号卷挂载的 CA 证书（位于 /var/run/secrets/kubernetes.io/serviceaccount/ca.crt）验证 API 服务器的 TLS 证书</span>      <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span>  <span class="comment"># 使用服务账号的 Bearer 令牌（位于 /var/run/secrets/kubernetes.io/serviceaccount/token）进行身份验证</span>      <span class="attr">relabel_configs:</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>, <span class="string">__meta_kubernetes_service_name</span>, <span class="string">__meta_kubernetes_endpoint_port_name</span>]    <span class="comment"># 断点所在的名称空间，断点所在的 Service， 断点端口名称</span>          <span class="attr">action:</span> <span class="string">keep</span>                      <span class="comment"># 仅保留匹配正则表达式的端点，未匹配的端点被丢弃。</span>          <span class="attr">regex:</span> <span class="string">default;kubernetes;https</span>   <span class="comment"># 确保 Prometheus 只抓取 default 命名空间中 kubernetes 服务的 HTTPS 端点（即 API 服务器的 /metrics）</span>              <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-service-endpoints&#x27;</span>        <span class="comment"># 抓取任务名称为 kubernetes-service-endpoints，用于监控 Kubernetes Service 的 Endpoints 指标。</span>      <span class="attr">kubernetes_sd_configs:</span>        <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">endpoints</span>                             <span class="comment"># 使用 Kubernetes 服务发现，角色为 endpoints，发现集群中所有 Service 的 Endpoints 对象</span>      <span class="attr">relabel_configs:</span>                                <span class="comment"># 定义标签重写规则，过滤和配置服务发现的目标，确保只抓取符合条件的 Service Endpoints</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scrape</span>]          <span class="attr">action:</span> <span class="string">keep</span>                                <span class="comment"># 仅保留注解 prometheus.io/scrape: &quot;true&quot; 的 Service Endpoints，未匹配的被丢弃</span>          <span class="attr">regex:</span> <span class="literal">true</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_scheme</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将匹配的值替换到 __scheme__ 标签，决定抓取协议（http 或 https），允许 Service 指定是否通过 HTTPS 抓取指标，适用于需要安全连接的场景</span>          <span class="attr">target_label:</span> <span class="string">__scheme__</span>          <span class="attr">regex:</span> <span class="string">(https?)</span>                             <span class="comment"># 匹配 http 或 https，若注解未设置，默认使用 http</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_annotation_prometheus_io_path</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 检查 Service 的注解 prometheus.io/path，将匹配的值替换到 __metrics_path__ 标签，指定指标端点的路径</span>          <span class="attr">target_label:</span> <span class="string">__metrics_path__</span>          <span class="attr">regex:</span> <span class="string">(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>, <span class="string">__meta_kubernetes_service_annotation_prometheus_io_port</span>]          <span class="attr">action:</span> <span class="string">replace</span>                             <span class="comment"># 将地址和端口组合替换到 __address__ 标签，允许 Service 指定抓取端口（如 prometheus.io/port: &quot;8080&quot;），覆盖 Endpoints 的默认端口</span>          <span class="attr">target_label:</span> <span class="string">__address__</span>          <span class="attr">regex:</span> <span class="string">([^:]+)(?::\d+)?;(\d+)</span>          <span class="attr">replacement:</span> <span class="string">$1:$2</span>        <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span>                            <span class="comment"># 将 Service 的标签（如 app=my-app）映射到 Prometheus 指标标签</span>          <span class="attr">regex:</span> <span class="string">__meta_kubernetes_service_label_(.+)</span>        <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>]      <span class="comment"># 将 Service 的命名空间（__meta_kubernetes_namespace）写入指标标签 kubernetes_namespace</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_namespace</span>                  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_service_name</span>]   <span class="comment"># 将 Service 名称（__meta_kubernetes_service_name）写入指标标签 kubernetes_name</span>          <span class="attr">action:</span> <span class="string">replace</span>          <span class="attr">target_label:</span> <span class="string">kubernetes_name</span>              <span class="attr">alerting:</span>               <span class="comment"># 定义 Prometheus 与 Alertmanager 的连接，用于发送告警</span>      <span class="attr">alertmanagers:</span>        <span class="comment"># 指定 Alertmanager 实例的地址</span>        <span class="bullet">-</span> <span class="attr">static_configs:</span>            <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&quot;prometheus.kube-ops.svc.cluster.local:9093&quot;</span>]   <span class="comment"># &lt;service-name&gt;.&lt;namespace&gt;.svc.&lt;cluster-domain&gt;</span>                  <span class="attr">rule_files:</span>             <span class="comment"># 指定告警规则文件路径</span>      <span class="bullet">-</span> <span class="string">/etc/prometheus/rules.yml</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，重新加载 ConfigMap</span>$ kubectl apply -f prometheus-cm.yaml<span class="comment">#  热更新 ConfingMap</span>$ kubectl get svc -n kube-opsNAME         TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGEgrafana      NodePort   10.109.7.30      &lt;none&gt;        3000:30339/TCP                  19hprometheus   NodePort   10.102.229.198   &lt;none&gt;        9090:31676/TCP,9093:31878/TCP   44h$ curl -X POST http://10.102.229.198:9090/-/reload</code></pre><p><strong>浏览器访问 Prometheus 查看告警规则是否生效</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-162449.png" alt="查看告警规则是否生效"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-205334.png" alt="AlertManager触发告警"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/24/20250724-205424.png" alt="接收到告警邮件"></p><p><strong>参考链接</strong></p><blockquote><p><a href="https://zhangquan.me/2022/09/04/shi-yong-prometheus-jian-kong-kubernetes-ji-qun-jie-dian/">https://zhangquan.me/2022/09/04/shi-yong-prometheus-jian-kong-kubernetes-ji-qun-jie-dian/</a></p><p><a href="https://cloudmessage.top/archives/prometheus-shou-dong-pei-zhi-jian-kong-kubernetesji-qun">https://cloudmessage.top/archives/prometheus-shou-dong-pei-zhi-jian-kong-kubernetesji-qun</a></p><p><a href="https://www.cnblogs.com/cyh00001/p/16725312.html">https://www.cnblogs.com/cyh00001/p/16725312.html</a></p><p><a href="https://csms.tech/202212141608/#%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF">https://csms.tech/202212141608/#%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;概要：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;简述 Loki 相关组件原理，并演示两种使用 Loki 监控Pod日志的部署方式：&lt;strong&gt;使用 yaml 资源清单部署&lt;/strong&gt; 和 &lt;strong&gt;使用 Helm 部署&lt;/strong&gt;&lt;/p&gt;
&lt;p</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Prometheus" scheme="https://georgechan95.github.io/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>014-K8S-部署Loki+Promtail+Grafana实现日志监控</title>
    <link href="https://georgechan95.github.io/blog/f8cf646f.html"/>
    <id>https://georgechan95.github.io/blog/f8cf646f.html</id>
    <published>2025-07-10T13:00:00.000Z</published>
    <updated>2025-07-22T06:19:53.678Z</updated>
    
    <content type="html"><![CDATA[<p><strong>概要：</strong></p><p>简述 Loki 相关组件原理，并演示两种使用 Loki 监控Pod日志的部署方式：<strong>使用 yaml 资源清单部署</strong> 和 <strong>使用 Helm 部署</strong></p><p><strong>集群环境</strong></p><table><thead><tr><th>IP</th><th>Hostname</th><th>用途</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td><td>Master节点，NFS Server</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td><td>Node节点, NFS Client</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td><td>Node节点, NFS Client</td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td><td>安装NFS，Harbor, NFS Client</td></tr></tbody></table><h1 id="一、Loki-简介"><a href="#一、Loki-简介" class="headerlink" title="一、Loki 简介"></a>一、Loki 简介</h1><p>是一个水平可扩展，高可用性，多租户的日志聚合系统，Loki 是基于仅索引有关日志元数据的想法而构建的：<strong>标签</strong>（就像 Prometheus 标签一样）。日志数据本身被压缩然后并存储在对象存储（例如 S3 或 GCS）的块中，甚至存储在本地文件系统上，轻量级的索引和高度压缩的块简化了操作，并显著降低了 Loki 的成本，Loki 更适合中小团队。由于 Loki 使用和 Prometheus 类似的标签概念，所以如果你熟悉 Prometheus 那么将很容易上手，也可以直接和 Grafana 集成，只需要添加 Loki 数据源就可以开始查询日志数据了。</p><p>Loki 还提供了一个专门用于日志查询的 <code>LogQL</code> 查询语句，类似于 <code>PromQL</code>，通过 LogQL 我们可以很容易查询到需要的日志，也可以很轻松获取监控指标。Loki 还能够将 LogQL 查询直接转换为 Prometheus 指标。此外 Loki 允许我们定义有关 LogQL 指标的报警，并可以将它们和 Alertmanager 进行对接。</p><p>Loki技术栈中使用了以下组件。</p><ul><li><p>Promtail</p><p>用来将容器日志发送到 Loki 或者 Grafana 服务上的日志收集工具，该工具主要包括发现采集目标以及给日志流添加上 Label 标签 然后发送给 Loki，Promtail 的服务发现是基于 Prometheus 的服务发现机制实现的。</p><p>相当于 EFK 中的 Filebeat&#x2F;Fluentd ，用于采集日志并将其发送给 Loki 。</p></li><li><p>Loki</p><p>受 Prometheus 启发的可以水平扩展、高可用以及支持多租户的日志聚合系统，使用了和 Prometheus 相同的服务发现机制，将标签添加到日志流中而不是构建全文索引，从 Promtail 接收到的日志和应用的 metrics 指标就具有相同的标签集，不仅提供了更好的日志和指标之间的上下文切换，还避免了对日志进行全文索引。</p><p>相当于 EFK 中的 ElasticSearch ，用于存储日志和处理查询。</p></li><li><p>Grafana</p><p>一个用于监控和可视化观测的开源平台，支持非常丰富的数据源，在 Loki 技术栈中它专门用来展示来自 Prometheus 和 Loki 等数据源的时间序列数据，可进行查询、可视化、报警等操作，可以用于创建、探索和共享数据 Dashboard，鼓励数据驱动。</p><p>相当于 EFK 中的 Kibana ，用于 UI 的展示。</p></li></ul><p><strong>Loki的工作原理如下图所示：</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/12/20250712-131130.png" alt="Loki原理"></p><p>Loki 针对本地运行（或小规模运行）和水平扩展进行了优化，Loki 带有单一进程模式，可在一个进程中运行所有必需的微服务。单进程模式非常适合测试 Loki 或以小规模运行。为了实现水平可伸缩性，可以将 Loki 的服务拆分为单独的组件，从而使它们彼此独立地扩展。每个组件都产生一个用于内部请求的 gRPC 服务器和一个用于外部 API 请求的 HTTP 服务，所有组件都带有 HTTP 服务器，但是大多数只暴露就绪接口、运行状况和指标端点。</p><h2 id="1-Loki-组件"><a href="#1-Loki-组件" class="headerlink" title="1. Loki 组件"></a>1. Loki 组件</h2><p>Loki 运行哪个组件取决于命令行中的 <code>-target</code> 标志或 Loki 的配置文件中的 <code>target：&lt;string&gt;</code> 配置。 当 target 的值为 <code>all</code> 时，Loki 将在单进程中运行其所有组件。这称为 <code>单进程</code> 或 <code>单体模式</code> 。 <em>使用 Helm 安装 Loki 时，单体模式是默认部署方式</em>。</p><p>当 target 未设置为 all（即被设置为 <code>querier</code>、<code>ingester</code>、<code>query-frontend</code> 或 <code>distributor</code>），则可以说 Loki 在 <code>水平伸缩</code> 或 <code>微服务模式</code> 下运行。</p><p>Loki 的每个组件，例如 <code>ingester</code> 和 <code>distributors</code> 都使用 Loki 配置中定义的 gRPC 监听端口通过 gRPC 相互通信。当以单体模式运行组件时，仍然是这样的，尽管每个组件都以相同的进程运行，但它们仍将通过本地网络相互连接进行组件之间的通信。</p><p>单体模式非常适合于本地开发、小规模等场景，单体模式可以通过多个进程进行扩展，但有以下限制：</p><ul><li>当运行带有多个副本的单体模式时，当前无法使用本地索引和本地存储，因为每个副本必须能够访问相同的存储后端，并且本地存储对于并发访问并不安全。</li><li>各个组件无法独立缩放，因此读取组件的数量不能超过写入组件的数量。</li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/12/20250712-132416.png" alt="Loki组件"></p><h3 id="1-1-Distributor"><a href="#1-1-Distributor" class="headerlink" title="1.1 Distributor"></a>1.1 Distributor</h3><p><code>distributor</code> 服务负责处理客户端写入的日志，它本质上是日志数据写入路径中的<strong>第一站</strong>，一旦 <code>distributor</code> 收到日志数据，会将其拆分为多个批次，然后并行发送给多个 <code>ingester</code>。<code>distributor</code> 通过 gRPC 与 <code>ingester</code> 通信，它们都是无状态的，所以可以根据需要扩大或缩小规模。</p><p><strong>Hashing</strong></p><p><code>distributor</code> 将<strong>一致性 Hash</strong>和可配置的复制因子结合使用，以确定 <code>ingester</code> 服务的哪些实例应该接收指定的数据流。</p><p>流是一组与<strong>租户和唯一标签集</strong>关联的日志，使用租户 ID 和标签集对流进行 hash 处理，然后使用哈希查询要发送流的 <code>ingester</code>。</p><p>存储在 <strong>Consul&#x2F;Etcd</strong> 中的哈希环被用来实现一致性哈希，所有的 <code>ingester</code> 都会使用自己拥有的一组 Token 注册到哈希环中，每个 Token 是一个随机的无符号 32 位数字，与一组 Token 一起，<code>ingester</code> 将其状态注册到哈希环中，状态 <code>JOINING</code> 和 <code>ACTIVE</code> 都可以接收写请求，而 <code>ACTIVE</code> 和 <code>LEAVING</code> 的 <code>ingester</code> 可以接收读请求。在进行哈希查询时，<code>distributor</code> 只使用处于请求的适当状态的 ingester 的 Token。</p><p>为了进行哈希查找，<code>distributor</code> 找到最小合适的 Token，其值大于日志流的哈希值，当复制因子大于 1 时，属于不同 <code>ingester</code> 的下一个后续 Token（在环中顺时针方向）也将被包括在结果中。</p><p>这种哈希配置的效果是，一个 <code>ingester</code> 拥有的每个 Token 都负责一个范围的哈希值，如果有三个值为 0、25 和 50 的 Token，那么 3 的哈希值将被给予拥有 25 这个 Token 的 <code>ingester</code>，拥有 25 这个 Token 的 <code>ingester</code> 负责<code>1-25</code>的哈希值范围。</p><h3 id="1-2-Ingester"><a href="#1-2-Ingester" class="headerlink" title="1.2 Ingester"></a>1.2 Ingester</h3><p><code>ingester</code> 负责接收 <code>distributor</code>  发送过来的日志数据，存储日志的索引数据以及内容数据。此外 <code>ingester</code> 会验证摄取的日志行是否按照时间戳递增的顺序接收的（即每条日志的时间戳都比前面的日志晚一些），当 <code>ingester</code> 收到不符合这个顺序的日志时，该日志行会被拒绝并返回一个错误。</p><ul><li><p>如果传入的行与之前收到的行完全匹配（与之前的时间戳和日志文本都匹配），传入的行将被视为完全重复并被忽略。</p></li><li><p>如果传入的行与前一行的时间戳相同，但内容不同，则接受该日志行，表示同一时间戳有两个不同的日志行是可能的。</p></li></ul><p>来自每个唯一标签集的日志在内存中被建立成 <code>chunks(块)</code>，然后可以根据配置的时间间隔刷新到支持的后端存储。在下列情况下，块被压缩并标记为只读：</p><ul><li>当前块容量已满（该值可配置）</li><li>过了太长时间没有更新当前块的内容</li><li>刷新了</li></ul><p>每当一个数据块被压缩并标记为只读时，一个可写的数据块就会取代它。<em>如果一个 <code>ingester</code> 进程崩溃或突然退出，所有尚未刷新的数据都会丢失，Loki 通常配置为多个副本来降低这种风险</em>。</p><p>当向持久存储刷新时，该块将根据其租户、标签和内容进行哈希处理，这意味着具有相同数据副本的多个 <code>ingester</code> 实例不会将相同的数据两次写入备份存储中，但如果对其中一个副本的写入失败，则会在备份存储中创建多个不同的块对象。（当写入因子大于1时，比如：3， 那么日志数据将会由3个不同的 Ingester 共同处理。每个日志都会计算出一个唯一hash值，同一个日志在不同的Ingester中 hash 值是相同的，正常情况下只会往持久存储中（入S3，minio）写入一次，如果某个Ingester 写入失败了，可能导入数据被重复写入持久存储中。）</p><p><strong>WAL</strong></p><p>上面我们提到了 <code>ingester</code> 将数据临时存储在内存中，如果发生了崩溃，可能会导致数据丢失，而 <code>WAL</code> 就可以帮助我们来提高这方面的可靠性。</p><p>在计算机领域，WAL（Write-ahead logging，预写式日志）是数据库系统提供原子性和持久化的一系列技术。</p><p>在使用 WAL 的系统中，所有的修改都先被写入到日志中，然后再被应用到系统状态中。通常包含 redo 和 undo 两部分信息。为什么需要使用 WAL，然后包含 redo 和 undo 信息呢？举个例子，如果一个系统直接将变更应用到系统状态中，那么在机器断电重启之后系统需要知道操作是成功了，还是只有部分成功或者是失败了（为了恢复状态）。如果使用了 WAL，那么在重启之后系统可以通过比较日志和系统状态来决定是继续完成操作还是撤销操作。</p><p><code>redo log</code> 称为重做日志，每当有操作时，在数据变更之前将操作写入 <code>redo log</code>，这样当发生断电之类的情况时系统可以在重启后继续操作。<code>undo log</code> 称为撤销日志，当一些变更执行到一半无法完成时，可以根据撤销日志恢复到变更之前的状态。</p><p>Loki 中的 WAL 记录了传入的数据，并将其存储在本地文件系统中，以保证在进程崩溃的情况下持久保存已确认的数据。重新启动后，Loki 将<strong>重放</strong>日志中的所有数据，然后将自身注册，准备进行后续写操作。这使得 Loki 能够保持在内存中缓冲数据的性能和成本优势，以及持久性优势（一旦写被确认，它就不会丢失数据）。</p><p>Loki 通过校验日志的 Hash 值，以及在 WAL 中创建检查点，确保重放时数据不会重复。</p><h3 id="1-3-Querier"><a href="#1-3-Querier" class="headerlink" title="1.3 Querier"></a>1.3 Querier</h3><p><code>Querier</code> 接收日志数据查询、聚合统计请求，使用 LogQL 查询语言处理查询，从 <code>ingester</code> 和长期存储中获取日志。</p><p>查询器查询所有 <code>ingester</code> 的内存数据，然后再到后端存储运行相同的查询。由于复制因子，查询器有可能会收到重复的数据。为了解决这个问题，查询器在内部对具有相同纳秒时间戳、标签集和日志信息的数据进行重复数据删除。</p><h3 id="1-4-Query-Frontend"><a href="#1-4-Query-Frontend" class="headerlink" title="1.4 Query Frontend"></a>1.4 Query Frontend</h3><p><code>Query Frontend</code> 查询前端是一个可选的服务，可以用来加速读取路径。当查询前端就位时，将传入的查询请求定向到查询前端，而不是 <code>querier</code>, 为了执行实际的查询，群集中仍需要 <code>querier</code> 服务。</p><p>查询前端在内部执行一些查询调整，并在内部队列中保存查询。<code>querier</code> 作为 workers 从队列中提取作业，执行它们，并将它们返回到查询前端进行汇总。<code>querier</code> 需要配置查询前端地址，以便允许它们连接到查询前端。</p><p>查询前端是无状态的，然而，由于内部队列的工作方式，建议运行几个查询前台的副本，以获得公平调度的好处，在大多数情况下，两个副本应该足够了。</p><p><strong>队列</strong></p><p>查询前端的排队机制用于：</p><ul><li>确保可能导致 <code>querier</code> 出现内存不足（OOM）错误的查询在失败时被重试。这样管理员就可以为查询提供稍低的内存，或者并行运行更多的小型查询，这有助于降低总成本。</li><li>通过使用先进先出队列（FIFO）将多个大型请求分配到所有 <code>querier</code> 上，以防止在单个 <code>querier</code> 中进行多个大型请求。</li><li>通过在租户之间公平调度查询。</li></ul><p><strong>分割</strong></p><p>查询前端将较大的查询分割成多个较小的查询，在下游 <code>querier</code> 上并行执行这些查询，并将结果再次拼接起来。这可以防止大型查询在单个查询器中造成内存不足的问题，并有助于更快地执行这些查询。</p><p><strong>缓存</strong></p><p>查询前端支持缓存查询结果，并在后续查询中重复使用。如果缓存的结果不完整，查询前端会计算所需的子查询，并在下游 <code>querier</code> 上并行执行这些子查询。查询前端可以选择将查询与其 <code>step</code> 参数对齐，以提高查询结果的可缓存性。</p><p><strong>举例</strong></p><p>假设你用 Grafana 查询 Loki 中的日志数据，系统中有 Query Frontend 和多个 Querier：</p><ol><li>客户端发送查询：<ul><li>你在 Grafana 输入查询 {app&#x3D;”frontend”} |~ “error”，请求发送到 Query Frontend。</li></ul></li><li>Query Frontend 处理：<ul><li>Query Frontend 接收请求，可能将查询拆分成多个子查询（比如按时间范围分成 3 段）。</li><li>这些子查询被放入内部队列，等待处理。</li></ul></li><li>Querier 执行查询：<ul><li>集群中有 3 个 Querier（Q1、Q2、Q3），它们连接到 Query Frontend，从队列中领取子查询任务。</li><li>Q1 取第一个子查询，Q2 取第二个，Q3 取第三个，分别去 ingester 或 S3 查询日志数据。</li></ul></li><li>结果汇总：<ul><li>Querier 完成查询后，将结果返回给 Query Frontend。</li><li>Query Frontend 合并 3 个子查询的结果，形成完整的日志列表，返回给 Grafana。</li></ul></li><li>多个副本：<ul><li>如果有 2 个 Query Frontend 副本，客户端请求可能随机分配到其中一个。</li><li>Querier 同时连接到两个副本的队列，动态领取任务，确保负载均衡。</li></ul></li></ol><h3 id="1-5-读取路径"><a href="#1-5-读取路径" class="headerlink" title="1.5 读取路径"></a>1.5 读取路径</h3><p>日志读取路径的流程如下所示：</p><ul><li>查询器收到一个对数据的 HTTP 请求。</li><li>查询器将查询传递给所有 <code>ingester</code>。</li><li><code>ingester</code> 收到读取请求，并返回与查询相匹配的数据。</li><li>如果没有 <code>ingester</code> 返回数据，查询器会从后端存储加载数据，并对其运行查询。</li><li>查询器对所有收到的数据进行迭代和重复计算，通过 HTTP 连接返回最后一组数据。</li></ul><p><strong>举个例子</strong></p><p>假设你在 Grafana 中查询 {app&#x3D;”frontend”} |~ “error”，时间范围是过去 6 小时：</p><ol><li>客户端发送请求：<ul><li>Grafana 通过 HTTP 发送查询到 Querier。</li></ul></li><li>Querier 分发查询：<ul><li>Querier 将查询 {app&#x3D;”frontend”} |~ “error” 广播给集群中的 3 个 Ingester（I1、I2、I3）。</li></ul></li><li>Ingester 处理：<ul><li>I1 发现自己有部分匹配的日志（比如过去 2 小时的数据），返回这些日志。</li><li>I2 和 I3 可能也有部分数据（由于复制因子），返回相同的或不同的日志。</li></ul></li><li>后端存储查询：<ul><li>如果查询的 6 小时范围超出了 Ingester 的内存存储（比如 Ingester 只存 4 小时数据），Querier 会从 S3 加载更老的块（4-6 小时的数据），并执行查询。</li></ul></li><li>合并和去重：<ul><li>Querier 收集 I1、I2、I3 和 S3 返回的数据。</li><li>如果 I1 和 I2 返回了相同的日志（由于复制），Querier 通过哈希值或时间戳去重。</li><li>Querier 按时间排序所有日志，生成最终结果。</li></ul></li><li>返回结果：<ul><li>Querier 通过 HTTP 返回整理好的日志列表，Grafana 显示这些日志。</li></ul></li></ol><h3 id="1-6-写入路径"><a href="#1-6-写入路径" class="headerlink" title="1.6 写入路径"></a>1.6 写入路径</h3><p>整体的日志写入路径如下所示：</p><ul><li><code>distributor</code> 收到一个 HTTP 请求，以存储流的数据。</li><li>每个流都使用哈希环进行哈希操作。</li><li><code>distributor</code> 将每个流发送到合适的 <code>ingester</code> 和他们的副本（基于配置的复制因子）。</li><li>每个 <code>ingester</code> 将为日志流数据创建一个块或附加到一个现有的块上。每个租户和每个标签集的块是唯一的。</li></ul><h2 id="2-Promtail"><a href="#2-Promtail" class="headerlink" title="2. Promtail"></a>2. Promtail</h2><p><a href="https://grafana.com/docs/loki/latest/send-data/promtail/">官方文档</a></p><p>promtail 是 loki 架构中最常用的采集器, 相当于 EFK 中的 filebeat&#x2F;fluentd 。</p><p>Promtail 是 Loki 官方支持的日志采集端，在需要采集日志的节点上运行采集代理，再统一发送到 Loki 进行处理。除了使用 Promtail，社区还有很多采集日志的组件，比如 fluentd、fluent bit、logstash 等，也都支持发送到 Loki。</p><p>但是 Promtail 是运行 Kubernetes 时的首选客户端，因为你可以将其配置为自动从 Promtail 运行的同一节点上运行的 Pod 中抓取日志。Promtail 和 Prometheus 在 Kubernetes 中一起运行，还可以实现非常强大的调试功能，如果 Prometheus 和 Promtail 使用相同的标签，用户还可以使用 Grafana 根据标签集在指标和日志之间切换。</p><p>它的主要工作流程:</p><ul><li>使用 fsnotify 监听指定目录下（例如：&#x2F;var&#x2F;log&#x2F;*.log）的文件创建与删除</li><li>对每个活跃的日志文件起一个 goroutine 进行类似 tail -f 的读取，读取到的内容发送给 channel</li><li>有一个单独的 goroutine 会读取 channel 中的日志行，分批并附加上标签后推送给 Loki</li></ul><h1 id="二、使用YAML部署-Loki"><a href="#二、使用YAML部署-Loki" class="headerlink" title="二、使用YAML部署 Loki"></a>二、使用YAML部署 Loki</h1><p>这次部署的 loki 整体架构如下, </p><ul><li>loki 使用 <code>StatefulSet</code> 的方式运行,</li><li>Promtail 以 <code>DaemonSet</code> 的方式运行在 k8s 集群的每个节点</li><li>Grafana 以 Deploment 方式运行，通过 Ingress 暴露访问端口</li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/12/20250712-161149.jpeg" alt="Loki-Promtail部署"></p><h2 id="1-Promtail部署"><a href="#1-Promtail部署" class="headerlink" title="1. Promtail部署"></a>1. Promtail部署</h2><h3 id="1-1-Promtail-部署文件"><a href="#1-1-Promtail-部署文件" class="headerlink" title="1.1 Promtail 部署文件"></a>1.1 Promtail 部署文件</h3><p>资源清单：<code>loki-promtail.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">logging</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.ServiceAccount</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki-promtail</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">promtail</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.集群角色</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">promtail-clusterrole</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">promtail</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 核心组</span>    <span class="attr">resources:</span>      <span class="bullet">-</span> <span class="string">nodes</span>      <span class="bullet">-</span> <span class="string">nodes/proxy</span>      <span class="bullet">-</span> <span class="string">services</span>      <span class="bullet">-</span> <span class="string">endpoints</span>      <span class="bullet">-</span> <span class="string">pods</span>    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># 4.集群角色绑定</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">promtail-clusterrolebinding</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">promtail</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">loki-promtail</span>    <span class="attr">kind:</span> <span class="string">ServiceAccount</span>    <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">roleRef:</span>  <span class="attr">name:</span> <span class="string">promtail-clusterrole</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 5.ConfigMap</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki-promtail</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">promtail</span><span class="attr">data:</span>  <span class="attr">promtail.yaml:</span> <span class="string">|</span><span class="string">    client:                # 定义 Promtail 如何与 Loki 服务器通信，发送收集到的日志</span><span class="string">      backoff_config:      # 配置当请求失败时的重试策略</span><span class="string">        max_period: 1s     # 重试间隔的最大时间为 1 秒</span><span class="string">        max_retries: 20    # 最多重试 20 次</span><span class="string">        min_period: 500ms  # 重试间隔的最小时间为 500 毫秒</span><span class="string">      batchsize: 10240        # 每次发送到 Loki 的日志批次最大大小为 10240 字节（约 10KB）</span><span class="string">      batchwait: 2s           # 即使批次大小未达到 batchsize，Promtail 最多等待 2 秒后也会发送日志。这是为了避免延迟过高</span><span class="string">      external_labels: &#123;&#125;     # 为所有发送到 Loki 的日志添加静态标签，这里为空（可以手动添加标签，如 env: prod）</span><span class="string">      timeout: 15s            # 等待 Loki 服务器响应的最大时间为 15 秒，超时后请求失败并触发重试</span><span class="string">    positions:</span><span class="string">      filename: /run/promtail/positions.yaml # Promtail 使用一个文件来记录它读取日志文件的位置（类似于书签），以避免重复读取或遗漏日志</span><span class="string">    server:</span><span class="string">      http_listen_port: 3101  # 配置 Promtail 自身的 HTTP 服务，用于暴露监控指标或调试</span><span class="string">    target_config:</span><span class="string">      sync_period: 10s        # 控制 Promtail 如何定期同步其发现目标（如 Kubernetes Pods）的元数据。</span><span class="string">    scrape_configs:           # 定义 Promtail 如何发现和收集 Kubernetes 集群中的日志。scrape_configs 包含多个任务（job），每个任务针对不同类型的 Pod 进行日志收集</span><span class="string">      - job_name: kubernetes-pods-name  # 收集由 name 标签定义的 Pod 日志</span><span class="string">        pipeline_stages:</span><span class="string">          - docker: &#123;&#125;                  # 指定日志格式为 Docker 格式（JSON 格式的容器日志）。Promtail 会解析 Docker 容器日志，提取时间戳和日志内容</span><span class="string">        kubernetes_sd_configs:</span><span class="string">          - role: pod                   # Promtail 通过 Kubernetes 服务发现（Service Discovery）查找 Pod，收集它们的日志</span><span class="string">        relabel_configs:</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_name  # 从 Pod 的标签中提取 name 标签的值，设置为 __service__ 标签</span><span class="string">            target_label: __service__             # Kubernetes Pod 可能有标签 name=my-app，Promtail 将其值 my-app 保存为 __service__，用于标识服务</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_node_name   # 将 Pod 所在节点的名称设置为 __host__ 标签</span><span class="string">            target_label: __host__                # 记录 Pod 运行在哪个 Kubernetes 节点上（比如 node-1），便于日志追踪</span><span class="string">          - action: drop                          # 如果 __service__ 标签为空（即 Pod 没有 name 标签），丢弃该 Pod，不收集其日志</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __service__</span><span class="string">          - action: labelmap                      # 将所有以 __meta_kubernetes_pod_label_ 开头的元数据标签（如 __meta_kubernetes_pod_label_app）映射为普通标签</span><span class="string">            regex: __meta_kubernetes_pod_label_(.+)</span><span class="string">          - action: replace                       # 将命名空间（namespace）和 __service__ 组合成 job 标签，格式为 namespace/service</span><span class="string">            replacement: $1</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace       # 如果命名空间是 default，__service__ 是 my-app，则 job 标签为 default/my-app</span><span class="string">              - __service__</span><span class="string">            target_label: job</span><span class="string">          - action: replace                       # 将 Pod 的命名空间设置为 namespace 标签</span><span class="string">            source_labels:                        # 如果 Pod 在 default 命名空间，日志会带上 namespace=default 标签</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">            target_label: namespace</span><span class="string">          - action: replace                       # 将 Pod 的名称设置为 pod 标签</span><span class="string">            source_labels:                        # 如果 Pod 名为 my-app-1234，日志会带上 pod=my-app-1234 标签</span><span class="string">              - __meta_kubernetes_pod_name</span><span class="string">            target_label: pod</span><span class="string">          - action: replace                       # 将容器的名称设置为 container 标签</span><span class="string">            source_labels:                        # 如果容器名为 app-container，日志会带上 container=app-container 标签</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: container</span><span class="string">          - replacement: /var/log/pods/*$1/*.log  # 生成日志文件的路径，告诉 Promtail 从哪里读取日志，路径格式为 /var/log/pods/*&lt;pod_uid&gt;/&lt;container_name&gt;.log</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_uid               # Pod 的唯一 ID</span><span class="string">              - __meta_kubernetes_pod_container_name    # 容器名称</span><span class="string">            target_label: __path__                      # 例如，Pod UID 是 abc-123，容器名为 app-container，日志路径为 /var/log/pods/*abc-123/app-container.log</span><span class="string">      - job_name: kubernetes-pods-app # 收集由 app 标签定义的 Pod 日志</span><span class="string">        pipeline_stages:</span><span class="string">          - docker: &#123;&#125;</span><span class="string">        kubernetes_sd_configs:</span><span class="string">          - role: pod</span><span class="string">        relabel_configs:</span><span class="string">          - action: drop</span><span class="string">            regex: .+</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_name</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_app</span><span class="string">            target_label: __service__</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_node_name</span><span class="string">            target_label: __host__</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __service__</span><span class="string">          - action: labelmap</span><span class="string">            regex: __meta_kubernetes_pod_label_(.+)</span><span class="string">          - action: replace</span><span class="string">            replacement: $1</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">              - __service__</span><span class="string">            target_label: job</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">            target_label: namespace</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_name</span><span class="string">            target_label: pod</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: container</span><span class="string">          - replacement: /var/log/pods/*$1/*.log</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_uid</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: __path__</span><span class="string">      - job_name: kubernetes-pods-direct-controllers # 收集由直接控制器（如 Deployment）管理的 Pod 日志</span><span class="string">        pipeline_stages:</span><span class="string">          - docker: &#123;&#125;</span><span class="string">        kubernetes_sd_configs:</span><span class="string">          - role: pod</span><span class="string">        relabel_configs:</span><span class="string">          - action: drop # 首先检查 __meta_kubernetes_pod_label_name（name 标签）</span><span class="string">            regex: .+       # 如果 name 标签存在（匹配正则 .+，即非空），执行 drop 动作，丢弃该 Pod</span><span class="string">            separator: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_name</span><span class="string">              - __meta_kubernetes_pod_label_app</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;[0-9a-z-.]+-[0-9a-f]&#123;8,10&#125;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_controller_name</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_controller_name</span><span class="string">            target_label: __service__</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_node_name</span><span class="string">            target_label: __host__</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __service__</span><span class="string">          - action: labelmap</span><span class="string">            regex: __meta_kubernetes_pod_label_(.+)</span><span class="string">          - action: replace</span><span class="string">            replacement: $1</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">              - __service__</span><span class="string">            target_label: job</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">            target_label: namespace</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_name</span><span class="string">            target_label: pod</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: container</span><span class="string">          - replacement: /var/log/pods/*$1/*.log</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_uid</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: __path__</span><span class="string">      - job_name: kubernetes-pods-indirect-controller # 收集由间接控制器（如 ReplicaSet）管理的 Pod 日志</span><span class="string">        pipeline_stages:</span><span class="string">          - docker: &#123;&#125;</span><span class="string">        kubernetes_sd_configs:</span><span class="string">          - role: pod</span><span class="string">        relabel_configs:</span><span class="string">          - action: drop        # 如果 Pod 有 name 或 app 标签，触发 drop 动作，丢弃该 Pod</span><span class="string">            regex: .+</span><span class="string">            separator: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_name</span><span class="string">              - __meta_kubernetes_pod_label_app</span><span class="string">          - action: keep        # 如果 Pod 由 ReplicaSet 控制器管理（控制器名称匹配 xxx-12345678 模式），触发 keep 动作，保留该 Pod</span><span class="string">            regex: &#x27;[0-9a-z-.]+-[0-9a-f]&#123;8,10&#125;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_controller_name</span><span class="string">          - action: replace</span><span class="string">            regex: &#x27;([0-9a-z-.]+)-[0-9a-f]&#123;8,10&#125;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_controller_name</span><span class="string">            target_label: __service__</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_node_name</span><span class="string">            target_label: __host__</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __service__</span><span class="string">          - action: labelmap</span><span class="string">            regex: __meta_kubernetes_pod_label_(.+)</span><span class="string">          - action: replace</span><span class="string">            replacement: $1</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">              - __service__</span><span class="string">            target_label: job</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">            target_label: namespace</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_name</span><span class="string">            target_label: pod</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: container</span><span class="string">          - replacement: /var/log/pods/*$1/*.log</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_uid</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: __path__</span><span class="string">      - job_name: kubernetes-pods-static # 收集静态配置的 Pod 日志（基于特定的注解）</span><span class="string">        pipeline_stages:</span><span class="string">          - docker: &#123;&#125;</span><span class="string">        kubernetes_sd_configs:</span><span class="string">          - role: pod</span><span class="string">        relabel_configs:</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_annotation_kubernetes_io_config_mirror</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_label_component</span><span class="string">            target_label: __service__</span><span class="string">          - source_labels:</span><span class="string">              - __meta_kubernetes_pod_node_name</span><span class="string">            target_label: __host__</span><span class="string">          - action: drop</span><span class="string">            regex: &#x27;&#x27;</span><span class="string">            source_labels:</span><span class="string">              - __service__</span><span class="string">          - action: labelmap</span><span class="string">            regex: __meta_kubernetes_pod_label_(.+)</span><span class="string">          - action: replace</span><span class="string">            replacement: $1</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">              - __service__</span><span class="string">            target_label: job</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_namespace</span><span class="string">            target_label: namespace</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_name</span><span class="string">            target_label: pod</span><span class="string">          - action: replace</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: container</span><span class="string">          - replacement: /var/log/pods/*$1/*.log</span><span class="string">            separator: /</span><span class="string">            source_labels:</span><span class="string">              - __meta_kubernetes_pod_annotation_kubernetes_io_config_mirror</span><span class="string">              - __meta_kubernetes_pod_container_name</span><span class="string">            target_label: __path__</span><span class="string"></span><span class="meta">---</span><span class="meta"></span><span class="comment"># 6.DaemonSet</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">DaemonSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki-promtail</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">promtail</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">promtail</span>  <span class="attr">updateStrategy:</span> <span class="comment"># 更新策略</span>    <span class="attr">rollingUpdate:</span>      <span class="attr">maxUnavailable:</span> <span class="number">1</span> <span class="comment"># 滚动更新时最多一个pod不可用，即同一时刻只允许一个节点上的Pod不可用</span>    <span class="attr">type:</span> <span class="string">RollingUpdate</span> <span class="comment"># 滚动更新</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">promtail</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">loki-promtail</span> <span class="comment"># 绑定的SA</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">promtail</span>          <span class="attr">image:</span> <span class="string">grafana/promtail:2.9.2</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">-config.file=/etc/promtail/promtail.yaml</span>        <span class="comment"># 指定 Promtail 的配置文件路径，位于容器内的 /etc/promtail/promtail.yaml（由 ConfigMap 提供）</span>            <span class="bullet">-</span> <span class="string">-client.url=http://loki:3100/loki/api/v1/push</span>   <span class="comment"># 指定 Loki 服务器的地址，Promtail 将日志发送到 http://loki:3100/loki/api/v1/push</span>          <span class="attr">env:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">HOSTNAME</span>              <span class="attr">valueFrom:</span>                <span class="attr">fieldRef:</span>                  <span class="attr">apiVersion:</span> <span class="string">v1</span>                  <span class="attr">fieldPath:</span> <span class="string">spec.nodeName</span>      <span class="comment"># 从 Kubernetes Pod 的元数据中获取节点名称（如 k8s-node01）</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/promtail</span>          <span class="comment"># 挂载 config 卷，包含 Promtail 配置文件（promtail.yaml）</span>              <span class="attr">name:</span> <span class="string">config</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/run/promtail</span>          <span class="comment"># 挂载 run 卷，存储 Promtail 的位置文件（positions.yaml），用于记录日志读取偏移量</span>              <span class="attr">name:</span> <span class="string">run</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/data/docker/containers</span>    <span class="comment"># 挂载 docker 卷，包含 Docker 容器的日志文件（路径需要根据容器运行时调整,如果使用 containerd 可忽略）</span>              <span class="attr">name:</span> <span class="string">docker</span>              <span class="attr">readOnly:</span> <span class="literal">true</span>        <span class="comment"># 挂载卷只读</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/log/pods</span>              <span class="comment"># 挂载 pods 卷，包含 Kubernetes Pod 的日志文件（标准路径）</span>              <span class="attr">name:</span> <span class="string">pods</span>              <span class="attr">readOnly:</span> <span class="literal">true</span>        <span class="comment"># 挂载卷只读</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3101</span>   <span class="comment">#Promtail 容器在 3101 端口提供 HTTP 服务，与 promtail.yaml 中的 server.http_listen_port: 3101 一致</span>              <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">securityContext:</span>          <span class="comment"># 定义容器的安全上下文，控制运行权限和文件系统访问</span>            <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span>    <span class="comment"># 容器根文件系统为只读，增强安全性，防止意外修改。Promtail 需要 root 权限访问节点上的日志文件（如 /var/log/pods）</span>            <span class="attr">runAsGroup:</span> <span class="number">0</span>                   <span class="comment"># 容器以 root 用户（UID 0）运行</span>            <span class="attr">runAsUser:</span> <span class="number">0</span>                    <span class="comment"># 容器以 root 组（GID 0）运行</span>          <span class="attr">readinessProbe:</span>             <span class="comment"># 定义就绪探针，检查 Promtail 容器是否准备好提供服务</span>            <span class="attr">httpGet:</span>              <span class="attr">path:</span> <span class="string">/ready</span>            <span class="comment"># 访问 /ready 端点</span>              <span class="attr">port:</span> <span class="string">http</span>              <span class="comment"># 使用命名为 http 的端口（3101）</span>              <span class="attr">scheme:</span> <span class="string">HTTP</span>            <span class="attr">failureThreshold:</span> <span class="number">5</span>       <span class="comment"># 连续 5 次探测失败后，标记容器为未就绪</span>            <span class="attr">initialDelaySeconds:</span> <span class="number">10</span>   <span class="comment"># 容器启动后等待 10 秒开始第一次探测</span>            <span class="attr">periodSeconds:</span> <span class="number">10</span>         <span class="comment"># 每 10 秒探测一次</span>            <span class="attr">successThreshold:</span> <span class="number">1</span>       <span class="comment"># 一次探测成功即标记为就绪</span>            <span class="attr">timeoutSeconds:</span> <span class="number">1</span>         <span class="comment"># 每次探测的超时时间为 1 秒</span>      <span class="attr">tolerations:</span>        <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">Exists</span>            <span class="comment"># 允许 Pod 调度到带有任何污点（taint）的节点上</span>      <span class="attr">volumes:</span>                <span class="comment"># 定义 Pod 使用的卷，供容器挂载</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span>          <span class="attr">configMap:</span>            <span class="attr">defaultMode:</span> <span class="number">420</span>              <span class="comment"># 文件权限为 0644（即 rw-r--r--），适合配置文件（420为十进制，0644是Linux系统中使用的八进制）</span>            <span class="attr">name:</span> <span class="string">loki-promtail</span>           <span class="comment"># 使用名为 loki-promtail 的 ConfigMap（即之前提供的配置）</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/run/promtail</span>           <span class="comment"># 挂载节点上的 /run/promtail 目录</span>            <span class="attr">type:</span> <span class="string">&quot;&quot;</span>                      <span class="comment"># 默认类型，目录不存在时不会自动创建</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">docker</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/data/docker/containers</span> <span class="comment"># 挂载节点上的 Docker 容器日志目录</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pods</span>          <span class="attr">hostPath:</span>            <span class="attr">path:</span> <span class="string">/var/log/pods</span>           <span class="comment"># 挂载节点上的 Kubernetes Pod 日志目录</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f loki-promtail.yaml</code></pre><p><strong>查看资源</strong></p><pre><code class="highlight bash"><span class="comment"># 查看命名空间</span>$ kubectl get nsNAME              STATUS   AGEdefault           Active   13dharbor            Active   7d4hkube-node-lease   Active   13dkube-public       Active   13dkube-system       Active   13dlogging           Active   2d4h<span class="comment"># 查看 ServiceAccount</span>$ kubectl get sa -n loggingNAME            SECRETS   AGEdefault         0         2d4hloki-promtail   0         2d4h<span class="comment"># 查看集群角色</span>$ kubectl get ClusterRole | grep promtailpromtail-clusterrole<span class="comment"># 查看集群角色绑定</span>$ kubectl get ClusterRoleBinding | grep promtailpromtail-clusterrolebinding                              ClusterRole/promtail-clusterrole                                                   2d4h<span class="comment"># 查看 ConfigMap</span>$ kubectl get cm -n loggingNAME               DATA   AGEkube-root-ca.crt   1      2d4hloki-promtail      1      2d1h<span class="comment"># 查看 DaemonSet</span>$ kubectl get ds -n loggingNAME            DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGEloki-promtail   4         4         4       4            4           &lt;none&gt;          27m<span class="comment"># 查看Pod</span>$ kubectl get pods -n loggingNAME                  READY   STATUS    RESTARTS   AGEloki-promtail-lsqsg   1/1     Running   0          27mloki-promtail-r7vjh   1/1     Running   0          27mloki-promtail-szd8m   1/1     Running   0          27mloki-promtail-whffb   1/1     Running   0          27m</code></pre><h3 id="1-2-scrape-configs-配置详解"><a href="#1-2-scrape-configs-配置详解" class="headerlink" title="1.2 scrape_configs 配置详解"></a>1.2 scrape_configs 配置详解</h3><p><code>scrape_configs</code> 配置了 Promtail 如何使用指定的发现方法从一系列目标中抓取日志，类似于 Prometheus 中的抓取配置。</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">任务名称，用于在 Promtail 中识别该抓取配置的名称。</span>job_name: &lt;string&gt;<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">描述如何对目标日志进行结构化</span>[pipeline_stages: &lt;pipeline_stages&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">如何从 jounal 抓取日志</span>[journal: &lt;journal_config&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">如何从 syslog 抓取日志</span>[syslog: &lt;syslog_config&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">如何通过 Loki push API 接收日志 (例如从其他 Promtail 或 Docker Logging Driver 中获取的数据)</span>[loki_push_api: &lt;loki_push_api_config&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">描述了如何 relabel 目标</span>relabel_configs:  - [&lt;relabel_config&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">抓取日志静态目标配置</span>static_configs:  - [&lt;static_config&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">包含要抓取的目标文件</span>file_sd_configs:  - [&lt;file_sd_configs&gt;]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">基于kubernetes的自动发现配置</span>kubernetes_sd_configs:  - [&lt;kubernetes_sd_config&gt;]</code></pre><p><strong>relabel_configs</strong></p><p><code>Relabeling</code> 是一个强大的工具，可以在日志被抓取之前动态地重写其标签集。每个抓取配置可以配置多个 <code>relabeling</code> 步骤，按照它们在配置文件中出现的顺序应用于每个目标的标签集。和 Prometheus 中的 Relabel 操作也非常类似。</p><p>在 <code>relabeling</code> 之后，如果 <code>instance</code> 标签在 relabeling 的时候没有被设置，则默认设置为 <code>__address__</code> 的值。<code>__param_&lt;name&gt;</code> 标签被设置为第一个传递的 URL 参数 <code>&lt;name&gt;</code> 的值。</p><p>在 <code>relabeling</code> 阶段，以 <code>__meta_</code> 为前缀的额外标签也是可用的，它们是由提供目标的服务发现机制设置的，不同的机制之间有所不同。</p><p>在目标 <code>relabeling</code> 完成后，以 <code>__</code> 开头的标签将从标签集中删除。</p><p>如果一个 <code>relabeling</code> 操作只需要临时存储一个标签值（作为后续重新标注步骤的输入），则可以使用 <code>__tmp</code> 标签名称前缀。</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">从现有标签中选择 values 值的源标签</span><span class="meta prompt_"># </span><span class="language-bash">它们的内容使用配置的分隔符连接起来，并与配置的正则表达式相匹配，以进行替换、保留和删除操作。</span>[ source_labels: &#x27;[&#x27; &lt;labelname&gt; [, ...] &#x27;]&#x27; ]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">连接源标签值之间的分隔符</span>[ separator: &lt;string&gt; | default = ; ]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">在一个 replace 替换操作后结果值被写入的标签</span><span class="meta prompt_"># </span><span class="language-bash">它对替换动作是强制性的，Regex 捕获组是可用的。</span>[ target_label: &lt;labelname&gt; ]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">正则表达式，提取的值与之匹配</span>[ regex: &lt;regex&gt; | default = (.*) ][ modulus: &lt;uint64&gt; ]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">Replacement 值：如果正则表达式匹配，则对其进行 regex 替换</span>[ replacement: &lt;string&gt; | default = $1 ]<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">根据正则匹配结果执行的动作</span>[ action: &lt;relabel_action&gt; | default = replace ]</code></pre><p><code>&lt;regex&gt;</code> 是任何有效的 <code>RE2</code> 正则表达式，它是 <code>replace</code>、<code>keep</code>、<code>drop</code>、<code>labelmap</code>、<code>labeldrop</code> 和 <code>labelkeep</code> 操作的必要条件。</p><p><code>&lt;relabel_action&gt;</code> 决定了要采取的 <code>relabeling</code> 动作：</p><ul><li><code>replace</code>：将正则表达式与连接的 <code>source_labels</code> 匹配，然后设置 <code>target_label</code> 为 <code>replacement</code>，用 replacement 中的匹配组引用（${1}、${2}…）替换其值，如果正则表达式不匹配，则不会进行替换。</li><li><code>keep</code>：删除那些 regex 与 <code>source_labels</code> 不匹配的目标。</li><li><code>drop</code>：删除与 regex 相匹配的 <code>source_labels</code> 目标。</li><li><code>hashmod</code>：将 <code>target_label</code> 设置为 <code>source_labels</code> 的哈希值的模。</li><li><code>labelmap</code>：将正则表达式与所有标签名称匹配，然后将匹配的标签值复制到由 <code>replacement</code> 给出的标签名中，replacement 中的匹配组引用（${1}, ${2}, …）由其值代替。</li><li><code>labeldrop</code>：将正则表达式与所有标签名称匹配，任何匹配的标签都将从标签集中删除。</li><li><code>labelkeep</code>：将正则表达式与所有标签名称匹配，任何不匹配的标签将被从标签集中删除。</li></ul><p>关于 Promotail 配置更加详细的介绍，见：<a href="https://www.qikqiak.com/k3s/logging/loki/promtail/">https://www.qikqiak.com/k3s/logging/loki/promtail/</a></p><h2 id="2-Loki-部署"><a href="#2-Loki-部署" class="headerlink" title="2. Loki 部署"></a>2. Loki 部署</h2><h3 id="2-1-安装NFS"><a href="#2-1-安装NFS" class="headerlink" title="2.1 安装NFS"></a>2.1 安装NFS</h3><p>安装 NFS,配置存储卷自动分配 PV，用于持久化日志数据。</p><p>这里选用 k8s-master (10.20.1.139) 作为 nfs 服务端，其它节点作为 nfs 客户端</p><h4 id="2-1-1-安装-NFS-服务"><a href="#2-1-1-安装-NFS-服务" class="headerlink" title="2.1.1 安装 NFS 服务"></a>2.1.1 安装 NFS 服务</h4><blockquote><p>master节点、node01、node02、node03 节点都需要安装执行</p></blockquote><pre><code class="highlight bash">$ yum install -y nfs-utils rpcbind</code></pre><h4 id="2-1-2-创建共享目录"><a href="#2-1-2-创建共享目录" class="headerlink" title="2.1.2 创建共享目录"></a>2.1.2 创建共享目录</h4><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash"><span class="comment"># 创建 共享目录</span>$ <span class="built_in">mkdir</span> -p /root/data/loki/<span class="comment"># 目录提权</span><span class="built_in">chmod</span> 777 /root/data/loki/<span class="comment"># 变更用户组</span><span class="built_in">chown</span> nobody /root/data/loki/</code></pre><h4 id="2-1-3-编辑共享目录读写配置"><a href="#2-1-3-编辑共享目录读写配置" class="headerlink" title="2.1.3 编辑共享目录读写配置"></a>2.1.3 编辑共享目录读写配置</h4><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash">$ vim /etc/exports/root/data     10.20.1.0/24(rw,fsid=0,no_root_squash)/root/data/loki       10.20.1.0/24(rw,no_root_squash,no_all_squash,no_subtree_check,<span class="built_in">sync</span>)</code></pre><p>这里使用的是 NFS4 服务，上面的配置表示 10.20.1.0&#x2F;24 网段的 ip 都可以与 nfs 主服务器共享 <code>/root/data/prometheus</code> 目录内容</p><h4 id="2-1-4-启动NFS服务"><a href="#2-1-4-启动NFS服务" class="headerlink" title="2.1.4 启动NFS服务"></a>2.1.4 启动NFS服务</h4><blockquote><p>集群内所有节点都需要操作</p></blockquote><pre><code class="highlight bash"> <span class="comment"># 启动服务</span>$ systemctl start rpcbind$ systemctl restart nfs-server.service<span class="comment"># 设置开机自启</span>$ systemctl <span class="built_in">enable</span> rpcbind$ systemctl <span class="built_in">enable</span> nfs-server.service</code></pre><h4 id="2-1-5-测试-NFS-目录挂载"><a href="#2-1-5-测试-NFS-目录挂载" class="headerlink" title="2.1.5 测试 NFS 目录挂载"></a>2.1.5 测试 NFS 目录挂载</h4><pre><code class="highlight bash"><span class="comment"># NFS 客户端执行：创建目录</span>$ <span class="built_in">mkdir</span> /data/test1<span class="comment"># NFS 客户端执行：挂载目录到NFS服务端</span>$ mount -t nfs4 10.20.1.139:/loki /data/test1<span class="comment"># NFS 客户端执行：查看挂载结果</span>$ mount | grep /data/test110.20.1.139:/loki on /data/test1 <span class="built_in">type</span> nfs4 (rw,relatime,vers=4.2,rsize=524288,wsize=524288,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.1.142,local_lock=none,addr=10.20.1.139)<span class="comment"># NFS 客户端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;this is client&quot;</span> &gt; /data/test1/a.txt<span class="comment"># NFS 服务端执行：查看数据， 结论：客户端数据已写入服务端挂载目录</span>$ <span class="built_in">cat</span> /root/data/loki/a.txt this is client<span class="comment"># NFS 服务端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;This is Server&quot;</span> &gt;&gt; /root/data/loki/a.txt<span class="comment"># NFS 客户端执行：查看数据， 结论：服务端数据已写入客户端挂载目录</span>$ <span class="built_in">cat</span> /data/test1/a.txt this is clientThis is Server</code></pre><p><strong>取消挂载</strong></p><pre><code class="highlight bash"><span class="comment"># 取消挂载</span>umount /data/test1<span class="comment"># 如果取消挂载出现报错，例如：</span>$ umount /data/test1umount.nfs4: /data/test1: device is busy<span class="comment"># 查看目录占用进程</span>$ fuser -m /data/test1/data/test1:         32679c<span class="comment"># kill 进程</span>$ <span class="built_in">kill</span> -9 32679<span class="comment"># 方式二：强制卸载</span>umount -l /data/test1</code></pre><h3 id="2-2-创建-StorageClass"><a href="#2-2-创建-StorageClass" class="headerlink" title="2.2 创建 StorageClass"></a>2.2 创建 StorageClass</h3><p>promtail 抓取到的日志，推送给 Loki 存储，这里将 Loki 的数据通过 StorageClass 动态创建PV，将数据存储起来。</p><p>资源清单：<code>loki-storage.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.存储类</span><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">StorageClass</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span>  <span class="attr">name:</span> <span class="string">loki-storage</span><span class="comment"># provisioner: nfs-provisioner</span><span class="attr">provisioner:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定动态配置器，NFS 子目录外部配置器</span><span class="attr">parameters:</span>  <span class="attr">pathPattern:</span> <span class="string">$&#123;.PVC.namespace&#125;/$&#123;.PVC.name&#125;</span> <span class="comment"># 动态生成的 NFS 路径，格式为 &lt;PVC 命名空间&gt;/&lt;PVC 名称&gt;，例如 loki-storageclass/test-claim。</span>  <span class="attr">archiveOnDelete:</span> <span class="string">&quot;true&quot;</span> <span class="comment">##删除 pv,pv内容是否备份</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 指定使用的 ServiceAccountName</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span>          <span class="attr">image:</span> <span class="string">k8s.dockerproxy.com/sig-storage/nfs-subdir-external-provisioner:v4.0.2</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 挂载的卷名称，与 volumes 部分定义的卷对应</span>              <span class="attr">mountPath:</span> <span class="string">/persistentvolumes</span> <span class="comment"># 将 NFS 卷挂载到容器内的 /persistentvolumes 路径，供容器读写 NFS 共享数据。</span>          <span class="attr">env:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PROVISIONER_NAME</span>              <span class="attr">value:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定配置器名称，与 StorageClass 保持一致</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_SERVER</span>              <span class="attr">value:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_PATH</span>              <span class="attr">value:</span> <span class="string">/root/data/loki</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 定义一个名为 nfs-client-root 的 NFS 卷，连接到 NFS 服务器的指定地址和路径</span>          <span class="attr">nfs:</span>            <span class="attr">server:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="attr">path:</span> <span class="string">/root/data/loki</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">nodeSelector:</span> <span class="comment"># 指定Pod运行的节点</span>        <span class="attr">kubernetes.io/hostname:</span> <span class="string">k8s-node01</span>      <span class="comment"># nodeName: k8s-node01 # 指定 Pod 运行在 k8s-node02 节点上</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4.服务账户</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># SA 的名称</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 5.集群角色</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;nodes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumeclaims&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;storage.k8s.io&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;storageclasses&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;events&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># 6.集群角色绑定</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-nfs-client-provisioner</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定类型 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># ServiceAccount 的名称</span>    <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span> <span class="comment"># 绑定的角色类型</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span> <span class="comment"># 集群角色名称 nfs-client-provisioner-runner</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 角色</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称，表明它与 NFS 客户端存储提供者的领导者选举（leader election）机制相关。</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 空字符串表示核心 API 组（core API group），包含 Kubernetes 的基本资源，如 endpoints。</span>    <span class="attr">resources:</span> [<span class="string">&quot;endpoints&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># SA角色绑定</span><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-leader-locking-nfs-client-provisioner</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定资源类型为 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 绑定的ServiceAccount 名称</span>    <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">Role</span> <span class="comment"># 绑定角色（loki-storage名称空间的角色）</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 创建 StorageClass</span>$ kubectl apply -f loki-storage.yaml<span class="comment"># 查看 StorageClass</span>$ kubectl get StorageClassNAME           PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGEloki-storage   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  16mnfs-client     k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  109m<span class="comment"># 查看 Pod</span>$ kubectl get pods -n loki-storage -o wideNAME                                      READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESnfs-client-provisioner-79f97f7689-w2mtj   1/1     Running   0          15m   192.168.85.236   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h3 id="2-3-部署-Loki"><a href="#2-3-部署-Loki" class="headerlink" title="2.3 部署 Loki"></a>2.3 部署 Loki</h3><p>Loki在接收日志后会对日志数据进行一定的加工整理，因为存储的数据为有状态的，安装时候推荐使用StatefulSet。</p><p>资源清单：<code>loki.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">logging</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.ServiceAccount</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.Role</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span>      <span class="bullet">-</span> <span class="string">extensions</span>          <span class="comment"># 指定 API 组为 extensions，这是 PodSecurityPolicy 在 Kubernetes 早期版本（v1.21 之前）使用的 API 组，v1.25 后完全移除</span>    <span class="attr">resourceNames:</span>      <span class="bullet">-</span> <span class="string">loki</span>    <span class="attr">resources:</span>              <span class="comment"># 指定权限针对的资源类型为 podsecuritypolicies（PSP）</span>      <span class="bullet">-</span> <span class="string">podsecuritypolicies</span> <span class="comment"># PSP 是一种 Kubernetes 资源，用于控制 Pod 的安全策略，例如是否允许以 root 运行、挂载主机路径等。在 v1.29 中，podsecuritypolicies 资源不存在，规则无效</span>    <span class="attr">verbs:</span>      <span class="bullet">-</span> <span class="string">use</span>                 <span class="comment"># 指定允许的操作是 use，表示主体可以应用指定的 PSP（loki）到 Pod</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4. RoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">roleRef:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">kind:</span> <span class="string">Role</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">loki</span>    <span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 5. ConfigMap</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">loki</span><span class="attr">data:</span>  <span class="attr">loki.yaml:</span> <span class="string">|</span>    <span class="comment"># Loki 的核心配置文件，控制认证、日志存储、索引、块存储、保留策略等</span>    <span class="comment"># 通过 X-Scope-OrgID Header 启用身份验证，如果为 true，该 Header 必须存在。</span>    <span class="comment"># 如果为 false，OrgID 将始终设置为 &quot;fake&quot;。（用于多租户隔离）</span>    <span class="attr">auth_enabled:</span> <span class="literal">false</span>    <span class="attr">ingester:</span>      <span class="attr">chunk_idle_period:</span> <span class="string">3m</span>        <span class="comment"># 如果一个块在 3 分钟内没有新日志写入，且未达到最大大小，Loki 会将其刷新到存储</span>      <span class="attr">chunk_block_size:</span> <span class="number">65535</span>      <span class="comment"># 每个块的最大大小（字节），这里约为 64KB</span>      <span class="attr">chunk_retain_period:</span> <span class="string">1m</span>      <span class="comment"># 块刷新到存储后，在内存中保留 1 分钟，允许查询最近的日志</span>      <span class="attr">max_transfer_retries:</span> <span class="number">0</span>      <span class="comment"># 当 ingester 退出时，尝试将块转移到其他 ingester 的次数（0 表示不转移，直接刷新到存储）</span>      <span class="attr">lifecycler:</span>                  <span class="comment"># 配置 ingester 的生命周期管理，决定如何注册和发现其他 ingester</span>        <span class="attr">ring:</span>          <span class="attr">kvstore:</span>            <span class="attr">store:</span> <span class="string">inmemory</span>        <span class="comment"># 使用内存作为环存储（其他选项如 consul、etcd）</span>          <span class="attr">replication_factor:</span> <span class="number">1</span>    <span class="comment"># 写入和读取的ingesters数量，至少为1（为了冗余和弹性，默认情况下为3)</span>      <span class="attr">wal:</span>                         <span class="comment"># 配置日志预写</span>        <span class="attr">enabled:</span> <span class="literal">true</span>              <span class="comment"># 启用预写日志（Write-Ahead Log, WAL），在崩溃恢复时确保数据不丢失</span>        <span class="attr">dir:</span> <span class="string">/data/wal</span>             <span class="comment"># WAL 文件存储路径</span>    <span class="attr">limits_config:</span>                 <span class="comment"># 设置日志写入的限制规则</span>      <span class="attr">enforce_metric_name:</span> <span class="literal">false</span>          <span class="comment"># 不强制要求日志流具有指标名称（metric name）</span>      <span class="attr">reject_old_samples:</span> <span class="literal">true</span>            <span class="comment"># 拒绝时间戳早于当前时间的旧日志</span>      <span class="attr">reject_old_samples_max_age:</span> <span class="string">8h</span>      <span class="comment"># 拒绝时间戳早于当前时间 8 小时的日志</span>    <span class="attr">schema_config:</span>                        <span class="comment"># 配置从特定时间段开始应该使用哪些索引模式</span>      <span class="attr">configs:</span>                       <span class="comment"># 定义 Loki 的索引模式和存储配置，指定从某个日期开始的存储方式</span>        <span class="bullet">-</span> <span class="attr">from:</span> <span class="number">2025-07-15</span>           <span class="comment"># 指定此配置从 2023-12-05 开始生效</span>          <span class="attr">store:</span> <span class="string">boltdb-shipper</span>      <span class="comment"># 索引存储使用 boltdb-shipper，一种高效的键值存储，适合分布式环境</span>          <span class="attr">object_store:</span> <span class="string">filesystem</span>   <span class="comment"># 日志块（chunks）存储在本地文件系统，支持 S3、GCS 等，filesystem 适合单节点或测试环境</span>          <span class="attr">schema:</span> <span class="string">v11</span>           <span class="comment"># 使用 Loki 的 v11 索引模式（Loki 的版本化架构）</span>          <span class="attr">index:</span>                <span class="comment"># 配置如何更新和存储索引</span>            <span class="attr">prefix:</span> <span class="string">index_</span>      <span class="comment"># 索引表的名称前缀（如 index_2025_07_15 ）</span>            <span class="attr">period:</span> <span class="string">24h</span>         <span class="comment"># 索引表的时间周期为 24 小时（每天生成新表）</span>    <span class="attr">server:</span>      <span class="attr">http_listen_port:</span> <span class="number">3100</span>    <span class="comment"># 配置 Loki 的 HTTP 服务端口，Promtail 将日志发送到 http://loki:3100/loki/api/v1/push（与之前的 Promtail 配置一致）</span>    <span class="attr">storage_config:</span>            <span class="comment"># 为索引和块配置一个或多个存储</span>      <span class="attr">boltdb_shipper:</span>        <span class="attr">active_index_directory:</span> <span class="string">/data/loki/boltdb-shipper-active</span>    <span class="comment"># 活动索引存储路径</span>        <span class="attr">cache_location:</span> <span class="string">/data/loki/boltdb-shipper-cache</span>             <span class="comment"># 索引缓存路径</span>        <span class="attr">cache_ttl:</span> <span class="string">24h</span>                                              <span class="comment"># 缓存有效期为 24 小时</span>        <span class="attr">shared_store:</span> <span class="string">filesystem</span>                                    <span class="comment"># 索引使用文件系统存储</span>      <span class="attr">filesystem:</span>        <span class="attr">directory:</span> <span class="string">/data/loki/chunks</span>                                <span class="comment"># 日志块存储路径</span>    <span class="attr">chunk_store_config:</span>             <span class="comment"># 配置日志块的缓存和查询行为</span>      <span class="attr">max_look_back_period:</span> <span class="string">0s</span>      <span class="comment"># 限制查询数据的时间，默认是禁用的，这个值应该小于或等于table_manager.retention_period中的值</span>    <span class="attr">table_manager:</span>                  <span class="comment"># 管理索引表的保留和删除</span>      <span class="attr">retention_deletes_enabled:</span> <span class="literal">true</span>   <span class="comment"># 启用索引表和日志的删除</span>      <span class="attr">retention_period:</span> <span class="string">48h</span>             <span class="comment"># 日志和索引保留 48 小时，超过的会被删除，保留期必须是索引周期（schema_config.index.period: 24h）的倍数</span>    <span class="attr">compactor:</span>                      <span class="comment"># 配置 Loki 的压缩器（compactor），用于压缩和清理索引</span>      <span class="attr">working_directory:</span> <span class="string">/data/loki/boltdb-shipper-compactor</span>  <span class="comment"># 压缩器工作目录</span>      <span class="attr">shared_store:</span> <span class="string">filesystem</span>                                <span class="comment"># 压缩器使用文件系统存储，工作目录需持久化存储，避免数据丢失</span>    <span class="comment"># ruler:                              # 配置 Loki 的告警规则（ruler），用于基于日志触发告警。如果需要告警功能，需取消注释并确保 Alertmanager 服务可用</span>    <span class="comment">#   storage:                          # rules规则存储</span>    <span class="comment">#     type: local                     # 主要支持本地存储（local）和对象文件系统（azure, gcs, s3, swift）</span>    <span class="comment">#     local:</span>    <span class="comment">#       directory: /etc/loki/rules    # 告警文件存放目录</span>    <span class="comment">#   rule_path: /data/loki/rules-temp  # rules临时规则文件存储路径</span>    <span class="comment">#   flush_period: 1m                  # 规则刷新间隔为 1 分钟。</span>    <span class="comment">#   alertmanager_url: http://alertmanager-main.monitoring.svc:9093 # alertmanager地址 </span>    <span class="comment">#   external_url: http://alertmanager.od.com           # 外部访问 alertmanager</span>    <span class="comment">#   ring:</span>    <span class="comment">#     kvstore:</span>    <span class="comment">#       store: inmemory           # 规则环存储使用内存</span>    <span class="comment">#   enable_api: true              # 启用规则管理 API</span>    <span class="comment">#   enable_alertmanager_v2: true  # 支持 Alertmanager v2 协议</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 6.Lock Pod</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">StatefulSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">loki</span><span class="attr">spec:</span>  <span class="attr">podManagementPolicy:</span> <span class="string">OrderedReady</span>   <span class="comment"># 指定 Pod 的管理策略为 OrderedReady：Pod 按顺序（0, 1, 2...）创建和删除，等待前一个 Pod 就绪后再创建下一个</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">loki</span>  <span class="attr">serviceName:</span> <span class="string">loki</span>  <span class="attr">updateStrategy:</span>    <span class="attr">type:</span> <span class="string">RollingUpdate</span>               <span class="comment"># 使用滚动更新策略，逐步替换旧 Pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">loki</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">loki</span>        <span class="comment"># 指定 Pod 使用 loki 服务账号（之前定义的 ServiceAccount）</span>      <span class="attr">securityContext:</span>          <span class="comment"># 定义 Pod 级别的安全上下文，控制文件系统权限和用户/组 ID</span>        <span class="attr">fsGroup:</span> <span class="number">10001</span>          <span class="comment"># Pod 挂载的卷（如 /data）将归属组 ID 10001</span>        <span class="attr">runAsGroup:</span> <span class="number">10001</span>       <span class="comment"># 容器进程以组 ID 10001 运行，确保挂载的卷（如 PVC）归属组 10001，Loki 进程可以访问</span>        <span class="attr">runAsNonRoot:</span> <span class="literal">true</span>      <span class="comment"># 强制容器以非 root 用户运行，增强安全性</span>        <span class="attr">runAsUser:</span> <span class="number">10001</span>        <span class="comment"># 容器进程以用户 ID 10001 运行</span>      <span class="attr">initContainers:</span>           <span class="comment"># 定义初始化容器，在主容器启动前调整存储路径的权限</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fix-permissions</span> <span class="comment"># 初始化容器名称</span>          <span class="attr">image:</span> <span class="string">busybox:1.37.0</span> <span class="comment"># 使用 busybox 镜像，适合执行简单命令</span>          <span class="attr">securityContext:</span>            <span class="attr">privileged:</span> <span class="literal">true</span>    <span class="comment"># 以特权模式运行，允许修改文件系统权限</span>            <span class="attr">runAsGroup:</span> <span class="number">0</span>       <span class="comment"># 以 root 用户运行</span>            <span class="attr">runAsNonRoot:</span> <span class="literal">false</span>            <span class="attr">runAsUser:</span> <span class="number">0</span>          <span class="attr">command:</span>              <span class="comment"># 创建 /data/loki 目录，将 /data 及其子目录的拥有者改为 UID 10001 和 GID 10001，列出 /data 目录内容，验证权限</span>            <span class="bullet">-</span> <span class="string">sh</span>            <span class="bullet">-</span> <span class="string">-c</span>            <span class="bullet">-</span> <span class="string">&gt;-</span><span class="string">              id;</span><span class="string">              mkdir -p /data/loki;</span><span class="string">              chown 10001:10001 /data -R;</span><span class="string">              ls -la /data/</span><span class="string"></span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/data</span>  <span class="comment"># 挂载 storage 卷到 /data，与主容器共享</span>              <span class="attr">name:</span> <span class="string">storage</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">loki</span>          <span class="attr">image:</span> <span class="string">grafana/loki:2.9.2</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">args:</span>            <span class="bullet">-</span> <span class="string">-config.file=/etc/loki/config/loki.yaml</span>   <span class="comment"># 指定配置文件路径</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span>              <span class="attr">mountPath:</span> <span class="string">/etc/loki/config/loki.yaml</span>     <span class="comment"># 挂载 ConfigMap loki 的 loki.yaml 到 /etc/loki/config/loki.yaml</span>              <span class="attr">subPath:</span> <span class="string">loki.yaml</span>                        <span class="comment"># subPath: loki.yaml 表示只挂载 ConfigMap 中 loki.yaml 键对应的文件内容到 mountPath 指定的路径（/etc/loki/config/loki.yaml）</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">storage</span>              <span class="attr">mountPath:</span> <span class="string">&quot;/data&quot;</span>                        <span class="comment"># 挂载 PVC 到 /data，用于存储 WAL、索引和块</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http-metrics</span>              <span class="attr">containerPort:</span> <span class="number">3100</span>       <span class="comment"># Loki 监听 3100 端口（HTTP），用于接收日志和监控指标</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">livenessProbe:</span>                <span class="comment"># 存活探测</span>            <span class="attr">httpGet:</span>              <span class="attr">path:</span> <span class="string">/ready</span>              <span class="comment"># 检查 /ready 端点，确认 Loki 是否健康/就绪</span>              <span class="attr">port:</span> <span class="string">http-metrics</span>              <span class="attr">scheme:</span> <span class="string">HTTP</span>            <span class="attr">initialDelaySeconds:</span> <span class="number">45</span>     <span class="comment"># 启动后 45 秒开始探测</span>            <span class="attr">timeoutSeconds:</span> <span class="number">1</span>           <span class="comment"># 每次探测超时 1 秒</span>            <span class="attr">periodSeconds:</span> <span class="number">10</span>           <span class="comment"># 每 10 秒探测一次</span>            <span class="attr">successThreshold:</span> <span class="number">1</span>         <span class="comment"># 1 次成功即健康</span>            <span class="attr">failureThreshold:</span> <span class="number">3</span>         <span class="comment"># 3 次失败标记不健康</span>          <span class="attr">readinessProbe:</span>               <span class="comment"># 就绪探测</span>            <span class="attr">httpGet:</span>              <span class="attr">path:</span> <span class="string">/ready</span>              <span class="attr">port:</span> <span class="string">http-metrics</span>              <span class="attr">scheme:</span> <span class="string">HTTP</span>            <span class="attr">initialDelaySeconds:</span> <span class="number">45</span>            <span class="attr">timeoutSeconds:</span> <span class="number">1</span>            <span class="attr">periodSeconds:</span> <span class="number">10</span>            <span class="attr">successThreshold:</span> <span class="number">1</span>            <span class="attr">failureThreshold:</span> <span class="number">3</span>          <span class="attr">securityContext:</span>            <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span>    <span class="comment"># 容器根文件系统为只读，增强安全性。</span>      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">4800</span>   <span class="comment"># Pod 终止时的宽限期为 4800 秒（80 分钟）</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span>          <span class="comment"># 定义卷，将 ConfigMap loki 挂载到容器</span>          <span class="attr">configMap:</span>            <span class="attr">defaultMode:</span> <span class="number">0640</span>   <span class="comment"># 文件权限为 rw-r-----（所有者读写，组可读）。0640 前面有0，因此被解析为八进制数</span>            <span class="attr">name:</span> <span class="string">loki</span>          <span class="comment"># 引用名为 loki ConfigMap</span>  <span class="attr">volumeClaimTemplates:</span>    <span class="bullet">-</span> <span class="attr">metadata:</span>        <span class="attr">name:</span> <span class="string">storage</span>        <span class="attr">labels:</span>          <span class="attr">app:</span> <span class="string">loki</span>      <span class="attr">spec:</span>        <span class="attr">storageClassName:</span> <span class="string">&quot;loki-storage&quot;</span>   <span class="comment"># 注意修改 storageClass 名称</span>        <span class="attr">accessModes:</span>          <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>        <span class="attr">resources:</span>          <span class="attr">requests:</span>            <span class="attr">storage:</span> <span class="string">&quot;10Gi&quot;</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 7.Loki Service</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">loki</span><span class="attr">spec:</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">3100</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">targetPort:</span> <span class="string">http-metrics</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">loki</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f loki.yaml<span class="comment"># ConfigMap</span>$ kubectl get configMap -n loggingNAME               DATA   AGEkube-root-ca.crt   1      55mloki               1      54mloki-promtail      1      55m<span class="comment"># StatefulSet</span>$ kubectl get StatefulSet -n loggingNAME   READY   AGEloki   1/1     55m<span class="comment"># Pod</span>$ kubectl get pod -n loggingNAME                  READY   STATUS    RESTARTS   AGEloki-0                1/1     Running   0          55mloki-promtail-cbllm   1/1     Running   0          56mloki-promtail-h7pz5   1/1     Running   0          56mloki-promtail-rrwtf   1/1     Running   0          56mloki-promtail-vs4df   1/1     Running   0          56m<span class="comment"># Service</span>$ kubectl get svc -n loggingNAME   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGEloki   ClusterIP   10.106.23.220   &lt;none&gt;        3100/TCP   55m</code></pre><h2 id="3-部署-Grafana"><a href="#3-部署-Grafana" class="headerlink" title="3. 部署 Grafana"></a>3. 部署 Grafana</h2><p>部署 Grafana， 展示推送到 Loki 的日志数据</p><h3 id="3-1-Grafana-资源清单"><a href="#3-1-Grafana-资源清单" class="headerlink" title="3.1 Grafana 资源清单"></a>3.1 Grafana 资源清单</h3><p><strong>资源清单：</strong> <code>loki-grafana.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.声明 PVC ，使用 StorageClass 动态创建PV</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-pvc</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">spec:</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">resources:</span>    <span class="attr">requests:</span>      <span class="attr">storage:</span> <span class="string">5Gi</span>  <span class="attr">storageClassName:</span> <span class="string">loki-storage</span> <span class="comment"># 使用 StorageClass 动态创建PV</span>  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.创建Deployment</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">name:</span> <span class="string">grafana</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">grafana</span>    <span class="attr">spec:</span>      <span class="attr">securityContext:</span>        <span class="attr">fsGroup:</span> <span class="number">472</span>        <span class="attr">supplementalGroups:</span>          <span class="bullet">-</span> <span class="number">0</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grafana</span>          <span class="attr">image:</span> <span class="string">grafana/grafana:8.3.5</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3000</span>              <span class="attr">name:</span> <span class="string">http-grafana</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>          <span class="attr">resources:</span>            <span class="attr">requests:</span>              <span class="attr">cpu:</span> <span class="string">500m</span>              <span class="attr">memory:</span> <span class="string">1024Mi</span>            <span class="attr">limits:</span>              <span class="attr">cpu:</span> <span class="string">1000m</span>              <span class="attr">memory:</span> <span class="string">2048Mi</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/lib/grafana</span>              <span class="attr">name:</span> <span class="string">grafana-pv</span>      <span class="attr">volumes:</span>                              <span class="comment"># 挂载容器卷</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grafana-pv</span>          <span class="attr">persistentVolumeClaim:</span>            <span class="attr">claimName:</span> <span class="string">grafana-pvc</span>          <span class="comment"># 使用声明的PVC，通过 StorageClass 动态创建PV</span>      <span class="attr">nodeSelector:</span> <span class="comment"># 指定Pod运行的节点</span>        <span class="attr">kubernetes.io/hostname:</span> <span class="string">k8s-node02</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.创建Service</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana</span>  <span class="attr">namespace:</span> <span class="string">logging</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">3000</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="string">http-grafana</span>      <span class="attr">nodePort:</span> <span class="number">30339</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">grafana</span>  <span class="attr">type:</span> <span class="string">NodePort</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4.创建 Ingress</span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-ui</span>  <span class="attr">namespace:</span> <span class="string">logging</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">grafana</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span>       <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">loki.grafana.com</span>    <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 loki.grafana.com 的流量。客户端必须通过该域名访问</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>             <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>    <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">grafana</span>   <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">3000</span>  <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f loki-grafana.yaml <span class="comment"># 查看 Ingress</span>$ kubectl get ingress -n loggingNAME         CLASS   HOSTS              ADDRESS   PORTS   AGEgrafana-ui   nginx   loki.grafana.com             80      10s<span class="comment"># 查看 Serivce</span>$ kubectl get svc -n loggingNAME      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEgrafana   NodePort    10.104.180.186   &lt;none&gt;        3000:30339/TCP   6m13sloki      ClusterIP   10.106.23.220    &lt;none&gt;        3100/TCP         148m<span class="comment"># 查看 PVC</span>$ kubectl get pvc -n loggingNAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGEgrafana-pvc      Bound    pvc-649c73ed-2885-4924-a219-ee58a8ab0166   5Gi        RWO            loki-storage   &lt;<span class="built_in">unset</span>&gt;                 6m28sstorage-loki-0   Bound    pvc-819fb39b-1ad9-48ff-8dfe-fafa62885af7   10Gi       RWO            loki-storage   &lt;<span class="built_in">unset</span>&gt;                 149m<span class="comment"># 查看 PV</span>$ kubectl get pv -n loggingNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                    STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGEpvc-649c73ed-2885-4924-a219-ee58a8ab0166   5Gi        RWO            Delete           Bound    logging/grafana-pvc                      loki-storage   &lt;<span class="built_in">unset</span>&gt;                          6m36spvc-819fb39b-1ad9-48ff-8dfe-fafa62885af7   10Gi       RWO            Delete           Bound    logging/storage-loki-0                   loki-storage   &lt;<span class="built_in">unset</span>&gt;                          149m<span class="comment"># 查看 Pod</span>$ kubectl get pods -n loggingNAME                       READY   STATUS    RESTARTS   AGEgrafana-599d67bdbb-m6zjz   1/1     Running   0          6m54sloki-0                     1/1     Running   0          149mloki-promtail-cbllm        1/1     Running   0          150mloki-promtail-h7pz5        1/1     Running   0          150mloki-promtail-rrwtf        1/1     Running   0          150mloki-promtail-vs4df        1/1     Running   0          150m</code></pre><h3 id="3-2-配置-Host-域名映射"><a href="#3-2-配置-Host-域名映射" class="headerlink" title="3.2 配置 Host 域名映射"></a>3.2 配置 Host 域名映射</h3><p>在浏览器所在主机编辑 <code>/etc/hosts</code> </p><pre><code class="highlight plaintext">10.20.1.140 loki.grafana.com</code></pre><p>保存后，使用浏览器访问 Grafana，地址：<a href="https://loki.grafana.com/">https://loki.grafana.com/</a></p><h2 id="4-Grafana-基础使用"><a href="#4-Grafana-基础使用" class="headerlink" title="4. Grafana 基础使用"></a>4. Grafana 基础使用</h2><h3 id="4-1-登录-Grafana"><a href="#4-1-登录-Grafana" class="headerlink" title="4.1 登录 Grafana"></a>4.1 登录 Grafana</h3><p>默认用户名：admin  </p><p>默认密码：admin</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135129.png" alt="登录Grafana"></p><p><strong>Grafana 首页</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135208.png" alt="Grafana首页"></p><h3 id="4-2-添加-Loki-作为数据源"><a href="#4-2-添加-Loki-作为数据源" class="headerlink" title="4.2 添加 Loki 作为数据源"></a>4.2 添加 Loki 作为数据源</h3><p><strong>添加数据源</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135300.png" alt="添加 Loki 作为数据源1"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135317.png" alt="添加 Loki 作为数据源2"></p><p><strong>选择 Loki</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135333.png" alt="添加 Loki 作为数据源3"></p><p><strong>Loki数据源设置</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135515.png" alt="添加 Loki 作为数据源4"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-135555.png" alt="添加 Loki 作为数据源5"></p><h3 id="4-3-查看日志"><a href="#4-3-查看日志" class="headerlink" title="4.3 查看日志"></a>4.3 查看日志</h3><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/16/20250716-140241.png" alt="查看日志"></p><p>至此，基于资源清单 yaml 部署 Loki、Promtail、Grafana 就完成了。</p><h1 id="三、使用-Helm-部署-Loki"><a href="#三、使用-Helm-部署-Loki" class="headerlink" title="三、使用 Helm 部署 Loki"></a>三、使用 Helm 部署 Loki</h1><p><strong>使用 Helm 部署 Loki 需要保持网络通畅，如果你的服务器无法连接外网，那就需要提前将loki的helm安装包下载到服务器，并且提前将需要的镜像导入到服务器中。</strong></p><h2 id="1-部署-StorageClass"><a href="#1-部署-StorageClass" class="headerlink" title="1. 部署 StorageClass"></a>1. 部署 StorageClass</h2><p>使用 StorageClass 自动创建 PV，管理文件存储。</p><p>资源清单：<code>loki-storage.yaml</code></p><pre><code class="highlight yaml"><span class="comment"># 1.命名空间</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Namespace</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loki-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 2.存储类</span><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">StorageClass</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span>  <span class="attr">name:</span> <span class="string">loki-storage</span><span class="comment"># provisioner: nfs-provisioner</span><span class="attr">provisioner:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定动态配置器，NFS 子目录外部配置器</span><span class="attr">parameters:</span>  <span class="attr">pathPattern:</span> <span class="string">$&#123;.PVC.namespace&#125;/$&#123;.PVC.name&#125;</span> <span class="comment"># 动态生成的 NFS 路径，格式为 &lt;PVC 命名空间&gt;/&lt;PVC 名称&gt;，例如 loki-storageclass/test-claim。</span>  <span class="attr">archiveOnDelete:</span> <span class="string">&quot;true&quot;</span> <span class="comment">##删除 pv,pv内容是否备份</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 3.NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># NFS 动态存储配置器，用于自动为 PVC 创建 PV</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 指定使用的 ServiceAccountName</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span>          <span class="attr">image:</span> <span class="string">k8s.dockerproxy.com/sig-storage/nfs-subdir-external-provisioner:v4.0.2</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 挂载的卷名称，与 volumes 部分定义的卷对应</span>              <span class="attr">mountPath:</span> <span class="string">/persistentvolumes</span> <span class="comment"># 将 NFS 卷挂载到容器内的 /persistentvolumes 路径，供容器读写 NFS 共享数据。</span>          <span class="attr">env:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PROVISIONER_NAME</span>              <span class="attr">value:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定配置器名称，与 StorageClass 保持一致</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_SERVER</span>              <span class="attr">value:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_PATH</span>              <span class="attr">value:</span> <span class="string">/root/data/loki</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 定义一个名为 nfs-client-root 的 NFS 卷，连接到 NFS 服务器的指定地址和路径</span>          <span class="attr">nfs:</span>            <span class="attr">server:</span> <span class="number">10.20</span><span class="number">.1</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="attr">path:</span> <span class="string">/root/data/loki</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">nodeSelector:</span> <span class="comment"># 指定Pod运行的节点</span>        <span class="attr">kubernetes.io/hostname:</span> <span class="string">k8s-node01</span>      <span class="comment"># nodeName: k8s-node01 # 指定 Pod 运行在 k8s-node02 节点上</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 4.服务账户</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># SA 的名称</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 5.集群角色</span><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;nodes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumeclaims&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;storage.k8s.io&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;storageclasses&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;events&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># 6.集群角色绑定</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-nfs-client-provisioner</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定类型 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># ServiceAccount 的名称</span>    <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span> <span class="comment"># 绑定的角色类型</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span> <span class="comment"># 集群角色名称 nfs-client-provisioner-runner</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="meta">---</span><span class="meta"></span><span class="comment"># 角色</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称，表明它与 NFS 客户端存储提供者的领导者选举（leader election）机制相关。</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 空字符串表示核心 API 组（core API group），包含 Kubernetes 的基本资源，如 endpoints。</span>    <span class="attr">resources:</span> [<span class="string">&quot;endpoints&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]<span class="meta">---</span><span class="meta"></span><span class="comment"># SA角色绑定</span><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-leader-locking-nfs-client-provisioner</span>  <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定资源类型为 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 绑定的ServiceAccount 名称</span>    <span class="attr">namespace:</span> <span class="string">loki-storage</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">Role</span> <span class="comment"># 绑定角色（loki-storage名称空间的角色）</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash"><span class="comment"># 执行</span>$ kubectl apply -f loki-storage.yaml<span class="comment"># 查看Pod</span>$ kubectl get pods -n loki-storageNAME                                      READY   STATUS    RESTARTS   AGEnfs-client-provisioner-79f97f7689-h5rrl   1/1     Running   0          20h</code></pre><h2 id="2-下载-Helm-Chat-包"><a href="#2-下载-Helm-Chat-包" class="headerlink" title="2. 下载 Helm Chat 包"></a>2. 下载 Helm Chat 包</h2><pre><code class="highlight bash"><span class="comment"># 添加grafana仓库</span>$ helm repo add grafana https://grafana.github.io/helm-charts<span class="comment"># 更新仓库</span>$ helm repo update<span class="comment"># 拉取 Chart 包</span>$ helm pull grafana/loki-stack --version=2.9.11<span class="comment"># 查看下载的 chat 包</span>$ ll-rw-r--r-- 1 root root 132807 Jul 16 15:09 loki-stack-2.9.11.tgz<span class="comment"># 如果上面的命令由于网络问题无法下载 Chat 包, 就手动下载，然后上传到服务器上</span><span class="comment"># helm包下载地址 https://github.com/grafana/helm-charts/releases/download/loki-stack-2.9.11/loki-stack-2.9.11.tgz</span></code></pre><p><strong>解压 Chart 包</strong></p><pre><code class="highlight bash"><span class="comment"># 解压</span>$ tar -zxvf loki-stack-2.9.11.tgz<span class="comment"># 查看解压目录</span>$ <span class="built_in">ls</span> loki-stack  loki-stack-2.9.11.tgz</code></pre><h2 id="3-编辑-values-yaml"><a href="#3-编辑-values-yaml" class="headerlink" title="3. 编辑 values.yaml"></a>3. 编辑 values.yaml</h2><p><code>vim loki-stack/values.yaml</code></p><p>内容如下：</p><pre><code class="highlight yaml"><span class="attr">loki:</span>  <span class="attr">enabled:</span> <span class="literal">true</span>  <span class="attr">isDefault:</span> <span class="literal">true</span>  <span class="attr">url:</span> <span class="string">http://&#123;&#123;(include</span> <span class="string">&quot;loki.serviceName&quot;</span> <span class="string">.)&#125;&#125;:&#123;&#123;</span> <span class="string">.Values.loki.service.port</span> <span class="string">&#125;&#125;</span>  <span class="attr">readinessProbe:</span>    <span class="attr">httpGet:</span>      <span class="attr">path:</span> <span class="string">/ready</span>      <span class="attr">port:</span> <span class="string">http-metrics</span>    <span class="attr">initialDelaySeconds:</span> <span class="number">45</span>  <span class="attr">livenessProbe:</span>    <span class="attr">httpGet:</span>      <span class="attr">path:</span> <span class="string">/ready</span>      <span class="attr">port:</span> <span class="string">http-metrics</span>    <span class="attr">initialDelaySeconds:</span> <span class="number">45</span>  <span class="attr">datasource:</span>    <span class="attr">jsonData:</span> <span class="string">&quot;&#123;&#125;&quot;</span>    <span class="attr">uid:</span> <span class="string">&quot;&quot;</span>  <span class="attr">persistence:</span> <span class="comment"># 添加存储设置</span>    <span class="attr">enabled:</span> <span class="literal">true</span>    <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>    <span class="attr">size:</span> <span class="string">10Gi</span>    <span class="attr">storageClassName:</span> <span class="string">loki-storage</span> <span class="comment"># 使用 loki-storage 自动创建PV</span><span class="attr">promtail:</span>  <span class="attr">enabled:</span> <span class="literal">true</span>  <span class="attr">config:</span>    <span class="attr">logLevel:</span> <span class="string">info</span>    <span class="attr">serverPort:</span> <span class="number">3101</span>    <span class="attr">clients:</span>      <span class="bullet">-</span> <span class="attr">url:</span> <span class="string">http://&#123;&#123;</span> <span class="string">.Release.Name</span> <span class="string">&#125;&#125;:3100/loki/api/v1/push</span>  <span class="attr">defaultVolumes:</span> <span class="comment"># 定时 Promtail Pod 使用的卷</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span>      <span class="attr">hostPath:</span>        <span class="attr">path:</span> <span class="string">/run/promtail</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">containers</span>      <span class="attr">hostPath:</span>        <span class="attr">path:</span> <span class="string">/data/docker/containers</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pods</span>      <span class="attr">hostPath:</span>        <span class="attr">path:</span> <span class="string">/var/log/pods</span>  <span class="attr">defaultVolumeMounts:</span> <span class="comment"># 定义容器内的挂载点，将上述卷挂载到 Promtail 容器</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span>      <span class="attr">mountPath:</span> <span class="string">/run/promtail</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">containers</span>      <span class="attr">mountPath:</span> <span class="string">/data/docker/containers</span>      <span class="attr">readOnly:</span> <span class="literal">true</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pods</span>      <span class="attr">mountPath:</span> <span class="string">/var/log/pods</span>      <span class="attr">readOnly:</span> <span class="literal">true</span><span class="attr">grafana:</span>  <span class="attr">enabled:</span> <span class="literal">true</span>     <span class="comment"># 启用部署Grafana</span>  <span class="attr">persistence:</span>    <span class="attr">enabled:</span> <span class="literal">true</span>    <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>    <span class="attr">size:</span> <span class="string">5Gi</span>    <span class="attr">storageClassName:</span> <span class="string">loki-storage</span> <span class="comment"># 使用 loki-storage 自动创建PV</span>    <span class="comment"># 显式禁用不需要的子 Chart</span><span class="attr">test_pod:</span>  <span class="attr">enabled:</span> <span class="literal">false</span>  <span class="attr">filebeat:</span>  <span class="attr">enabled:</span> <span class="literal">false</span><span class="attr">fluent-bit:</span>  <span class="attr">enabled:</span> <span class="literal">false</span><span class="attr">prometheus:</span>  <span class="attr">enabled:</span> <span class="literal">false</span><span class="attr">logstash:</span>  <span class="attr">enabled:</span> <span class="literal">false</span></code></pre><p>如上，修改了 loki、promtail、grafana ，使用 helm 部署时会依次安装这3个组件，并且关闭其它不需要的模块</p><h2 id="4-修改-grafana-密码"><a href="#4-修改-grafana-密码" class="headerlink" title="4. 修改 grafana 密码"></a>4. 修改 grafana 密码</h2><p>编辑 grafana 目录下的 <code>values.yaml</code> 文件</p><pre><code class="highlight bash">$ vim loki-stack/charts/grafana/values.yaml<span class="comment"># 编辑下面的内容，将 admin 用户的密码也设置成 admin</span><span class="comment"># Administrator credentials when not using an existing secret (see below)</span>adminUser: adminadminPassword: admin</code></pre><h2 id="5-使用Helm部署Loki"><a href="#5-使用Helm部署Loki" class="headerlink" title="5. 使用Helm部署Loki"></a>5. 使用Helm部署Loki</h2><pre><code class="highlight bash"><span class="comment"># 进入 loki 解压目录</span>$ <span class="built_in">cd</span> loki-stack<span class="comment"># 查看文件夹内容</span>$ lltotal 20-rw-r--r-- 1 root root  374 Jul 16 16:50 Chart.yaml-rw-r--r-- 1 root root 2027 Jul 16 16:50 README.mddrwxr-xr-x 9 root root  117 Jul 16 16:50 charts-rw-r--r-- 1 root root  729 Jul 16 16:50 requirements.lock-rw-r--r-- 1 root root  867 Jul 16 16:50 requirements.yamldrwxr-xr-x 3 root root   80 Jul 16 16:50 templates-rw-r--r-- 1 root root 1455 Jul 16 16:50 values.yaml<span class="comment"># 执行 helm 命令，安装 loki</span>$ helm install loki -n loki --create-namespace -f values.yaml .NAME: lokiLAST DEPLOYED: Wed Jul 16 17:00:37 2025NAMESPACE: lokiSTATUS: deployedREVISION: 1NOTES:The Loki stack has been deployed to your cluster. Loki can now be added as a datasource <span class="keyword">in</span> Grafana.See http://docs.grafana.org/features/datasources/loki/ <span class="keyword">for</span> more detail.<span class="comment"># 补充命令：更新部署</span>helm upgrade loki -n loki -f values.yaml .</code></pre><p>查看部署资源</p><pre><code class="highlight bash">$ helm list -n lokiNAMENAMESPACEREVISIONUPDATED                                STATUS  CHART            APP VERSIONlokiloki     1       2025-07-16 17:15:50.136762865 +0800 CSTdeployedloki-stack-2.9.11v2.6.1$ kubectl get pods -n lokiNAME                           READY   STATUS    RESTARTS   AGEloki-0                         1/1     Running   0          3m38sloki-grafana-8869df8b7-ggnnh   1/1     Running   0          3m38sloki-promtail-5gvgd            1/1     Running   0          3m38sloki-promtail-bb5l9            1/1     Running   0          3m38sloki-promtail-gbv8t            1/1     Running   0          3m38sloki-promtail-mrw6n            1/1     Running   0          3m38s$ kubectl get svc -n lokiNAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGEloki              ClusterIP   10.97.142.238   &lt;none&gt;        3100/TCP   76sloki-grafana      ClusterIP   10.111.244.51   &lt;none&gt;        80/TCP     76sloki-headless     ClusterIP   None            &lt;none&gt;        3100/TCP   76sloki-memberlist   ClusterIP   None            &lt;none&gt;        7946/TCP   76s$ kubectl get statefulset -n lokiNAME   READY   AGEloki   1/1     91s$ kubectl get deployment -n lokiNAME           READY   UP-TO-DATE   AVAILABLE   AGEloki-grafana   1/1     1            1           99s$ kubectl get cm -n lokiNAME               DATA   AGEkube-root-ca.crt   1      16mloki-grafana       1      107s</code></pre><h2 id="6-部署-Ingress"><a href="#6-部署-Ingress" class="headerlink" title="6. 部署 Ingress"></a>6. 部署 Ingress</h2><p>用于浏览器访问 Grafana</p><p>资源清单：<code>loki-ingress.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">grafana-ui</span>  <span class="attr">namespace:</span> <span class="string">loki</span>  <span class="attr">labels:</span>    <span class="attr">k8s-app:</span> <span class="string">grafana</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span>       <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">loki.grafana.com</span>    <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 loki.grafana.com 的流量。客户端必须通过该域名访问</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>             <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>    <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">loki-grafana</span>   <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span>  <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f loki-ingress.yaml</code></pre><p><strong>修改 HOSTS 文件</strong></p><p>添加域名映射</p><pre><code class="highlight plaintext">10.20.1.140 loki.grafana.com</code></pre><p><strong>补充：如果没有设置 grafana 的初始密码，grafana 在创建时会默认生成密码</strong></p><pre><code class="highlight bash"><span class="comment"># 查看有哪些 Secret</span>$ kubectl get secret -n lokiNAME                         TYPE                 DATA   AGEloki                         Opaque               1      13mloki-grafana                 Opaque               3      13mloki-promtail                Opaque               1      13msh.helm.release.v1.loki.v1   helm.sh/release.v1   1      13m<span class="comment"># 查看默认用户名</span>$ kubectl get secret -n loki loki-grafana -o jsonpath=<span class="string">&quot;&#123;.data.admin-user&#125;&quot;</span> | <span class="built_in">base64</span> --decode admin<span class="comment"># 查看默认密码</span>$ $ kubectl get secret -n loki loki-grafana -o jsonpath=<span class="string">&quot;&#123;.data.admin-password&#125;&quot;</span> | <span class="built_in">base64</span> --decodeUnBUY0EbcPuaLrHnBybhYuZOSFb5rmDvNpXQn2vr</code></pre><h2 id="7-添加-Loki-数据源"><a href="#7-添加-Loki-数据源" class="headerlink" title="7. 添加 Loki 数据源"></a>7. 添加 Loki 数据源</h2><p><strong>登录 Grafana</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135126.png" alt="Grafana"></p><p><strong>添加数据源</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135316.png" alt="添加数据源"></p><p><strong>选择 Loki 作为数据源</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135346.png" alt="选择默认的 Loki 数据源"></p><p><strong>编辑数据源</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135559.png" alt="编辑数据源"></p><p><strong>保存数据源配置</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135639.png" alt="保存数据源配置"></p><p><strong>选择数据源，搜索查看日志</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-135917.png" alt="查看日志"></p><p><strong>选择标签，点击查询</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/17/20250717-140204.png" alt="选择标签，点击查询"></p><p><strong>至此，关于如何使用 Helm 部署 Loki 就介绍完成了</strong></p><p><strong>参考链接：</strong></p><blockquote><p><a href="https://grafana.org.cn/docs/loki/latest/get-started/overview/">https://grafana.org.cn/docs/loki/latest/get-started/overview/</a></p><p><a href="https://www.cnblogs.com/starsray/p/17549842.html">https://www.cnblogs.com/starsray/p/17549842.html</a></p><p><a href="https://www.boysec.cn/boy/632ed78c.html">https://www.boysec.cn/boy/632ed78c.html</a></p><p><a href="https://www.qikqiak.com/k3s/logging/loki/overview/">https://www.qikqiak.com/k3s/logging/loki/overview/</a></p><p><a href="https://blog.frognew.com/tags/loki.html">https://blog.frognew.com/tags/loki.html</a></p><p><a href="https://blog.csdn.net/sj1163739403/article/details/142638504">https://blog.csdn.net/sj1163739403/article/details/142638504</a></p><p><a href="https://blog.csdn.net/ichen820/article/details/134287977">https://blog.csdn.net/ichen820/article/details/134287977</a></p><p><a href="https://www.ywbj.cc/?p=951">https://www.ywbj.cc/?p=951</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;概要：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;简述 Loki 相关组件原理，并演示两种使用 Loki 监控Pod日志的部署方式：&lt;strong&gt;使用 yaml 资源清单部署&lt;/strong&gt; 和 &lt;strong&gt;使用 Helm 部署&lt;/strong&gt;&lt;/p&gt;
&lt;p</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Loki" scheme="https://georgechan95.github.io/tags/Loki/"/>
    
  </entry>
  
  <entry>
    <title>013-K8S-使用Helm安装Harbor</title>
    <link href="https://georgechan95.github.io/blog/3fee6d19.html"/>
    <id>https://georgechan95.github.io/blog/3fee6d19.html</id>
    <published>2025-07-07T14:37:00.000Z</published>
    <updated>2025-07-10T05:33:47.929Z</updated>
    
    <content type="html"><![CDATA[<p><strong>当前集群环境</strong></p><table><thead><tr><th>IP</th><th>Hostname</th><th>用途</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td><td></td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td><td></td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td><td></td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td><td>安装NFS，Harbor</td></tr></tbody></table><h1 id="一、安装准备"><a href="#一、安装准备" class="headerlink" title="一、安装准备"></a>一、安装准备</h1><h2 id="1-安装NFS-配置存储卷"><a href="#1-安装NFS-配置存储卷" class="headerlink" title="1. 安装NFS,配置存储卷"></a>1. 安装NFS,配置存储卷</h2><p>安装 NFS,配置存储卷自动分配 PV，用于持久化 Harbor 存储的镜像。</p><p>这里选用 k8s-master (10.20.1.139) 作为 nfs 服务端，其它节点作为 nfs 客户端</p><h3 id="1-1-安装-NFS-服务"><a href="#1-1-安装-NFS-服务" class="headerlink" title="1.1 安装 NFS 服务"></a>1.1 安装 NFS 服务</h3><blockquote><p>master节点、node01、node02、node03 节点都需要安装执行</p></blockquote><pre><code class="highlight bash">$ yum install -y nfs-utils rpcbind</code></pre><h3 id="1-2-创建共享目录"><a href="#1-2-创建共享目录" class="headerlink" title="1.2 创建共享目录"></a>1.2 创建共享目录</h3><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash"><span class="comment"># 创建 共享目录</span>$ <span class="built_in">mkdir</span> -p /root/data/harbor/<span class="comment"># 目录提权</span><span class="built_in">chmod</span> 777 /root/data/harbor/<span class="comment"># 变更用户组</span><span class="built_in">chown</span> nobody /root/data/harbor/</code></pre><h3 id="1-3-编辑共享目录读写配置"><a href="#1-3-编辑共享目录读写配置" class="headerlink" title="1.3 编辑共享目录读写配置"></a>1.3 编辑共享目录读写配置</h3><blockquote><p>仅在 nfs 服务端 (master节点) 执行</p></blockquote><pre><code class="highlight bash">$ vim /etc/exports/root/data     10.20.1.0/24(rw,fsid=0,no_root_squash)/root/data/harbor     10.20.1.0/24(rw,no_root_squash,no_all_squash,<span class="built_in">sync</span>)</code></pre><p>这里使用的是 NFS4 服务，上面的配置表示 10.20.1.0&#x2F;24 网段的 ip 都可以与 nfs 主服务器共享 <code>/root/data/harbor</code> 目录内容</p><h3 id="1-4-启动NFS服务"><a href="#1-4-启动NFS服务" class="headerlink" title="1.4 启动NFS服务"></a>1.4 启动NFS服务</h3><blockquote><p>集群内所有节点都需要操作</p></blockquote><pre><code class="highlight bash"> <span class="comment"># 启动服务</span>$ systemctl start rpcbind$ systemctl restart nfs-server.service<span class="comment"># 设置开机自启</span>$ systemctl <span class="built_in">enable</span> rpcbind$ systemctl <span class="built_in">enable</span> nfs-server.service</code></pre><h3 id="1-5-测试-NFS-目录挂载"><a href="#1-5-测试-NFS-目录挂载" class="headerlink" title="1.5 测试 NFS 目录挂载"></a>1.5 测试 NFS 目录挂载</h3><pre><code class="highlight bash"><span class="comment"># NFS 客户端执行：创建目录</span>$ <span class="built_in">mkdir</span> /data/test1<span class="comment"># NFS 客户端执行：挂载目录到NFS服务端</span>$ mount -t nfs4 10.20.1.139:/harbor /data/test1<span class="comment"># NFS 客户端执行：查看挂载结果</span>$ mount | grep /data/test110.20.1.139:/harbor on /data/test1 <span class="built_in">type</span> nfs4 (rw,relatime,vers=4.2,rsize=524288,wsize=524288,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.1.142,local_lock=none,addr=10.20.1.139)<span class="comment"># NFS 客户端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;this is client&quot;</span> &gt; /data/test1/a.txt<span class="comment"># NFS 服务端执行：查看数据， 结论：客户端数据已写入服务端挂载目录</span>$ <span class="built_in">cat</span> /root/data/harbor/a.txt this is client<span class="comment"># NFS 服务端执行：写入数据</span>$ <span class="built_in">echo</span> <span class="string">&quot;This is Server&quot;</span> &gt;&gt; /root/data/harbor/a.txt<span class="comment"># NFS 客户端执行：查看数据， 结论：服务端数据已写入客户端挂载目录</span>$ <span class="built_in">cat</span> /data/test1/a.txt this is clientThis is Server</code></pre><p><strong>取消挂载</strong></p><pre><code class="highlight bash"><span class="comment"># 取消挂载</span>umount /data/test1<span class="comment"># 如果取消挂载出现报错，例如：</span>$ umount /data/test1umount.nfs4: /data/test1: device is busy<span class="comment"># 查看目录占用进程</span>$ fuser -m /data/test1/data/test1:         32679c<span class="comment"># kill 进程</span>$ <span class="built_in">kill</span> -9 32679<span class="comment"># 方式二：强制卸载</span>umount -l /data/test1</code></pre><h3 id="1-6-配置存储卷"><a href="#1-6-配置存储卷" class="headerlink" title="1.6 配置存储卷"></a>1.6 配置存储卷</h3><h4 id="1-6-1-创建命名空间"><a href="#1-6-1-创建命名空间" class="headerlink" title="1.6.1 创建命名空间"></a>1.6.1 创建命名空间</h4><p>nfs存储卷相关配置放到指定的命名空间中</p><pre><code class="highlight bash"><span class="comment"># 创建命名空间，</span>$ kubectl create ns nfs-storagenamespace/nfs-storage created</code></pre><h4 id="1-6-2-配置nfs-storage-yaml并运行"><a href="#1-6-2-配置nfs-storage-yaml并运行" class="headerlink" title="1.6.2 配置nfs-storage.yaml并运行"></a>1.6.2 配置<code>nfs-storage.yaml</code>并运行</h4><pre><code class="highlight bash">apiVersion: storage.k8s.io/v1kind: StorageClassmetadata:  namespace: nfs-storage  name: nfs-client<span class="comment"># provisioner: nfs-provisioner</span>provisioner: k8s-sigs.io/nfs-subdir-external-provisioner <span class="comment"># 指定动态配置器，NFS 子目录外部配置器</span>parameters:  pathPattern: <span class="variable">$&#123;.PVC.namespace&#125;</span>/<span class="variable">$&#123;.PVC.name&#125;</span> <span class="comment"># 动态生成的 NFS 路径，格式为 &lt;PVC 命名空间&gt;/&lt;PVC 名称&gt;，例如 nfs-storageclass/test-claim。</span>  archiveOnDelete: <span class="string">&quot;true&quot;</span> <span class="comment">##删除 pv,pv内容是否备份</span>---apiVersion: apps/v1kind: Deploymentmetadata:  namespace: nfs-storage  name: nfs-client-provisioner <span class="comment"># NFS 动态存储配置器，用于自动为 PVC 创建 PV</span>spec:  replicas: 1  selector:    matchLabels:      app: nfs-client-provisioner  template:    metadata:      labels:        app: nfs-client-provisioner    spec:      serviceAccountName: nfs-client-provisioner <span class="comment"># 指定使用的 ServiceAccountName</span>      containers:        - name: nfs-client-provisioner          image: k8s.dockerproxy.com/sig-storage/nfs-subdir-external-provisioner:v4.0.2          imagePullPolicy: IfNotPresent          volumeMounts:            - name: nfs-client-root <span class="comment"># 挂载的卷名称，与 volumes 部分定义的卷对应</span>              mountPath: /persistentvolumes <span class="comment"># 将 NFS 卷挂载到容器内的 /persistentvolumes 路径，供容器读写 NFS 共享数据。</span>          <span class="built_in">env</span>:            - name: PROVISIONER_NAME              value: k8s-sigs.io/nfs-subdir-external-provisioner <span class="comment"># 指定配置器名称，与 StorageClass 保持一致</span>            - name: NFS_SERVER              value: 10.20.1.139 <span class="comment"># NFS 服务器地址</span>            - name: NFS_PATH              value: /root/data/harbor <span class="comment"># NFS 共享路径</span>      volumes:        - name: nfs-client-root <span class="comment"># 定义一个名为 nfs-client-root 的 NFS 卷，连接到 NFS 服务器的指定地址和路径</span>          nfs:            server: 10.20.1.139 <span class="comment"># NFS 服务器地址</span>            path: /root/data/harbor <span class="comment"># NFS 共享路径</span>      nodeName: k8s-node02 <span class="comment"># 指定 Pod 运行在 k8s-node02 节点上</span>---apiVersion: v1kind: ServiceAccountmetadata:  name: nfs-client-provisioner <span class="comment"># SA 的名称</span>  namespace: nfs-storage---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata:  name: nfs-client-provisioner-runnerrules:  - apiGroups: [<span class="string">&quot;&quot;</span>]    resources: [<span class="string">&quot;nodes&quot;</span>]    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  - apiGroups: [<span class="string">&quot;&quot;</span>]    resources: [<span class="string">&quot;persistentvolumes&quot;</span>]    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>]  - apiGroups: [<span class="string">&quot;&quot;</span>]    resources: [<span class="string">&quot;persistentvolumeclaims&quot;</span>]    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]  - apiGroups: [<span class="string">&quot;storage.k8s.io&quot;</span>]    resources: [<span class="string">&quot;storageclasses&quot;</span>]    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  - apiGroups: [<span class="string">&quot;&quot;</span>]    resources: [<span class="string">&quot;events&quot;</span>]    verbs: [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata:  name: run-nfs-client-provisionersubjects:  - kind: ServiceAccount <span class="comment"># 绑定类型 ServiceAccount</span>    name: nfs-client-provisioner <span class="comment"># ServiceAccount 的名称</span>    namespace: nfs-storageroleRef:  kind: ClusterRole <span class="comment"># 绑定的角色类型</span>  name: nfs-client-provisioner-runner <span class="comment"># 集群角色名称 nfs-client-provisioner-runner</span>  apiGroup: rbac.authorization.k8s.io---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata:  name: leader-locking-nfs-client-provisioner <span class="comment"># 角色的名称，表明它与 NFS 客户端存储提供者的领导者选举（leader election）机制相关。</span>  namespace: nfs-storagerules:  - apiGroups: [<span class="string">&quot;&quot;</span>] <span class="comment"># 空字符串表示核心 API 组（core API group），包含 Kubernetes 的基本资源，如 endpoints。</span>    resources: [<span class="string">&quot;endpoints&quot;</span>]    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]---kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata:  name: run-leader-locking-nfs-client-provisioner  namespace: nfs-storagesubjects:  - kind: ServiceAccount <span class="comment"># 绑定资源类型为 ServiceAccount</span>    name: nfs-client-provisioner <span class="comment"># 绑定的ServiceAccount 名称</span>    namespace: nfs-storageroleRef:  kind: Role <span class="comment"># 绑定角色（nfs-storage名称空间的角色）</span>  apiGroup: rbac.authorization.k8s.io  name: leader-locking-nfs-client-provisioner <span class="comment"># 角色的名称</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f nfs-storage.yaml$ kubectl get all -n nfs-storageNAME                                         READY   STATUS    RESTARTS   AGEpod/nfs-client-provisioner-c485df84f-44hmr   1/1     Running   0          112sNAME                                     READY   UP-TO-DATE   AVAILABLE   AGEdeployment.apps/nfs-client-provisioner   1/1     1            1           112sNAME                                               DESIRED   CURRENT   READY   AGEreplicaset.apps/nfs-client-provisioner-c485df84f   1         1         1       112s</code></pre><h3 id="2-安装-Helm，添加-Harbor-仓库"><a href="#2-安装-Helm，添加-Harbor-仓库" class="headerlink" title="2. 安装 Helm，添加 Harbor 仓库"></a>2. 安装 Helm，添加 Harbor 仓库</h3><h4 id="2-1-安装-Helm"><a href="#2-1-安装-Helm" class="headerlink" title="2.1 安装 Helm"></a>2.1 安装 Helm</h4><p>参考：<a href="https://georgechan95.github.io/blog/d8e3c7b3.html">https://georgechan95.github.io/blog/d8e3c7b3.html</a></p><p><strong>下载二进制安装包</strong></p><p>下载地址：<a href="https://github.com/helm/helm/releases">https://github.com/helm/helm/releases</a></p><pre><code class="highlight bash">wget https://get.helm.sh/helm-v3.12.3-linux-amd64.tar.gz</code></pre><p><strong>解压二进制包</strong></p><pre><code class="highlight bash">$ tar -zxvf helm-v3.12.3-linux-amd64.tar.gz</code></pre><p><strong>将二进制文件移动到对应的目录中</strong></p><pre><code class="highlight bash">$ <span class="built_in">mv</span> linux-amd64/helm /usr/local/bin/helm</code></pre><p><strong>测试</strong></p><pre><code class="highlight bash"><span class="comment"># 查看Helm版本</span>$ helm versionversion.BuildInfo&#123;Version:<span class="string">&quot;v3.12.3&quot;</span>, GitCommit:<span class="string">&quot;3a31588ad33fe3b89af5a2a54ee1d25bfe6eaa5e&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, GoVersion:<span class="string">&quot;go1.20.7&quot;</span>&#125;</code></pre><h3 id="3-安装-Ingress-控制器"><a href="#3-安装-Ingress-控制器" class="headerlink" title="3. 安装 Ingress 控制器"></a>3. 安装 Ingress 控制器</h3><p>参考：<a href="https://georgechan95.github.io/blog/6436eaf1.html">https://georgechan95.github.io/blog/6436eaf1.html</a> 第三节</p><pre><code class="highlight bash"><span class="comment"># 下载 ingress-nginx 需要的镜像</span><span class="comment"># k8s-node03 节点需要导入这些镜像</span>docker pull registry.k8s.io/ingress-nginx/controller:v1.9.4docker pull registry.k8s.io/defaultbackend-amd64:1.5docker pull registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231011-8b53cabe0docker pull registry.k8s.io/ingress-nginx/opentelemetry:v20230721-3e2062ee5</code></pre><p>master节点重新安装 Ingress-nginx ，让 k8s-node03 节点安装上 Ingress 控制器</p><pre><code class="highlight bash"><span class="comment"># 卸载原有的 ingress-nginx</span>[root@k8s-master01 /opt/k8s/10/ingress-nginx]$ helm uninstall ingress-nginx --namespace ingress-nginx<span class="comment"># 或者更新 ingress-nginx</span>$ helm upgrade ingress-nginx /opt/k8s/10/ingress-nginx --namespace ingress-nginx -f /opt/k8s/10/ingress-nginx/values.yaml<span class="comment"># 重新安装</span>[root@k8s-master01 /opt/k8s/10/ingress-nginx]$ helm install ingress-nginx --namespace ingress-nginx --create-namespace .<span class="comment"># 查看 Ingress，k8s-node03 成功运行了 ingress控制器</span>$ kubectl get pod -n ingress-nginx -o wideNAME                             READY   STATUS    RESTARTS   AGE     IP            NODE         NOMINATED NODE   READINESS GATESingress-nginx-controller-5wzqt   1/1     Running   0          2m33s   10.20.1.141   k8s-node02   &lt;none&gt;           &lt;none&gt;ingress-nginx-controller-9wfpq   1/1     Running   0          2m33s   10.20.1.142   k8s-node03   &lt;none&gt;           &lt;none&gt;ingress-nginx-controller-z9sl8   1/1     Running   0          2m33s   10.20.1.140   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h2 id="2-安装-Harbor"><a href="#2-安装-Harbor" class="headerlink" title="2. 安装 Harbor"></a>2. 安装 Harbor</h2><h3 id="2-1-添加-Harbor-仓库，下载安装包"><a href="#2-1-添加-Harbor-仓库，下载安装包" class="headerlink" title="2.1  添加 Harbor 仓库，下载安装包"></a>2.1  添加 Harbor 仓库，下载安装包</h3><pre><code class="highlight bash"><span class="comment"># 添加Harbor仓库</span>$ helm repo add harbor https://helm.goharbor.io<span class="comment"># 从仓库中查看harbor安装包，最新的4个</span>$ helm search repo harbor -l |  grep harbor/harbor  | <span class="built_in">head</span>  -4<span class="comment"># 拉取指定版本的harbor helm安装包</span>$ helm pull harbor/harbor --version 1.17.1<span class="comment"># 解压</span>tar -zxvf harbor-1.17.1.tgz harbor</code></pre><h3 id="2-2-创建命名空间，指定安装节点"><a href="#2-2-创建命名空间，指定安装节点" class="headerlink" title="2.2 创建命名空间，指定安装节点"></a>2.2 创建命名空间，指定安装节点</h3><p>这里将 harbor 安装到 k8s-node03 节点上，并在单独的命名空间中。</p><pre><code class="highlight bash"><span class="comment"># 给 k8s-node03 节点打一个标签</span>$ kubectl label node k8s-node03 harbor=<span class="built_in">env</span></code></pre><p><strong>创建命名空间，并指定节点</strong></p><pre><code class="highlight bash">$ <span class="built_in">cat</span> namespace-harbor.yaml apiVersion: v1kind: Namespacemetadata:  name: harbor<span class="comment"># 执行资源清单</span>$ kubectl apply -f namespace-harbor.yaml<span class="comment"># 查看命名空间</span>$ kubectl get ns | grep harborharbor            Active   44m</code></pre><h3 id="2-3-修改-harbor-目录下的-values-yaml"><a href="#2-3-修改-harbor-目录下的-values-yaml" class="headerlink" title="2.3 修改 harbor 目录下的 values.yaml"></a>2.3 修改 harbor 目录下的 values.yaml</h3><h4 id="2-3-1-修改-hostname-定义自己的域名"><a href="#2-3-1-修改-hostname-定义自己的域名" class="headerlink" title="2.3.1 修改 hostname 定义自己的域名"></a>2.3.1 修改 hostname 定义自己的域名</h4><pre><code class="highlight yaml"><span class="attr">expose:</span>  <span class="attr">type:</span> <span class="string">ingress</span>  <span class="attr">ingress:</span>    <span class="attr">hosts:</span>      <span class="attr">core:</span> <span class="string">my.harbor.docker</span> <span class="comment"># 自定义域名</span><span class="attr">externalURL:</span> <span class="string">https://my.harbor.docker</span> <span class="comment"># 与上面保持一致</span></code></pre><h4 id="2-3-2-持久卷配置"><a href="#2-3-2-持久卷配置" class="headerlink" title="2.3.2 持久卷配置"></a>2.3.2 持久卷配置</h4><p>持久卷修改storageClass ，改成前面定义 nfs-client</p><pre><code class="highlight yaml"><span class="attr">persistence:</span>  <span class="attr">enabled:</span> <span class="literal">true</span>  <span class="attr">resourcePolicy:</span> <span class="string">&quot;keep&quot;</span>  <span class="attr">persistentVolumeClaim:</span>    <span class="attr">registry:</span>      <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span>      <span class="attr">accessMode:</span> <span class="string">ReadWriteOnce</span>      <span class="attr">size:</span> <span class="string">5Gi</span>    <span class="attr">jobservice:</span>      <span class="attr">jobLog:</span>        <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span>        <span class="attr">accessMode:</span> <span class="string">ReadWriteOnce</span>        <span class="attr">size:</span> <span class="string">1Gi</span>    <span class="attr">database:</span>      <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span>      <span class="attr">accessMode:</span> <span class="string">ReadWriteOnce</span>      <span class="attr">size:</span> <span class="string">1Gi</span>    <span class="attr">redis:</span>      <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span>      <span class="attr">accessMode:</span> <span class="string">ReadWriteOnce</span>      <span class="attr">size:</span> <span class="string">1Gi</span>    <span class="attr">trivy:</span>      <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span>      <span class="attr">accessMode:</span> <span class="string">ReadWriteOnce</span>      <span class="attr">size:</span> <span class="string">5Gi</span></code></pre><h4 id="2-3-3-修改Pod节点选择器"><a href="#2-3-3-修改Pod节点选择器" class="headerlink" title="2.3.3 修改Pod节点选择器"></a>2.3.3 修改Pod节点选择器</h4><p>修改 nodeSelector ，让 harbor 所有 Pod 都运行在 k8s-node03 节点上。</p><pre><code class="highlight yaml"><span class="attr">nginx:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">portal:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">core:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">jobservice:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">registry:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">trivy:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">database:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">redis:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span>    <span class="attr">exporter:</span>  <span class="attr">nodeSelector:</span>    <span class="attr">harbor:</span> <span class="string">env</span></code></pre><p>修改database资源</p><pre><code class="highlight yaml"><span class="attr">database:</span>  <span class="attr">internal:</span>    <span class="attr">resources:</span>      <span class="attr">requests:</span>        <span class="attr">memory:</span> <span class="string">256Mi</span>        <span class="attr">cpu:</span> <span class="string">100m</span></code></pre><h3 id="2-4-安装-Harbor-到集群"><a href="#2-4-安装-Harbor-到集群" class="headerlink" title="2.4 安装 Harbor 到集群"></a>2.4 安装 Harbor 到集群</h3><pre><code class="highlight bash"><span class="comment"># 进入Harbor 解压目录，安装Harbor</span>$ helm install harbor /opt/software/harbor -n harbor<span class="comment"># 修改 values.yaml 更新安装</span><span class="comment">#$ helm upgrade harbor /opt/software/harbor -n harbor -f /opt/software/harbor/values.yaml</span><span class="comment"># 在任务目录下安装Harbor</span><span class="comment">#$ helm install harbor /opt/software/harbor -n harbor -f /opt/software/harbor/values.yaml</span></code></pre><p><strong>特别注意：</strong></p><p>由于 habor 运行依赖的镜像都在国外仓库，因此在执行安装时会出现镜像拉取失败的情况，这里我通过docker代理的形式下载镜像，并导入到 k8s-node03 节点上。具体参考：<a href="https://georgechan95.github.io/blog/b01d5c62.html">Docker配置网络代理实现外网镜像下载</a></p><p>所有镜像都在 values.yaml 文件中</p><pre><code class="highlight bash">docker pull goharbor/nginx-photon:v2.13.1docker pull goharbor/harbor-portal:v2.13.1docker pull goharbor/harbor-core:v2.13.1docker pull goharbor/harbor-jobservice:v2.13.1docker pull goharbor/registry-photon:v2.13.1docker pull goharbor/harbor-registryctl:v2.13.1docker pull goharbor/trivy-adapter-photon:v2.13.1docker pull goharbor/harbor-db:v2.13.1docker pull goharbor/redis-photon:v2.13.1docker pull goharbor/harbor-exporter:v2.13.1<span class="built_in">echo</span> <span class="string">&quot;镜像下载完成&quot;</span>docker save goharbor/nginx-photon:v2.13.1 -o nginx-photon-v2.13.1.tardocker save goharbor/harbor-portal:v2.13.1 -o harbor-portal-v2.13.1.tardocker save goharbor/harbor-core:v2.13.1 -o harbor-core-v2.13.1.tardocker save goharbor/harbor-jobservice:v2.13.1 -o harbor-jobservice-v2.13.1.tardocker save goharbor/registry-photon:v2.13.1 -o registry-photon-v2.13.1.tardocker save goharbor/harbor-registryctl:v2.13.1 -o harbor-registryctl-v2.13.1.tardocker save goharbor/trivy-adapter-photon:v2.13.1 -o trivy-adapter-photon-v2.13.1.tardocker save goharbor/harbor-db:v2.13.1 -o harbor-db-v2.13.1.tardocker save goharbor/redis-photon:v2.13.1 -o redis-photon-v2.13.1.tardocker save goharbor/harbor-exporter:v2.13.1 -o harbor-exporter-v2.13.1.tar<span class="built_in">echo</span> <span class="string">&quot;镜像打包完成&quot;</span>docker load -i nginx-photon-v2.13.1.tardocker load -i harbor-portal-v2.13.1.tardocker load -i harbor-core-v2.13.1.tardocker load -i harbor-jobservice-v2.13.1.tardocker load -i registry-photon-v2.13.1.tardocker load -i harbor-registryctl-v2.13.1.tardocker load -i trivy-adapter-photon-v2.13.1.tardocker load -i harbor-db-v2.13.1.tardocker load -i redis-photon-v2.13.1.tardocker load -i harbor-exporter-v2.13.1.tar<span class="built_in">echo</span> <span class="string">&quot;镜像加载完成&quot;</span></code></pre><h3 id="2-5-Docker-导入-Harbor-密钥"><a href="#2-5-Docker-导入-Harbor-密钥" class="headerlink" title="2.5 Docker 导入 Harbor 密钥"></a>2.5 Docker 导入 Harbor 密钥</h3><h4 id="2-5-1-导出-Harbor-公钥"><a href="#2-5-1-导出-Harbor-公钥" class="headerlink" title="2.5.1 导出 Harbor 公钥"></a>2.5.1 导出 Harbor 公钥</h4><pre><code class="highlight bash"><span class="comment"># 查看Harbor生成的Secret</span>$ kubectl get secret -n harborNAME                           TYPE                 DATA   AGEharbor-core                    Opaque               8      13mharbor-database                Opaque               1      13mharbor-ingress                 kubernetes.io/tls    3      13mharbor-jobservice              Opaque               2      13mharbor-registry                Opaque               2      13mharbor-registry-htpasswd       Opaque               1      13mharbor-registryctl             Opaque               0      13mharbor-trivy                   Opaque               2      13msh.helm.release.v1.harbor.v1   helm.sh/release.v1   1      13m<span class="comment"># 1. 查看 harbor 公钥内容，ca.crt 就是公钥</span>$ kubectl get secret harbor-ingress -n harbor -o yamlapiVersion: v1data:  ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lRTlZRd3VoTk5ERjNSQmZPTTM3c25sakFOQmdrcWhraUc5dzBCQVFzRkFEQVUKTVJJd0VBWURWUVFERXdsb1lYSmliM0l0WTJFd0hoY05NalV3TnpBNE1EWXhNRE0wV2hjTk1qWXdOekE0TURZeApNRE0wV2pBVU1SSXdFQVlEVlFRREV3bG9ZWEppYjNJdFkyRXdnZ0VpTUEwR0NTcUdTSWIzRFFFQkFRVUFBNElCCkR3QXdnZ0VLQW9JQkFRRGZQdjFoWDhPYVpYWkNkOXFzSld0RUtWbXdUakRrMlhGZFJQRS93dnV5T2V5UW1tZDYKSzFJUW0zYXpqQThvMGlvSHdScXhZaGNjYjN2SmUxRld1TDFoTTBQTkRWRWRVakxzc0kzWm1pcXlTano1N1YxMgpVeWlabGRqcHVCYlBQcGNhL3dLc0V6bG04SFFhMkI4NndsaEJzUFUxd0dxT1FPbSt5WlVBdEZ1dGVrT2xDNGZHCnM0SFd5MlVJNm5pclFKRXFWc2Foek83dHFaRzhNK1NZQTJLRnpkTEN1R0pkTnpjR3QrTzJ2NjRyNy9SVVRHTk8KVWlpRTIweXhYVFl2NTVrcnd6dlhRNXhKRlBzb0w1YmsycjVxU3lKVTlydmtpNEhjV0pubUhHSFN3OTJTU3FGZwpwVUZKNm4rQkEzbThEdk1CL2pZOW5EcUk1NzluM3dxSm9QaURBZ01CQUFHallUQmZNQTRHQTFVZER3RUIvd1FFCkF3SUNwREFkQmdOVkhTVUVGakFVQmdnckJnRUZCUWNEQVFZSUt3WUJCUVVIQXdJd0R3WURWUjBUQVFIL0JBVXcKQXdFQi96QWRCZ05WSFE0RUZnUVVoZXRCUEpwUkxSKzdOTHFFWEZyN2FXakJ6VDB3RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFINDJqOGtSUFNMdjNjaGFEU3BMUDdWeG9obU9lRythajYvMVBSTmFpWjlvZVdDd3kveGVRODlZCnFycEViVmF5anVJUlpFcDh2VE4yL3pxcUFzOGh5MHRSY3NxNzAraE8rUlJpdStNUFJ0ZzNmTlY3RlZVVzd5aXkKMG0xTmpPL1U1RXpxbnlQQkNGbWJZM1Z6Q3Vmdzc0bElFU0JDZHc4SW03ODRTeDBoa1dTRmd4RFY3djZZZDlKdgorN3laek4zQ2Flem1KS2xXT3VNQjByeTZNTC95bldPKzJxWVFZQjB6OGhyTFFwMS9aTzhpb05rMEVtL1pDL1JXCkNocVRmUFFsYzZUbGhJUFkrSnVYRDNVLzlIRXd4YWVWVzVqblI4cXpXdEJMVHUzSTE5ZERSUGJUQVN0N0w4MUoKU1BTb1lJMTFLTCt2cDBPRDY2ankzWjZ6VDQ4enNtbz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUROakNDQWg2Z0F3SUJBZ0lRTTh2VW9aMlhzMHowbVJFNXYyVU1BekFOQmdrcWhraUc5dzBCQVFzRkFEQVUKTVJJd0VBWURWUVFERXdsb1lYSmliM0l0WTJFd0hoY05NalV3TnpBNE1EWXhNRE0wV2hjTk1qWXdOekE0TURZeApNRE0wV2pBYk1Sa3dGd1lEVlFRREV4QnRlUzVvWVhKaWIzSXVaRzlqYTJWeU1JSUJJakFOQmdrcWhraUc5dzBCCkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXpLVEVmcjg1S1hza1JUVjF4TGhYbnRraExTUmhGM25GV0hYSzZyQ3QKMjdSRXhTSnlabDdZQU81U2RlT2tCRGs1dE5oRVhVTG83MHhYbThRdTQxNC9oeThtdHpvYmJXWWJrcHNtNGxlYQp2UmM1dTl3REhiSjVhNVpnV1FLaWJTd01nUWtLR3RmbHdhUUFUcTVMQm05TXRVc2hCN1hUQXB6R1dENXZEc3MzCm5MZXpCbFp0TUFyZmtncU9vLzQxMFVWTWtYV05CcVFpNFFkUUFoTVVuclR6d0ovdWo5UDhFR3podGxBMkVMTU4KamIrL1FUK05HcGVEQmFGWXcrNDdJa0V5RkY2RFJqdE9VTSt0SWt0Q2hCek5xd1BVUjJ0UCtSWWhrZnM4TnJlYQp2bDdwNC8rWnlIRWkwVXMwV3B4R2lqbXZITHY3Rmw0dENXam5LZkRoMVZjZ253SURBUUFCbzMwd2V6QU9CZ05WCkhROEJBZjhFQkFNQ0JhQXdIUVlEVlIwbEJCWXdGQVlJS3dZQkJRVUhBd0VHQ0NzR0FRVUZCd01DTUF3R0ExVWQKRXdFQi93UUNNQUF3SHdZRFZSMGpCQmd3Rm9BVWhldEJQSnBSTFIrN05McUVYRnI3YVdqQnpUMHdHd1lEVlIwUgpCQlF3RW9JUWJYa3VhR0Z5WW05eUxtUnZZMnRsY2pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQVAyZnUwd2p1CkQ0em1uWFdNRVYxMnhPbnJmZEUwNkxiUysxTXZMcmwyVGluZkwvY1F2M1VuNkZJWlVDVEsrSFJkUWxLdmZsK2cKSTZJUzJHWXJpcWQ1ZWk5Q1Z5YjZORUMrZzZ2RkhCZjZlK0tQaFNYNTVVTDhFQ2pDaUU4aURRdEZjOEdVUWg5MwoxNTFSdmo3VTZxVTV1WnBuck10NURJTy9LQ2F3NHRjcEpJUjhBR3RUUVFQUnRXRExvYzB5UityNWlaVWRpZyszClJNVzNReS9LZEtqamprK0UzYUU1Y2Z1RmFzeHNVZU9IcDcxQ2lhaEtGN3MwRW96QzhJRSsySFNEK3pLTFhpV3kKM203Q2pTdWhyTnhVL1pkNXZKSmkvVUUxWjB6dUh4dFBZenlHTWVQYWN0VFBDK1ZOWDJlU3hHRGgrN2tNS0Y3cQpqcmk1RVlRanNHQU43QT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K  tls.key: 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kind: Secretmetadata:  annotations:    meta.helm.sh/release-name: harbor    meta.helm.sh/release-namespace: harbor  creationTimestamp: <span class="string">&quot;2025-07-08T06:10:36Z&quot;</span>  labels:    app: harbor    app.kubernetes.io/instance: harbor    app.kubernetes.io/managed-by: Helm    app.kubernetes.io/name: harbor    app.kubernetes.io/part-of: harbor    app.kubernetes.io/version: 2.13.1    chart: harbor    heritage: Helm    release: harbor  name: harbor-ingress  namespace: harbor  resourceVersion: <span class="string">&quot;866456&quot;</span>  uid: f816d990-e733-45a1-999c-51ea9efeb1f7<span class="built_in">type</span>: kubernetes.io/tls<span class="comment"># 2. 将 ca.crt 解密后导出</span>$ <span class="built_in">echo</span> <span class="string">&#x27;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFekNDQWZ1Z0F3SUJBZ0lRTlZRd3VoTk5ERjNSQmZPTTM3c25sakFOQmdrcWhraUc5dzBCQVFzRkFEQVUKTVJJd0VBWURWUVFERXdsb1lYSmliM0l0WTJFd0hoY05NalV3TnpBNE1EWXhNRE0wV2hjTk1qWXdOekE0TURZeApNRE0wV2pBVU1SSXdFQVlEVlFRREV3bG9ZWEppYjNJdFkyRXdnZ0VpTUEwR0NTcUdTSWIzRFFFQkFRVUFBNElCCkR3QXdnZ0VLQW9JQkFRRGZQdjFoWDhPYVpYWkNkOXFzSld0RUtWbXdUakRrMlhGZFJQRS93dnV5T2V5UW1tZDYKSzFJUW0zYXpqQThvMGlvSHdScXhZaGNjYjN2SmUxRld1TDFoTTBQTkRWRWRVakxzc0kzWm1pcXlTano1N1YxMgpVeWlabGRqcHVCYlBQcGNhL3dLc0V6bG04SFFhMkI4NndsaEJzUFUxd0dxT1FPbSt5WlVBdEZ1dGVrT2xDNGZHCnM0SFd5MlVJNm5pclFKRXFWc2Foek83dHFaRzhNK1NZQTJLRnpkTEN1R0pkTnpjR3QrTzJ2NjRyNy9SVVRHTk8KVWlpRTIweXhYVFl2NTVrcnd6dlhRNXhKRlBzb0w1YmsycjVxU3lKVTlydmtpNEhjV0pubUhHSFN3OTJTU3FGZwpwVUZKNm4rQkEzbThEdk1CL2pZOW5EcUk1NzluM3dxSm9QaURBZ01CQUFHallUQmZNQTRHQTFVZER3RUIvd1FFCkF3SUNwREFkQmdOVkhTVUVGakFVQmdnckJnRUZCUWNEQVFZSUt3WUJCUVVIQXdJd0R3WURWUjBUQVFIL0JBVXcKQXdFQi96QWRCZ05WSFE0RUZnUVVoZXRCUEpwUkxSKzdOTHFFWEZyN2FXakJ6VDB3RFFZSktvWklodmNOQVFFTApCUUFEZ2dFQkFINDJqOGtSUFNMdjNjaGFEU3BMUDdWeG9obU9lRythajYvMVBSTmFpWjlvZVdDd3kveGVRODlZCnFycEViVmF5anVJUlpFcDh2VE4yL3pxcUFzOGh5MHRSY3NxNzAraE8rUlJpdStNUFJ0ZzNmTlY3RlZVVzd5aXkKMG0xTmpPL1U1RXpxbnlQQkNGbWJZM1Z6Q3Vmdzc0bElFU0JDZHc4SW03ODRTeDBoa1dTRmd4RFY3djZZZDlKdgorN3laek4zQ2Flem1KS2xXT3VNQjByeTZNTC95bldPKzJxWVFZQjB6OGhyTFFwMS9aTzhpb05rMEVtL1pDL1JXCkNocVRmUFFsYzZUbGhJUFkrSnVYRDNVLzlIRXd4YWVWVzVqblI4cXpXdEJMVHUzSTE5ZERSUGJUQVN0N0w4MUoKU1BTb1lJMTFLTCt2cDBPRDY2ankzWjZ6VDQ4enNtbz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=&#x27;</span> | <span class="built_in">base64</span> -d &gt; ca.crt</code></pre><h4 id="2-5-2-Docker-安装公钥"><a href="#2-5-2-Docker-安装公钥" class="headerlink" title="2.5.2 Docker 安装公钥"></a>2.5.2 Docker 安装公钥</h4><pre><code class="highlight bash"><span class="comment"># 将harbor证书保存在docker目录下，创建根域名相同的子目录，这一步建议所有机器都执行</span>$ <span class="built_in">mkdir</span> -p /etc/docker/certs.d/my.harbor.docker$ <span class="built_in">cp</span> ca.crt /etc/docker/certs.d/my.harbor.docker/</code></pre><h4 id="2-5-3-修改Docker-daemon-json"><a href="#2-5-3-修改Docker-daemon-json" class="headerlink" title="2.5.3 修改Docker daemon.json"></a>2.5.3 修改Docker daemon.json</h4><pre><code class="highlight bash">sudo vi /etc/docker/daemon.json<span class="comment"># 添加如下配置，my.harbor.docker 是自定义的harbor域名</span>&#123;  <span class="string">&quot;insecure-registries&quot;</span>: [<span class="string">&quot;my.harbor.docker&quot;</span>]&#125;<span class="comment"># 保存后重启Docker</span>systemctl daemon-reloadsystemctl restart docker</code></pre><h4 id="2-5-4-Dockers-登录Harbor"><a href="#2-5-4-Dockers-登录Harbor" class="headerlink" title="2.5.4 Dockers 登录Harbor"></a>2.5.4 Dockers 登录Harbor</h4><pre><code class="highlight bash"><span class="comment"># 服务器写入Host域名映射</span>$ <span class="built_in">echo</span> <span class="string">&quot;10.20.1.142 my.harbor.docker&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># docker 登录Harbor私服</span>$ docker login -u admin -p Harbor12345 my.harbor.dockerWARNING! Using --password via the CLI is insecure. Use --password-stdin.WARNING! Your credentials are stored unencrypted <span class="keyword">in</span> <span class="string">&#x27;/root/.docker/config.json&#x27;</span>.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/go/credential-store/Login Succeeded</code></pre><h4 id="2-5-6-浏览器访问"><a href="#2-5-6-浏览器访问" class="headerlink" title="2.5.6 浏览器访问"></a>2.5.6 浏览器访问</h4><p>客户端写入 Host 域名映射</p><pre><code class="highlight plaintext">10.20.1.142 my.harbor.docker</code></pre><p>访问地址：<a href="https://my.harbor.docker/">https://my.harbor.docker/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/08/20250708-151720.png" alt="浏览器登录Harbor"></p><h4 id="2-5-6-测试推送镜像到-Harbor-私服"><a href="#2-5-6-测试推送镜像到-Harbor-私服" class="headerlink" title="2.5.6 测试推送镜像到 Harbor 私服"></a>2.5.6 测试推送镜像到 Harbor 私服</h4><p><strong>在Harbor中创建一个新的项目</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/08/20250708-145248.png" alt="新建项目"></p><pre><code class="highlight bash"><span class="comment"># 给镜像打标签</span>$ docker tag busybox:latest my.harbor.docker/my-harbor/busybox:latest<span class="comment"># 查看镜像</span>$ docker images | grep busyboxbusybox                                                                       latest                ff7a7936e930   9 months ago    4.28MBmy.harbor.docker/my-harbor/busybox                                            latest                ff7a7936e930   9 months ago    4.28MB<span class="comment"># 将镜像推送到Harbor</span>$ docker push my.harbor.docker/my-harbor/busybox:latestThe push refers to repository [my.harbor.docker/my-harbor/busybox]068f50152bbc: Pushed latest: digest: sha256:f2e98ad37e4970f48e85946972ac4acb5574c39f27c624efbd9b17a3a402bfe4 size: 527</code></pre><p><strong>再次查看Harbor，镜像已推送到Harbor中</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/08/20250708-145650.png" alt="查看镜像"></p><h3 id="2-6-卸载-Harbor"><a href="#2-6-卸载-Harbor" class="headerlink" title="2.6 卸载 Harbor"></a>2.6 卸载 Harbor</h3><pre><code class="highlight bash">$ helm uninstall harbor -n harbor$ kubectl delete pvc -n harbor --all</code></pre><p><strong>参考链接</strong></p><blockquote><p><a href="https://www.cnblogs.com/qlsem/p/17714509.html">https://www.cnblogs.com/qlsem/p/17714509.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;当前集群环境&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;Hostname&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;10.20.1.139&lt;/td</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
    <category term="Harbor" scheme="https://georgechan95.github.io/tags/Harbor/"/>
    
  </entry>
  
  <entry>
    <title>012-新建Node节点添加到K8S集群中</title>
    <link href="https://georgechan95.github.io/blog/b42f2c7b.html"/>
    <id>https://georgechan95.github.io/blog/b42f2c7b.html</id>
    <published>2025-07-07T12:32:00.000Z</published>
    <updated>2025-07-07T06:38:02.613Z</updated>
    
    <content type="html"><![CDATA[<p>需求：当前集群为一主两从，共3个节点，需要增加一个从节点。</p><p><strong>当前集群如下：</strong></p><table><thead><tr><th>IP</th><th>Hostname</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td></tr><tr><td><strong>需新增如下节点</strong></td><td></td></tr><tr><td>10.20.1.142</td><td>k8s-node03</td></tr></tbody></table><h1 id="一、节点初始化设置"><a href="#一、节点初始化设置" class="headerlink" title="一、节点初始化设置"></a>一、节点初始化设置</h1><p>参考：<a href="https://georgechan95.github.io/blog/b00f53e9.html">基于Rocky9.3系统使用kubeadm安装k8s1.29集群</a></p><h2 id="1-设置主机名"><a href="#1-设置主机名" class="headerlink" title="1. 设置主机名"></a>1. 设置主机名</h2><pre><code class="highlight bash">hostnamectl set-hostname k8s-node03</code></pre><h2 id="2-修改Host文件"><a href="#2-修改Host文件" class="headerlink" title="2. 修改Host文件"></a>2. 修改Host文件</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt; <span class="string">&quot;EOF&quot;</span>10.20.1.139 k8s-master0110.20.1.140 k8s-node0110.20.1.141 k8s-node0210.20.1.142 k8s-node03EOF</code></pre><h2 id="3-修改终端颜色"><a href="#3-修改终端颜色" class="headerlink" title="3. 修改终端颜色"></a>3. 修改终端颜色</h2><p>这里只是修改shell终端显示文本的颜色，非必要步骤。</p><pre><code class="highlight bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF &gt;&gt; ~/.bashrc</span><span class="string">PS1=&quot;\[\e[37;47m\][\[\e[32;47m\]\u\[\e[34;47m\]@\h \[\e[36;47m\]\w\[\e[0m\]]\\$ &quot;</span><span class="string">EOF</span><span class="comment"># 让修改立即见效</span><span class="built_in">source</span> ~/.bashrc</code></pre><h2 id="4-更换系统软件源"><a href="#4-更换系统软件源" class="headerlink" title="4. 更换系统软件源"></a>4. 更换系统软件源</h2><pre><code class="highlight bash"><span class="comment"># 更新源</span>sed -e <span class="string">&#x27;s|^mirrorlist=|#mirrorlist=|g&#x27;</span> \    -e <span class="string">&#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27;</span> \    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo    <span class="comment"># 刷新dnf缓存</span>dnf makecache<span class="comment"># 验证源更新</span>dnf repolist</code></pre><ul><li><p>命令解析</p><pre><code class="highlight plaintext"># 使用 sed 命令修改 Rocky Linux 的 YUM/DNF 源配置文件，切换到阿里云的镜像源。sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \    -e &#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27; \    -i.bak /etc/yum.repos.d/[Rr]ocky*.repo    # 将以 mirrorlist= 开头的行注释掉（在前面加 #）-e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27;# 将以 #baseurl= 开头并指向默认 Rocky Linux 源的行取消注释，并替换为阿里云镜像源 URL。&#x27;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#x27;# -i.bak：直接修改文件，并为原文件创建备份（扩展名为 .bak）。# 修改 /etc/yum.repos.d/ 目录下所有以 rocky 或 Rocky 开头的 .repo 文件。# 修改完成后，原始文件会被备份为 .bak 文件。-i.bak /etc/yum.repos.d/[Rr]ocky*.repo# 更新本地缓存，确保系统可以快速查询软件包信息。dnf makecache</code></pre></li></ul><h2 id="5-修改防火墙"><a href="#5-修改防火墙" class="headerlink" title="5. 修改防火墙"></a>5. 修改防火墙</h2><pre><code class="highlight bash">systemctl stop firewalldsystemctl <span class="built_in">disable</span> firewalldyum -y install iptables-servicessystemctl start iptablesiptables -Fsystemctl <span class="built_in">enable</span> iptablesservice iptables save</code></pre><ul><li><p>命令解析</p><pre><code class="highlight plaintext"># 停止运行 firewalldsystemctl stop firewalld# 禁止 firewalld 开机自启systemctl disable firewalld# 安装 iptables 服务，用于管理 Linux 的防火墙规则yum -y install iptables-services# 使防火墙规则立即生效，并开始运行 iptables 防火墙服务。systemctl start iptables# 删除当前的防火墙规则，通常用于重置或清理防火墙规则。iptables -F# 设置 iptables 服务开机自启动，确保服务器重启后，iptables 服务会自动加载防火墙规则。systemctl enable iptables# 将当前 iptables 的规则配置保存到文件中（通常是 /etc/sysconfig/iptables），以便在系统重启或 iptables 服务重新启动后，能够自动加载保存的规则。service iptables save</code></pre></li></ul><h2 id="6-禁用-Selinux"><a href="#6-禁用-Selinux" class="headerlink" title="6 禁用 Selinux"></a>6 禁用 Selinux</h2><pre><code class="highlight bash">setenforce 0sed -i <span class="string">&quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot;</span> /etc/selinux/configgrubby --update-kernel ALL --args selinux=0</code></pre><ul><li><p>命令解析</p><pre><code class="highlight plaintext"># 将 SELinux 的模式设置为 Permissive（宽容模式）。# 0：表示设置为 Permissive 模式，此模式下 SELinux 不会强制执行安全策略，而是记录违规日志。# 1：表示 Enforcing 模式，此模式下 SELinux 会强制执行安全策略。setenforce 0# 修改 SELinux 配置文件 /etc/selinux/config，将 SELINUX 设置为 disabled。永久禁用 SELinux，即使系统重启也不会再启用。sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config# 通过 grubby 工具将 selinux=0 参数添加到所有内核启动配置中。grubby --update-kernel ALL --args selinux=0grubby --info DEFAULT# 查看是否禁用，grubby --info DEFAULT# 回滚内核层禁用操作，、grubby --update-kernel ALL --remove-args selinux</code></pre></li><li><p>修改完成后重启系统</p><pre><code class="highlight bash">reboot</code></pre></li></ul><h2 id="7-设置时区"><a href="#7-设置时区" class="headerlink" title="7 设置时区"></a>7 设置时区</h2><pre><code class="highlight bash">timedatectl set-timezone Asia/Shanghai</code></pre><h2 id="8-集群时间同步设置"><a href="#8-集群时间同步设置" class="headerlink" title="8 集群时间同步设置"></a>8 集群时间同步设置</h2><pre><code class="highlight bash">timedatectldnf install -y chronysystemctl <span class="built_in">enable</span> chronyd.servicesystemctl restart chronyd.servicesystemctl status chronyd.servicevim /etc/chrony.conf<span class="comment"># 修改完chrony配置后，重启chrony服务</span>systemctl <span class="built_in">enable</span> chronyd  --now</code></pre><ul><li><p>chrony配置内容如下</p><pre><code class="highlight plaintext"># 添加阿里云NTP服务器pool ntp1.aliyun.com iburstpool ntp2.aliyun.com iburstpool cn.pool.ntp.org iburst    # 允许指定网段访问此时间服务器，不然只允许本地网络allow 10.20.0.0/16</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/07/20250707-111802.png" alt="chrony配置内容"></p><p>chrony配置内容</p></li><li><p>命令解析</p><pre><code class="highlight plaintext"># 检查时区和时间timedatectl# 安装chrony进行时间同步，ntpdate在Rocky 9中不再支持dnf install -y chrony# 启用chronyd服务systemctl enable chronyd.service# 重启chronyd服务systemctl restart chronyd.service# 查看chronyd服务状态systemctl status chronyd.service</code></pre></li></ul><h2 id="9-修改系统最大打开文件数"><a href="#9-修改系统最大打开文件数" class="headerlink" title="9 修改系统最大打开文件数"></a>9 修改系统最大打开文件数</h2><p>在 <code>/etc/security/limits.conf</code> 文件的末尾追加以下内容</p><pre><code class="highlight bash">*softnofile65535*hardnofile65535</code></pre><p>目的：修改最大打开文件数限制</p><h2 id="10-安装必要的库和修改-sysctl-conf-内核参数配置"><a href="#10-安装必要的库和修改-sysctl-conf-内核参数配置" class="headerlink" title="10 安装必要的库和修改 sysctl.conf 内核参数配置"></a>10 安装必要的库和修改 <code>sysctl.conf</code> 内核参数配置</h2><pre><code class="highlight bash">dnf install -y epel-releasednf install -y bridge-utilsmodprobe br_netfilter<span class="built_in">echo</span> <span class="string">&#x27;br_netfilter&#x27;</span> &gt;&gt; /etc/modules-load.d/bridge.conf<span class="built_in">cat</span> &gt;&gt; /etc/sysctl.conf &lt;&lt;<span class="string">EOF</span><span class="string">net.bridge.bridge-nf-call-iptables=1</span><span class="string">net.bridge.bridge-nf-call-ip6tables=1</span><span class="string">net.ipv4.ip_forward=1</span><span class="string">net.ipv4.tcp_syncookies = 1</span><span class="string">net.ipv4.tcp_max_tw_buckets = 20480</span><span class="string">net.ipv4.tcp_max_syn_backlog = 20480</span><span class="string">net.core.netdev_max_backlog = 262144</span><span class="string">net.ipv4.tcp_fin_timeout = 20</span><span class="string">EOF</span><span class="comment"># 重新加载 /etc/sysctl.conf 中的所有内核参数配置，并使其立即生效。</span>sysctl -p</code></pre><ul><li><p>命令解释</p><pre><code class="highlight plaintext"># 安装 EPEL（Extra Packages for Enterprise Linux） 仓库的 Release 包。# EPEL 是由 Fedora 社区维护的一个软件仓库，提供许多额外的软件包，这些包在默认的 RHEL（或其衍生版如 CentOS、Rocky Linux 等）中没有包含。yum install -y epel-release# 安装 bridge-utils 软件包。# bridge-utils 是一个 Linux 工具集，用于创建和管理网络桥接（bridging）。yum install -y bridge-utils# 加载 br_netfilter 内核模块。# 该模块用于启用网络桥接（bridge）时的流量过滤功能。# 允许通过桥接的网络流量被 iptables 规则管理。# 在容器或虚拟化环境中，确保桥接网络的流量可以被正确处理。modprobe br_netfilter# 将 br_netfilter 模块名称添加到 /etc/modules-load.d/bridge.conf 文件中。# 配置系统在启动时自动加载 br_netfilter 模块。echo &#x27;br_netfilter&#x27; &gt;&gt; /etc/modules-load.d/bridge.conf# 向 /etc/sysctl.conf 文件添加配置，使桥接流量可以通过 iptables 规则管理。# 启用桥接网络上的 IPv4 流量通过 iptables 的规则处理。net.bridge.bridge-nf-call-iptables=1# 向 /etc/sysctl.conf 文件添加配置，使桥接流量中的 IPv6 流量可以通过 ip6tables 规则管理。net.bridge.bridge-nf-call-ip6tables=1# 向 /etc/sysctl.conf 文件添加配置，启用 IP 转发功能。# 用途：在容器网络或 Kubernetes 集群中，允许跨子网通信。net.ipv4.ip_forward=1# 启用 TCP SYN Cookie 技术，用于防范 SYN Flood 攻击。# 在服务器收到大量的 TCP SYN 请求但无法分配足够资源时，启用 SYN Cookie 可通过一种临时编码方式验证连接合法性，避免资源耗尽。net.ipv4.tcp_syncookies = 1# 设置系统同时保持的 TCP TIME_WAIT 状态的连接数上限。达到上限后，系统会直接丢弃多余的连接（而不是继续占用资源）。# 默认值180000,对于高并发的 Web 服务器或反向代理，适当调低该值（如 20480）以避免 TIME_WAIT 数量过多。net.ipv4.tcp_max_tw_buckets = 20480# 设置 TCP 三次握手中 SYN 请求的队列长度上限。# 当服务器接收的 SYN 请求超过该值时，新的连接请求会被丢弃。# 如果服务器负载较高且连接数较多，可以调高到 20480 或更高。net.ipv4.tcp_max_syn_backlog = 20480# 设置网络设备接收队列的最大长度。# 如果接收队列中的数据包数量超过该值，内核将直接丢弃后续数据包。# 在高流量环境中，设置为较高值（如 262144）以避免丢包，提高吞吐量。net.core.netdev_max_backlog = 262144# 设置 TCP 连接处于 FIN_WAIT2 状态的超时时间（单位：秒）。# FIN_WAIT2 状态表示服务端已发送 FIN 包等待客户端确认，此状态会持续占用资源。# 默认值：通常为 60 秒。# 在高并发服务器上，将该值调低（如 20）以减少 FIN_WAIT2 状态的资源占用。net.ipv4.tcp_fin_timeout = 20# 重新加载 /etc/sysctl.conf 中的所有内核参数配置，并使其立即生效。sysctl -p</code></pre></li></ul><h2 id="11-关闭-swap-分区"><a href="#11-关闭-swap-分区" class="headerlink" title="11 关闭 swap 分区"></a>11 关闭 swap 分区</h2><pre><code class="highlight bash">swapoff -ased -i <span class="string">&#x27;s:/dev/mapper/rl-swap:#/dev/mapper/rl-swap:g&#x27;</span> /etc/fstab</code></pre><ul><li><p>命令解释</p><pre><code class="highlight bash"><span class="comment">#  立即关闭系统中所有的交换分区</span>swapoff -a<span class="comment"># 注释掉 /etc/fstab 文件中定义的交换分区挂载条目，防止系统在重启后重新启用交换分区。</span>sed -i <span class="string">&#x27;s:/dev/mapper/rl-swap:#/dev/mapper/rl-swap:g&#x27;</span> /etc/fstab<span class="comment"># 验证交换分区是否关系</span>free -h输出中 Swap 一栏的值会变为 0。</code></pre></li></ul><h1 id="二、安装Docker服务"><a href="#二、安装Docker服务" class="headerlink" title="二、安装Docker服务"></a>二、安装Docker服务</h1><h2 id="1-添加-docker-ce-yum-源"><a href="#1-添加-docker-ce-yum-源" class="headerlink" title="1 添加 docker-ce yum 源"></a>1 添加 docker-ce yum 源</h2><p>在 master01、node01、node02 三台服务器分别执行</p><pre><code class="highlight bash">sudo dnf config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.reposudo sed -i <span class="string">&#x27;s+download.docker.com+mirrors.aliyun.com/docker-ce+&#x27;</span> /etc/yum.repos.d/docker-ce.reposudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</code></pre><ul><li><p>命令解析</p><pre><code class="highlight bash"><span class="comment"># 使用 dnf config-manager 命令添加 Docker 软件包的官方仓库（在这里是阿里云的镜像）。</span>sudo dnf config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo<span class="comment"># 修改 docker-ce.repo 文件中的镜像源地址，将默认的 download.docker.com 替换为阿里云的镜像地址 mirrors.aliyun.com/docker-ce。</span>sudo sed -i <span class="string">&#x27;s+download.docker.com+mirrors.aliyun.com/docker-ce+&#x27;</span> /etc/yum.repos.d/docker-ce.repo<span class="comment"># 安装最新版本docker</span>sudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</code></pre></li></ul><h2 id="2-开启Docker服务"><a href="#2-开启Docker服务" class="headerlink" title="2 开启Docker服务"></a>2 开启Docker服务</h2><pre><code class="highlight plaintext">systemctl start dockersystemctl enable docker</code></pre><h2 id="3-配置-daemon-json"><a href="#3-配置-daemon-json" class="headerlink" title="3 配置 daemon.json"></a>3 配置 daemon.json</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &gt;&gt;/etc/docker/daemon.json &lt;&lt;<span class="string">EOF</span><span class="string">&#123;</span><span class="string">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><span class="string">  &quot;log-opts&quot;: &#123;</span><span class="string">        &quot;max-size&quot;: &quot;100m&quot;,</span><span class="string">        &quot;max-file&quot;: &quot;10&quot;</span><span class="string">  &#125;,</span><span class="string">  &quot;data-root&quot;:&quot;/data/docker&quot;,</span><span class="string">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><span class="string">  &quot;registry-mirrors&quot;: [</span><span class="string">   &quot;https://kfp63jaj.mirror.aliyuncs.com&quot;,</span><span class="string">    &quot;https://hub-mirror.c.163.com&quot;,</span><span class="string">    &quot;https://mirror.baidubce.com&quot;</span><span class="string">  ]</span><span class="string">&#125;</span><span class="string">EOF</span></code></pre><ul><li><p>配置解析</p><pre><code class="highlight plaintext">&quot;data-root&quot;: &quot;/data/docker&quot;指定 Docker 数据的存储目录为 /data/docker。包括容器、镜像、卷等内容。默认存储在 /var/lib/docker，此配置用于更改默认路径。&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]配置 Docker 使用 systemd 作为 Cgroup 驱动程序。推荐在使用现代 Linux 发行版（如 Rocky Linux 9）或 Kubernetes 时采用此配置，以实现更好的资源管理和兼容性。&quot;log-driver&quot;: &quot;json-file&quot;指定 Docker 的日志驱动为 json-file。json-file 是 Docker 默认的日志存储方式，将日志保存在 JSON 文件中。&quot;log-opts&quot;: &#123;&#125;配置日志驱动的选项：&quot;max-size&quot;: &quot;100m&quot;：每个日志文件的最大大小为 100MB。&quot;max-file&quot;: &quot;100&quot;：最多保留 100 个日志文件（滚动日志机制）。&quot;insecure-registries&quot;: [&quot;harbor.xinxainghf.com&quot;]配置不安全的私有镜像仓库地址（即未启用 HTTPS 的仓库）。例如，harbor.xinxainghf.com 是一个私有仓库地址。&quot;registry-mirrors&quot;: [&quot;https://kfp63jaj.mirror.aliyuncs.com&quot;]配置 Docker 镜像加速器。镜像地址为阿里云镜像服务，加速从官方 Docker Hub 拉取镜像的速度。</code></pre></li></ul><h2 id="4-创建-Docker-服务的自定义配置目录"><a href="#4-创建-Docker-服务的自定义配置目录" class="headerlink" title="4 创建 Docker 服务的自定义配置目录"></a>4 创建 Docker 服务的自定义配置目录</h2><pre><code class="highlight bash"><span class="built_in">mkdir</span> -p /etc/systemd/system/docker.service.d</code></pre><p>用于存放 Docker 服务的自定义配置文件。</p><h2 id="5-重新加载-Docker-配置"><a href="#5-重新加载-Docker-配置" class="headerlink" title="5 重新加载 Docker 配置"></a>5 重新加载 Docker 配置</h2><pre><code class="highlight bash">systemctl daemon-reloadsystemctl restart docker</code></pre><ul><li><p>验证配置是否生效</p><pre><code class="highlight plaintext">docker info</code></pre></li></ul><h1 id="三、安装-cri-docker"><a href="#三、安装-cri-docker" class="headerlink" title="三、安装 cri-docker"></a>三、安装 cri-docker</h1><p>从 kubernetes 1.24 开始，dockershim 已经从 kubelet 中移除（ dockershim 是 Kubernetes 的一个组件，主要目的是为了通过 CRI 操作 Docker），但因为历史问题 docker 却不支持 kubernetes 主推的CRI（容器运行时接口）标准，所以 docker 不能再作为 kubernetes 的容器运行时了，即从 kubernetesv1.24 开始不再使用 docker 了，默认使用的容器运行时是 containerd 。目前 containerd 比较新，可能存在一些功能不稳定的情况，所以这里我们使用容器运行时还是选择 docker。</p><p>如果想继续使用 docker 的话，可以在 kubelet 和 docker 之间加上一个中间层 cri-docker 。cri-docker 是一个支持CRI标准的 shim（垫片）。一头通过CRI跟kubelet 交互，另一头跟 docker api 交互，从而间接的实现了 kubernetes 以 docker 作为容器运行时。这里需要在全部节点执行 cri-docker 安装。</p><h2 id="1-下载-cri-docker"><a href="#1-下载-cri-docker" class="headerlink" title="1 下载 cri-docker"></a>1 下载 cri-docker</h2><pre><code class="highlight bash"><span class="comment"># 创建目录,并下载 cri-docker 安装文件到目录中</span><span class="built_in">mkdir</span> -p /opt/software<span class="built_in">cd</span> /opt/softwarewget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.16/cri-dockerd-0.3.16.amd64.tgz</code></pre><h2 id="2-解压-cri-docker"><a href="#2-解压-cri-docker" class="headerlink" title="2 解压 cri-docker"></a>2 解压 cri-docker</h2><pre><code class="highlight bash">tar -xvf /opt/software/cri-dockerd-0.3.16.amd64.tgz --strip-components=1 -C /usr/local/bin/</code></pre><h2 id="3-下载并修改-cri-docker-配置文件"><a href="#3-下载并修改-cri-docker-配置文件" class="headerlink" title="3 下载并修改 cri-docker 配置文件"></a>3 下载并修改 cri-docker 配置文件</h2><h3 id="3-1-下载-cri-docker-配置文件"><a href="#3-1-下载-cri-docker-配置文件" class="headerlink" title="3.1 下载 cri-docker 配置文件"></a>3.1 下载 cri-docker 配置文件</h3><p>在浏览器下载文件，通过xftp传到服务器上</p><pre><code class="highlight bash"><span class="comment"># 下载 cri-docker.service</span><span class="comment"># cri-docker.service 下载地址：https://github.com/Mirantis/cri-dockerd/blob/v0.3.16/packaging/systemd/cri-docker.service</span><span class="built_in">mv</span> /opt/software/cri-docker.service /etc/systemd/system/<span class="comment"># 下载 cri-docker.socket</span><span class="comment"># cri-docker.socket 下载地址：https://github.com/Mirantis/cri-dockerd/blob/v0.3.16/packaging/systemd/cri-docker.socket</span><span class="built_in">mv</span> /opt/software/cri-docker.socket /etc/systemd/system/</code></pre><h3 id="3-2-修改-cri-docker-配置文件"><a href="#3-2-修改-cri-docker-配置文件" class="headerlink" title="3.2 修改 cri-docker 配置文件"></a>3.2 修改 cri-docker 配置文件</h3><p><strong>修改 cri-docker.service 的启动命令 ExecStart</strong></p><pre><code class="highlight bash">vim /etc/systemd/system/cri-docker.service</code></pre><ul><li><p>修改内容如下：</p><pre><code class="highlight bash"><span class="comment"># ExecStart=/usr/bin/cri-dockerd --container-runtime-endpoint fd://</span>ExecStart=/usr/local/bin/cri-dockerd --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9 --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --cri-dockerd-root-directory=/data/dockershim --cri-dockerd-root-directory=/data/docker</code></pre><ul><li><p>配置解析</p><pre><code class="highlight plaintext">ExecStart作用: 定义 Systemd 启动服务时执行的命令。此命令会在服务启动时运行。/usr/local/bin/cri-dockerd解释: cri-dockerd 的可执行文件路径。作用: 启动 cri-dockerd 服务，为 Kubernetes 提供 CRI（容器运行时接口）支持。--pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9解释: 定义 Pod 的基础容器镜像。--container-runtime-endpoint=unix:///var/run/cri-dockerd.sock解释: 定义 CRI 的监听端点。作用: cri-dockerd 使用 Unix Socket 文件 /var/run/cri-dockerd.sock 提供与 Kubernetes 的交互接口。--cri-dockerd-root-directory=/data/dockershim解释: 定义 cri-dockerd 的根目录，用于存储临时文件或配置数据。作用: /data/dockershim 是修改后的 cri-dockerd 数据目录，默认存放在 /var/lib/dockershim，用于存放与 Docker 和 Kubernetes 通信相关的数据。--cri-dockerd-root-directory=/data/docker解释: 定义 Docker 的根目录。作用: Docker 的所有容器数据、镜像数据都存放在 /data/docker 目录下。</code></pre></li></ul></li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/01/07/20250107-213036.png" alt="cri-docker.service"></p><ul><li><p>修改cri-docker.socket的ListenStream参数</p><pre><code class="highlight bash">vim /etc/systemd/system/cri-docker.socket</code></pre><ul><li><p>修改内容如下：</p><pre><code class="highlight bash"><span class="comment"># ListenStream=%t/cri-dockerd.sock</span>ListenStream=/var/run/cri-dockerd.sock</code></pre><ul><li><p>配置解析</p><pre><code class="highlight plaintext">ListenStream作用:定义 cri-dockerd 服务监听的通信地址和端口。在这里，指定了一个 Unix Socket 文件 /var/run/cri-dockerd.sock。/var/run/cri-dockerd.sock解释:这是一个 Unix Domain Socket 文件路径。Unix Sockets 是一种轻量级的进程间通信（IPC）方式，通常用于本地通信（与网络无关）。cri-dockerd 和 Kubernetes 的 kubelet 通过这个 Socket 文件进行交互。</code></pre></li></ul></li></ul><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/07/20250707-130350.png" alt="cri-dockerd.sock"></p></li></ul><p><strong>注意每个节点 cri-docker 都需要这么配置</strong></p><h2 id="4-启动-cri-docker-对应服务"><a href="#4-启动-cri-docker-对应服务" class="headerlink" title="4 启动 cri-docker 对应服务"></a>4 启动 cri-docker 对应服务</h2><pre><code class="highlight bash">systemctl daemon-reloadsystemctl <span class="built_in">enable</span> cri-dockersystemctl start cri-dockersystemctl is-active cri-docker</code></pre><ul><li><p>命令解析</p><pre><code class="highlight bash"><span class="comment"># 告诉 Systemd 重新加载所有服务配置文件。</span>systemctl daemon-reload<span class="comment"># 设置 cri-docker 服务为 开机自启。</span>systemctl <span class="built_in">enable</span> cri-docker<span class="comment"># 启动 cri-docker 服务。</span>systemctl start cri-docker<span class="comment"># 检查 cri-docker 服务是否正在运行。</span>systemctl is-active cri-docker</code></pre></li></ul><h1 id="四、节点加入集群"><a href="#四、节点加入集群" class="headerlink" title="四、节点加入集群"></a>四、节点加入集群</h1><h2 id="1-配置阿里云K8S源"><a href="#1-配置阿里云K8S源" class="headerlink" title="1 配置阿里云K8S源"></a>1 配置阿里云K8S源</h2><pre><code class="highlight bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><span class="string">[kubernetes]</span><span class="string">name=Kubernetes</span><span class="string">baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/</span><span class="string">enabled=1</span><span class="string">gpgcheck=1</span><span class="string">gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/repodata/repomd.xml.key</span><span class="string">EOF</span></code></pre><h2 id="2-安装K8S集群管理工具"><a href="#2-安装K8S集群管理工具" class="headerlink" title="2 安装K8S集群管理工具"></a>2 安装K8S集群管理工具</h2><pre><code class="highlight bash">yum install -y kubelet kubeadm kubectl</code></pre><h2 id="3-配置k8s-Cgoup控制组"><a href="#3-配置k8s-Cgoup控制组" class="headerlink" title="3 配置k8s Cgoup控制组"></a>3 配置k8s Cgoup控制组</h2><pre><code class="highlight bash">vim /etc/sysconfig/kubelet</code></pre><ul><li><p>配置内容如下：</p><pre><code class="highlight plaintext">KUBELET_EXTRA_ARGS=&quot;--cgroup-driver=systemd&quot;</code></pre></li><li><p>配置解析</p><pre><code class="highlight plaintext">KUBELET_EXTRA_ARGS含义:KUBELET_EXTRA_ARGS 是一个变量，用于为 kubelet 添加自定义的启动参数。这些参数会被系统初始化脚本或服务文件加载并传递给 kubelet 进程。--cgroup-driver=systemd作用:指定 kubelet 使用的 cgroup 驱动（Cgroup Driver）。Cgroup Driver 是 Kubernetes 用来与 Linux 内核 cgroup（控制组）交互的机制，负责资源（CPU、内存等）的限制和管理。该参数将驱动类型设置为 systemd，表示使用 systemd 来管理 cgroup。</code></pre></li></ul><h2 id="4-配置kubelet自启动"><a href="#4-配置kubelet自启动" class="headerlink" title="4 配置kubelet自启动"></a>4 配置kubelet自启动</h2><pre><code class="highlight bash">systemctl <span class="built_in">enable</span> kubelet.service</code></pre><h2 id="5-Master-节点重新生成-Token"><a href="#5-Master-节点重新生成-Token" class="headerlink" title="5 Master 节点重新生成 Token"></a>5 Master 节点重新生成 Token</h2><pre><code class="highlight bash"><span class="comment"># 在集群 Master 节点执行命令</span>$ kubeadm token create --print-join-command<span class="comment"># 生成内容如下：</span>kubeadm <span class="built_in">join</span> 10.20.1.139:6443 --token 4jlfko.bsw2lqp28syw1fb7 --discovery-token-ca-cert-hash sha256:9450138de7634306c27d22950c943dd348662019b710bc00248e815df86fa789</code></pre><h2 id="6-当前节点加入集群中"><a href="#6-当前节点加入集群中" class="headerlink" title="6 当前节点加入集群中"></a>6 当前节点加入集群中</h2><pre><code class="highlight bash">$ kubeadm <span class="built_in">join</span> 10.20.1.139:6443 --token 4jlfko.bsw2lqp28syw1fb7 --discovery-token-ca-cert-hash sha256:9450138de7634306c27d22950c943dd348662019b710bc00248e815df86fa789 --cri-socket=unix:///var/run/cri-dockerd.sock</code></pre><p><strong>在master节点查看节点状态</strong></p><pre><code class="highlight bash">$ kubectl get nodesNAME           STATUS     ROLES           AGE    VERSIONk8s-master01   Ready      control-plane   5d2h   v1.29.15k8s-node01     Ready      &lt;none&gt;          5d     v1.29.15k8s-node02     Ready      &lt;none&gt;          5d     v1.29.15k8s-node03     NotReady   &lt;none&gt;          18s    v1.29.15</code></pre><p>k8s-node03 节点已加入集群中。</p><p>k8s-node03 虽然已经加入集群中，但处于未就绪状态，查看原因：</p><pre><code class="highlight bash"><span class="comment"># 在master节点查看Pod运行情况</span>$ kubectl get pods -n kube-system -o wide</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/07/20250707-140848.png" alt="master节点查看Pod"></p><p>通过查看Pod，了解到是由于 node03 节点的 calico Pod运行异常，calico 镜像拉取失败了。</p><p><strong>导入Calico镜像</strong></p><p>由于 colico 相关镜像在国外，这里使用代理的方式，提前下载好镜像，然后导入到 node03 节点中</p><pre><code class="highlight bash"><span class="comment"># 查看要下载的镜像</span><span class="comment"># 查看集群初始化时，安装 Calico 插件使用的yaml文件，里面有calico所需的相关镜像</span>$ <span class="built_in">cat</span> calico.yaml<span class="comment"># 拉取 Calico 镜像</span>docker pull docker.io/calico/cni:v3.26.3docker pull docker.io/calico/node:v3.26.3docker pull docker.io/calico/kube-controllers:v3.26.3docker pull docker.io/calico/typha:v3.26.3<span class="comment"># Calico 镜像打包</span>docker save docker.io/calico/cni:v3.26.3 cni-v3.26.3.tardocker save docker.io/calico/node:v3.26.3 node-v3.26.3.tardocker save docker.io/calico/kube-controllers:v3.26.3 kube-controllers-v3.26.3.tardocker save docker.io/calico/typha:v3.26.3 typha-v3.26.3.tar<span class="comment"># 导入 Calico 镜像</span>docker load -i cni-v3.26.3.tardocker load -i node-v3.26.3.tardocker load -i kube-controllers-v3.26.3.tardocker load -i typha-v3.26.3.tar</code></pre><p><strong>再次查看集群Node状态</strong></p><p>k8s-node03 节点导入calico镜像后，再次查看</p><pre><code class="highlight bash"><span class="comment"># 在 master 节点查看节点状态</span>$ kubectl get nodesNAME           STATUS   ROLES           AGE    VERSIONk8s-master01   Ready    control-plane   5d3h   v1.29.15k8s-node01     Ready    &lt;none&gt;          5d1h   v1.29.15k8s-node02     Ready    &lt;none&gt;          5d1h   v1.29.15k8s-node03     Ready    &lt;none&gt;          25m    v1.29.15<span class="comment"># 在master节点查看Pod运行情况</span>$ kubectl get pods -n kube-system -o wide</code></pre><h2 id="7-其它配置"><a href="#7-其它配置" class="headerlink" title="7 其它配置"></a>7 其它配置</h2><p>让新加入的 k8s-node03 节点可执行 kubectl 命令，只要把 master上的管理文件 <code>/etc/kubernetes/admin.conf</code> 拷贝到 Worker 节点的 <code>$HOME/.kube/config</code> 就可以让 Worker 节点也可以实现 kubectl 命令管理。</p><pre><code class="highlight bash"><span class="comment"># 在 node03 节点执行</span>[root@k8s-node03 ~]$ <span class="built_in">mkdir</span> /root/.kube<span class="comment"># 在master节点执行</span>[root@k8s-master01 ~]$ scp /etc/kubernetes/admin.conf root@10.20.1.142:/root/.kube/config</code></pre><ul><li><p>测试：在 node03 节点测试</p><pre><code class="highlight bash">[root@k8s-node03 ~]$ kubectl get nodesNAME           STATUS   ROLES           AGE    VERSIONk8s-master01   Ready    control-plane   5d3h   v1.29.15k8s-node01     Ready    &lt;none&gt;          5d1h   v1.29.15k8s-node02     Ready    &lt;none&gt;          5d1h   v1.29.15k8s-node03     Ready    &lt;none&gt;          42m    v1.29.15</code></pre></li></ul><p><strong>至此完成了新节点的的初始化，及加入k8s集群中</strong></p><p><strong>参考链接</strong></p><blockquote><p><a href="https://georgechan95.github.io/blog/3c79d8d9.html">https://georgechan95.github.io/blog/3c79d8d9.html</a></p><p><a href="https://georgechan95.github.io/blog/b00f53e9.html">https://georgechan95.github.io/blog/b00f53e9.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;需求：当前集群为一主两从，共3个节点，需要增加一个从节点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;当前集群如下：&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;Hostname&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbod</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>011-Kubernetes Ingress-Nginx</title>
    <link href="https://georgechan95.github.io/blog/6436eaf1.html"/>
    <id>https://georgechan95.github.io/blog/6436eaf1.html</id>
    <published>2025-06-25T11:42:00.000Z</published>
    <updated>2025-07-06T09:01:02.206Z</updated>
    
    <content type="html"><![CDATA[<p><strong>K8S集群服务器</strong></p><table><thead><tr><th>IP</th><th>Hostname</th></tr></thead><tbody><tr><td>10.20.1.139</td><td>k8s-master01</td></tr><tr><td>10.20.1.140</td><td>k8s-node01</td></tr><tr><td>10.20.1.141</td><td>k8s-node02</td></tr></tbody></table><h1 id="一、负载均衡器"><a href="#一、负载均衡器" class="headerlink" title="一、负载均衡器"></a>一、负载均衡器</h1><p>负载均衡器有两类，区别在于 <strong>四层网络</strong> 和 <strong>七层网络</strong> 的支持，传输层在第四层，这层协议有 TCP&#x2F;UDP&#x2F;TCP SSL 等，而七层有 HTTP&#x2F;HTTPS。</p><h2 id="1-基于-LVS-的-HTTPS-负载均衡"><a href="#1-基于-LVS-的-HTTPS-负载均衡" class="headerlink" title="1. 基于 LVS 的 HTTPS 负载均衡"></a>1. 基于 LVS 的 HTTPS 负载均衡</h2><p>基于 LVS 的 HTTPS 负载均衡 是 典型的四层代理架构。客户端发出请求，经过LVS直接转发到服务器，然后服务器返回结果，从请求的发出到结果的响应，中间仅仅产生一次完整的TCP连接。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/26/20250626-194737.png" alt="四层代理架构"></p><h2 id="2-基于-Nginx-的-HTTPS-负载均衡"><a href="#2-基于-Nginx-的-HTTPS-负载均衡" class="headerlink" title="2. 基于 Nginx 的 HTTPS 负载均衡"></a>2. 基于 Nginx 的 HTTPS 负载均衡</h2><p>基于 Nginx 的 HTTPS 负载均衡是一种基于七层网络代理架构的实现。客户端发出 https 请求，请求到达nginx服务器，nginx 重新生成一个新的 http 请求发到真实的服务器，服务器计算结果后发往 nginx，nginx再将结果以 https 的方式返回给客户端。从请求的发出到结果的响应，中间产生了两次请求。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/26/20250626-195032.png" alt="七层代理架构"></p><h1 id="二、Ingress简介"><a href="#二、Ingress简介" class="headerlink" title="二、Ingress简介"></a>二、Ingress简介</h1><h2 id="1-Ingress-介绍"><a href="#1-Ingress-介绍" class="headerlink" title="1. Ingress 介绍"></a>1. Ingress 介绍</h2><p>Ingress 是从 Kubernetes 集群外部访问集群内部服务的入口，同时为集群内的 Service 提供七层负载均衡能力。它提供了 HTTP 和 HTTPS 路由功能，使外部流量能够访问集群内部的服务。通过定义 Ingress 资源，可以控制哪些外部请求能够访问集群中的哪些服务，以及如何路由这些请求。</p><p>具体架构图如下：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/26/20250626-193516" alt="Ingress架构"></p><p>我们做网站时，使用 Nginx 做 Web 服务器，会使用一个子域名绑定一个网站，<code>a.xxx.com</code> 绑定 A 网站，<code>b.xxx.com</code> 绑定 B 网站，这样在一个域名的不同子域名可以访问不同的站点，对于现在的大多数互联网网站，依然会使用这种方法划分。</p><p>在微服务架构中，多个模块部署在不同的服务器上，则但是我们希望都通过 <code>xxx.com</code> 这个域名直接访问，就好像所有模块都在一起，让用户感觉只有一个网站。则可能会使用目录路径对模块进行划分，例如如果我们要实现 <code>xxx.com/a</code> 访问 A 模块，<code>xxx.com/b</code> 访问 B 模块，但对用户来说，一直在访问 <code>xxx.com</code> 这个域名。</p><p>这种需求，我们可以使用 nginx 进行反向代理，而在 Kubernetes 中，这种需求也是一模一样的。</p><p>首先，我们可以为 A、B、C 等应用，创建多个 Service，每个 Service 访问一个应用，然后使用 Ingress 配置路由规则，决定 URL 可以访问哪个 Service。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/26/20250626-200950.png" alt="Ingress代理请求"></p><blockquote><p>Ingress 公开了从集群外部到集群内服务的 HTTP 和 HTTPS 路由，Ingress 资源上定义的规则控制了路由。</p></blockquote><p>Ingress 可以让集群中的多个 Service 能够从集群外访问，Ingress 还提供负载均衡、SSL&#x2F;TLS 和基于名称的虚拟服务器等，Ingress 可以配置边缘路由器或其他前端工具来帮助处理网络流量，但是一般都是通自己的负载均衡器来实现。</p><p>Ingress 有两部分，一部分是 LoadBalancer ，提供统一入口，代理请求；另一部分是 Ingress 控制器，复制定义路由规则等。</p><p>如果不使用公有云平台的 LoadBalancer ，那么就自己搭建一个服务器，这台服务器加入到 Kubernetes 集群中，做流量入口，这台服务器网络接口必须够大，抗得住流量。</p><h2 id="2-Ingress-与-Service"><a href="#2-Ingress-与-Service" class="headerlink" title="2.  Ingress 与 Service"></a>2.  Ingress 与 Service</h2><p>在前面，我们已经学习到了 Service，通过 Service 我们可以暴露一个端口到外网中，通过这个端口可以访问应用。</p><p>其中，有两种方法可以暴露 Service，可以让其被集群外部访问：</p><ul><li>使用 <code>Service.Type=LoadBalancer</code></li><li>使用 <code>Service.Type=NodePort</code></li></ul><p>Service 的访问方式是 IP，每次要将服务公开给外界时，都必须创建一个新的 LoadBalancer 并向云服务商获取一个公网 IP 地址。或者使用 <code>NodePort</code>，但是只能在一台服务器上被访问，而且 Service 只能为一种 Pod 服务，暴露一个或多个端口，那么 N 个服务，就需要创建 N 个 Service。Service 虽然能够公开端口到外部网络中，但是无法将这些服务合并到一个 <code>example.com/&#123;服务&#125;</code> 中访问，Service 需要通过不同的端口访问。</p><p>如果你有一个 <code>example.com</code> 域名，你部署了多个 Web 服务，其中有两个子模块分别为课程(course)、考试(exam) 两个微服务，这些模块构成了一个培训网站。此时我们希望访问 <code>example.com/api/course</code> 能够访问课程学习模块，访问 <code>example.com/api/exam</code> 能够访问考试模块。显然，Service 是无法做到的。</p><p>使用 Ingress ，可以轻松设置路由规则，而且无需创建一堆 LoadBalancers&#x2F;Nodes 公开每个服务，并且 Ingress 本身具有很多功能。</p><blockquote><p>Ingress 也需要 Service 。</p></blockquote><h1 id="三、-安装-Ingress-控制器"><a href="#三、-安装-Ingress-控制器" class="headerlink" title="三、 安装 Ingress 控制器"></a>三、 安装 Ingress 控制器</h1><p>Ingress 控制器有多种实现，其中 Kubernetes 官方有一个名为 Ingress-nginx 的实现，其它实现还有 Kong Ingress、Traefik、HAProxy Ingress 等。这里演示 使用 Helm 安装 Ingress-nginx 。</p><p>官方文档：<a href="https://kubernetes.github.io/ingress-nginx/deploy/#using-helm">https://kubernetes.github.io/ingress-nginx/deploy/#using-helm</a></p><h2 id="1-下载-Ingress-nginx-安装包"><a href="#1-下载-Ingress-nginx-安装包" class="headerlink" title="1. 下载 Ingress-nginx 安装包"></a>1. 下载 Ingress-nginx 安装包</h2><p>需要首先安装helm管理工具：<a href="https://georgechan95.github.io/blog/d8e3c7b3.html">https://georgechan95.github.io/blog/d8e3c7b3.html</a></p><p>ingress-nginx 的仓库在国外，国内下载需要vpn支持，参考：<a href="https://georgechan95.github.io/blog/7f174b3e.html">https://georgechan95.github.io/blog/7f174b3e.html</a></p><pre><code class="highlight bash"><span class="comment"># 添加 ingress-nginx仓库</span>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx<span class="comment"># 下载 ingress-nginx 安装包</span>helm pull ingress-nginx/ingress-nginx --version=4.8.3</code></pre><h2 id="2-导入-Ingress-nginx-镜像"><a href="#2-导入-Ingress-nginx-镜像" class="headerlink" title="2. 导入 Ingress-nginx 镜像"></a>2. 导入 Ingress-nginx 镜像</h2><p>这些镜像是 ingress-nginx 启动时所需的镜像，由于国内的网络无法从国外下载镜像，因此需要提前把这些镜像下载好，导入到服务器中。</p><p>关于如何使用 Docker 拉取谷歌镜像，参考这篇博客：<a href="https://georgechan95.github.io/blog/b01d5c62.html">https://georgechan95.github.io/blog/b01d5c62.html</a></p><pre><code class="highlight bash"><span class="comment"># 下载 ingress-nginx 需要的镜像</span><span class="comment"># 所有节点都需要导入这些镜像</span>docker pull registry.k8s.io/ingress-nginx/controller:v1.9.4docker pull registry.k8s.io/defaultbackend-amd64:1.5docker pull registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231011-8b53cabe0docker pull registry.k8s.io/ingress-nginx/opentelemetry:v20230721-3e2062ee5</code></pre><h2 id="3-安装-Ingress-nginx"><a href="#3-安装-Ingress-nginx" class="headerlink" title="3. 安装 Ingress-nginx"></a>3. 安装 Ingress-nginx</h2><h3 id="3-1-解压-Ingress-nginx-压缩包"><a href="#3-1-解压-Ingress-nginx-压缩包" class="headerlink" title="3.1 解压  Ingress-nginx 压缩包"></a>3.1 解压  Ingress-nginx 压缩包</h3><pre><code class="highlight bash"><span class="comment"># 安装包解压</span>$ tar -zxvf ingress-nginx-4.8.3.tgz<span class="comment"># 进入 ingress-nginx 解压后的目录</span>$ <span class="built_in">cd</span> ingress-nginx<span class="comment"># 当前所在目录</span>$ <span class="built_in">pwd</span>/opt/k8s/10/ingress-nginx<span class="comment"># 查看 ingress-nginx 目录结构</span>$ tree ..├── CHANGELOG.md├── Chart.yaml├── .....├── README.md.gotmpl├── changelog│   ├── Changelog-4.5.2.md│   ├── .....│   └── Changelog-4.8.3.md├── changelog.md.gotmpl├── ci│   ├── controller-admission-tls-cert-manager-values.yaml........│   └── deployment-webhook-values.yaml├── templates│   ├── NOTES.txt│   ├── admission-webhooks│   │   ├── cert-manager.yaml│   │   ├── job-patch│   │   │   ├── clusterrole.yaml│   │   │   ├── ......│   │   │   └── serviceaccount.yaml│   │   └── validating-webhook.yaml│   ├── clusterrole.yaml│   ├── .....│   └── default-backend-serviceaccount.yaml└── values.yaml</code></pre><h3 id="3-2-编辑-values-yaml"><a href="#3-2-编辑-values-yaml" class="headerlink" title="3.2 编辑 values.yaml"></a>3.2 编辑 values.yaml</h3><pre><code class="highlight yaml"><span class="comment"># 修改 values.yaml 文件</span><span class="string">$</span> <span class="string">vim</span> <span class="string">values.yaml</span><span class="comment"># 修改1：</span><span class="comment"># 修改如下内容：</span><span class="string">controller</span>  <span class="attr">hostNetwork:</span> <span class="literal">true</span> <span class="comment"># 使用主机网路</span>  <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirstWithHostNet</span> <span class="comment"># Pod 的网络命名空间与主机共享，Pod 使用主机的网络栈</span>  <span class="attr">kind:</span> <span class="string">DaemonSet</span> <span class="comment"># 每个节点部署一个 ingress-nginx-controller</span>  <span class="attr">ingressClassResource:</span>    <span class="attr">default:</span> <span class="literal">true</span> <span class="comment"># 使用默认的Inginx类，默认是 nginx</span><span class="comment"># 修改2：</span><span class="comment">#注释 digest 相关内容</span><span class="string">controller</span>  <span class="attr">image:</span>    <span class="comment">#digest: sha256:xxxxx</span>    <span class="comment">#digestChroot: sha256:xxxxx</span>  <span class="attr">admissionWebhooks:</span>    <span class="attr">patch:</span>      <span class="attr">image:</span>        <span class="comment">#digest: sha256:xxxxx</span></code></pre><blockquote><p>将解压后的 ingress-nginx 目录内 values.yaml 文件中的 digest: sha256xxxx 所在的所有的行注释掉，避免因为下载镜像的指纹与文件要求不一致，无法运行</p></blockquote><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/25/20250625-171224.png" alt="注释digest指纹信息"></p><h3 id="3-3-关于-dnsPolicy"><a href="#3-3-关于-dnsPolicy" class="headerlink" title="3.3 关于 dnsPolicy"></a>3.3 关于 dnsPolicy</h3><p><strong>ClusterFirstWithHostNet</strong>：</p><ul><li>当 Pod 的 <code>hostNetwork</code> 设置为 true 时，使用该 DNS 策略。</li><li>这意味着 Pod 的网络命名空间与主机共享，Pod 使用主机的网络栈。</li><li>在此配置下，Pod 将首先尝试通过主机上的 DNS 解析 DNS 请求。如果主机上没有找到，则会将请求发送到 kube-dns 服务，由 kube-dns 服务进行处理。</li><li>这种策略适用于需要与主机网络共享的特殊情况，但它不会为 Pod 提供专用的 DNS 解析功能。</li></ul><p><strong>ClusterFirst</strong>：</p><ul><li>这是 Kubernetes 中默认的 DNS 策略。</li><li>当 Pod 的 <code>hostNetwork</code> 设置为 false 或未设置时，使用该策略。</li><li>在此策略下，Pod 首先尝试通过 kube-dns 服务解析 DNS 请求。如果 kube-dns 无法解析，则会向上级 DNS 服务器继续发起请求。</li><li>这种策略适用于大多数情况，其中 Pod 需要使用 Kubernetes 集群的 DNS 服务解析其他 Pod 或服务的主机名。</li></ul><h3 id="3-4-安装-ingress-nginx"><a href="#3-4-安装-ingress-nginx" class="headerlink" title="3.4 安装 ingress-nginx"></a>3.4 安装 ingress-nginx</h3><pre><code class="highlight bash"><span class="comment"># 使用 Helm 安装 ingress-nginx</span>$ helm install ingress-nginx --namespace ingress-nginx --create-namespace .<span class="comment"># 查看 ingress-nginx release</span>$ helm list -n ingress-nginxNAME         NAMESPACE    REVISIONUPDATED                                STATUS  CHART              APP VERSIONingress-nginxingress-nginx1       2025-06-26 18:35:32.209570796 +0800 CSTdeployedingress-nginx-4.8.31.9.4<span class="comment"># 查看 IngressClass</span>$ kubectl get ingressclassNAME    CONTROLLER             PARAMETERS   AGEnginx   k8s.io/ingress-nginx   &lt;none&gt;       153m<span class="comment"># 查看 Service</span>$ kubectl get service -n ingress-nginxNAME                                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGEingress-nginx-controller             LoadBalancer   10.105.7.64     &lt;pending&gt;     80:32570/TCP,443:31991/TCP   117mingress-nginx-controller-admission   ClusterIP      10.102.42.201   &lt;none&gt;        443/TCP                      117m<span class="comment"># 查看 Pod</span>$ kubectl get pod -n ingress-nginx -o wideNAME                             READY   STATUS    RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATESingress-nginx-controller-pf6sb   1/1     Running   0          117m   192.168.6.141   k8s-node02   &lt;none&gt;           &lt;none&gt;ingress-nginx-controller-qmb7h   1/1     Running   0          117m   192.168.6.140   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 DaemonSet</span>$ kubectl get daemonset -n ingress-nginx -o wideNAME                       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE    CONTAINERS   IMAGES                                            SELECTORingress-nginx-controller   2         2         2       2            2           kubernetes.io/os=linux   118m   controller   registry.k8s.io/ingress-nginx/controller:v1.9.4   app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx</code></pre><h2 id="4-测试-Ingress-nginx"><a href="#4-测试-Ingress-nginx" class="headerlink" title="4. 测试 Ingress-nginx"></a>4. 测试 Ingress-nginx</h2><h3 id="4-1-创建-Service-和-Deployment"><a href="#4-1-创建-Service-和-Deployment" class="headerlink" title="4.1 创建 Service 和 Deployment"></a>4.1 创建 Service 和 Deployment</h3><p><code>httpproxy-dep-svc.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">protocol:</span> <span class="string">TCP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span></code></pre><blockquote><p>执行资源清单</p></blockquote><pre><code class="highlight bash">$ kubectl apply -f httpproxy-dep-svc.yaml</code></pre><blockquote><p>查看资源</p></blockquote><pre><code class="highlight bash">$ kubectl get svc -o wideNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE   SELECTORkubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   59d   &lt;none&gt;nginx-svc    ClusterIP   10.111.16.251   &lt;none&gt;        80/TCP    8s    app=nginx$ kubectl get deployment -o wide NAME           READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTORnginx-deploy   2/2     2            2           16s   my-nginx     nginx:1.29.0   app=nginx$ kubectl get pods -o wideNAME                            READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnginx-deploy-6fc4ff86dc-n76xc   1/1     Running   0          22s   172.16.58.249   k8s-node02   &lt;none&gt;           &lt;none&gt;nginx-deploy-6fc4ff86dc-nlmw5   1/1     Running   0          22s   172.16.85.206   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h3 id="4-2-创建-Ingress"><a href="#4-2-创建-Ingress" class="headerlink" title="4.2 创建 Ingress"></a>4.2 创建 Ingress</h3><p><code>ingress.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-httpproxy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www.test-http-proxy.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 www.test-http-proxy.com 的流量。客户端必须通过该域名访问, 如果省略 host，Ingress 会匹配所有域名（即通配规则）。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><blockquote><p>执行资源清单</p></blockquote><pre><code class="highlight bash">$ curl http://www.test-http-proxy.com</code></pre><blockquote><p>查看资源</p></blockquote><pre><code class="highlight bash">$ kubectl get ingress -o wideNAME                CLASS   HOSTS                     ADDRESS   PORTS   AGEingress-httpproxy   nginx   www.test-http-proxy.com             80      18</code></pre><h3 id="4-3-修改主机-host-文件"><a href="#4-3-修改主机-host-文件" class="headerlink" title="4.3 修改主机 host 文件"></a>4.3 修改主机 host 文件</h3><p>修改host文件，将其中一台集群节点的IP，映射域名：<a href="http://www.test-http-proxy.com/">www.test-http-proxy.com</a></p><pre><code class="highlight bash">$ <span class="built_in">cat</span> /etc/hosts10.20.1.140 www.test-http-proxy.com</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-151113.png" alt="测试Host文件域名映射"></p><p>10.20.1.140 是 node节点的Ip，部署了 Ingress 控制器。这里通过 Ingress 控制器 将请求转发到 SVC。</p><h3 id="4-4-浏览器访问域名"><a href="#4-4-浏览器访问域名" class="headerlink" title="4.4 浏览器访问域名"></a>4.4 浏览器访问域名</h3><p>打开浏览器，访问 <a href="http://www.test-http-proxy.com,/">http://www.test-http-proxy.com，</a> 通过访问 Ingress Controller ，访问到 Nginx Svc</p><pre><code class="highlight bash">$ kubectl get service -n ingress-nginxNAME                                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGEingress-nginx-controller             LoadBalancer   10.105.7.64     &lt;pending&gt;     80:32570/TCP,443:31991/TCP   117mingress-nginx-controller-admission   ClusterIP      10.102.42.201   &lt;none&gt;        443/TCP                      117m</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-151605.png" alt="Ingress-Nginx 实现 Http 代理"></p><p>至此可以了解到通过使用 Ingress-Nginx 让外部流量能够访问集群内部的服务。</p><h1 id="四、Ingress-Nginx-使用"><a href="#四、Ingress-Nginx-使用" class="headerlink" title="四、Ingress Nginx 使用"></a>四、Ingress Nginx 使用</h1><p>ingress的api版本历经过多次变化他们的配置项也不太一样分别是：</p><ul><li>extensions&#x2F;v1beta1：1.16版本之前使用</li><li>networking.k8s.io&#x2F;v1beta1：1.19版本之前使用</li><li>networking.k8s.io&#x2F;v1：1.19版本之后使用</li></ul><h2 id="1-Ingress-nginx-HTTP-代理"><a href="#1-Ingress-nginx-HTTP-代理" class="headerlink" title="1. Ingress-nginx HTTP 代理"></a>1. Ingress-nginx HTTP 代理</h2><p>资源清单：<code>ingress-nginx-http-proxy.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器监听的端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span> <span class="comment"># 指定端口使用的协议，TCP 表示端口处理 TCP 流量，适合 nginx 的 HTTP 服务</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴露的端口号</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># Service 将流量转发到的目标 Pod 的端口号</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># Service 将流量路由到带有标签 app=nginx 的 Pod</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-httpproxy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www.test-http-proxy.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 www.test-http-proxy.com 的流量。客户端必须通过该域名访问, 如果省略 host，Ingress 会匹配所有域名（即通配规则）。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><blockquote><p>执行资源清单</p></blockquote><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-http-proxy.yaml deployment.apps/nginx-deploy createdservice/nginx-svc createdingress.networking.k8s.io/ingress-httpproxy created</code></pre><blockquote><p>查看部署资源</p></blockquote><pre><code class="highlight bash">$ kubectl get svc -o wideNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE   SELECTORkubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   59d   &lt;none&gt;nginx-svc    ClusterIP   10.111.16.251   &lt;none&gt;        80/TCP    8s    app=nginx$ kubectl get deployment -o wide NAME           READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTORnginx-deploy   2/2     2            2           16s   my-nginx     nginx:1.29.0   app=nginx$ kubectl get pods -o wideNAME                            READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnginx-deploy-6fc4ff86dc-n76xc   1/1     Running   0          22s   172.16.58.249   k8s-node02   &lt;none&gt;           &lt;none&gt;nginx-deploy-6fc4ff86dc-nlmw5   1/1     Running   0          22s   172.16.85.206   k8s-node01   &lt;none&gt;           &lt;none&gt;$ kubectl get ingress -o wideNAME                CLASS   HOSTS                     ADDRESS   PORTS   AGEingress-httpproxy   nginx   www.test-http-proxy.com             80      18</code></pre><blockquote><p>修改主机 Host 文件</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p></blockquote><pre><code class="highlight bash">10.20.1.140 www.test-http-proxy.com</code></pre><blockquote><p>测试访问 HTTP</p></blockquote><pre><code class="highlight bash">$ curl http://www.test-http-proxy.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt;html &#123; color-scheme: light dark; &#125;body &#123; width: 35em; margin: 0 auto;font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=<span class="string">&quot;http://nginx.org/&quot;</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=<span class="string">&quot;http://nginx.com/&quot;</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="2-Ingress-nginx-HTTPS-代理"><a href="#2-Ingress-nginx-HTTPS-代理" class="headerlink" title="2. Ingress-nginx HTTPS 代理"></a>2. Ingress-nginx HTTPS 代理</h2><h3 id="2-1-生成证书和私钥"><a href="#2-1-生成证书和私钥" class="headerlink" title="2.1 生成证书和私钥"></a>2.1 生成证书和私钥</h3><pre><code class="highlight bash"><span class="comment"># 1. 创建证书扩展文件</span>$ vim http.ext[ v3_req ]basicConstraints = CA:FALSEkeyUsage = nonRepudiation, digitalSignature, keyEnciphermentextendedKeyUsage = serverAuthsubjectAltName = @alt_names[ alt_names ]DNS.1 = www.https-proxy.comIP.1 = 127.0.0.1<span class="comment"># 2. 创建证书</span><span class="comment"># 生成证书步骤1 ： 生成 CSR(证书签名请求) 和 私钥文件 tls.key</span>openssl req -new -newkey rsa:2048 -sha256 -nodes -out tls.csr -keyout tls.key -subj <span class="string">&quot;/C=CN/ST=Beijing/L=Beijing/O=Super Inc./OU=Web Security/CN=www.https-proxy.com&quot;</span><span class="comment"># 生成证书步骤2 ： 生成证书tls.crt，并指定证书扩展文件</span>openssl x509 -req -days 365 -<span class="keyword">in</span> tls.csr -signkey tls.key -out tls.crt -extfile http.ext -extensions v3_req<span class="comment"># 查看生成的证书文件</span>$ <span class="built_in">ls</span>http.ext  tls.crt  tls.csr  tls.key<span class="comment"># 3. 将证书和私钥存储到 Secret </span>$ kubectl create secret tls ingress-nginx-tls  --key tls.key --cert tls.crt</code></pre><blockquote><p>查看证书 Secret</p><pre><code class="highlight bash"><span class="comment"># 查看 Secret</span>$ kubectl get secret ingress-nginx-tls -n defaultNAME                TYPE                DATA   AGEingress-nginx-tls   kubernetes.io/tls   2      22s<span class="comment"># 查看 Secret 详情</span>$ kubectl describe secret ingress-nginx-tls -n defaultName:         ingress-nginx-tlsNamespace:    defaultLabels:       &lt;none&gt;Annotations:  &lt;none&gt;Type:  kubernetes.io/tlsData====tls.crt:  1436 bytestls.key:  1708 bytes<span class="comment"># 查看 Secret 数据</span>$ kubectl get secret ingress-nginx-tls -n default -o yamlapiVersion: v1data:  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUQrRENDQXVDZ0F3SUJBZ0lVWk9iZ3V4cUR5bTlVWk1XUDROMEdnR3pTZkw4d0RRWUpLb1pJaHZjTkFRRUwKQlFBd2V6RUxNQWtHQTFVRUJoTUNRMDR4RURBT0JnTlZCQWdNQjBKbGFXcHBibWN4RURBT0JnTlZCQWNNQjBKbAphV3BwYm1jeEV6QVJCZ05WQkFvTUNsTjFjR1Z5SUVsdVl5NHhGVEFUQmdOVkJBc01ERmRsWWlCVFpXTjFjbWwwCmVURWNNQm9HQTFVRUF3d1RkM2QzTG1oMGRIQnpMWEJ5YjNoNUxtTnZiVEFlRncweU5UQTJNamN3TXpBeE1qWmEKRncweU5qQTJNamN3TXpBeE1qWmFNSHN4Q3pBSkJnTlZCQVlUQWtOT01SQXdEZ1lEVlFRSURBZENaV2xxYVc1bgpNUkF3RGdZRFZRUUhEQWRDWldscWFXNW5NUk13RVFZRFZRUUtEQXBUZFhCbGNpQkpibU11TVJVd0V3WURWUVFMCkRBeFhaV0lnVTJWamRYSnBkSGt4SERBYUJnTlZCQU1NRTNkM2R5NW9kSFJ3Y3kxd2NtOTRlUzVqYjIwd2dnRWkKTUEwR0NTcUdTSWIzRFFFQkFRVUFBNElCRHdBd2dnRUtBb0lCQVFDUVJkTE1TZGpNdHQ2NzVPclVhbmNRNTN5eQpTZitEYVZ2Q2xPdjlGNDRkbG1GSFlrVVZXRW9VQkNIRzdCM1pBb0pRWGFpaEJRbUl5UTNJV0o2ODhsWVpEOU1XClgzU212MGp3Q1A0SVcxaTYyVHBwb0JVRHhlNlI3SHhBQXJXeG9pMzV6Q1lFVVRoZzY3OExhWDRma04xR0pYY3AKaERqZ1FFZ3NqTmVwdGNGRVBLaUxicTNhNVlkRWdpTmpVTnh3dWpKY1RFYllkMXgwUFh5V1lYVDNDV29Fd3JUZQozcU0zWUxTdThjRXdIT21VUW13Rzhvc1p4c2lLeXZjN2MwK3JWWUpqeXR1MFJDRVRjY3Njb2hhSWpqT25xaTN0ClVhd0tKbG9Fa3M5Y2dCb05BSzFodXRDRk9UbzJMY3VZSjA1akhSdy84VXI4RG4rc0w4cGFFSWNqZ2VqOUFnTUIKQUFHamREQnlNQWtHQTFVZEV3UUNNQUF3Q3dZRFZSMFBCQVFEQWdYZ01CTUdBMVVkSlFRTU1Bb0dDQ3NHQVFVRgpCd01CTUNRR0ExVWRFUVFkTUJ1Q0UzZDNkeTVvZEhSd2N5MXdjbTk0ZVM1amIyMkhCSDhBQUFFd0hRWURWUjBPCkJCWUVGTU9jdUNxSTVpL3kwazBtSDVWeFFNaEdhRTA0TUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCQVFBeHZ5LzUKWGE1TjRxc3B4WS9rN0NPSTZoT2VBTitqaGF1SWVMeUkrb1UvczkzVnVLTkRrQ0ErakEyRHRWQmhtQ0xrVUdnbQo1enN5MkJHTndZZW4zV05mTXZZUmQ1ZFhjK3ZzUVNaV2VROWwwZ3FKaTdTeEQwaDJZa3BOUlJVcy84RXRSOUJFCmFKSmNkYTV1dlVwT2VFQ3JrWVhGRnIvK09yZW9Mdi9MV3dtK3VLRytLd204YUU1V3Z6czM0SUlqM1pOMlk1ZVQKVDh3dVhhOVJqbU1mRldaaDA4UHJUd3RXT1R1cW5TQUZ3Z2tpeTBab0RtNFd5amlUNmluZWpzTlpSa2ZCcW5ieQpwQVN0eGlmUWk4S2hRNVUzOEhkUVMzYnpNdnFiS2g3ZlZoamh4Si8wNVBQVHE0NGU3eG56dnlEazFUaC9vWnZ0CjJLdUZuVVkxLzlMayt1U1cKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=  tls.key: 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kind: Secretmetadata:  creationTimestamp: <span class="string">&quot;2025-06-27T03:10:37Z&quot;</span>  name: ingress-nginx-tls  namespace: default  resourceVersion: <span class="string">&quot;13338253&quot;</span>  uid: fffb5d77-97c4-4237-8be9-a487d96dbf34<span class="built_in">type</span>: kubernetes.io/tls</code></pre></blockquote><h3 id="2-2-创建资源清单"><a href="#2-2-创建资源清单" class="headerlink" title="2.2 创建资源清单"></a>2.2 创建资源清单</h3><p>资源清单：<code>ingress-nginx-https-proxy.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx-https</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx-https</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器监听的端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span> <span class="comment"># 指定端口使用的协议，TCP 表示端口处理 TCP 流量，适合 nginx 的 HTTP 服务</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-https-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴露的端口号</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># Service 将流量转发到的目标 Pod 的端口号</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx-https</span> <span class="comment"># Service 将流量路由到带有标签 app=nginx-https 的 Pod</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-https-proxy</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/ssl-redirect:</span> <span class="string">&quot;true&quot;</span> <span class="comment"># HTTP 重定向为HTTPS, true表示强制重定向</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www.https-proxy.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 www.www.https-proxy.com 的流量。客户端必须通过该域名访问, 如果省略 host，Ingress 会匹配所有域名（即通配规则）。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-https-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-https-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span>  <span class="attr">tls:</span>    <span class="bullet">-</span> <span class="attr">hosts:</span>        <span class="bullet">-</span> <span class="string">www.https-proxy.com</span> <span class="comment"># 指定域名</span>      <span class="attr">secretName:</span> <span class="string">ingress-nginx-tls</span> <span class="comment"># 证书和私钥保存的 Secret</span></code></pre><p>可以看到Ingress添加TLS配置也非常简单，只需要在 spec下添加一个 tls 字段即可：</p><ul><li>hosts：证书所授权的域名列表</li><li>secretName：证书的 Secret 名字</li><li>ingressClassName: ingress class 的名字，1.22+需要配置</li></ul><blockquote><p>执行资源清单</p></blockquote><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-https-proxy.yaml deployment.apps/nginx-deploy createdservice/nginx-https-svc createdingress.networking.k8s.io/ingress-https-proxy created</code></pre><blockquote><p>查看部署资源</p></blockquote><pre><code class="highlight bash">$ kubectl get svc -o wideNAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE   SELECTORkubernetes        ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   59d   &lt;none&gt;nginx-https-svc   ClusterIP   10.99.219.148   &lt;none&gt;        80/TCP    96s   app=nginx-https$ kubectl get deployment -o wideNAME           READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTORnginx-deploy   2/2     2            2           8s    my-nginx     nginx:1.29.0   app=nginx-https$ kubectl get pods -o wideNAME                            READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnginx-deploy-7d6bd7f587-47kqv   1/1     Running   0          21s   172.16.85.213   k8s-node01   &lt;none&gt;           &lt;none&gt;nginx-deploy-7d6bd7f587-92hhz   1/1     Running   0          21s   172.16.58.233   k8s-node02   &lt;none&gt;           &lt;none&gt;$ kubectl get ingress -o wideNAME                  CLASS   HOSTS                 ADDRESS   PORTS     AGEingress-https-proxy   nginx   www.https-proxy.com             80, 443   2m57s</code></pre><blockquote><p>修改主机 Host 文件</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p></blockquote><pre><code class="highlight bash">10.20.1.140 www.https-proxy.com</code></pre><blockquote><p>测试访问 HTTPS访问<br>端口号通过命令：kubectl get svc -n ingress-nginx 查看 443 映射端口</p></blockquote><pre><code class="highlight bash"><span class="comment"># 用命令行测试 https 请求，其中 -k 表示忽略自签名证书警告</span>$ curl -k https://www.https-proxy.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt;html &#123; color-scheme: light dark; &#125;body &#123; width: 35em; margin: 0 auto;font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=<span class="string">&quot;http://nginx.org/&quot;</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=<span class="string">&quot;http://nginx.com/&quot;</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-152114.png" alt="浏览器访问HTTPS"></p><p>需要将自签发的 tls.crt 证书导入到浏览器中，否则会有 “不安全” 的告警提示</p><p>如果在ingress中设置tls,即默认的http会被强制重定向到https，http即不可访问,如果需要http与https同时可以使用可以设置</p><ul><li>nginx.ingress.kubernetes.io&#x2F;ssl-redirect: “false” ：禁用强制重定向，这样可以同时使用http与https</li></ul><h2 id="3-Ingress-nginx-BasicAuth-代理"><a href="#3-Ingress-nginx-BasicAuth-代理" class="headerlink" title="3. Ingress-nginx BasicAuth 代理"></a>3. Ingress-nginx BasicAuth 代理</h2><p>有些网站可能需要通过密码来访问，对于这类网站可以使用 Nginx 的 basic-auth 设置密码访 问，具体方法如下，由于需要使用 htpasswd 工具，所以需要安装httpd。</p><pre><code class="highlight bash"><span class="comment"># 安装 htpasswd 工具</span>$ dnf -y install httpd-tools<span class="comment"># 使用 htpasswd 命令创建一个新的基本认证密码文件 auth，并为用户 george 设置密码。</span>$ htpasswd -c auth georgeNew password: Re-<span class="built_in">type</span> new password: Adding password <span class="keyword">for</span> user george<span class="comment"># 创建一个 Kubernetes Secret 资源，类型为 generic，用于存储基本认证的密码文件 auth，以便在 Ingress 或 Nginx 中启用 HTTP 基本认证。</span>$ kubectl create secret generic ingress-basic-auth --from-file=auth</code></pre><blockquote><p>查看 Secret</p><pre><code class="highlight bash">$ kubectl get secret ingress-basic-auth -o yamlapiVersion: v1data:  auth: Z2VvcmdlOiRhcHIxJEpoZFB6aVNPJDVXcjhqTDYyQll5Nm5aa3ZHWlB3ejAKkind: Secretmetadata:  creationTimestamp: <span class="string">&quot;2025-06-27T06:12:07Z&quot;</span>  name: ingress-basic-auth  namespace: default  resourceVersion: <span class="string">&quot;13361989&quot;</span>  uid: 9550e4af-4a83-48d7-9b40-fc207303a192<span class="built_in">type</span>: Opaque</code></pre></blockquote><p><strong>创建包含密码认证的Ingress</strong>：</p><ul><li>nginx.ingress.kubernetes.io&#x2F;auth-type：认证类型，可以是 basic 和 digest</li><li>nginx.ingress.kubernetes.io&#x2F;auth-secret：密码文件的 Secret 名称</li><li>nginx.ingress.kubernetes.io&#x2F;auth-realm：需要密码认证的消息提醒</li></ul><p><strong>资源清单</strong></p><p><code>ingress-nginx-basic-auth.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器监听的端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span> <span class="comment"># 指定端口使用的协议，TCP 表示端口处理 TCP 流量，适合 nginx 的 HTTP 服务</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴露的端口号</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># Service 将流量转发到的目标 Pod 的端口号</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># Service 将流量路由到带有标签 app=nginx 的 Pod</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-basic-auth</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/auth-type:</span> <span class="string">basic</span> <span class="comment"># 认证类型</span>    <span class="attr">nginx.ingress.kubernetes.io/auth-secret:</span> <span class="string">ingress-basic-auth</span> <span class="comment"># 密码文件的 Secret 名称</span>    <span class="attr">nginx.ingress.kubernetes.io/auth-realm:</span> <span class="string">&#x27;请输入用户名和密码：&#x27;</span> <span class="comment"># 需要密码认证的消息提醒</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">auth.basic.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 auth.basic.com 的流量。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">ImplementationSpecific</span> <span class="comment"># 表示路径匹配行为由 Ingress 控制器定义,对于 nginx Ingress 控制器，ImplementationSpecific 通常等同于 Prefix，即匹配以指定路径开头的请求。</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-basic-auth.yaml</code></pre></blockquote><blockquote><p>修改主机 Host 文件</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p></blockquote><pre><code class="highlight bash">10.20.1.140 auth.basic.com</code></pre><blockquote><p>浏览器访问测试</p></blockquote><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-152550.png" alt="basic auth 认证测试-登录用户名/密码"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-152642.png" alt="basic auth 认证测试-登录成功"></p><h2 id="4-Ingress-nginx-域名重定向"><a href="#4-Ingress-nginx-域名重定向" class="headerlink" title="4. Ingress-nginx 域名重定向"></a>4. Ingress-nginx 域名重定向</h2><p><strong>官方说明</strong>：<a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#permanent-redirect">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#permanent-redirect</a></p><p>在 Nginx 作为代理服务器时，Redirect 可用于域名的重定向，比如访问 old.com 被重定向到 new.com。Ingress 可以更简单的实现 Redirect 功能，接下来用 ingress-redirect.com 作为旧域名， <a href="http://www.baidu.com/">www.baidu.com</a> 作为新域名进行演示：</p><p><strong>相关配置项</strong>：</p><ul><li>permanent-redirect：重定向到的域名</li><li>permanent-redirect-code：重定向代码，不配置默认301(永久重定向,如有其他原因可自行配置)</li></ul><p>资源清单：<code>ingress-nginx-redirect.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器监听的端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span> <span class="comment"># 指定端口使用的协议，TCP 表示端口处理 TCP 流量，适合 nginx 的 HTTP 服务</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴露的端口号</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># Service 将流量转发到的目标 Pod 的端口号</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># Service 将流量路由到带有标签 app=nginx-https 的 Pod</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-redirect</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">&quot;nginx&quot;</span> <span class="comment"># 指定使用的Ingress控制器类名，与 ingressClassName 作用相同</span>    <span class="attr">nginx.ingress.kubernetes.io/permanent-redirect:</span> <span class="string">https://www.baidu.com</span> <span class="comment"># 永久重定向网址</span>    <span class="attr">nginx.ingress.kubernetes.io/permanent-redirect-code:</span> <span class="string">&#x27;301&#x27;</span> <span class="comment"># 永久重定向状态码</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">ingress-redirect.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 ingress-redirect.com 的流量。客户端必须通过该域名访问, 如果省略 host，Ingress 会匹配所有域名（即通配规则）。</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-redirect.yaml</code></pre></blockquote><blockquote><p>修改主机host文件，添加域名映射</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p><pre><code class="highlight plaintext">10.20.1.140 ingress-redirect.com</code></pre></blockquote><blockquote><p>浏览器访问测试</p><p><a href="http://ingress-redirect.com/">http://ingress-redirect.com</a></p></blockquote><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/27/20250627-134058.png" alt="域名重定向"></p><h2 id="5-Ingress-nginx-Rewrite"><a href="#5-Ingress-nginx-Rewrite" class="headerlink" title="5. Ingress-nginx  Rewrite"></a>5. Ingress-nginx  Rewrite</h2><p>官方示例：<a href="https://kubernetes.github.io/ingress-nginx/examples/rewrite/">https://kubernetes.github.io/ingress-nginx/examples/rewrite/</a></p><p><strong>相关配置项</strong>：</p><ul><li>nginx.ingress.kubernetes.io&#x2F;rewrite-target: 重定向配置</li></ul><h3 id="5-1-案例"><a href="#5-1-案例" class="headerlink" title="5.1 案例"></a>5.1 案例</h3><p>资源清单：<code>ingress-nginx-rewrite.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器监听的端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span> <span class="comment"># 指定端口使用的协议，TCP 表示端口处理 TCP 流量，适合 nginx 的 HTTP 服务</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴露的端口号</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># Service 将流量转发到的目标 Pod 的端口号</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># Service 将流量路由到带有标签 app=nginx-https 的 Pod</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-rewrite</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/rewrite-target:</span> <span class="string">/$2</span> <span class="comment"># 对匹配的 URL 路径进行重写。$2 引用正则表达式捕获组</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">ingress-rewrite.com</span> <span class="comment"># 定义流量路由规则，基于主机名（host）。这里指定只处理发送到 ingress-rewrite.com 的请求</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/api(/|$)(.*)</span> <span class="comment"># 匹配以 /api 开头的路径，后面可以跟 / 或直接结束（|$ 表示路径结束），并捕获剩余部分 (.*) 作为捕获组 $2， 例如：/api、/api/、/api/anything 都会匹配</span>            <span class="attr">pathType:</span> <span class="string">ImplementationSpecific</span> <span class="comment"># 路径匹配的具体行为由 Ingress 控制器（NGINX）定义。通常与正则表达式结合使用，允许更灵活的匹配逻辑</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-rewrite.yaml</code></pre></blockquote><blockquote><p>修改主机host文件，添加域名映射</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p><pre><code class="highlight plaintext">10.20.1.140 ingress-rewrite.com</code></pre></blockquote><blockquote><p>访问域名，不加 &#x2F;api 前缀：404</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-152851.png" alt="不加 /api 前缀：404"></p></blockquote><blockquote><p>访问域名，添加 &#x2F;api 前缀：成功访问到 nginx-svc Service 的默认页面</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-152935.png" alt="添加 /api 前缀：成功访问到 nginx-svc Service 的默认页面"></p></blockquote><blockquote><p>访问域名，添加路径 &#x2F;api&#x2F;index.html 成功访问到 nginx-svc Service 的 &#x2F;index.html 页面</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-153050.png" alt="访问路径 /api/index.html 成功访问到 nginx-svc Service 的 /index.html 页面"></p></blockquote><h3 id="5-1-rewrite-和-redirect"><a href="#5-1-rewrite-和-redirect" class="headerlink" title="5.1 rewrite 和 redirect"></a>5.1 rewrite 和 redirect</h3><p>在 Ingress 控制器中，rewrite 和 redirect 是两种不同的操作，它们的作用和行为有所不同：</p><p><strong>Rewrite（重写）</strong></p><ul><li>作用：重写是指修改请求的路径，但是客户端不会察觉到这个变化，它仅在服务器内部发生。在 Kubernetes 中，可以通过 Ingress 的注解来配置重写规则</li><li>示例：比如你有一个服务部署在 &#x2F;v1 路径下，但是你希望用户访问时不需要输入 &#x2F;v1，那么你可以使用重写将请求从根路径 &#x2F; 重写到 &#x2F;v1</li></ul><p><strong>Redirect（重定向）</strong></p><ul><li>作用：重定向是指服务器向客户端发出一个新的 URL，让客户端进行新的请求。客户端会收到一个 HTTP 3xx 状态码，然后根据其中的重定向地址进行新的请求。这意味着客户端会知道发生了重定向，它会发起新的请求</li><li>示例：比如你有一个网站的旧地址是 <a href="http://example.com,但是你希望所有的请求都转发到/">http://example.com，但是你希望所有的请求都转发到</a> <a href="https://example.com,这时你就可以使用重定向将所有的/">https://example.com，这时你就可以使用重定向将所有的</a> HTTP 请求重定向到 HTTPS</li></ul><p><strong>区别：</strong></p><ul><li>影响范围：Rewrite 只在服务器内部修改请求路径，不会影响到客户端，而 Redirect 则会向客户端发送一个新的 URL，让客户端发起新的请求</li><li>状态码：Rewrite 不涉及状态码的改变，而 Redirect 会向客户端发送一个重定向的 HTTP 状态码（例如 301 永久重定向、302 临时重定向等）</li><li>可见性：Rewrite 对于客户端来说是透明的，而 Redirect 则会告知客户端发生了重定向</li></ul><p>在选择使用 Rewrite 还是 Redirect 时，需要根据具体的需求来决定。如果你希望在不修改客户端请求的情况下修改路径，那么使用 Rewrite；如果你希望客户端知道发生了重定向，并且根据新的 URL 进行新的请求，那么使用 Redirect。</p><h2 id="6-Ingress-nginx-错误代码重定向"><a href="#6-Ingress-nginx-错误代码重定向" class="headerlink" title="6. Ingress-nginx 错误代码重定向"></a>6. Ingress-nginx 错误代码重定向</h2><p>这里的错误代码重定向分为全局设置与某个ingress设置</p><h3 id="6-1-默认错误后端（全局）"><a href="#6-1-默认错误后端（全局）" class="headerlink" title="6.1 默认错误后端（全局）"></a>6.1 默认错误后端（全局）</h3><p>错误代码重定向功能需要使用 helm 重新部署 ingress-nginx 控制器部署步骤如下：</p><h4 id="6-1-1-修改-values-yaml"><a href="#6-1-1-修改-values-yaml" class="headerlink" title="6.1.1 修改 values.yaml"></a>6.1.1 修改 values.yaml</h4><pre><code class="highlight yaml"><span class="comment"># 修改 ingress-nginx 目录内 valume.yml 文件</span><span class="attr">defaultBackend:</span>  <span class="attr">enabled:</span> <span class="literal">true</span> <span class="comment"># 开启全局错误码重定向</span>  <span class="attr">name:</span> <span class="string">defaultbackend</span>  <span class="attr">image:</span>    <span class="attr">registry:</span> <span class="string">registry.k8s.io</span>    <span class="attr">image:</span> <span class="string">defaultbackend-amd64</span>    <span class="attr">tag:</span> <span class="string">&quot;1.5&quot;</span>    <span class="attr">pullPolicy:</span> <span class="string">IfNotPresent</span></code></pre><p><em>这里的镜像是 ingress-nginx 的默认镜像，需要提前下载并导入到服务器中</em></p><h4 id="6-1-2-更新-Ingress-Nginx"><a href="#6-1-2-更新-Ingress-Nginx" class="headerlink" title="6.1.2 更新 Ingress Nginx"></a>6.1.2 更新 Ingress Nginx</h4><pre><code class="highlight bash"><span class="comment"># 更新 Ingress Nginx</span>$ helm upgrade ingress-nginx . -n ingress-nginx<span class="comment"># 查看 Pod 是否更新，如果是则为刚创建的</span>$ kubectl get pod -n ingress-nginxNAME                                           READY   STATUS        RESTARTS   AGEingress-nginx-controller-cpbcd                 1/1     Terminating   0          31hingress-nginx-controller-szlfb                 1/1     Running       0          25singress-nginx-defaultbackend-f7797494f-t77x4   1/1     Running       0          39s<span class="comment"># 旧的 controller 正在关闭，新创建的在运行中，Ingress Nginx 更新成功</span></code></pre><h4 id="6-1-3-测试资源清单"><a href="#6-1-3-测试资源清单" class="headerlink" title="6.1.3 测试资源清单"></a>6.1.3 测试资源清单</h4><p><code>ingress-nginx-global-errorcode.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">protocol:</span> <span class="string">TCP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-global-errorcode</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">global.errorcode.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 global.errorcode.com 的流量。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-global-errorcode.yaml</code></pre></blockquote><blockquote><p>修改主机host文件，添加域名映射</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p><pre><code class="highlight plaintext">10.20.1.140 global.errorcode.com</code></pre></blockquote><p>当开启 Ingress Nginx 全局错误码重定向时，此时请求不存在的路径，服务端会返回默认的内容</p><p>例如请求 <a href="http://ingress-rewrite.com/123.html">http://ingress-rewrite.com/123.html</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/28/20250628-172533.png" alt="全局错误码重定向"></p><h3 id="6-2-单独声明错误后端"><a href="#6-2-单独声明错误后端" class="headerlink" title="6.2 单独声明错误后端"></a>6.2 单独声明错误后端</h3><p><strong>设置某个ingress的错误重定向会覆盖全局设置，示例如下</strong></p><ul><li>nginx.ingress.kubernetes.io&#x2F;default-backend: 默认后端service名称</li><li>nginx.ingress.kubernetes.io&#x2F;custom-http-errors: 那些错误代理重定向到默认后端svc</li></ul><p><strong>资源清单</strong></p><p><code>ingress-nginx-single-errorcode.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">error-code-deploy</span> <span class="comment"># 用于当请求出现规定的错误码时，返回默认内容</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">error</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">error</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">error-web</span>          <span class="attr">image:</span> <span class="string">registry.k8s.io/defaultbackend-amd64:1.5</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">protocol:</span> <span class="string">TCP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">error-code-svc</span> <span class="comment"># 当请求异常，接收到规定的错误码时，请求会重定向到这个service，用来处理错误请求，返回默认内容</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">error</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">protocol:</span> <span class="string">TCP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-svc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span> <span class="comment"># 指定 API 版本</span><span class="attr">kind:</span> <span class="string">Ingress</span> <span class="comment"># 指定资源类型为 Ingress，表示这是一个用于管理 HTTP/HTTPS 流量的 Kubernetes 资源</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">ingress-single-errorcode</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/default-backend:</span> <span class="string">&#x27;error-code-svc&#x27;</span> <span class="comment"># 指定请求异常时，重定向到哪个SVC处理</span>    <span class="attr">nginx.ingress.kubernetes.io/custom-http-errors:</span> <span class="string">&quot;404,415&quot;</span> <span class="comment"># 哪些错误代理重定向到默认后端svc</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">nginx</span> <span class="comment"># 指定此 Ingress 资源由名称为 nginx 的 IngressClass 处理，定义在 values.yaml 中 controller.ingressClassResource.name</span>  <span class="attr">rules:</span> <span class="comment"># 定义了流量路由的规则，即如何根据域名（host）和路径（path）将请求转发到后端服务。</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">single.errorcode.com</span> <span class="comment"># 指定此规则适用于请求的 HTTP 主机头（Host Header）为 single.errorcode.com 的流量。</span>      <span class="attr">http:</span> <span class="comment"># 定义了 HTTP 协议的路由规则</span>        <span class="attr">paths:</span> <span class="comment"># 用于指定路径匹配规则</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span> <span class="comment"># 指定匹配的 URL 路径为 /，即根路径,这是最常见的路径，表示匹配所有以 / 开头的请求</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span> <span class="comment"># 定义请求的转发目标，即后端服务</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">nginx-svc</span> <span class="comment"># 指定后端服务的名称为 nginx-svc.（必须存在于同一命名空间，或通过 &lt;namespace&gt;/&lt;service-name&gt; 跨命名空间引用）</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span> <span class="comment"># 指定目标 Service 的端口为 80</span></code></pre><p>为了体现出单独为 Ingress 声明错误码的处理效果，这里先将 ingress-nginx 的全局错误码处理关闭</p><pre><code class="highlight yaml"><span class="comment"># 修改 values.yaml</span><span class="attr">defaultBackend:</span>  <span class="attr">enabled:</span> <span class="literal">false</span> <span class="comment"># 关闭全局错误码重定向</span>  <span class="attr">name:</span> <span class="string">defaultbackend</span>  <span class="attr">image:</span>    <span class="attr">registry:</span> <span class="string">registry.k8s.io</span>    <span class="attr">image:</span> <span class="string">defaultbackend-amd64</span>    <span class="attr">tag:</span> <span class="string">&quot;1.5&quot;</span>    <span class="attr">pullPolicy:</span> <span class="string">IfNotPresent</span>    <span class="comment"># 更新 Ingress Nginx</span><span class="string">$</span> <span class="string">helm</span> <span class="string">upgrade</span> <span class="string">ingress-nginx</span> <span class="string">.</span> <span class="string">-n</span> <span class="string">ingress-nginx</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-single-errorcode.yaml</code></pre></blockquote><blockquote><p>修改主机host文件，添加域名映射</p><p>IP 可以是集群内部署了 Ingress-Controler 的任意一台服务器 IP</p><pre><code class="highlight plaintext">10.20.1.140 single.errorcode.com</code></pre></blockquote><p><strong>测试：</strong></p><p>使用浏览器访问一个不存在的路径，在没有错误码重定向时会返回 404， 如今为 Ingress 单独配置了错误码，会返回配置的 Service 的数据。</p><p><a href="http://single.errorcode.com/api/index1.html">http://single.errorcode.com/api/index1.html</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/04/20250704-153741.png" alt="自定义错误码返回"></p><h2 id="7-Ingress-nginx-匹配请求头"><a href="#7-Ingress-nginx-匹配请求头" class="headerlink" title="7. Ingress-nginx  匹配请求头"></a>7. Ingress-nginx  匹配请求头</h2><p>使用 ingress-nginx 实现根据不同的请求头，将请求转发到不同的服务。需要先开启 ingress-nginx 的 snippet 功能。</p><h3 id="7-1-开启-Snippet"><a href="#7-1-开启-Snippet" class="headerlink" title="7.1 开启 Snippet"></a>7.1 开启 Snippet</h3><pre><code class="highlight bash"><span class="comment"># 编辑 ingress-nginx-controller ConfigMap</span>$ kubectl edit cm ingress-nginx-controller -n ingress-nginx<span class="comment"># 开启 snippet</span>apiVersion: v1data:  allow-snippet-annotations: <span class="string">&quot;true&quot;</span></code></pre><h3 id="7-2-编辑资源清单"><a href="#7-2-编辑资源清单" class="headerlink" title="7.2 编辑资源清单"></a>7.2 编辑资源清单</h3><p><code>ingress-nginx-match-request-header.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">snippet</span>  <span class="attr">name:</span> <span class="string">snippet-dep</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">snippet</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">snippet</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">snippet-deploy</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">snippet</span>  <span class="attr">name:</span> <span class="string">snippet-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">snippet</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">snippet-igs</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/server-snippet:</span> <span class="string">|</span><span class="string">      set $agentflag 0;</span><span class="string">      if ($http_user_agent ~* &quot;(Android|IPhone)&quot;) &#123; # 如果是Android或IPhone访问会重定向到 www.baidu.com 的新网站</span><span class="string">        set $agentflag 1;</span><span class="string">      &#125;</span><span class="string">      if ($agentflag = 1) &#123;</span><span class="string">        return 302 http://www.baidu.com;</span><span class="string">      &#125;</span><span class="string"></span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">snippet.request.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span> <span class="comment"># 定义路径匹配的类型为 Prefix，表示匹配以指定路径（/) 开头的所有请求</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">snippet-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><blockquote><p>执行资源清单</p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-match-request-header.yaml</code></pre></blockquote><blockquote><p>编辑Host文件</p><pre><code class="highlight bash">$ <span class="built_in">cat</span> /etc/hosts10.20.1.140 snippet.request.com</code></pre><p>10.20.1.140 是 node 节点，部署了 Ingress 控制器</p></blockquote><blockquote><p>测试访问：<strong>默认请求头</strong></p><pre><code class="highlight bash">$ curl http://snippet.request.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt;</code></pre><p>成功访问到 Nginx</p></blockquote><blockquote><p>测试访问：添加请求头</p><pre><code class="highlight bash">$ curl http://snippet.request.com -H <span class="string">&#x27;User-Agent: Android&#x27;</span>  -IHTTP/1.1 302 Moved TemporarilyDate: Fri, 04 Jul 2025 07:08:56 GMTContent-Type: text/htmlContent-Length: 138Connection: keep-aliveLocation: http://www.baidu.com</code></pre><p>请求重定向到了 <a href="http://www.baidu.com/">www.baidu.com</a></p></blockquote><h2 id="8-Ingress-nginx-配置黑白名单"><a href="#8-Ingress-nginx-配置黑白名单" class="headerlink" title="8. Ingress-nginx  配置黑白名单"></a>8. Ingress-nginx  配置黑白名单</h2><h3 id="8-1-配置方案"><a href="#8-1-配置方案" class="headerlink" title="8.1. 配置方案"></a>8.1. 配置方案</h3><p>Ingress-nginx 配置黑白名单有两种方式：</p><ul><li>Annotations：只对指定的ingress生效</li><li>ConfigMap：全局生效</li></ul><p>configmap官方配置文档说明：<a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/</a></p><p><strong>若是同时配置了 Annotations 和 configmap，一般都是 annotations 生效，configmap 不生效，因为 annotations 优先级比 configmap 高</strong></p><h3 id="8-2-黑白名单的区别"><a href="#8-2-黑白名单的区别" class="headerlink" title="8.2 黑白名单的区别"></a>8.2 黑白名单的区别</h3><ul><li>白名单是默认是拒绝所有，只允许一个地址去访问</li><li>黑名单是不允许该地址去访问所有</li></ul><p>黑白名单配置使用 configmap 还是 annotations</p><ul><li>黑名单建议使用 ConfigMap 去配置</li><li>白名单建议使用 Annotations 去配置</li></ul><h3 id="8-3-ConfigMap-添加黑名单"><a href="#8-3-ConfigMap-添加黑名单" class="headerlink" title="8.3 ConfigMap 添加黑名单"></a>8.3 ConfigMap 添加黑名单</h3><p>配置黑名单禁止某一个或某一段 IP，需要在 Nginx Ingress 的 ConfigMap 中配置，比如将 10.20.1.141（多个配置逗号分隔）添加至黑名单。</p><p>configmap官方配置文档说明：<a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/</a></p><h4 id="8-3-1-编辑-Ingress-Nginx-ConfigMap"><a href="#8-3-1-编辑-Ingress-Nginx-ConfigMap" class="headerlink" title="8.3.1 编辑 Ingress-Nginx ConfigMap"></a>8.3.1 编辑 Ingress-Nginx ConfigMap</h4><pre><code class="highlight bash">$ kubectl  edit cm ingress-nginx-controller -n ingress-nginxapiVersion: v1data:  allow-snippet-annotations: <span class="string">&quot;true&quot;</span>  block-cidrs: 10.20.1.141,10.20.1.149</code></pre><p>编辑后保存！</p><h4 id="8-3-2-测试资源清单"><a href="#8-3-2-测试资源清单" class="headerlink" title="8.3.2 测试资源清单"></a>8.3.2 测试资源清单</h4><p><code>ingress-nginx-black-block.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">name:</span> <span class="string">test-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">test</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">name:</span> <span class="string">test-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">global.black.com</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">global.black.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">test-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-global-black.yaml</code></pre><p><strong>修改Host文件</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 global.black.com&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># 在 10.20.1.141 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.141 global.black.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>访问测试</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器上测试，可以成功访问 Ingress</span>$ curl global.block.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;<span class="comment"># 在 10.20.1.141 服务器上测试，访问被禁止，全局配置生效</span>$ curl global.block.com&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="8-4-Annotations-添加黑名单"><a href="#8-4-Annotations-添加黑名单" class="headerlink" title="8.4 Annotations 添加黑名单"></a>8.4 Annotations 添加黑名单</h3><p><strong>资源清单：</strong> <code>ingress-nginx-annotations-black.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">black</span>  <span class="attr">name:</span> <span class="string">black-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">black</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">black</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">black</span>  <span class="attr">name:</span> <span class="string">black-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">black</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/server-snippet:</span> <span class="string">|</span><span class="string">      deny 10.20.1.141;       # 拒绝特定 IP</span><span class="string">      deny 192.168.6.0/24;    # 拒绝特定网段</span><span class="string">      allow all;              # 允许其他 IP</span><span class="string"></span>  <span class="attr">name:</span> <span class="string">annotaions.black.com</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">annotaions.black.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">black-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span>            <span class="attr">path:</span> <span class="string">/</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-annotations-black.yaml</code></pre><p><strong>修改Host文件</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 annotaions.black.com&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># 在 10.20.1.141 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.141 annotaions.black.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>访问测试</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器上测试，可以成功访问 Ingress</span>$ curl annotaions.black.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;<span class="comment"># 在 10.20.1.141 服务器上测试，访问被禁止，全局配置生效</span>$ curl annotaions.black.com&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="8-5-ConfigMap-设置白名单"><a href="#8-5-ConfigMap-设置白名单" class="headerlink" title="8.5 ConfigMap 设置白名单"></a>8.5 ConfigMap 设置白名单</h3><p>白名单表示只允许某个IP可以访问 </p><h4 id="8-5-1-编辑-Ingress-Nginx-ConfigMap"><a href="#8-5-1-编辑-Ingress-Nginx-ConfigMap" class="headerlink" title="8.5.1 编辑 Ingress-Nginx ConfigMap"></a>8.5.1 编辑 Ingress-Nginx ConfigMap</h4><p>添加 <code>whitelist-source-range</code> 配置</p><pre><code class="highlight bash">$ kubectl  edit cm ingress-nginx-controller -n ingress-nginxapiVersion: v1data:  allow-snippet-annotations: <span class="string">&quot;true&quot;</span>  block-cidrs: 10.20.1.141,10.20.1.149  whitelist-source-range: 10.20.1.139,10.20.1.88</code></pre><p>编辑后保存！</p><h4 id="8-5-2-测试资源清单"><a href="#8-5-2-测试资源清单" class="headerlink" title="8.5.2 测试资源清单"></a>8.5.2 测试资源清单</h4><p><code>ingress-nginx-global-white.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">name:</span> <span class="string">test-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">test</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">name:</span> <span class="string">test-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">test</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">global.white.com</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">global.white.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">test-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-global-white.yaml</code></pre><p><strong>修改Host文件</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 global.white.com&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># 在 10.20.1.139 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 global.white.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>访问测试</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.139 服务器上测试，可以成功访问 Ingress</span>$ curl global.white.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;<span class="comment"># 在 10.20.1.140 服务器上测试，访问被禁止，全局配置生效</span>$ curl global.white.com&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="8-6-Annotations-添加白名单"><a href="#8-6-Annotations-添加白名单" class="headerlink" title="8.6 Annotations 添加白名单"></a>8.6 Annotations 添加白名单</h3><p><strong>资源清单：</strong> <code>ingress-nginx-annotations-white.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">white</span>  <span class="attr">name:</span> <span class="string">white-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">white</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">white</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">white</span>  <span class="attr">name:</span> <span class="string">white-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">white</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/whitelist-source-range:</span> <span class="string">&quot;10.20.1.140&quot;</span>  <span class="attr">name:</span> <span class="string">annotations.white.com</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">annotations.white.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">white-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-annotations-white.yaml</code></pre><p><strong>修改Host文件</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 annotations.white.com&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># 在 10.20.1.141 服务器添加 Host 配置</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.141 annotations.white.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>访问测试</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器上测试，可以成功访问 Ingress</span>$ curl annotations.white.com&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;<span class="comment"># 在 10.20.1.141 服务器上测试，访问被禁止，全局配置生效</span>$ curl annotations.white.com&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="9-Ingress-nginx-速率限制"><a href="#9-Ingress-nginx-速率限制" class="headerlink" title="9. Ingress-nginx  速率限制"></a>9. Ingress-nginx  速率限制</h2><p>有时候可能需要限制速率以降低后端压力，或者限制单个IP每秒的访问速率防止攻击。此时可以使用  Nginx 的 rate limit 进行配置</p><h3 id="9-1-速率限制设置"><a href="#9-1-速率限制设置" class="headerlink" title="9.1 速率限制设置"></a>9.1 速率限制设置</h3><pre><code class="highlight bash"><span class="comment">#限制每秒的连接，单个 IP： </span>nginx.ingress.kubernetes.io/limit-rps<span class="comment">#限制每分钟的连接，单个 IP： </span>nginx.ingress.kubernetes.io/limit-rpm <span class="comment">#限制客户端每秒传输的字节数，单位为 K，需要开启 proxy-buffering： </span>nginx.ingress.kubernetes.io/limit-rate <span class="comment">#速率限制白名单 </span>nginx.ingress.kubernetes.io/limit-whitelist</code></pre><h3 id="9-2-测试案例：无速率限制"><a href="#9-2-测试案例：无速率限制" class="headerlink" title="9.2 测试案例：无速率限制"></a>9.2 测试案例：无速率限制</h3><p>资源清单 ：<code>ingress-nginx-rate-limit-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">speed-deploy</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">2</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">speed</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">speed</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp</span>          <span class="attr">image:</span> <span class="string">nginx:1.29.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">speed-svc</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">speed</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-rate-limit-pod.yaml</code></pre><p><strong>编辑Host文件</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.140 服务器写入</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 rate.limit.com&quot;</span> &gt;&gt; /etc/hosts<span class="comment"># 在 10.20.1.141 服务器写入</span><span class="built_in">echo</span> <span class="string">&quot;10.20.1.141 rate.limit.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>测试在无Ingress 限制速率的情况下， 发起100次请求</strong></p><pre><code class="highlight bash"><span class="comment"># 安装 ab 工具</span>$ sudo yum install -y httpd-tools<span class="comment"># 测试发起100个请求，并发数是 10</span>$ ab -c 10 -n 100 http://rate.limit.com/ | grep requestsComplete requests:      100Failed requests:        0Time per request:       0.188 [ms] (mean, across all concurrent requests)Percentage of the requests served within a certain time (ms)</code></pre><p>结论：在没有速率限制的情况下，100个请求全部成功。</p><h3 id="9-3-测试案例：使用-Ingress-限制请求速率"><a href="#9-3-测试案例：使用-Ingress-限制请求速率" class="headerlink" title="9.3 测试案例：使用 Ingress 限制请求速率"></a>9.3 测试案例：使用 Ingress 限制请求速率</h3><p>资源清单：<code>ingress-nginx-rate-limit-ingress.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">speed-ingress</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/limit-rps:</span> <span class="string">&quot;10&quot;</span>  <span class="comment"># 每秒最多 10 个请求</span>    <span class="attr">nginx.ingress.kubernetes.io/limit-whitelist:</span> <span class="string">&quot;10.20.1.140,192.168.6.0/24&quot;</span>  <span class="comment"># 这些 IP 范围免于速率限制</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">rate.limit.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">speed-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-rate-limit-ingress.yaml</code></pre><p><strong>测试速率限制</strong></p><pre><code class="highlight bash"><span class="comment"># 在 10.20.1.141 服务器上使用 ab 同时发起100个请求</span>$ ab -c 10 -n 100 http://rate.limit.com/ | grep requestsComplete requests:      100Failed requests:        49Time per request:       0.205 [ms] (mean, across all concurrent requests)Percentage of the requests served within a certain time (ms)<span class="comment">###</span>由于 Ingress 做了请求速率的限制，发起100个请求，有49个失败了<span class="comment">###</span><span class="comment"># 在 10.20.1.140 服务器上使用 ab 同时发起100个请求</span>$ ab -c 10 -n 100 http://rate.limit.com/ | grep requestsComplete requests:      100Failed requests:        0Time per request:       0.137 [ms] (mean, across all concurrent requests)Percentage of the requests served within a certain time (ms)<span class="comment">###</span>虽然Ingress对请求做了速率限制，由于 10.20.1.140 服务器ip在ingress 速率限制的白名单中，因此请求速率不受限制，100个请求全部成功<span class="comment">###</span></code></pre><h2 id="10-Ingress-nginx-灰度或者金丝雀发布"><a href="#10-Ingress-nginx-灰度或者金丝雀发布" class="headerlink" title="10. Ingress-nginx  灰度或者金丝雀发布"></a>10. Ingress-nginx  灰度或者金丝雀发布</h2><h3 id="10-1-概述"><a href="#10-1-概述" class="headerlink" title="10.1 概述"></a>10.1 概述</h3><p>灰度发布（也称金丝雀发布，Canary Release）是一种软件部署策略，旨在降低新版本上线带来的风险。它通过将新版本逐步推送给一小部分用户或系统（称为“金丝雀”），观察其表现、稳定性及用户反馈，再决定是否推广到全部用户。以下是详细解释：</p><p><strong>核心概念</strong></p><ol><li><strong>逐步推广</strong>：新版本不会一次性部署到所有用户，而是先部署到小规模用户群（如1%的用户或特定区域）。</li><li><strong>监控与验证</strong>：在灰度发布期间，开发团队会密切监控新版本的性能、错误率、用户体验等指标。</li><li><strong>快速回滚</strong>：如果发现问题，可以迅速回滚到旧版本，减少对用户的影响。</li><li><strong>金丝雀的由来</strong>：名称源于煤矿工人使用金丝雀鸟来检测矿井中有毒气体。如果鸟儿出现异常，工人会立即撤离。类似地，灰度发布通过小范围测试来“预警”潜在问题。</li></ol><p><strong>实施步骤</strong></p><ol><li><strong>选择目标群体</strong>：确定一小部分用户或服务器作为“金丝雀”，可以基于地理位置、用户ID、设备类型等条件。</li><li><strong>部署新版本</strong>：将新版本部署到选定群体，同时旧版本继续服务其他用户。</li><li><strong>监控表现</strong>：使用监控工具（如日志分析、性能指标、用户反馈）评估新版本的稳定性。</li><li><strong>逐步扩展</strong>：如果表现良好，逐步增加新版本的覆盖范围（如从1%到10%、50%直至100%）。</li><li><strong>回滚或全量发布</strong>：若发现问题，回滚到旧版本；若一切正常，完成全量发布。</li></ol><h3 id="10-2-创建-V1-版本的-Ingress"><a href="#10-2-创建-V1-版本的-Ingress" class="headerlink" title="10.2 创建  V1 版本的 Ingress"></a>10.2 创建  V1 版本的 Ingress</h3><p><strong>资源清单：</strong> <code>ingress-nginx-canary-release-v1.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">canary-deploy-v1</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">v1</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">10</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">v1</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">v1</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">deploy-v1</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">v1</span>  <span class="attr">name:</span> <span class="string">canary-svc-v1</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">v1</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">ingress-v1</span>  <span class="attr">annotations:</span>    <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">&quot;nginx&quot;</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">&quot;nginx&quot;</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">canary.release.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">canary-svc-v1</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-canary-release-v1.yaml</code></pre><p><strong>编辑Hosts文件</strong></p><pre><code class="highlight bash">$ <span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 canary.release.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>测试请求</strong></p><pre><code class="highlight bash">$ curl http://canary.release.comwww.xinxianghf.com | hello MyAPP | version v1.0</code></pre><h3 id="10-3-创建-V2-版本的-Ingress"><a href="#10-3-创建-V2-版本的-Ingress" class="headerlink" title="10.3 创建 V2 版本的 Ingress"></a>10.3 创建 V2 版本的 Ingress</h3><p><strong>资源清单：</strong><code>ingress-nginx-canary-release-v2.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">canary-deploy-v2</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">v2</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">10</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">v2</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">v2</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">deploy-v2</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v2.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">v2</span>  <span class="attr">name:</span> <span class="string">canary-svc-v2</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">v2</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">ingress-v2</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/canary:</span> <span class="string">&quot;true&quot;</span> <span class="comment"># 启用金丝雀发布模式</span>    <span class="attr">nginx.ingress.kubernetes.io/canary-weight:</span> <span class="string">&quot;10&quot;</span> <span class="comment"># 定义金丝雀服务的流量权重，单位为百分比</span><span class="attr">spec:</span>  <span class="attr">ingressClassName:</span> <span class="string">&quot;nginx&quot;</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">canary.release.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">Prefix</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">canary-svc-v2</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">80</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-canary-release-v2.yaml</code></pre><p><strong>编辑Hosts文件</strong></p><pre><code class="highlight bash">$ <span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 canary.release.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>测试请求</strong></p><p>测试请求 100次， 查看请求汇总信息</p><pre><code class="highlight bash"><span class="comment"># 做100次请求</span>$ <span class="keyword">for</span> i <span class="keyword">in</span> &#123;1..100&#125;;<span class="keyword">do</span> curl http://canary.release.com  &gt;&gt; <span class="built_in">sum</span>;<span class="keyword">done</span><span class="comment"># 查看请求汇总信息</span>$ <span class="built_in">cat</span> <span class="built_in">sum</span> | <span class="built_in">sort</span> | <span class="built_in">uniq</span> -c     92 www.xinxianghf.com | hello MyAPP | version v1.0      8 www.xinxianghf.com | hello MyAPP | version v2.0</code></pre><p>结论：请求了100次，其中 92次请求到了 v1.0 版本， 8次请求到 v2.0版本。v2.0 大约占了 10%</p><h2 id="11-Ingress-nginx-代理后端-https-协议"><a href="#11-Ingress-nginx-代理后端-https-协议" class="headerlink" title="11. Ingress-nginx  代理后端 https 协议"></a>11. Ingress-nginx  代理后端 https 协议</h2><p>如果后端服务是 https 协议，需要使用 <code>nginx.ingress.kubernetes.io/backend-protocols</code> 声明后端服务是 <code>https</code> 。这里代理K8s的web控制台作为示例。代理后访问默认会强制跳转到 https 协议，返回的证书也是服务本身的证书。</p><p>资源清单：<code>ingress-nginx-proxy-https-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">name:</span> <span class="string">proxyhttps-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">proxyhttps</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">wangyanglinux/tools:httpsv1</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">name:</span> <span class="string">proxyhttps-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">443</span><span class="number">-443</span>      <span class="attr">port:</span> <span class="number">443</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">443</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-proxy-https-pod.yaml</code></pre><p><strong>访问Service</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 Service 资源</span>$ kubectl get svc -o wideNAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE     SELECTORproxyhttps-svc   ClusterIP   10.103.15.21   &lt;none&gt;        443/TCP   3m25s   app=proxyhttps<span class="comment"># 访问Service</span>$ curl -k https://10.103.15.21Hello, HTTPS!$ curl http://10.103.15.21:443Client sent an HTTP request to an HTTPS server.</code></pre><p>当前Service只能使用 HTTPS 访问</p><p><strong>只用 Ingress 代理后端 HTTPS 服务</strong></p><p>资源清单：<code>ingress-nginx-proxy-https-ingress.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Ingress</span><span class="attr">metadata:</span>  <span class="attr">annotations:</span>    <span class="attr">nginx.ingress.kubernetes.io/backend-protocol:</span> <span class="string">HTTPS</span>  <span class="attr">name:</span> <span class="string">ingress.https.com</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">rules:</span>    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">ingress.https.com</span>      <span class="attr">http:</span>        <span class="attr">paths:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span>            <span class="attr">pathType:</span> <span class="string">ImplementationSpecific</span>            <span class="attr">backend:</span>              <span class="attr">service:</span>                <span class="attr">name:</span> <span class="string">proxyhttps-svc</span>                <span class="attr">port:</span>                  <span class="attr">number:</span> <span class="number">443</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-proxy-https-ingress.yaml</code></pre><p><strong>编辑Host文件</strong></p><pre><code class="highlight bash">$ <span class="built_in">echo</span> <span class="string">&quot;10.20.1.140 ingress.https.com&quot;</span> &gt;&gt; /etc/hosts</code></pre><p><strong>请求测试</strong></p><pre><code class="highlight bash">$ curl http://ingress.https.comHello, HTTPS!</code></pre><p>结论：使用 Ingress 代理了后端HTTPS请求</p><h2 id="12-Ingress-nginx-四层代理"><a href="#12-Ingress-nginx-四层代理" class="headerlink" title="12. Ingress-nginx  四层代理"></a>12. Ingress-nginx  四层代理</h2><p>在新版本的nginx也引入了四层代理的概念，可直接代理TCP与UDP协议，在ingress-nginx也可以通过四层代理实现service的代理，实现方式如下：</p><p>官方文档：<a href="https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/">https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/</a></p><p>首先在使用 helm 部署 ingress-nginx 之后，需修改 nginx 启动资源的启动参数添加<code>--tcp-services-configmap</code>、<code>--udp-services-configmap</code> 的配置启用四层代理，通过修改配置 configmap 资源进行四层代理的配置。</p><h3 id="12-1TCP代理"><a href="#12-1TCP代理" class="headerlink" title="12.1TCP代理"></a>12.1TCP代理</h3><p><strong>修改 ingress-nginx 控制器</strong></p><p>在 ingress-nginx-controller 中添加 <code>--tcp-services-configmap</code> 启动参数</p><pre><code class="highlight bash">$ kubectl  edit ds -n ingress-nginx ingress-nginx-controller    spec:      containers:      - args:        - /nginx-ingress-controller        - --tcp-services-configmap=$(POD_NAMESPACE)/nginx-ingress-tcp-configmap        <span class="comment">#参数说明如下</span>--tcp-services-configmap=$(POD_NAMESPACE)/  这里为固定，表示tcp配置选择ingress-nginx安装的命名空间的configmap资源nginx-ingress-tcp-configmap  为configmap资源的名称</code></pre><p><strong>编辑 ConfigMap</strong></p><p><code>nginx-ingress-tcp-configmap.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-ingress-tcp-configmap</span>  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span> <span class="comment"># ingress-nginx 所在的命名空间</span><span class="attr">data:</span>  <span class="attr">&quot;9000&quot;:</span> <span class="string">&quot;default/proxyhttps-svc:443&quot;</span></code></pre><pre><code class="highlight bash">$ kubectl apply -f nginx-ingress-tcp-configmap.yaml</code></pre><p><strong>Pod资源清单</strong></p><p><code>ingress-nginx-tcp-proxy-pod.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">name:</span> <span class="string">proxyhttps-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">proxyhttps</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">wangyanglinux/tools:httpsv1</span>          <span class="attr">name:</span> <span class="string">myapp</span><span class="meta">---</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">name:</span> <span class="string">proxyhttps-svc</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="number">443</span><span class="number">-443</span>      <span class="attr">port:</span> <span class="number">443</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">443</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">proxyhttps</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span></code></pre><p><strong>执行资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f ingress-nginx-tcp-proxy-pod.yaml</code></pre><p><strong>测试四层代理访问</strong></p><pre><code class="highlight bash">$ kubectl get svc -o wideNAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE    SELECTORproxyhttps-svc   ClusterIP   10.96.172.123   &lt;none&gt;        443/TCP   63s    app=proxyhttps<span class="comment"># 首先直接访问 SVC，确认服务可用</span>$ curl -k https://10.96.172.123:443Hello, HTTPS!<span class="comment"># 测试通过ingress 4层代理访问</span>$ curl -k https://10.20.1.140:9000Hello, HTTPS!</code></pre><h3 id="12-2-UDP代理"><a href="#12-2-UDP代理" class="headerlink" title="12.2 UDP代理"></a>12.2 UDP代理</h3><p><strong>修改 ingress-nginx 控制器</strong></p><p>在 ingress-nginx-controller 中添加 <code>--tcp-services-configmap</code> 启动参数</p><pre><code class="highlight bash">$ kubectl  edit ds -n ingress-nginx ingress-nginx-controller    spec:      containers:      - args:        - /nginx-ingress-controller        - --udp-services-configmap=$(POD_NAMESPACE)/nginx-ingress-udp-configmap        <span class="comment">#参数说明如下</span>--tcp-services-configmap=$(POD_NAMESPACE)/  这里为固定，表示tcp配置选择ingress-nginx安装的命名空间的configmap资源nginx-ingress-tcp-configmap  为configmap资源的名称</code></pre><p><strong>编辑 ConfigMap</strong></p><p><code>nginx-ingress-udp-configmap.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx-ingress-udp-configmap</span>  <span class="attr">namespace:</span> <span class="string">ingress</span><span class="attr">data:</span>  <span class="attr">&quot;53&quot;:</span> <span class="string">&quot;kube-system/kube-dns:53&quot;</span></code></pre><h2 id="13-Ingress-nginx-链路追踪"><a href="#13-Ingress-nginx-链路追踪" class="headerlink" title="13. Ingress-nginx  链路追踪"></a>13. Ingress-nginx  链路追踪</h2><p>官方文档：<a href="https://kubernetes.github.io/ingress-nginx/user-guide/third-party-addons/opentracing/#jaeger">https://kubernetes.github.io/ingress-nginx/user-guide/third-party-addons/opentracing/#jaeger</a></p><p>官方推荐的链路追踪插件为 Zipkin 或者 Jaeger。这里我们选用 Jaeger。</p><p>官方部署示例文件: <a href="https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/all-in-one/jaeger-all-in-one-template.yml">https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/all-in-one/jaeger-all-in-one-template.yml</a></p><h3 id="13-1-部署-Jaeger"><a href="#13-1-部署-Jaeger" class="headerlink" title="13.1 部署 Jaeger"></a>13.1 部署 Jaeger</h3><pre><code class="highlight bash"><span class="comment"># 下载部署资源清单</span>wget https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/all-in-one/jaeger-all-in-one-template.yml</code></pre><p>修改 jaeger 资源清单</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">List</span><span class="attr">items:</span><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># 将版本修改为 apps/v1</span>  <span class="attr">kind:</span> <span class="string">Deployment</span>  <span class="attr">metadata:</span>    <span class="attr">name:</span> <span class="string">jaeger</span>    <span class="attr">labels:</span>      <span class="attr">app:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span>  <span class="attr">spec:</span>    <span class="attr">replicas:</span> <span class="number">1</span>    <span class="attr">selector:</span> <span class="comment"># 添加选择器， apps/v1版本需要</span>      <span class="attr">matchLabels:</span>        <span class="attr">app:</span> <span class="string">jaeger</span>    <span class="attr">strategy:</span>      <span class="attr">type:</span> <span class="string">Recreate</span>    <span class="attr">template:</span>      <span class="attr">metadata:</span>        <span class="attr">labels:</span>          <span class="attr">app:</span> <span class="string">jaeger</span>          <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>          <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span>        <span class="attr">annotations:</span>          <span class="attr">prometheus.io/scrape:</span> <span class="string">&quot;true&quot;</span>          <span class="attr">prometheus.io/port:</span> <span class="string">&quot;16686&quot;</span>      <span class="attr">spec:</span>          <span class="attr">containers:</span>          <span class="bullet">-</span>   <span class="attr">env:</span>              <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">COLLECTOR_ZIPKIN_HTTP_PORT</span>                <span class="attr">value:</span> <span class="string">&quot;9411&quot;</span>              <span class="attr">image:</span> <span class="string">jaegertracing/all-in-one</span>              <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 修改镜像下载策略，提前将镜像下载好</span>              <span class="attr">name:</span> <span class="string">jaeger</span>              <span class="attr">ports:</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">5775</span>                  <span class="attr">protocol:</span> <span class="string">UDP</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">6831</span>                  <span class="attr">protocol:</span> <span class="string">UDP</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">6832</span>                  <span class="attr">protocol:</span> <span class="string">UDP</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">5778</span>                  <span class="attr">protocol:</span> <span class="string">TCP</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">16686</span>                  <span class="attr">protocol:</span> <span class="string">TCP</span>                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9411</span>                  <span class="attr">protocol:</span> <span class="string">TCP</span>              <span class="attr">readinessProbe:</span>                <span class="attr">httpGet:</span>                  <span class="attr">path:</span> <span class="string">&quot;/&quot;</span>                  <span class="attr">port:</span> <span class="number">14269</span>                <span class="attr">initialDelaySeconds:</span> <span class="number">5</span><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">v1</span>  <span class="attr">kind:</span> <span class="string">Service</span>  <span class="attr">metadata:</span>    <span class="attr">name:</span> <span class="string">jaeger-query</span>    <span class="attr">labels:</span>      <span class="attr">app:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">query</span>  <span class="attr">spec:</span>    <span class="attr">ports:</span>      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">query-http</span>        <span class="attr">port:</span> <span class="number">80</span>        <span class="attr">protocol:</span> <span class="string">TCP</span>        <span class="attr">targetPort:</span> <span class="number">16686</span>    <span class="attr">selector:</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span>    <span class="attr">type:</span> <span class="string">LoadBalancer</span><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">v1</span>  <span class="attr">kind:</span> <span class="string">Service</span>  <span class="attr">metadata:</span>    <span class="attr">name:</span> <span class="string">jaeger-collector</span>    <span class="attr">labels:</span>      <span class="attr">app:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">collector</span>  <span class="attr">spec:</span>    <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jaeger-collector-tchannel</span>      <span class="attr">port:</span> <span class="number">14267</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">14267</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jaeger-collector-http</span>      <span class="attr">port:</span> <span class="number">14268</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">14268</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jaeger-collector-zipkin</span>      <span class="attr">port:</span> <span class="number">9411</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">9411</span>    <span class="attr">selector:</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span>    <span class="attr">type:</span> <span class="string">ClusterIP</span><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">v1</span>  <span class="attr">kind:</span> <span class="string">Service</span>  <span class="attr">metadata:</span>    <span class="attr">name:</span> <span class="string">jaeger-agent</span>    <span class="attr">labels:</span>      <span class="attr">app:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">agent</span>  <span class="attr">spec:</span>    <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">agent-zipkin-thrift</span>      <span class="attr">port:</span> <span class="number">5775</span>      <span class="attr">protocol:</span> <span class="string">UDP</span>      <span class="attr">targetPort:</span> <span class="number">5775</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">agent-compact</span>      <span class="attr">port:</span> <span class="number">6831</span>      <span class="attr">protocol:</span> <span class="string">UDP</span>      <span class="attr">targetPort:</span> <span class="number">6831</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">agent-binary</span>      <span class="attr">port:</span> <span class="number">6832</span>      <span class="attr">protocol:</span> <span class="string">UDP</span>      <span class="attr">targetPort:</span> <span class="number">6832</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">agent-configs</span>      <span class="attr">port:</span> <span class="number">5778</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">5778</span>    <span class="attr">clusterIP:</span> <span class="string">None</span>    <span class="attr">selector:</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">v1</span>  <span class="attr">kind:</span> <span class="string">Service</span>  <span class="attr">metadata:</span>    <span class="attr">name:</span> <span class="string">zipkin</span>    <span class="attr">labels:</span>      <span class="attr">app:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">zipkin</span>  <span class="attr">spec:</span>    <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jaeger-collector-zipkin</span>      <span class="attr">port:</span> <span class="number">9411</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">9411</span>    <span class="attr">clusterIP:</span> <span class="string">None</span>    <span class="attr">selector:</span>      <span class="attr">app.kubernetes.io/name:</span> <span class="string">jaeger</span>      <span class="attr">app.kubernetes.io/component:</span> <span class="string">all-in-one</span></code></pre><blockquote><p>可以将所有的 SVC、Deployment 都放到单独的命名空间中，这样就不会被误删除</p></blockquote><p><strong>执行 Jaeger 资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f jaeger-all-in-one-template.yml <span class="comment"># 查看 SVC, !!! 注意：浏览器访问 jaeger 是通过 jaeger-query， 这里的 31272 就是对外暴露的端口</span>$ kubectl get svcNAME               TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                               AGEjaeger-agent       ClusterIP      None            &lt;none&gt;        5775/UDP,6831/UDP,6832/UDP,5778/TCP   12mjaeger-collector   ClusterIP      10.99.111.240   &lt;none&gt;        14267/TCP,14268/TCP,9411/TCP          12mjaeger-query       LoadBalancer   10.100.53.251   &lt;pending&gt;     80:31272/TCP                          12mkubernetes         ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP                               4d5hzipkin             ClusterIP      None            &lt;none&gt;        9411/TCP                              12m<span class="comment"># 查看 Deployment</span>$ kubectl get deployNAME     READY   UP-TO-DATE   AVAILABLE   AGEjaeger   1/1     1            1           20s<span class="comment"># 查看 Pod</span>$ kubectl get podNAME                     READY   STATUS    RESTARTS   AGEjaeger-cbfbf99b4-cxgq6   1/1     Running   0          22s</code></pre><p>到此 Jaeger 就部署好了</p><p><strong>注意：浏览器访问 jaeger 是通过 jaeger-query， 这里的 31272 就是对外暴露的端口，可以通过：http:&#x2F;&#x2F;物理机ip:31035 访问 Jaeger</strong></p><h3 id="13-2-ingress-设置"><a href="#13-2-ingress-设置" class="headerlink" title="13.2 ingress 设置"></a>13.2 ingress 设置</h3><p>需要修改 ingress 的 configmap 文件，添加相应参数，开启 Ingress 链路追踪</p><pre><code class="highlight bash">$ kubectl edit cm -n ingress-nginx ingress-nginx-controllerapiVersion: v1data:  allow-snippet-annotations: <span class="string">&quot;true&quot;</span>  enable-opentracing: <span class="string">&quot;true&quot;</span>   <span class="comment">#开启链路追踪</span>  jaeger-collector-host: jaeger-agent.default.svc.cluster.local  <span class="comment">#链路追踪的svc名称</span></code></pre><p><strong>重建 Ingress-Nginx Pod</strong></p><pre><code class="highlight bash"><span class="comment"># 查看Pod</span>$ kubectl get pods -n ingress-nginxNAME                             READY   STATUS    RESTARTS   AGEingress-nginx-controller-25wk6   1/1     Running   0          150mingress-nginx-controller-qcbp2   1/1     Running   0          151m<span class="comment"># 删除Pod，等待重建</span>$ kubectl delete pod ingress-nginx-controller-25wk6 ingress-nginx-controller-qcbp2 -n ingress-nginx</code></pre><p><strong>浏览器访问Jaeger</strong></p><p><a href="http://10.20.1.139:31272/">http://10.20.1.139:31272/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/06/20250706-165831.png" alt="浏览器访问Jaeger"></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/07/06/20250706-170040.png" alt="查看请求"></p><p>参考链接</p><blockquote><p><a href="https://zhangzhuo.ltd/articles/2022/03/20/1647773666928.html">https://zhangzhuo.ltd/articles/2022/03/20/1647773666928.html</a></p><p><a href="https://www.cnblogs.com/tencent-cloud-native/p/13865502.html">https://www.cnblogs.com/tencent-cloud-native/p/13865502.html</a></p><p><a href="https://k8s.whuanle.cn/4.network/3.ingress.html">https://k8s.whuanle.cn/4.network/3.ingress.html</a></p><p><a href="https://www.cnblogs.com/linyb-geek/p/18153533">https://www.cnblogs.com/linyb-geek/p/18153533</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;K8S集群服务器&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;Hostname&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;10.20.1.139&lt;/td&gt;
&lt;td&gt;k8s-</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>010-Kubernetes Helm</title>
    <link href="https://georgechan95.github.io/blog/d8e3c7b3.html"/>
    <id>https://georgechan95.github.io/blog/d8e3c7b3.html</id>
    <published>2025-06-21T06:12:00.000Z</published>
    <updated>2025-06-25T05:29:37.300Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h1><p>没有使用 Helm 之前，在 Kubernetes 部署应用，我们要依次部署 deployment、service 等，步骤比较繁琐。况且随着很多项目微服务化，复杂的应用在容器中部署以及管理显得较为复杂。</p><p>helm 通过打包的方式，支持发布的版本管理和控制，很大程度上简化了 Kubernetes 应用的部署和管理。Helm 本质就是让 k8s 的应用管理（Deployment、Service等）可配置，能动态生成。通过动态生成K8S资源清单文件（deployment.yaml、service.yaml）。然后 kubectl 自动调用 K8S 资源部署。</p><p>官网：<a href="https://helm.sh/">Helm</a> </p><p>Helm 具备如下的能力：</p><ul><li><strong>简化部署</strong> ：Helm允许使用单个命令轻松部署和管理应用程序，从而简化了整个部署过程；</li><li><strong>高度可配置</strong>：Helm Charts提供了高度可配置的选项，可以轻松自定义和修改应用程序的部署配置；</li><li><strong>版本控制</strong> ：Helm允许管理应用程序的多个版本，从而轻松实现版本控制和回滚；</li><li><strong>模板化</strong>：Helm Charts使用YAML模板来定义Kubernetes对象的配置，从而简化了配置过程，并提高了可重复性和可扩展性；</li><li><strong>应用程序库</strong>：Helm具有应用程序库的概念，可以轻松地共享和重用Helm Charts，从而简化了多个应用程序的部署和管理；</li><li><strong>插件系统</strong>：Helm拥有一个强大的插件系统，允许您扩展和定制Helm的功能，以满足特定的需求和要求。</li></ul><h1 id="二、Helm-V2-与-V3-的区别"><a href="#二、Helm-V2-与-V3-的区别" class="headerlink" title="二、Helm V2 与 V3 的区别"></a>二、Helm V2 与 V3 的区别</h1><p>Helm v2 是 C&#x2F;S 架构，主要分为客户端 helm 和服务器端 tiller。而由于 RBAC 等权限控制体系的逐渐完善，多租户和安全的需求日益兴起，tiller 变得越来越不安全，社区在权限控制领域遇到了极大的阻碍。所以在 Helm3 版本中，直接将 tiller 这一核心组件移除，helm 直接和 kubernetes API 进行通信。直接带来的好处如下：</p><ul><li>Helm 的架构变的更为简单和灵活</li><li>不再需要创建 ServiceAccount，直接使用当前环境中的 kubeconfig 配置</li><li>可以直接和 kubernetes API 交互，更为安全</li><li>不再需要使用 helm init 来进行初始化</li></ul><h1 id="三、Helm工作流程"><a href="#三、Helm工作流程" class="headerlink" title="三、Helm工作流程"></a>三、Helm工作流程</h1><p>以下是Helm的工作流程（<strong>注意：这里使用的是Helm的v3版本，该版本没有了<code>tiller</code>并并使用更加简单和灵活的架构，直接通过 <code>kubeconfig</code> 连接 <code>apiserver</code> ，简化安全模块，降低了用户的使用壁垒</strong>）：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/21/20250621-143827" alt="Helm工作流程"></p><p><strong>如上图所示，Helm的工作流程总结如下：</strong></p><ol><li>开发者首先创建并编辑 chart 的配置；</li><li>接着打包并发布至 Helm 的仓库（Repository）；</li><li>当管理员使用 helm 命令安装时，相关的依赖会从仓库下载；</li><li>接着helm 会根据下载的配置部署资源至 k8s ；</li></ol><h1 id="四、Helm概念"><a href="#四、Helm概念" class="headerlink" title="四、Helm概念"></a>四、Helm概念</h1><p><strong>在使用Helm的过程中，需要理解如下的几个核心的概念：</strong></p><table><thead><tr><th>概念</th><th>描述</th></tr></thead><tbody><tr><td><strong>Chart</strong></td><td>一个 Helm 包，其中包含了运行一个应用所需要的镜像、依赖和资源定义等，还可能包含 Kubernetes 集群中的服务定义，类似 Homebrew 中的 formula、APT 的 dpkg 或者 Yum 的 rpm 文件</td></tr><tr><td><strong>Repository</strong></td><td>存储 Helm Charts 的地方</td></tr><tr><td><strong>Release</strong></td><td>Chart 在 k8s上运行的 Chart 的一个实例，例如，如果一个 MySQL Chart 想在服务器上运行两个数据库，可以将这个 Chart 安装两次，并在每次安装中生成自己的 Release 以及 Release 名称。</td></tr><tr><td><strong>Value</strong></td><td>Helm Chart 的参数，用于配置 Kubernetes 对象</td></tr><tr><td><strong>Template</strong></td><td>使用 Go 模板语言生成 Kubernetes 对象的定义文件</td></tr><tr><td><strong>Namespace</strong></td><td>Kubernetes 中用于隔离资源的逻辑分区</td></tr></tbody></table><h1 id="五、Helm的使用"><a href="#五、Helm的使用" class="headerlink" title="五、Helm的使用"></a>五、Helm的使用</h1><h2 id="1-安装Helm"><a href="#1-安装Helm" class="headerlink" title="1. 安装Helm"></a>1. 安装Helm</h2><p>参考官方文档：<a href="https://helm.sh/zh/docs/intro/install/">安装Helm</a></p><h3 id="1-1-用二进制版本安装"><a href="#1-1-用二进制版本安装" class="headerlink" title="1.1 用二进制版本安装"></a>1.1 用二进制版本安装</h3><p><strong>下载二进制安装包</strong></p><p>下载地址：<a href="https://github.com/helm/helm/releases">https://github.com/helm/helm/releases</a></p><p><strong>解压二进制包</strong></p><pre><code class="highlight bash">$ tar -zxvf helm-v3.12.3-linux-amd64.tar.gz</code></pre><p><strong>将二进制文件移动到对应的目录中</strong></p><pre><code class="highlight bash">$ <span class="built_in">mv</span> linux-amd64/helm /usr/local/bin/helm</code></pre><p><strong>测试</strong></p><pre><code class="highlight bash"><span class="comment"># 查看Helm版本</span>$ helm versionversion.BuildInfo&#123;Version:<span class="string">&quot;v3.12.3&quot;</span>, GitCommit:<span class="string">&quot;3a31588ad33fe3b89af5a2a54ee1d25bfe6eaa5e&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, GoVersion:<span class="string">&quot;go1.20.7&quot;</span>&#125;</code></pre><h3 id="1-2-使用脚本安装"><a href="#1-2-使用脚本安装" class="headerlink" title="1.2 使用脚本安装"></a>1.2 使用脚本安装</h3><p>Helm现在有个安装脚本可以自动拉取最新的Helm版本并在 <a href="https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3">本地安装</a>。</p><pre><code class="highlight bash"><span class="comment"># 在线安装脚本</span>$ curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3<span class="comment"># 给脚本授权</span>$ <span class="built_in">chmod</span> 700 get_helm.sh<span class="comment"># 执行脚本</span>$ ./get_helm.sh</code></pre><h2 id="2-Helm-初始化"><a href="#2-Helm-初始化" class="headerlink" title="2. Helm 初始化"></a>2. Helm 初始化</h2><p>当您已经安装好了Helm之后，您可以添加一个 chart 仓库。从  <a href="https://artifacthub.io/packages/search?kind=0">Artifact Hub </a>中查找有效的 Helm chart 仓库</p><pre><code class="highlight bash">$ helm repo add bitnami https://charts.bitnami.com/bitnami<span class="string">&quot;bitnami&quot;</span> has been added to your repositories</code></pre><p>当添加完成，您将可以看到可以被您安装的 charts 列表：</p><pre><code class="highlight bash">$ helm search repo bitnamiNAME                                        CHART VERSIONAPP VERSION  DESCRIPTION                                       bitnami/airflow                             24.1.4       3.0.2        Apache Airflow is a tool to express and execute...bitnami/apache                              11.3.16      2.4.63       Apache HTTP Server is an open-source HTTP serve...bitnami/apisix                              5.0.3        3.12.0       Apache APISIX is high-performance, real-time AP...bitnami/appsmith                            6.0.11       1.77.0       Appsmith is an open <span class="built_in">source</span> platform <span class="keyword">for</span> buildin...bitnami/argo-cd                             9.0.22       3.0.9        Argo CD is a continuous delivery tool <span class="keyword">for</span> Kuber...</code></pre><h2 id="3-Helm-仓库管理"><a href="#3-Helm-仓库管理" class="headerlink" title="3. Helm 仓库管理"></a>3. Helm 仓库管理</h2><h3 id="3-1-添加仓库"><a href="#3-1-添加仓库" class="headerlink" title="3.1 添加仓库"></a>3.1 添加仓库</h3><pre><code class="highlight bash"><span class="comment"># 添加 bitnami 仓库</span>$ helm repo add bitnami https://charts.bitnami.com/bitnami<span class="comment"># 添加阿里云仓库</span>$ helm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts<span class="comment"># 添加微软仓库</span>$ helm repo add ms http://mirror.azure.cn/kubernetes/charts/</code></pre><h3 id="3-2-查看仓库"><a href="#3-2-查看仓库" class="headerlink" title="3.2 查看仓库"></a>3.2 查看仓库</h3><pre><code class="highlight bash">$ helm repo listNAME   URL                                                   bitnamihttps://charts.bitnami.com/bitnami                    aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/chartsms     http://mirror.azure.cn/kubernetes/charts/</code></pre><h3 id="3-3-更新仓库索引"><a href="#3-3-更新仓库索引" class="headerlink" title="3.3 更新仓库索引"></a>3.3 更新仓库索引</h3><pre><code class="highlight bash">$ helm repo update</code></pre><h3 id="3-4-删除仓库"><a href="#3-4-删除仓库" class="headerlink" title="3.4 删除仓库"></a>3.4 删除仓库</h3><pre><code class="highlight bash">$ helm repo remove [仓库名称]</code></pre><h3 id="3-5-在仓库中搜索-Chart-应用"><a href="#3-5-在仓库中搜索-Chart-应用" class="headerlink" title="3.5 在仓库中搜索 Chart 应用"></a>3.5 在仓库中搜索 Chart 应用</h3><pre><code class="highlight bash"><span class="comment"># 只在 ms 仓库搜索应用</span>$ helm search repo ms/redis<span class="comment"># 在添加的所有仓库搜索应用</span>$ helm search repo redis</code></pre><h3 id="3-6-查看指定仓库中Chart的版本"><a href="#3-6-查看指定仓库中Chart的版本" class="headerlink" title="3.6  查看指定仓库中Chart的版本"></a>3.6  查看指定仓库中Chart的版本</h3><pre><code class="highlight bash">helm search repo [chart名称] --versions$ helm search repo ms/redis --versionsNAME       CHART VERSIONAPP VERSION    DESCRIPTION                                       ms/redis   10.5.7       5.0.7          DEPRECATED Open <span class="built_in">source</span>, advanced key-value stor...ms/redis   9.5.4        5.0.6          Open <span class="built_in">source</span>, advanced key-value store. It is of...ms/redis   9.5.3        5.0.6          Open <span class="built_in">source</span>, advanced key-value store. It is of...ms/redis   9.5.2        5.0.5          Open <span class="built_in">source</span>, advanced key-value store. It is of...</code></pre><h3 id="3-7-拉取远程仓库的-Chart"><a href="#3-7-拉取远程仓库的-Chart" class="headerlink" title="3.7 拉取远程仓库的 Chart"></a>3.7 拉取远程仓库的 Chart</h3><pre><code class="highlight bash"><span class="comment"># 语法，--version对应的是chart version，--untar自动解压，</span><span class="comment"># --destination：指定下载的 Chart 文件（.tgz）保存的目标目录（默认当前目录）。</span><span class="comment"># --repo [仓库URL]直接从指定 URL 下载 Chart，而不使用已添加的仓库名称。</span>helm pull [chart名出] --version [版本号] --untar --destination [/path] --repo [仓库URL] <span class="comment"># 示例</span>$ helm pull ms/redis --version 10.5.7$ ll-rw-r--r-- 1 root root      31909 Jun 22 15:52 redis-10.5.7.tgz</code></pre><h2 id="4-安装-chart-示例"><a href="#4-安装-chart-示例" class="headerlink" title="4. 安装 chart 示例"></a>4. 安装 chart 示例</h2><h3 id="4-1-在线安装"><a href="#4-1-在线安装" class="headerlink" title="4.1 在线安装"></a>4.1 在线安装</h3><pre><code class="highlight bash"><span class="comment"># 更新 charts 列表</span>$ helm repo updateHang tight <span class="keyword">while</span> we grab the latest from your chart repositories......Successfully got an update from the <span class="string">&quot;bitnami&quot;</span> chart repositoryUpdate Complete. ⎈Happy Helming!⎈<span class="comment"># 显示 Bitnami 提供的 Apache Helm chart 的默认配置文件（values.yaml）内容</span>$ helm show values bitnami/apache<span class="comment"># 在 Kubernetes 集群中安装 Bitnami 提供的 Apache Helm chart，并自动生成一个唯一的 release 名称</span>$ helm install bitnami/apache --generate-name</code></pre><p>上面的操作用的 chart 源是 bitnami , 而 bitnami 服务器在国外，国内无法访问，我尝试服务器翻墙，依然报错，错误信息如下：</p><pre><code class="highlight bash">$ helm install my-apache bitnami/apache --version 11.3.16Error: INSTALLATION FAILED: failed to <span class="keyword">do</span> request: Head <span class="string">&quot;https://registry-1.docker.io/v2/bitnamicharts/apache/manifests/11.3.16&quot;</span>: dial tcp: lookup registry-1.docker.io: i/o <span class="built_in">timeout</span></code></pre><h3 id="4-2-离线安装"><a href="#4-2-离线安装" class="headerlink" title="4.2 离线安装"></a>4.2 离线安装</h3><pre><code class="highlight bash"><span class="comment"># 下载chart安装包</span>wget https://charts.bitnami.com/bitnami/apache-11.3.16.tgz<span class="comment"># 解压</span>tar -zxvf apache-11.3.16.tgz <span class="comment"># 进入解压后的chart目录</span><span class="built_in">cd</span> apache<span class="comment"># 安装Chart，运行生成一个Release</span><span class="comment"># 方式一：使用解压后的chart安装， . 表示当前解压的目录</span>$ helm install my-apache .<span class="comment"># 方式二：直接使用下载的 chart 压缩包安装</span>helm install my-apache apache-11.3.16.tgz<span class="comment"># 查看Release实例</span>$ helm list -n defaultNAME     NAMESPACEREVISIONUPDATED                                STATUS  CHART         APP VERSIONmy-apachedefault  1       2025-06-22 14:05:26.557276416 +0800 CSTdeployedapache-11.3.162.4.63</code></pre><p>查看运行的Pod</p><pre><code class="highlight bash"><span class="comment"># 查看运行的Service</span>$ kubectl get svc -o wideNAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE    SELECTORkubernetes   ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP                      54d    &lt;none&gt;my-apache    LoadBalancer   10.108.203.41   &lt;pending&gt;     80:31349/TCP,443:32630/TCP   105s   app.kubernetes.io/instance=my-apache,app.kubernetes.io/name=apache<span class="comment"># 查看Deployment</span>$ kubectl get deployment -o wideNAME        READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS   IMAGES                                          SELECTORmy-apache   0/1     1            0           112s   apache       docker.io/bitnami/apache:2.4.63-debian-12-r16   app.kubernetes.io/instance=my-apache,app.kubernetes.io/name=apache<span class="comment"># 查看Pod</span>$ kubectl get pods -o wideNAME                         READY   STATUS              RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATESmy-apache-74b6d9f88b-lknsr   0/1     Init:ErrImagePull   0          114s   172.16.58.254   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>Pod未能运行成功，查找原因</p><pre><code class="highlight bash">$ kubectl describe pod my-apache-74b6d9f88b-lknsrName:             my-apache-74b6d9f88b-lknsrNamespace:        defaultPriority:         0Service Account:  my-apacheNode:             k8s-node02/192.168.6.141............Events:  Type     Reason     Age                    From               Message  ----     ------     ----                   ----               -------  Normal   Scheduled  6m39s                  default-scheduler  Successfully assigned default/my-apache-74b6d9f88b-lknsr to k8s-node02  Warning  Failed     5m51s (x2 over 6m21s)  kubelet            Failed to pull image <span class="string">&quot;docker.io/bitnami/apache:2.4.63-debian-12-r16&quot;</span>: Error response from daemon: Get <span class="string">&quot;https://registry-1.docker.io/v2/&quot;</span>: net/http: request canceled <span class="keyword">while</span> waiting <span class="keyword">for</span> connection (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)  Warning  Failed     5m10s                  kubelet            Failed to pull image <span class="string">&quot;docker.io/bitnami/apache:2.4.63-debian-12-r16&quot;</span>: Error response from daemon: Get <span class="string">&quot;https://registry-1.docker.io/v2/&quot;</span>: context deadline exceeded  Normal   Pulling    4m17s (x4 over 6m36s)  kubelet            Pulling image <span class="string">&quot;docker.io/bitnami/apache:2.4.63-debian-12-r16&quot;</span>  Warning  Failed     4m1s (x4 over 6m21s)   kubelet            Error: ErrImagePull  Warning  Failed     4m1s                   kubelet            Failed to pull image <span class="string">&quot;docker.io/bitnami/apache:2.4.63-debian-12-r16&quot;</span>: Error response from daemon: Get <span class="string">&quot;https://registry-1.docker.io/v2/&quot;</span>: context deadline exceeded (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)  Warning  Failed     3m46s (x6 over 6m20s)  kubelet            Error: ImagePullBackOff  Normal   BackOff    91s (x14 over 6m20s)   kubelet            Back-off pulling image <span class="string">&quot;docker.io/bitnami/apache:2.4.63-debian-12-r16&quot;</span></code></pre><p><strong>原因：镜像  docker.io&#x2F;bitnami&#x2F;apache:2.4.63-debian-12-r16 拉取失败，可以通过修改 chart 解压路径中的 value.yaml 文件，将镜像替换成国内的镜像即可。</strong></p><p>也可以添加国内的阿里云 chart 仓库，地址：<a href="https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts">https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</a> （chart包没有官网那么全），</p><p>还有<strong>微软的chart 仓库地址</strong>：<a href="http://mirror.azure.cn/kubernetes/charts/">http://mirror.azure.cn/kubernetes/charts/</a> （官网有的，它大多都有, <strong>推荐使用</strong>）</p><pre><code class="highlight bash">$ helm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts$ helm repo add ms http://mirror.azure.cn/kubernetes/charts/$ helm repo update$ helm search repo ms<span class="comment"># 显示 微软 提供的 Apache Helm chart 的默认配置文件（values.yaml）内容</span>$ helm show values ms/redis<span class="comment"># 在 Kubernetes 集群中安装 Bitnami 提供的 Apache Helm chart，并自动生成一个唯一的 release 名称</span>$ helm install ms/redis --generate-name</code></pre><h3 id="4-3-Chart-安装资源顺序"><a href="#4-3-Chart-安装资源顺序" class="headerlink" title="4.3 Chart 安装资源顺序"></a>4.3 Chart 安装资源顺序</h3><pre><code class="highlight plaintext">Namespace&gt;NetworkPolicy&gt;ResourceQuota&gt;LimitRange&gt;PodSecurityPolicy&gt;PodDisruptionBudget&gt;ServiceAccount&gt;Secret&gt;SecretList&gt;ConfigMap&gt;StorageClassPersistentVolume&gt;PersistentVolumeClaim&gt;CustomResourceDefinition&gt;ClusterRoleClusterRoleList&gt;ClusterRoleBinding&gt;ClusterRoleBindingList&gt;Role&gt;RoleListRoleBinding&gt;RoleBindingList&gt;Service&gt;DaemonSet&gt;Pod&gt;ReplicationController&gt;ReplicaSet&gt;Deployment&gt;HorizontalPodAutoscaler&gt;StatefulSet&gt;Job&gt;CronJob&gt;Ingress&gt;APIService</code></pre><!--Helm 客户端不会等到所有资源都运行才退出。许多 charts 需要大小超过 600M 的 Docker 镜像，可能需要很长时间才能安装到集群中。--><h3 id="4-4-安装过程中有两种方式传递配置数据"><a href="#4-4-安装过程中有两种方式传递配置数据" class="headerlink" title="4.4 安装过程中有两种方式传递配置数据"></a>4.4 安装过程中有两种方式传递配置数据</h3><ul><li><code>--values</code> (或 <code>-f</code>)：使用 YAML 文件覆盖配置。可以指定多次，优先使用最右边的文件</li><li><code>--set</code>：通过命令行的方式对指定项进行覆盖</li></ul><p>如果同时使用两种方式，则 <code>--set</code> 中的值会被合并到 <code>--values</code> 中，但是 <code>--set</code> 中的值优先级更高。在<code>--set</code> 中覆盖的内容会被被保存在 ConfigMap 中。可以通过 <code>helm get values &lt;release-name&gt;</code> 来查看指定 release 中 <code>--set</code> 设置的值。也可以通过运行 <code>helm upgrade</code> 并指定 <code>--reset-values</code> 字段来清除 <code>--set</code> 中设置的值</p><h4 id="4-4-1-set-的格式和限制"><a href="#4-4-1-set-的格式和限制" class="headerlink" title="4.4.1 --set 的格式和限制"></a>4.4.1 <code>--set</code> 的格式和限制</h4><p><code>--set</code> 选项使用0或多个 name&#x2F;value 对。最简单的用法类似于： <code>--set name=value</code> ，等价于如下 YAML 格式：</p><pre><code class="highlight yaml"><span class="attr">name:</span> <span class="string">value</span></code></pre><p>多个值使用逗号分割，因此 <code>--set a=b,c=d</code> 的 YAML 表示是：</p><pre><code class="highlight yaml"><span class="attr">a:</span> <span class="string">b</span><span class="attr">c:</span> <span class="string">d</span></code></pre><p>支持更复杂的表达式。例如，<code>--set outer.inner=value</code> 被转换成了：</p><pre><code class="highlight yaml"><span class="attr">outer:</span>  <span class="attr">inner:</span> <span class="string">value</span></code></pre><p>列表使用花括号（<code>&#123;&#125;</code>）来表示。例如，<code>--set name=&#123;a, b, c&#125;</code> 被转换成了：</p><pre><code class="highlight yaml"><span class="attr">name:</span>  <span class="bullet">-</span> <span class="string">a</span>  <span class="bullet">-</span> <span class="string">b</span>  <span class="bullet">-</span> <span class="string">c</span></code></pre><p>某些 name&#x2F;key 可以设置为 <code>null</code> 或者空数组，例如  <code>--set name=[],a=null</code>  </p><pre><code class="highlight yaml"><span class="attr">name:</span> []<span class="attr">a:</span> <span class="literal">null</span></code></pre><p>从 2.5.0 版本开始，可以使用数组下标的语法来访问列表中的元素。例如 <code>--set servers[0].port=80</code> 就变成了：</p><pre><code class="highlight yaml"><span class="attr">servers:</span>  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></code></pre><p>多个值也可以通过这种方式来设置。<code>--set servers[0].port=80,servers[0].host=example</code> 变成了：</p><pre><code class="highlight yaml"><span class="attr">servers:</span>  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>    <span class="attr">host:</span> <span class="string">example</span></code></pre><p>如果需要在 <code>--set</code> 中使用特殊字符，你可以使用反斜线来进行转义；<code>--set name=value1\,value2</code> 就变成了：</p><pre><code class="highlight yaml"><span class="attr">name:</span> <span class="string">&quot;value1,value2&quot;</span></code></pre><p>–set nodeSelector.”kubernetes.io&#x2F;role”&#x3D;master</p><pre><code class="highlight yaml"><span class="attr">nodeSelector:</span>  <span class="attr">kubernetes.io/role:</span> <span class="string">master</span></code></pre><h3 id="4-5-安装、升级、回滚时的有用选项"><a href="#4-5-安装、升级、回滚时的有用选项" class="headerlink" title="4.5 安装、升级、回滚时的有用选项"></a>4.5 安装、升级、回滚时的有用选项</h3><ul><li>–timeout：一个 Go duration 类型的值， 用来表示等待 Kubernetes 命令完成的超时时间，默认值为 5m0s。such as “300ms”, “-1.5h” or “2h45m”. Valid time units are “ns”, “us” (or “µs”), “ms”, “s”, “m”, “h”。</li><li>–wait：表示必须要等到所有的 Pods 都处于 ready 状态，PVC 都被绑定，Deployments 都至少拥有最小 ready 状态 Pods 个数（Desired 减去 maxUnavailable ），并且 Services 都具有 IP 地址（如果是 LoadBalancer， 则为 Ingress ），才会标记该 release 为成功。最长等待时间由 –timeout 值指定。如果达到超时时间，release 将被标记为 FAILED。注意：当 Deployment 的 replicas 被设置为1，但其滚动升级策略中的 maxUnavailable 没有被设置为0时，–wait 将返回就绪，因为已经满足了最小 ready Pod 数</li><li><code>--no-hooks</code>：不运行当前命令的钩子，即为安装此 chart 时的已定义的安装前或者安装后的动作</li><li>–recreate-pods：（仅适用于 <code>upgrade</code> 和 <code>rollback</code>）：这个参数会导致重建所有的 Pod（deployment 中的 Pod 除外）。（在 Helm 3 中已被废弃）</li></ul><h2 id="5-卸载Chart应用"><a href="#5-卸载Chart应用" class="headerlink" title="5. 卸载Chart应用"></a>5. 卸载Chart应用</h2><p>卸载一个已安装的 Release 实例</p><pre><code class="highlight bash"><span class="comment"># 查看当前运行的 release </span>$ helm listNAME            NAMESPACEREVISIONUPDATED                                STATUS  CHART         APP VERSIONchart-1750577584default  1       2025-06-22 15:33:04.623161176 +0800 CSTdeployedapache-11.3.162.4.63<span class="comment"># 卸载应用</span>$ helm uninstall chart-1750577584<span class="comment"># 再次查看 release ，应用已卸载</span>$ helm listNAMENAMESPACEREVISIONUPDATEDSTATUSCHARTAPP VERSION</code></pre><h1 id="六、案例-安装Nginx"><a href="#六、案例-安装Nginx" class="headerlink" title="六、案例-安装Nginx"></a>六、案例-安装Nginx</h1><h2 id="1-下载-Nginx-Chart-安装包"><a href="#1-下载-Nginx-Chart-安装包" class="headerlink" title="1. 下载 Nginx Chart 安装包"></a>1. 下载 Nginx Chart 安装包</h2><pre><code class="highlight bash"><span class="comment"># 搜索要下载的 Chart 版本</span>$ helm search repo bitnami/nginx --versionsNAME                            CHART VERSIONAPP VERSIONDESCRIPTION                                       bitnami/nginx                   20.1.3       1.28.0     NGINX Open Source is a web server that can be a...bitnami/nginx                   20.1.2       1.28.0     NGINX Open Source is a web server that can be a...<span class="comment"># 使用 pull 拉取Chart， 失败</span>$ helm pull bitnami/nginx --version 20.1.3Error: failed to <span class="keyword">do</span> request: Head <span class="string">&quot;https://registry-1.docker.io/v2/bitnamicharts/nginx/manifests/20.1.3&quot;</span>: dial tcp 199.59.148.202:443: i/o <span class="built_in">timeout</span><span class="comment"># 使用 wget 命令下载安装包，成功</span>$ wget https://charts.bitnami.com/bitnami/nginx-20.1.3.tgz</code></pre><h2 id="2-安装-Nginx-Chart"><a href="#2-安装-Nginx-Chart" class="headerlink" title="2. 安装 Nginx Chart"></a>2. 安装 Nginx Chart</h2><pre><code class="highlight bash"><span class="comment"># 执行命令，根据Chart压缩包创建实例，生成 svc、deployment、pod</span>$ helm install my-nginx nginx-20.1.3.tgz \--<span class="built_in">set</span> service.type=NodePort \--<span class="built_in">set</span> service.nodePorts.http=30003 \    --namespace default --create-namespace        <span class="comment"># --set service.type=NodePort  手动设置Service类型为NodePort,模板文件 values.yaml 中默认为 LoadBalance</span><span class="comment"># --set service.nodePorts.http=30003 手动设置NodePort端口，模板文件中默认为空，自动生成端口</span><span class="comment"># --namespace default --create-namespace 指定 Pod、SVC、Deployment 所在的工作空间，不存在则创建</span></code></pre><p> 由于模板文件中的镜像默认都从 docker hub 下载，国内存在网络限制，在执行下面的命令前，先将镜像下载下来，导入到集群的 Node 节点。</p><p>关于如下下载外网镜像，参考这篇博客：<a href="https://georgechan95.github.io/blog/b01d5c62.html">Docker配置网络代理实现外网镜像下载</a></p><p><strong>查看结果：</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 Release</span>$ helm listNAME    NAMESPACEREVISIONUPDATED                                STATUS  CHART       APP VERSIONmy-nginxdefault  1       2025-06-22 16:57:21.546051288 +0800 CSTdeployednginx-20.1.31.28.0<span class="comment"># 查看 SVC</span>$ kubectl get svc -o wideNAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE   SELECTORmy-nginx     NodePort    10.105.158.179   &lt;none&gt;        80:30003/TCP,443:31458/TCP   12m   app.kubernetes.io/instance=my-nginx,app.kubernetes.io/name=nginx<span class="comment"># 查看 Deploy</span>$ kubectl get deploy -o wideNAME       READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                                        SELECTORmy-nginx   1/1     1            1           12m   nginx        docker.io/bitnami/nginx:1.28.0-debian-12-r3   app.kubernetes.io/instance=my-nginx,app.kubernetes.io/name=nginx<span class="comment"># 查看 Pod</span>$ kubectl get pod -o wideNAME                        READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESmy-nginx-58cf875b74-tp8ct   1/1     Running   0          13m   172.16.58.223   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>浏览器访问 SVC</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/22/20250622-171105.png" alt="Helm 安装 Nginx"></p><h2 id="3-更新Chart"><a href="#3-更新Chart" class="headerlink" title="3. 更新Chart"></a>3. 更新Chart</h2><pre><code class="highlight bash"><span class="comment"># 更新 Realse ， 将Pod 副本数从 1 变成 3</span>$ helm upgrade my-nginx nginx-20.1.3.tgz --<span class="built_in">set</span> replicaCount=3<span class="comment"># 再次查看 Realse</span><span class="comment"># 版本号REVISION 更新了，从 1 变成了 2</span>$ helm listNAME    NAMESPACEREVISIONUPDATED                                STATUS  CHART       APP VERSIONmy-nginxdefault  2       2025-06-22 17:24:48.296877982 +0800 CSTdeployednginx-20.1.31.28.0<span class="comment"># 查看 Pod</span>$ kubectl get pods -o wideNAME                        READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESmy-nginx-58cf875b74-gszn4   1/1     Running   0          2m54s   172.16.58.208   k8s-node02   &lt;none&gt;           &lt;none&gt;my-nginx-58cf875b74-q76q6   1/1     Running   0          17s     172.16.58.210   k8s-node02   &lt;none&gt;           &lt;none&gt;my-nginx-58cf875b74-zgbtp   1/1     Running   0          2m42s   172.16.85.193   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h2 id="4-卸载Nginx"><a href="#4-卸载Nginx" class="headerlink" title="4. 卸载Nginx"></a>4. 卸载Nginx</h2><pre><code class="highlight bash">$ helm uninstall my-nginx</code></pre><h1 id="七、Helm-常用命令"><a href="#七、Helm-常用命令" class="headerlink" title="七、Helm 常用命令"></a>七、Helm 常用命令</h1><h2 id="1-Repository-相关命令"><a href="#1-Repository-相关命令" class="headerlink" title="1. Repository 相关命令"></a>1. Repository 相关命令</h2><p>见本文 <code>helm的使用 / Helm 仓库管理</code></p><h2 id="2-Chart-相关命令"><a href="#2-Chart-相关命令" class="headerlink" title="2. Chart 相关命令"></a>2. Chart 相关命令</h2><h3 id="2-1-helm-create"><a href="#2-1-helm-create" class="headerlink" title="2.1 helm create"></a>2.1 <code>helm create</code></h3><p>该命令用于创建一个新的 Chart 目录：</p><pre><code class="highlight bash">$ helm create demoCreating demo</code></pre><p>创建的 Chart 目录是下面这样的结构：</p><pre><code class="highlight bash">$ tree demodemo├── Chart.yaml├── charts├── templates│   ├── NOTES.txt│   ├── _helpers.tpl│   ├── deployment.yaml│   ├── hpa.yaml│   ├── ingress.yaml│   ├── service.yaml│   ├── serviceaccount.yaml│   └── tests│       └── test-connection.yaml└── values.yaml3 directories, 10 files</code></pre><h3 id="2-2-helm-package"><a href="#2-2-helm-package" class="headerlink" title="2.2 helm package"></a>2.2 <code>helm package</code></h3><p>将 Chart 目录（必须包含 <code>Chart.yaml</code> 文件）打包成 Chart 归档文件：</p><pre><code class="highlight bash">$ helm package demoSuccessfully packaged chart and saved it to: /opt/k8s/10/demo-0.1.0.tgz</code></pre><h3 id="2-3-helm-lint"><a href="#2-3-helm-lint" class="headerlink" title="2.3 helm lint"></a>2.3 <code>helm lint</code></h3><p>验证 Chart 是否存在问题：</p><pre><code class="highlight bash">$ helm lint ./demo==&gt; Linting ./demo[INFO] Chart.yaml: icon is recommended1 chart(s) linted, 0 chart(s) failed</code></pre><h3 id="2-4-helm-show"><a href="#2-4-helm-show" class="headerlink" title="2.4 helm show"></a>2.4 <code>helm show</code></h3><p>该命令用于显示 Chart 的基本信息，包括：</p><ul><li><code>helm show chart</code> - 显示 Chart 定义，实际上就是 <code>Chart.yaml</code> 文件的内容</li><li><code>helm show crds</code> - 显示 Chart 的 CRD</li><li><code>helm show readme</code> - 显示 Chart 的 <code>README.md</code> 文件中的内容</li><li><code>helm show values</code> - 显示 Chart 的 <code>values.yaml</code> 文件中的内容</li><li><code>helm show all</code> - 显示 Chart 的所有信息</li></ul><pre><code class="highlight bash">$ helm show chart demo-0.1.0.tgz$ helm show values demo-0.1.0.tgz</code></pre><h3 id="2-5-helm-pull"><a href="#2-5-helm-pull" class="headerlink" title="2.5 helm pull"></a>2.5 <code>helm pull</code></h3><p>从仓库中将 Chart 安装包下载到本地：</p><pre><code class="highlight bash">$ helm pull bitnami/nginx$ <span class="built_in">ls</span>nginx-13.2.23.tgz</code></pre><h3 id="2-6-helm-push"><a href="#2-6-helm-push" class="headerlink" title="2.6 helm push"></a>2.6 <code>helm push</code></h3><p>将 Chart 安装包推送到远程仓库：</p><pre><code class="highlight bash">$ helm push [chart] [remote]</code></pre><h2 id="3-Release-相关命令"><a href="#3-Release-相关命令" class="headerlink" title="3. Release 相关命令"></a>3. Release 相关命令</h2><h3 id="3-1-helm-install"><a href="#3-1-helm-install" class="headerlink" title="3.1 helm install"></a>3.1 <code>helm install</code></h3><p>将 Chart 安装到 Kubernetes 集群：</p><pre><code class="highlight bash">$ helm install my-nginx bitnami/nginx --version 20.1.3</code></pre><p>安装时可以通过 <code>--set</code> 选项修改配置参数：</p><pre><code class="highlight bash">$ helm install my-nginx bitnami/nginx --version 20.1.3 \    --<span class="built_in">set</span> service.ports.http=8080</code></pre><p>其中 <code>bitnami/nginx</code> 是要安装的 Chart，这种写法是最常用的格式，被称为 <code>Chart 引用</code>，一共有六种不同的 Chart 写法：</p><ul><li>通过 Chart 引用：<code>helm install my-nginx bitnami/nginx</code></li><li>通过 Chart 包：<code>helm install my-nginx ./nginx-13.2.23.tgz</code></li><li>通过未打包的 Chart 目录：<code>helm install my-nginx ./nginx</code></li><li>通过 Chart URL：<code>helm install my-nginx https://example.com/charts/nginx-13.2.23.tgz</code></li><li>通过仓库 URL 和 Chart 引用：<code>helm install --repo https://example.com/charts/ my-nginx nginx</code></li><li>通过 OCI 注册中心：<code>helm install my-nginx --version 13.2.23 oci://example.com/charts/nginx</code></li></ul><h3 id="3-2-helm-list"><a href="#3-2-helm-list" class="headerlink" title="3.2 helm list"></a>3.2 <code>helm list</code></h3><p>显示某个命名空间下的所有 Release：</p><pre><code class="highlight bash">$ helm list --namespace defaultNAME    NAMESPACEREVISIONUPDATED                                STATUS  CHART       APP VERSIONmy-nginxdefault  1       2025-06-22 17:50:26.273823328 +0800 CSTdeployednginx-20.1.31.28.0</code></pre><h3 id="3-3-helm-status"><a href="#3-3-helm-status" class="headerlink" title="3.3 helm status"></a>3.3 <code>helm status</code></h3><p>查询某个 Release 的状态信息：</p><pre><code class="highlight bash">$ helm status my-nginxNAME: my-nginxLAST DEPLOYED: Sun Jun 22 17:50:26 2025NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:CHART NAME: nginxCHART VERSION: 20.1.3APP VERSION: 1.28.0Did you know there are enterprise versions of the Bitnami catalog? For enhanced secure software supply chain features, unlimited pulls from Docker, LTS support, or application customization, see Bitnami Premium or Tanzu Application Catalog. See https://www.arrow.com/globalecs/na/vendors/bitnami <span class="keyword">for</span> more information.** Please be patient <span class="keyword">while</span> the chart is being deployed **NGINX can be accessed through the following DNS name from within your cluster:    my-nginx.default.svc.cluster.local (port 80)</code></pre><h3 id="3-4-helm-get"><a href="#3-4-helm-get" class="headerlink" title="3.4 helm get"></a>3.4 <code>helm get</code></h3><p>获取某个 Release 的扩展信息，包括：</p><ul><li><code>helm get hooks</code> - 获取 Release 关联的钩子信息</li><li><code>helm get manifest</code> - 获取 Release 的清单信息</li><li><code>helm get notes</code> - 获取 Release 的注释</li><li><code>helm get values</code> - 获取 Release 的 values 文件</li><li><code>helm get all</code> - 获取 Release 的所有信息</li></ul><pre><code class="highlight bash">$ helm get values my-nginxUSER-SUPPLIED VALUES:service:  nodePorts:    http: 30003  <span class="built_in">type</span>: NodePort</code></pre><h3 id="3-5-helm-upgrade"><a href="#3-5-helm-upgrade" class="headerlink" title="3.5 helm upgrade"></a>3.5 <code>helm upgrade</code></h3><p>将 Release 升级到新版本的 Chart：</p><pre><code class="highlight bash">$ helm upgrade my-nginx ./nginxRelease <span class="string">&quot;my-nginx&quot;</span> has been upgraded. Happy Helming!</code></pre><p>升级时可以通过 <code>--set</code> 选项修改配置参数：</p><pre><code class="highlight bash">$ helm upgrade my-nginx ./nginx \    --<span class="built_in">set</span> service.ports.http=8080</code></pre><h3 id="3-6-helm-history"><a href="#3-6-helm-history" class="headerlink" title="3.6 helm history"></a>3.6 <code>helm history</code></h3><p>查看某个 Release 的版本记录：</p><pre><code class="highlight bash">$ helm <span class="built_in">history</span> my-nginxREVISIONUPDATED                 STATUS    CHART       APP VERSIONDESCRIPTION     1       Sun Jun 22 17:50:26 2025supersedednginx-20.1.31.28.0     Install complete2       Sun Jun 22 17:55:25 2025deployed  nginx-20.1.31.28.0     Upgrade complete</code></pre><h3 id="3-7-helm-rollback"><a href="#3-7-helm-rollback" class="headerlink" title="3.7 helm rollback"></a>3.7 <code>helm rollback</code></h3><p>将 Release 回滚到某个版本：</p><pre><code class="highlight bash">$ helm rollback my-nginx 1Rollback was a success! Happy Helming!</code></pre><p>再查看版本记录可以看到多了一条记录：</p><pre><code class="highlight bash">$ helm <span class="built_in">history</span> my-nginxREVISIONUPDATED                 STATUS    CHART       APP VERSIONDESCRIPTION     1       Sun Jun 22 17:50:26 2025supersedednginx-20.1.31.28.0     Install complete2       Sun Jun 22 17:55:25 2025supersedednginx-20.1.31.28.0     Upgrade complete3       Sun Jun 22 17:56:48 2025deployed  nginx-20.1.31.28.0     Rollback to 1</code></pre><h3 id="3-8-helm-uninstall"><a href="#3-8-helm-uninstall" class="headerlink" title="3.8 helm uninstall"></a>3.8 <code>helm uninstall</code></h3><p>卸载 Release：</p><pre><code class="highlight bash">$ helm uninstall my-nginxrelease <span class="string">&quot;my-nginx&quot;</span> uninstalled</code></pre><h1 id="八、搭建-Chart-私有仓库"><a href="#八、搭建-Chart-私有仓库" class="headerlink" title="八、搭建 Chart 私有仓库"></a>八、搭建 Chart 私有仓库</h1><h2 id="1-创建一个-HTTP-Server-作为chart仓库"><a href="#1-创建一个-HTTP-Server-作为chart仓库" class="headerlink" title="1. 创建一个 HTTP Server 作为chart仓库"></a>1. 创建一个 HTTP Server 作为chart仓库</h2><pre><code class="highlight bash"><span class="comment"># 创建挂载目录</span>$ <span class="built_in">mkdir</span> -p /var/www/charts<span class="comment"># 拉取 httpd 镜像</span>$ docker pull httpd:2.4.63<span class="comment"># 启动容器</span>$ docker run -d -p 8899:80 --name=my-chart --restart=always -v /var/www:/usr/local/apache2/htdocs httpd:2.4.63</code></pre><p>浏览器访问 Chart 仓库</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/22/20250622-181042.png" alt="Chart 私有仓库"></p><p><strong>需要注意:</strong></p><ul><li><em>宿主机的&#x2F;var&#x2F;www目录需要存在,且有一定的访问权限。</em></li><li><em>容器内部的 httpd 配置不要和宿主机 8081 端口冲突。</em></li><li><em>可以添加-v宿主机日志目录:容器日志目录来收集日志。</em></li><li><em>可以设置时区等参数对容器进行定制。</em></li></ul><h2 id="2-Helm-Chart上传到私有仓库"><a href="#2-Helm-Chart上传到私有仓库" class="headerlink" title="2. Helm Chart上传到私有仓库"></a>2. Helm Chart上传到私有仓库</h2><p>这里为了测试方便，将前面案例中所使用的Chart 安装包：nginx-20.1.3.tgz 解压，然后打包上传到 Chart 私有仓库</p><pre><code class="highlight bash"><span class="comment"># 1.将 nginx 目录打包成tgz文件,用于发布。</span>$ helm package nginx/Successfully packaged chart and saved it to: /opt/software/nginx-20.1.3.tgz<span class="comment"># 2.创建文件夹作为chart仓库目录。</span>$ <span class="built_in">mkdir</span> myrepo<span class="comment"># 3. 将打包好的chart移动到仓库目录下。</span>$ <span class="built_in">mv</span> nginx-20.1.3.tgz myrepo/<span class="comment"># 4. 在myrepo目录生成index.yaml索引文件,用于仓库查询。</span>$ helm repo index myrepo --url http://192.168.6.203:8899/charts<span class="comment"># 5. 将index和chart复制到Web服务器目录下,提供下载。</span>$ <span class="built_in">cd</span> myrepo/$ scp index.yaml nginx-20.1.3.tgz /var/www/charts<span class="comment"># 6. 在本地Helm中添加这个chart仓库源,名为newrepo。</span>$ helm repo add newrepo http://192.168.6.203:8899/charts<span class="comment"># 7. 列出已知的仓库列表,确保newrepo添加成功。</span>$ helm repo list<span class="comment"># 8. 更新本地缓存的仓库index文件。</span>$ helm repo update<span class="comment"># 9. 在newrepo仓库中搜索 nginx 是否可用。</span>$ helm search repo newrepo/nginxNAME         CHART VERSIONAPP VERSIONDESCRIPTION                                       newrepo/nginx20.1.3       1.28.0     NGINX Open Source is a web server that can be a...</code></pre><h2 id="3-测试私有仓库"><a href="#3-测试私有仓库" class="headerlink" title="3. 测试私有仓库"></a>3. 测试私有仓库</h2><pre><code class="highlight bash"><span class="comment"># 使用本地仓库的Chart 安装Nginx</span>$ helm install newrepo/nginx --generate-name<span class="comment"># 查看Release</span>$ helm listNAME            NAMESPACEREVISIONUPDATED                                STATUS  CHART       APP VERSIONnginx-1750588514default  1       2025-06-22 18:35:14.639466957 +0800 CSTdeployednginx-20.1.31.28.0</code></pre><p>浏览器查看私有仓库</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/22/20250622-183645.png" alt="私有Chart仓库"></p><h1 id="九、自定义Chart"><a href="#九、自定义Chart" class="headerlink" title="九、自定义Chart"></a>九、自定义Chart</h1><h2 id="1-创建模板"><a href="#1-创建模板" class="headerlink" title="1. 创建模板"></a>1. 创建模板</h2><pre><code class="highlight bash"><span class="comment"># 创建chart模板</span>$ helm create myapp<span class="comment"># 查看模板目录结构</span>$ tree myapp/myapp/├── Chart.yaml├── charts├── templates│   ├── NOTES.txt│   ├── _helpers.tpl│   ├── deployment.yaml│   ├── hpa.yaml│   ├── ingress.yaml│   ├── service.yaml│   ├── serviceaccount.yaml│   └── tests│       └── test-connection.yaml└── values.yaml</code></pre><h2 id="2-删除多余的文件"><a href="#2-删除多余的文件" class="headerlink" title="2. 删除多余的文件"></a>2. 删除多余的文件</h2><pre><code class="highlight bash"><span class="comment"># 当前案例比较简单，暂时用不到这些文件，先删除</span>$ <span class="built_in">rm</span> -rf templates/_helpers.tpl templates/hpa.yaml templates/ingress.yaml templates/serviceaccount.yaml templates/tests/test-connection.yaml templates/NOTES.txt</code></pre><h2 id="3-service-yaml"><a href="#3-service-yaml" class="headerlink" title="3. service.yaml"></a>3. service.yaml</h2><pre><code class="highlight yaml"><span class="string">$</span> <span class="string">vim</span> <span class="string">service.yaml</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">myapp-test</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp-svc</span><span class="attr">spec:</span>  <span class="comment"># Service 类型，从 values.yaml 文件取</span>  <span class="attr">type:</span> &#123;&#123; <span class="string">.Values.service.type</span> &#125;&#125;  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> &#123;&#123; <span class="string">.Values.service.port</span> &#125;&#125; <span class="comment"># Service 端口，从 values.yaml 文件取</span>      <span class="attr">targetPort:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">name:</span> <span class="number">80</span><span class="number">-80</span>      <span class="attr">nodePort:</span> <span class="number">30003</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">myapp-test</span></code></pre><h2 id="4-deployment-yaml"><a href="#4-deployment-yaml" class="headerlink" title="4. deployment.yaml"></a>4. deployment.yaml</h2><pre><code class="highlight yaml"><span class="string">$</span> <span class="string">vim</span> <span class="string">deployment.yaml</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp-deploy</span>  <span class="attr">name:</span> <span class="string">myapp-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> &#123;&#123; <span class="string">.Values.replicaCount</span> &#125;&#125; <span class="comment"># Pod副本数，从 values.yaml 文件取</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp-test</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp-test</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> &#123;&#123; <span class="string">.Values.image.pullPolicy</span> &#125;&#125; <span class="comment"># 镜像拉取策略，从 values.yaml 文件取</span></code></pre><h2 id="5-values-yaml"><a href="#5-values-yaml" class="headerlink" title="5. values.yaml"></a>5. values.yaml</h2><pre><code class="highlight yaml"><span class="string">$</span> <span class="string">vim</span> <span class="string">values.yaml</span><span class="comment"># Pod副本数</span><span class="attr">replicaCount:</span> <span class="number">1</span><span class="attr">image:</span>  <span class="comment"># 镜像拉取策略</span>  <span class="attr">pullPolicy:</span> <span class="string">IfNotPresent</span><span class="attr">service:</span>  <span class="comment"># Service类型</span>  <span class="attr">type:</span> <span class="string">NodePort</span>  <span class="comment"># service端口</span>  <span class="attr">port:</span> <span class="number">80</span></code></pre><h2 id="6-Chart-yaml"><a href="#6-Chart-yaml" class="headerlink" title="6. Chart.yaml"></a>6. Chart.yaml</h2><pre><code class="highlight yaml"><span class="string">$</span> <span class="string">vim</span> <span class="string">Chart.yaml</span><span class="attr">apiVersion:</span> <span class="string">v2</span><span class="attr">name:</span> <span class="string">myapp</span><span class="attr">description:</span> <span class="string">A</span> <span class="string">Helm</span> <span class="string">chart</span> <span class="string">for</span> <span class="string">Kubernetes</span><span class="comment"># A chart can be either an &#x27;application&#x27; or a &#x27;library&#x27; chart.</span><span class="comment">#</span><span class="comment"># Application charts are a collection of templates that can be packaged into versioned archives</span><span class="comment"># to be deployed.</span><span class="comment">#</span><span class="comment"># Library charts provide useful utilities or functions for the chart developer. They&#x27;re included as</span><span class="comment"># a dependency of application charts to inject those utilities and functions into the rendering</span><span class="comment"># pipeline. Library charts do not define any templates and therefore cannot be deployed.</span><span class="attr">type:</span> <span class="string">application</span><span class="comment"># This is the chart version. This version number should be incremented each time you make changes</span><span class="comment"># to the chart and its templates, including the app version.</span><span class="comment"># Versions are expected to follow Semantic Versioning (https://semver.org/)</span><span class="attr">version:</span> <span class="number">0.1</span><span class="number">.0</span><span class="comment"># This is the version number of the application being deployed. This version number should be</span><span class="comment"># incremented each time you make changes to the application. Versions are not expected to</span><span class="comment"># follow Semantic Versioning. They should reflect the version the application is using.</span><span class="comment"># It is recommended to use it with quotes.</span><span class="attr">appVersion:</span> <span class="string">&quot;1.16.0&quot;</span></code></pre><h2 id="7-发布部署"><a href="#7-发布部署" class="headerlink" title="7. 发布部署"></a>7. 发布部署</h2><pre><code class="highlight bash">$ helm install myapp myapp/NAME: myappLAST DEPLOYED: Wed Jun 25 12:57:58 2025NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: None<span class="comment"># 查看部署的 Release</span>$ helm listNAME NAMESPACEREVISIONUPDATED                               STATUS  CHART      APP VERSIONmyappdefault  1       2025-06-25 12:57:58.07309733 +0800 CSTdeployedmyapp-0.1.01.16.0<span class="comment"># 查看 Service</span>$ kubectl get svc -o wideNAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE     SELECTORkubernetes   ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP        57d     &lt;none&gt;myapp-test   NodePort    10.108.147.243   &lt;none&gt;        80:30003/TCP   3m41s   app=myapp-test<span class="comment"># 查看 Deployment</span>$ kubectl get deploy -o wideNAME           READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES                     SELECTORmyapp-deploy   1/1     1            1           4m58s   myapp        wangyanglinux/myapp:v1.0   app=myapp-test<span class="comment"># 查看 Pod</span>$ kubectl get pod -o wideNAME                            READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESmyapp-deploy-7ff87cfb6c-nfff4   1/1     Running   0          5m29s   172.16.58.227   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>浏览器访问 Service</p><p><a href="http://192.168.6.139:30003/">http://192.168.6.139:30003/</a></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/25/20250625-130414.png" alt="访问自定Chart"></p><h2 id="8-打包Chart，发布到私有仓库"><a href="#8-打包Chart，发布到私有仓库" class="headerlink" title="8. 打包Chart，发布到私有仓库"></a>8. 打包Chart，发布到私有仓库</h2><pre><code class="highlight bash"><span class="comment"># 1.将 myapp 目录打包成tgz文件,用于发布。</span>$ helm package myapp/Successfully packaged chart and saved it to: /opt/k8s/10/myapp-0.1.0.tgz<span class="comment"># 2.将打包好的压缩包移动到创建的私有仓库目录中（本文第八段有说明）</span>$ <span class="built_in">mv</span> myapp-0.1.0.tgz /opt/software/myrepo/<span class="comment"># 3. 在myrepo目录生成index.yaml索引文件,用于仓库查询。</span>$ $ helm repo index /opt/software/myrepo/ --url http://192.168.6.203:8899/charts<span class="comment"># 4. 将index和chart复制到Web服务器目录下,提供下载。</span>$ <span class="built_in">cd</span> /opt/software/myrepo/$ scp -r ./* root@192.168.6.203:/var/www/charts/<span class="comment"># 5. 在本地Helm中添加这个chart仓库源,名为newrepo。</span>$ helm repo add newrepo http://192.168.6.203:8899/charts<span class="comment"># 6. 列出已知的仓库列表,确保newrepo添加成功。</span>$ helm repo list<span class="comment"># 7. 更新本地缓存的仓库index文件。</span>$ helm repo update<span class="comment"># 8. 在newrepo仓库中搜索 nginx 是否可用。</span>$ helm search repo newrepo/myappNAME         CHART VERSIONAPP VERSIONDESCRIPTION                newrepo/myapp0.1.0        1.16.0     A Helm chart <span class="keyword">for</span> Kubernetes<span class="comment"># 9. 从私有仓库拉取chart，并安装到服务器</span>$ helm install newrepo/myapp --generate-nameNAME: myapp-1750829238LAST DEPLOYED: Wed Jun 25 13:27:18 2025NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: None<span class="comment"># 10. 卸载 Chart</span>$ helm uninstall myapp-1750829238release <span class="string">&quot;myapp-1750829238&quot;</span> uninstalled</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、引言&quot;&gt;&lt;a href=&quot;#一、引言&quot; class=&quot;headerlink&quot; title=&quot;一、引言&quot;&gt;&lt;/a&gt;一、引言&lt;/h1&gt;&lt;p&gt;没有使用 Helm 之前，在 Kubernetes 部署应用，我们要依次部署 deployment、service 等，步骤</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>009-Kubernetes 集群安全机制</title>
    <link href="https://georgechan95.github.io/blog/424f1119.html"/>
    <id>https://georgechan95.github.io/blog/424f1119.html</id>
    <published>2025-06-14T01:18:00.000Z</published>
    <updated>2025-06-19T02:30:21.990Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、K8S认证与授权"><a href="#一、K8S认证与授权" class="headerlink" title="一、K8S认证与授权"></a>一、K8S认证与授权</h1><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/14/20250614-104507.png" alt="K8S认证与授权"></p><h2 id="1-认证「Authentication」"><a href="#1-认证「Authentication」" class="headerlink" title="1. 认证「Authentication」"></a>1. 认证「Authentication」</h2><p>认证有如下几种方式：</p><p>1、HTTP Token认证：通过一个Token来识别合法用户。</p><p>HTTP Token的认证是用一个很长的特殊编码方式的并且难以被模仿的字符串来表达客户的一种方式。每一个Token对应一个用户名，存储在API Server能访问的文件中。当客户端发起API调用请求时，需要在HTTP Header里放入Token。</p><p>2、HTTP Base认证：通过用户名+密码的方式认证</p><p>用户名:密码用 base64 算法进行编码后的字符串放在 HTTP Request 中的 Heather Authorization 域里发送给服务端，服务端收到后进行解码，获取用户名和密码。</p><p>3、最严格的 HTTPS 证书认证：基于 CA 根证书签名的客户端身份认证方式</p><h2 id="2-授权「Authorization」"><a href="#2-授权「Authorization」" class="headerlink" title="2. 授权「Authorization」"></a>2. 授权「Authorization」</h2><p>认证只是确认通信的双方都是可信的，可以相互通信。而授权是确定请求方有哪些资源的权限。API Server 目前支持如下几种授权策略（通过 API Server 的启动参数  <code>--authorization-mode</code> 设置，在控制平面节点上，路径：<code>/etc/kubernetes/manifests/kube-apiserver.yaml</code> ）</p><ul><li><code>AlwaysDeny</code> ：表示拒绝所有请求。仅用于测试</li><li><code>AlwaysAllow</code> ：表示允许所有请求。如果有集群不需要授权流程，则可以采用该策略</li><li><code>Node</code> ：节点授权是一种特殊用途的授权模式，专门授权由 kubelet 发出的 API 请求</li><li><code>Webhook</code> ：是一种 HTTP 回调模式，允许使用远程 REST 端点管理授权</li><li><code>ABAC</code>：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制</li><li><strong>RBAC：基于角色的访问控制，默认使用该规则</strong></li></ul><h1 id="二、RBAC授权模式"><a href="#二、RBAC授权模式" class="headerlink" title="二、RBAC授权模式"></a>二、RBAC授权模式</h1><p>RBAC（Role-Based Access Control）基于角色的访问控制，在Kubernetes 1.5 中引入，现为默认标准。相对其他访问控制方式，拥有如下优势：</p><ul><li>对集群中的资源和非资源均拥有完整的覆盖</li><li>整个RBAC完全由几个 API 对象完成，同其他API对象一样，可以用 kubectl 或 API 进行操作</li><li>可以在运行时进行操作，无需重启API Server</li></ul><h2 id="1-RBAC-API-类型"><a href="#1-RBAC-API-类型" class="headerlink" title="1. RBAC API 类型"></a>1. RBAC API 类型</h2><p>RBAC API 所声明的四种顶级类型【Role、ClusterRole、RoleBinding 和 ClusterRoleBinding】。用户可以像与其他 API 资源交互一样，（通过 kubectl API 调用等方式）与这些资源交互。</p><h3 id="1-1-Role-和-ClusterRole"><a href="#1-1-Role-和-ClusterRole" class="headerlink" title="1.1 Role 和 ClusterRole"></a>1.1 Role 和 ClusterRole</h3><p>在 RBAC API 中，一个角色包含一组相关权限的规则。权限是纯粹累加的（不存在拒绝某操作的规则），即只能给权限累加，不存在给了XX权限，然后去掉XX01权限的情况。角色可以用 Role 来定义到某个命名空间（namespace）上， 或者用 ClusterRole 来定义到整个集群作用域（所有namespace）。</p><p>一个 Role 只可以用来对某一命名空间中的资源赋予访问权限。</p><p><strong>Role示例：</strong></p><p>定义到名称为 “default” 的命名空间，可以用来授予对该命名空间中的 Pods 的读取权限：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Role</span>  <span class="comment"># 资源类型为：角色</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-reader</span> <span class="comment"># 角色的名称</span>  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment"># 角色所属的命名空间</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 指定 API 组，空字符串 &quot;&quot; 表示 Kubernetes 核心 API 组（例如 pods、services 等资源属于核心组）。</span>    <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>] <span class="comment"># 指定规则适用的资源类型，这里是 pods（即 Pod 资源）。</span>    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>] <span class="comment"># 指定角色对Pod资源允许的操作，获取、监控、列出</span></code></pre><p>ClusterRole 可以授予的权限和 Role 相同，但是因为 ClusterRole 属于集群范围，所以它也可以授予以下访问权限：</p><ul><li>集群范围资源 （比如 nodes访问）</li><li>非资源端点（比如 “&#x2F;healthz” 访问）</li><li>跨命名空间访问的有名称空间作用域的资源（如 Pods），比如运行命令<code>kubectl get pods --all-namespaces</code> 时需要此能力</li></ul><p><strong>ClusterRole示例</strong></p><p>可用来对某特定命名空间下的 Secrets 的读取操作授权，或者跨所有名称空间执行授权（取决于它是如何绑定的）：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">ClusterRole</span> <span class="comment"># 资源类型</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">secret-reader</span> <span class="comment"># 集群角色的名称</span>  <span class="comment"># 此处的 &quot;namespace&quot; 被省略掉是因为 ClusterRoles 是没有命名空间的。</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 指定 API 组，空字符串 &quot;&quot; 表示 Kubernetes 核心 API 组（secrets 属于核心组）。</span>    <span class="attr">resources:</span> [<span class="string">&quot;secrets&quot;</span>] <span class="comment"># 指定规则适用的规则类型</span>    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]</code></pre><h3 id="1-2-RoleBinding-和-ClusterRoleBinding"><a href="#1-2-RoleBinding-和-ClusterRoleBinding" class="headerlink" title="1.2 RoleBinding 和 ClusterRoleBinding"></a>1.2 RoleBinding 和 ClusterRoleBinding</h3><p>角色绑定（RoleBinding）是将角色中定义的权限赋予一个用户或者一组用户。 它包含若干主体【subjects】（users、groups 或 service accounts）的列表和对这些主体所获得的角色引用。</p><p><strong>可以使用 RoleBinding 在指定的命名空间中执行授权，或者在集群范围的命名空间使用 ClusterRoleBinding 来执行授权。</strong></p><p>一个 RoleBinding 可以引用同一的命名空间中的 Role。</p><p><strong>RoleBinding示例</strong></p><p>将 “pod-reader” 角色授予在 “default” 命名空间中的用户 “jane”； 这样，用户 “jane” 就具有了读取 “default” 命名空间中 pods 的权限。</p><p>在下面的例子中，角色绑定使用 roleRef 将用户 “jane” 绑定到前文创建的角色 Role，其名称是 pod-reader。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">RoleBinding</span> <span class="comment"># 定义资源的类型为 RoleBinding，用于将一个角色（Role 或 ClusterRole）绑定到用户、组或服务账户</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">read-pods</span> <span class="comment"># RoleBinding 的名称</span>  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment"># 此 RoleBinding 作用于 default 命名空间，仅对该命名空间内的资源生效</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span> <span class="comment"># 主体类型为用户</span>    <span class="attr">name:</span> <span class="string">jane</span> <span class="comment"># 名称大小写敏感</span>    <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span> <span class="comment"># 指定主体所属的 API 组</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">Role</span> <span class="comment"># 引用的角色类型为 Role（命名空间级别的角色），而不是 ClusterRole（集群级别的角色）</span>  <span class="attr">name:</span> <span class="string">pod-reader</span> <span class="comment"># 引用的角色名称为 pod-reader，需要在 default 命名空间中存在</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span> <span class="comment"># 角色所属的 API 组</span></code></pre><p>roleRef 里的内容决定了实际创建绑定的方法。kind 可以是 Role 或 ClusterRole，name 是你要引用的 Role 或 ClusterRole 的名称。</p><p>RoleBinding 也可以引用 ClusterRole，这可以允许管理者在 整个集群中定义一组通用的角色，然后在多个命名空间中重用它们。（集群角色与角色绑定进行匹配后，就对集群角色进行了降维，绑定的用户将只能操作命名空间下的资源。）</p><p><strong>RoleBinding示例2</strong></p><p>下面的例子，RoleBinding 引用的是 ClusterRole， “dave” （subjects区分大小写）将只可以读取在”development” 名称空间（ RoleBinding 的命名空间）中的”secrets” 。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">RoleBinding</span> <span class="comment"># 定义资源的类型为 RoleBinding，用于将一个角色（Role 或 ClusterRole）绑定到用户、组或服务账户</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">read-secrets</span> <span class="comment"># RoleBinding 的名称</span>  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment"># 此 RoleBinding 作用于 default 命名空间，仅对该命名空间内的资源生效</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span> <span class="comment"># 主体类型为用户</span>    <span class="attr">name:</span> <span class="string">dave</span> <span class="comment"># 名称大小写敏感</span>    <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span> <span class="comment"># 指定主体所属的 API 组</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span> <span class="comment"># 引用的角色类型为 ClusterRole（集群级别的角色）,集群角色降维到命名空间</span>  <span class="attr">name:</span> <span class="string">secret-reader</span> <span class="comment"># 引用的角色名称为 secret-reader，需要在 default 命名空间中存在</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span> <span class="comment"># 角色所属的 API 组</span></code></pre><p>最后，ClusterRoleBinding 可用来在集群级别并对所有命名空间执行授权。</p><p><strong>ClusterRoleBinding示例</strong></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="comment"># 这个集群角色绑定允许 &quot;manager&quot; 组中的任何用户读取任意命名空间中 &quot;secrets&quot;s</span><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">read-secrets-global</span> <span class="comment"># 集群角色的名称</span>  <span class="comment"># 不需要定义 namespace，对所有名称空间有效</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span> <span class="comment"># 绑定的主体类型为 Group</span>    <span class="attr">name:</span> <span class="string">manager</span> <span class="comment"># 名称区分大小写</span>    <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span>  <span class="attr">name:</span> <span class="string">secret-reader</span> <span class="comment"># 集群角色的名称，需要在集群中存在</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre><p><strong>当我们创建binding后，则不能修改binding所引用的Role或ClusterRole。尝试修改会导致验证错误；如果要改变binding的roleRef，那么应该删除该binding对象并且创建一个新的用来替换原来的。</strong></p><h2 id="2-资源引用-Referring-to-resources"><a href="#2-资源引用-Referring-to-resources" class="headerlink" title="2. 资源引用 Referring to resources"></a>2. 资源引用 Referring to resources</h2><p>Kubernetes集群内一些资源一般以其名称字符串来表示，这些字符串一般会在 API 的 URL 地址中出现；同时某些资源也会包含子资源，例如 pod 的 logs 资源就属于pods的子资源，API 中 URL 样例如下：</p><pre><code class="highlight plaintext">GET /api/v1/namespaces/&#123;namespace&#125;/pods/&#123;name&#125;/log</code></pre><p>在这种情况下，”pods” 是有名称空间的资源，而 “log” 是 pods 的子资源。在 RBAC 角色中，使用 “&#x2F;” 分隔资源和子资源。</p><p>允许一个主体（subject）要同时读取 pods 和 pod logs，你可以这么写：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">pod-and-pod-logs-reader</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>, <span class="string">&quot;pods/log&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>]</code></pre><p>对于某些请求，也可以通过 resourceNames 列表按名称引用资源。</p><p>例如：在指定时，可以将请求类型限制到资源的单个实例。限制只可以 “get” 和 “update” 到单个configmap，则可以这么写：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">Role</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">configmap-updater</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># 核心 API 组</span>    <span class="attr">resources:</span> [<span class="string">&quot;configmaps&quot;</span>] <span class="comment"># 可操作的资源类型为 Configmap</span>    <span class="attr">resourceNames:</span> [<span class="string">&quot;configmap-demo&quot;</span>] <span class="comment"># 可操作的具体是哪个 ConfigMap</span>    <span class="attr">verbs:</span> [<span class="string">&quot;update&quot;</span>, <span class="string">&quot;get&quot;</span>] <span class="comment"># 定义操作类型，只能 更新和读取</span></code></pre><p>需要注意的是，create 请求不能被 resourceName 限制，因为在鉴权时还不知道对象名称。 另一个例外是 deletecollection。</p><h2 id="3-主体引用-Referring-to-subjects"><a href="#3-主体引用-Referring-to-subjects" class="headerlink" title="3. 主体引用 Referring to subjects"></a>3. 主体引用 Referring to subjects</h2><p>RoleBinding 或 ClusterRoleBinding 绑定一个 role 到主体（subjects）。主体（subjects）可以是 groups，users 或 ServiceAccounts 。</p><p> Kubernetes将用户名表示为字符串。这些可以是：普通名称，比如 “alice” ；邮件风格的名字，比如 “<a href="mailto:&#98;&#x6f;&#98;&#x40;&#x65;&#120;&#x61;&#109;&#x70;&#108;&#x65;&#x2e;&#99;&#111;&#109;">&#98;&#x6f;&#98;&#x40;&#x65;&#120;&#x61;&#109;&#x70;&#108;&#x65;&#x2e;&#99;&#111;&#109;</a>” ；或表示为字符串的数字用户id。</p><p><strong>注意：前缀  <code>system:</code>  是保留给 Kubernetes 系统使用的，因此应该确保不会出现名称以 <code>system:</code>  开头的用户或组。除了这个特殊的前缀，RBAC 授权系统不要求用户名使用任何格式。</strong></p><p><strong>ServiceAccounts具有前缀为 <code>system:serviceaccount:</code>  的名称，属于具有前缀为 system:serviceaccounts: 的名称的组。</strong></p><h3 id="RoleBinding的示例"><a href="#RoleBinding的示例" class="headerlink" title="RoleBinding的示例"></a>RoleBinding的示例</h3><p>下面的示例只是展示 RoleBinding 中 subjects 的部分。</p><ul><li><p>用户的名称为 “<a href="mailto:&#97;&#x6c;&#x69;&#99;&#x65;&#x40;&#x65;&#x78;&#x61;&#x6d;&#112;&#108;&#x65;&#x2e;&#99;&#x6f;&#x6d;">&#97;&#x6c;&#x69;&#99;&#x65;&#x40;&#x65;&#x78;&#x61;&#x6d;&#112;&#108;&#x65;&#x2e;&#99;&#x6f;&#x6d;</a>” ：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span>  <span class="attr">name:</span> <span class="string">&quot;alice@example.com&quot;</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>组的名称为 “frontend-admins” ：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">&quot;frontend-admins&quot;</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>默认service account在 kube-system 命名空间中：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span>  <span class="attr">name:</span> <span class="string">default</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span></code></pre><ul><li><p>查看 default 命名空间下的 ServiceAccount</p><pre><code class="highlight bash">$ kubectl get saNAME      SECRETS   AGEdefault   0         77d</code></pre></li></ul></li><li><p>在名称为 “qa” 命名空间中所有的服务账号：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:serviceaccounts:qa</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>在任意名称空间的所有service accounts：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:serviceaccounts</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>所有认证过的用户（版本 1.5+）：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:authenticated</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>所有未认证的用户（版本 1.5+）：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:unauthenticated</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li><li><p>所有用户 （版本 1.5+）：</p><pre><code class="highlight yaml"><span class="attr">subjects:</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:authenticated</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span>  <span class="attr">name:</span> <span class="string">system:unauthenticated</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre></li></ul><h1 id="三、案例实操"><a href="#三、案例实操" class="headerlink" title="三、案例实操"></a>三、案例实操</h1><p><strong>创建一个用户只能管理 dev 名字空间</strong></p><h2 id="1-创建命名空间"><a href="#1-创建命名空间" class="headerlink" title="1. 创建命名空间"></a>1. 创建命名空间</h2><pre><code class="highlight bash"><span class="comment"># 创建 dev 名称空间</span>$ kubectl create namespace devnamespace/dev created<span class="comment"># 查看名称空间</span>$ kubectl get ns | grep devdev                Active   24s</code></pre><h2 id="2-创建证书"><a href="#2-创建证书" class="headerlink" title="2. 创建证书"></a>2. 创建证书</h2><p>在 master 节点操作，将证书创建在 <code>/etc/kubernetes/pki</code> 目录下， 该目录存放了 k8s 集群证书。</p><h3 id="2-1-创建证书描述文件"><a href="#2-1-创建证书描述文件" class="headerlink" title="2.1 创建证书描述文件"></a>2.1 创建证书描述文件</h3><pre><code class="highlight bash">vim /etc/kubernetes/pki/devuser.json<span class="comment"># 内容如下：</span>&#123;  <span class="string">&quot;CN&quot;</span>: <span class="string">&quot;devuser&quot;</span>,  <span class="string">&quot;hosts&quot;</span>: [],  <span class="string">&quot;key&quot;</span>: &#123;    <span class="string">&quot;algo&quot;</span>: <span class="string">&quot;rsa&quot;</span>,    <span class="string">&quot;size&quot;</span>: 2048  &#125;,  <span class="string">&quot;names&quot;</span>: [    &#123;      <span class="string">&quot;C&quot;</span>: <span class="string">&quot;CN&quot;</span>,      <span class="string">&quot;ST&quot;</span>: <span class="string">&quot;BeiJing&quot;</span>,      <span class="string">&quot;L&quot;</span>: <span class="string">&quot;BeiJing&quot;</span>,      <span class="string">&quot;O&quot;</span>: <span class="string">&quot;k8s&quot;</span>,      <span class="string">&quot;OU&quot;</span>: <span class="string">&quot;System&quot;</span>    &#125;  ]&#125;</code></pre><h3 id="2-2-下载证书生成工具"><a href="#2-2-下载证书生成工具" class="headerlink" title="2.2 下载证书生成工具"></a>2.2 下载证书生成工具</h3><pre><code class="highlight bash"><span class="comment"># 工具一</span>wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64<span class="built_in">mv</span> cfssl_linux-amd64 /usr/local/bin/cfssl<span class="comment"># 工具二</span>wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64<span class="built_in">mv</span> cfssljson_linux-amd64 /usr/local/bin/cfssljson<span class="comment"># 工具三</span>wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64<span class="built_in">mv</span> cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo<span class="comment"># 给生成工具授权</span><span class="built_in">chmod</span> a+x /usr/local/bin/cfssl*</code></pre><h3 id="2-3-生成证书"><a href="#2-3-生成证书" class="headerlink" title="2.3 生成证书"></a>2.3 生成证书</h3><pre><code class="highlight bash"><span class="comment"># 使用 cfssl 工具生成 Kubernetes 客户端证书，通常用于用户身份验证（如通过 kubectl 访问集群）</span>cfssl gencert -ca=/etc/kubernetes/pki/ca.crt -ca-key=/etc/kubernetes/pki/ca.key -profile=kubernetes /etc/kubernetes/pki/devuser.json | cfssljson -bare devuser</code></pre><p>命令解析：</p><ul><li>-ca&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt ： 指定 CA 的公钥证书文件路径</li><li>-ca-key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.key ：指定 CA 的私钥文件路径</li><li>-profile&#x3D;kubernetes ： 指定证书的配置文件中的一个 profile（指定导出的证书给谁用，这里就是 kubernetes ）</li><li>&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;devuser.json : 指定生成证书的 CSR（证书签名请求）配置文件路径。</li><li>cfssljson -bare devuser : cfssljson 是 cfssl 的辅助工具，用于解析 JSON 格式的证书数据并生成 PEM 格式的证书和私钥文件</li><li>-bare : 指定输出文件的基本名称，不添加默认后缀（如 -cert 或 -key）<ul><li>作用：生成的证书和私钥文件将以 devuser.pem（证书）和 devuser-key.pem（私钥）的形式保存，而不是 devuser-cert.pem 或 devuser-key.pem。</li></ul></li><li>devuser : 指定输出文件的前缀名称<ul><li>作用：生成的证书文件命名为 devuser.pem，私钥文件命名为 devuser-key.pem。</li></ul></li></ul><h3 id="2-4-声明环境变量：-Kubernetes-API-服务器的地址"><a href="#2-4-声明环境变量：-Kubernetes-API-服务器的地址" class="headerlink" title="2.4 声明环境变量： Kubernetes API 服务器的地址"></a>2.4 声明环境变量： Kubernetes API 服务器的地址</h3><pre><code class="highlight bash"><span class="comment"># 192.168.6.139 是master节点 API 服务器所在的主机地址</span><span class="comment"># 端口：6443 是 Kubernetes API 服务器的默认端口，用于处理客户端请求（如 kubectl）</span><span class="built_in">export</span> KUBE_APISERVER=<span class="string">&quot;https://192.168.6.139:6443&quot;</span></code></pre><h3 id="2-5-设置集群参数"><a href="#2-5-设置集群参数" class="headerlink" title="2.5 设置集群参数"></a>2.5 设置集群参数</h3><p>在指定的 kubeconfig 文件中添加或更新一个名为 kubernetes 的集群配置，包含 API 服务器地址和 CA 证书等信息</p><pre><code class="highlight bash">kubectl config set-cluster kubernetes \--certificate-authority=/etc/kubernetes/pki/ca.crt \--embed-certs=<span class="literal">true</span> \--server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \--kubeconfig=/etc/kubernetes/pki/devuser.kubeconfig</code></pre><p><strong>命令解析：</strong></p><ul><li><p><code>config set-cluster kubernetes</code> </p><p>设置或更新一个集群条目，kubernetes 是当前集群的名称，可以通过命令： </p><pre><code class="highlight bash">$ kubectl config get-clusters</code></pre><p>查看</p></li><li><p>–certificate-authority&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</p><p>指定集群的 CA（证书颁发机构）证书文件路径</p></li><li><p>–embed-certs&#x3D;true</p><p>指定是否将 CA 证书的内容嵌入到 kubeconfig 文件中，嵌入证书后，kubeconfig 文件是自包含的，无需依赖外部 ca.crt 文件，方便分发（如给开发人员使用）。</p></li><li><p>–server&#x3D;${KUBE_APISERVER}</p><p>指定 Kubernetes API 服务器的地址。</p></li><li><p>–kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;devuser.kubeconfig</p><p>将设置的内容保存到 devuser.kubeconfig 文件中，如果文件不存在，命令会创建新的 devuser.kubeconfig 文件。</p></li></ul><p>命令执行成功后，可以通过命令：</p><pre><code class="highlight bash">$ <span class="built_in">cat</span> /etc/kubernetes/pki/devuser.kubeconfig</code></pre><p>查看文件内容</p><h3 id="2-6-设置客户端认证参数"><a href="#2-6-设置客户端认证参数" class="headerlink" title="2.6 设置客户端认证参数"></a>2.6 设置客户端认证参数</h3><p>配置 Kubernetes 的 kubeconfig 文件，为用户 devuser 添加凭证信息</p><pre><code class="highlight bash">kubectl config set-credentials devuser \--client-certificate=/etc/kubernetes/pki/devuser.pem \--client-key=/etc/kubernetes/pki/devuser-key.pem \--embed-certs=<span class="literal">true</span> \--kubeconfig=/etc/kubernetes/pki/devuser.kubeconfig</code></pre><p><strong>命令解析：</strong></p><ul><li><p>config set-credentials</p><p>用于在 kubeconfig 文件中设置或更新用户（user）凭证信息</p></li><li><p>–client-certificate&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;devuser.pem</p><p>指定客户端证书文件的路径。此证书用于向 Kubernetes API 服务器证明用户 devuser 的身份。证书的 CN（Common Name，通常为 devuser）和 O（Organization，例如 system:masters）会影响 RBAC 权限。</p></li><li><p>–client-key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;devuser-key.pem</p><p>指定客户端私钥文件的路径，私钥用于签名客户端请求，与证书一起完成 TLS 身份验证。</p></li><li><p>–embed-certs&#x3D;true</p><p>指定是否将证书和私钥的内容嵌入到 kubeconfig 文件中。true 表示将 devuser.pem 和 devuser-key.pem 的内容（Base64 编码的 PEM 数据）写入 kubeconfig，而不是仅引用文件路径。</p></li><li><p>–kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;devuser.kubeconfig</p><p>将设置的内容保存到 devuser.kubeconfig 文件中</p></li></ul><h3 id="2-7-设置上下文参数"><a href="#2-7-设置上下文参数" class="headerlink" title="2.7 设置上下文参数"></a>2.7 设置上下文参数</h3><p>配置 Kubernetes 的 kubeconfig 文件，为用户 devuser 设置一个上下文（context），以便访问特定的集群和命名空间。</p><pre><code class="highlight bash">kubectl config set-context kubernetes \--cluster=kubernetes \--user=devuser \--namespace=dev \--kubeconfig=/etc/kubernetes/pki/devuser.kubeconfig</code></pre><p><strong>命令解析：</strong></p><ul><li><p>config set-context</p><p>kubectl config set-context 用于在 kubeconfig 文件中设置或更新一个上下文（context）。上下文定义了用户、集群和命名空间的组合，用于指定 kubectl 的操作环境。</p><p>kubernetes 是上下文的名称（可以自定义）。</p></li><li><p>–cluster&#x3D;kubernetes</p><p>指定上下文关联的集群名称，注意：集群名称必须与 kubeconfig 文件中 clusters 部分的 name 字段匹配</p></li><li><p>–user&#x3D;devuser</p><p>指定上下文关联的用户名称，注意：用户名称必须与 kubeconfig 文件中 users 部分的 name 字段匹配。</p></li><li><p>–namespace&#x3D;dev</p><p>指定上下文的默认命名空间，如果不指定 –namespace，默认使用 default 命名空间。确保 dev 命名空间存在（可用 kubectl get namespaces 检查）。</p></li></ul><h3 id="2-8-给用户授权"><a href="#2-8-给用户授权" class="headerlink" title="2.8 给用户授权"></a>2.8 给用户授权</h3><pre><code class="highlight bash">kubectl create rolebinding devuser-admin-binding --clusterrole=admin --user=devuser --namespace=dev<span class="comment"># 命令转换成资源清单</span>$ kubectl create rolebinding devuser-admin-binding --clusterrole=admin --user=devuser --namespace=dev --dry-run -o yamlW0614 17:49:28.687292 2342317 helpers.go:704] --dry-run is deprecated and can be replaced with --dry-run=client.apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata:  creationTimestamp: null  name: devuser-admin-binding  namespace: devroleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: adminsubjects:- apiGroup: rbac.authorization.k8s.io  kind: User  name: devuser</code></pre><p>命令解析：创建角色绑定（devuser-admin-binding），绑定到集群角色admin(系统默认存在的角色)， 绑定用户 devuser, 绑定到名称空间 dev。</p><h3 id="2-9-设置默认上下文"><a href="#2-9-设置默认上下文" class="headerlink" title="2.9 设置默认上下文"></a>2.9 设置默认上下文</h3><p>这条命令使用 kubectl config use-context 设置 Kubernetes 的 kubeconfig 文件中的默认上下文，以便 kubectl 使用指定的上下文进行操作。</p><p>在 devuser.kubeconfig 文件中将 current-context 设置为 kubernetes，使后续的 kubectl 命令使用该上下文的配置。</p><pre><code class="highlight bash">kubectl config use-context kubernetes --kubeconfig=/etc/kubernetes/pki/devuser.kubeconfig</code></pre><p>确保 kubectl 默认使用正确的集群（kubernetes）、用户（devuser）和命名空间（dev），无需每次手动指定 –kubeconfig 或 –context。</p><h3 id="2-10-测试-root-用户使用-devuser-kubeconfig-文件操作集群"><a href="#2-10-测试-root-用户使用-devuser-kubeconfig-文件操作集群" class="headerlink" title="2.10 测试 root 用户使用 devuser.kubeconfig 文件操作集群"></a>2.10 测试 root 用户使用 devuser.kubeconfig 文件操作集群</h3><pre><code class="highlight bash"><span class="comment"># 1. 将原有的kubeconfig 文件移除</span>$ <span class="built_in">mv</span> /root/.kube/config /root/<span class="comment"># 2. 将新建的 devuser.kubeconfig 放到 root 目录下</span>$ <span class="built_in">cp</span> -a /etc/kubernetes/pki/devuser.kubeconfig /root/.kube/config<span class="comment"># kubelet 命令</span>$ kubectl get podsNo resources found <span class="keyword">in</span> dev namespace.<span class="comment"># 创建 deploy</span>$ kubectl create deployment dev-deploy --image=wangyanglinux/myapp:v1.0deployment.apps/dev-deploy created$ kubectl get podsNAME                         READY   STATUS    RESTARTS   AGEdev-deploy-d7448d978-c8jkm   1/1     Running   0          10s</code></pre><h2 id="3-将-linux-用户与-k8s-用户绑定（非必须）"><a href="#3-将-linux-用户与-k8s-用户绑定（非必须）" class="headerlink" title="3. 将 linux 用户与 k8s 用户绑定（非必须）"></a>3. 将 linux 用户与 k8s 用户绑定（非必须）</h2><h3 id="3-1-创建-linux-用户"><a href="#3-1-创建-linux-用户" class="headerlink" title="3.1 创建 linux 用户"></a>3.1 创建 linux 用户</h3><pre><code class="highlight bash">$ useradd dev$ passwd dev</code></pre><h3 id="3-2-将-devuser-kubeconfig-文件放到新建用户的-家目录-中"><a href="#3-2-将-devuser-kubeconfig-文件放到新建用户的-家目录-中" class="headerlink" title="3.2 将 devuser.kubeconfig 文件放到新建用户的 家目录 中"></a>3.2 将 devuser.kubeconfig 文件放到新建用户的 家目录 中</h3><pre><code class="highlight bash"><span class="comment"># 创建文件目录</span>$ <span class="built_in">mkdir</span> /home/dev/.kube<span class="comment"># 将devuser.kubeconfig文件放到 dev 用户的家目录中</span>$ <span class="built_in">mv</span> /etc/kubernetes/pki/devuser.kubeconfig /home/dev/.kube/config<span class="comment"># 文件授权</span><span class="built_in">chown</span> -R dev:dev /home/dev/.kube</code></pre><h3 id="3-3-shell-使用-dev-用户登录测试"><a href="#3-3-shell-使用-dev-用户登录测试" class="headerlink" title="3.3 shell 使用 dev 用户登录测试"></a>3.3 shell 使用 dev 用户登录测试</h3><pre><code class="highlight bash">[dev@k8s-master01 ~]$ kubectl get podsNAME                         READY   STATUS    RESTARTS   AGEdev-deploy-d7448d978-c8jkm   1/1     Running   0          8m32s</code></pre><h1 id="四、补充"><a href="#四、补充" class="headerlink" title="四、补充"></a>四、补充</h1><h2 id="1-资源与角色类型的匹配"><a href="#1-资源与角色类型的匹配" class="headerlink" title="1. 资源与角色类型的匹配"></a>1. 资源与角色类型的匹配</h2><table><thead><tr><th>访问的资源</th><th>使用的角色类型</th><th>使用的绑定类型</th></tr></thead><tbody><tr><td>集群级别的资源（Namespace、Node、ClusterRole、ClusterRoleBinding、PersistentVolume (PV)、StorageClass 等）</td><td>ClusterRole</td><td>ClusterRoleBinding</td></tr><tr><td>非资源型URL（&#x2F;api、&#x2F;apis、&#x2F;apis&#x2F;<group>&#x2F;<version> 、&#x2F;healthz、&#x2F;livez、&#x2F;readyz、&#x2F;logs、&#x2F;metrics 等）</td><td>ClusterRole</td><td>ClusterRoleBinding</td></tr><tr><td>在任何命名空间中的资源（和跨所有命名空间的资源）</td><td>ClusterRole</td><td>ClusterRoleBinding</td></tr><tr><td>在具体命名空间中的资源（在多个命名空间中重用这个相同的ClusterRole)</td><td>ClusterRole</td><td>RoleBinding</td></tr><tr><td>在具体命名空间中的资源(Role必须在每个命名空间中定义好），例如：Pod、Deployment、ReplicaSet、StatefulSet、DaemonSet、Job、CronJob、Service、Ingress、ConfigMap、Secret、ServiceAccount、Role、RoleBinding、PersistentVolumeClaim (PVC)、NetworkPolicy、HorizontalPodAutoscaler (HPA)、Event、LimitRange、ResourceQuota</td><td>Role</td><td>RoleBinding</td></tr></tbody></table><h2 id="2-常见的预定义角色"><a href="#2-常见的预定义角色" class="headerlink" title="2. 常见的预定义角色"></a>2. 常见的预定义角色</h2><ul><li>view（ClusterRole）<ul><li>允许读取一个命名空间中的大多数资源， 除了Role、 RoleBinding 和 Secret</li></ul></li><li>edit（ClusterRole）<ul><li>允许读取和修改 Secret。 但是，它也不允许查看或修改 Role 和 RoleBinding, 这是为了防止权限扩散。</li></ul></li><li>admin（ClusterRole）<ul><li>一个命名空间中的资源的完全控制权是由 admin ClusterRole 赋予的。 有这个 ClusterRole 的主体可以读取和修改命名空间中的任何资源， 除了 ResourceQuota 和命名空间资源本身。 edit 和 admin ClusterRole  之间的主要区别是能否在命名空间中查看和修改 Role 和 RoleBinding。</li></ul></li><li>cluster-admin（ClusterRole）<ul><li>通过将 cluster-admin ClusterRole 赋给主体， 主体可以获得 Kubernetes 集群完全控制的权限</li></ul></li></ul><h1 id="五、准入控制"><a href="#五、准入控制" class="headerlink" title="五、准入控制"></a>五、准入控制</h1><p>Kubernetes（k8s）中的准入控制（Admission Control）是 Kubernetes API 服务器在处理请求（创建、更新、删除等）时，用于验证和修改资源对象的机制。它是 Kubernetes 扩展性和安全性的重要组成部分，允许管理员在资源对象被持久化到 etcd 之前对其进行检查或修改。准入控制通过准入控制器（Admission Controllers）和准入 webhook 实现。</p><h2 id="1-什么是准入控制？"><a href="#1-什么是准入控制？" class="headerlink" title="1. 什么是准入控制？"></a>1. 什么是准入控制？</h2><p>准入控制是 Kubernetes API 服务器在处理 API 请求时的一个阶段，位于 <strong>认证（Authentication）和授权（Authorization）</strong> 之后，但在对象持久化到 etcd 之前。它的主要作用是：</p><ul><li>验证（Validation）：检查请求是否符合特定的规则或策略（如资源配额、命名规范）。</li><li>修改（Mutation）：动态修改请求的资源对象（如自动添加标签、设置默认值）。</li><li>防止不符合策略的资源被创建或更新，确保集群的安全性、合规性和一致性。</li></ul><p>准入控制分为两个阶段：</p><ul><li>Mutating 阶段：修改资源对象的阶段，允许对请求的资源进行更改。</li><li>Validating 阶段：验证资源对象的阶段，决定是否允许请求通过。</li></ul><h2 id="2-准入控制的类型"><a href="#2-准入控制的类型" class="headerlink" title="2. 准入控制的类型"></a>2. 准入控制的类型</h2><p>Kubernetes 提供了两类准入控制机制：</p><h3 id="2-1-内置准入控制器（Admission-Controllers）"><a href="#2-1-内置准入控制器（Admission-Controllers）" class="headerlink" title="2.1 内置准入控制器（Admission Controllers）"></a>2.1 内置准入控制器（Admission Controllers）</h3><p>Kubernetes 提供了一系列内置的准入控制器，这些控制器是 API 服务器的静态插件，可以通过 API 服务器的启动参数 –enable-admission-plugins 启用或禁用。每个控制器负责特定的验证或修改逻辑。</p><p>常见的内置准入控制器包括：</p><ul><li><strong>NamespaceLifecycle</strong>：确保删除中的命名空间不能创建新资源，防止已删除命名空间的资源被访问。</li><li><strong>LimitRange</strong>：强制执行命名空间中的资源限制（如 CPU、内存）。</li><li><strong>ResourceQuota</strong>：确保命名空间的资源使用量不超过配额。</li><li><strong>PodSecurity</strong>：强制执行 Pod 安全策略（如限制特权容器）。</li><li><strong>DefaultStorageClass</strong>：为没有指定存储类的 PVC 设置默认 StorageClass。</li><li><strong>DefaultTolerationSeconds</strong>：为 Pod 设置默认的容忍时间（taint toleration）。</li><li><strong>MutatingAdmissionWebhook</strong>：调用外部 Mutating Webhook。</li><li><strong>ValidatingAdmissionWebhook</strong>：调用外部 Validating Webhook。</li><li><strong>NodeRestriction</strong>：限制 kubelet 能修改的资源，增强节点安全性。</li><li><strong>ImagePolicyWebhook</strong>：通过外部 webhook 验证容器镜像。</li><li><strong>ServiceAccount</strong>：自动为 Pod 分配 ServiceAccount。</li><li><strong>AlwaysPullImages</strong>：强制容器镜像总是拉取最新版本。</li></ul><h3 id="2-2-准入-Webhook（Admission-Webhooks）"><a href="#2-2-准入-Webhook（Admission-Webhooks）" class="headerlink" title="2.2 准入 Webhook（Admission Webhooks）"></a>2.2 准入 Webhook（Admission Webhooks）</h3><p>准入 webhook 是一种动态扩展机制，允许用户定义自定义的准入控制逻辑。Webhook 是一个外部 HTTP 服务，API 服务器会向其发送请求以验证或修改资源对象。Webhook 分为两类：</p><ul><li><strong>MutatingAdmissionWebhook</strong>：修改资源对象，例如添加标签、注入 sidecar 容器（如 Istio 的代理容器）。</li><li><strong>ValidatingAdmissionWebhook</strong>：验证资源对象，拒绝不符合策略的请求。</li></ul><p>Webhook 通常用于实现复杂的自定义逻辑，例如：</p><ul><li>强制执行组织的安全策略。</li><li>自动注入配置或 sidecar。</li><li>检查资源是否符合特定的合规性要求。</li></ul><h3 id="2-3-新引入的准入策略（Kubernetes-1-30-）"><a href="#2-3-新引入的准入策略（Kubernetes-1-30-）" class="headerlink" title="2.3 新引入的准入策略（Kubernetes 1.30+）"></a>2.3 新引入的准入策略（Kubernetes 1.30+）</h3><p>从 Kubernetes 1.30 开始，引入了 <code>ValidatingAdmissionPolicy</code> 和 <code>MutatingAdmissionPolicy</code>，作为一种更结构化的准入控制方式。这些策略使用 Common Expression Language (CEL) 定义规则，相比 webhook 更轻量且无需外部服务。它们是集群级别的资源，适合定义简单的验证或修改逻辑。</p><h2 id="3-准入控制的工作流程"><a href="#3-准入控制的工作流程" class="headerlink" title="3. 准入控制的工作流程"></a>3. 准入控制的工作流程</h2><p>当 Kubernetes API 服务器收到一个请求（如创建 Pod），会按照以下步骤处理：</p><ol><li><strong>认证（Authentication）</strong>：验证请求者的身份。</li><li><strong>授权（Authorization）</strong>：检查请求者是否有权限执行操作。</li><li><strong>准入控制（Admission Control）</strong>：<ul><li><strong>Mutating 阶段</strong>：按顺序调用所有启用的 Mutating 准入控制器和 Mutating Webhook，修改资源对象。</li><li><strong>Validating 阶段</strong>：按顺序调用所有启用的 Validating 准入控制器和 Validating Webhook，验证资源对象。</li><li>如果任一 Validating 控制器拒绝请求，请求失败并返回错误。</li></ul></li><li><strong>持久化</strong>：通过验证的资源对象被写入 etcd。</li></ol><p><strong>注意</strong>：</p><ul><li>Mutating 阶段先于 Validating 阶段执行。</li><li>准入控制器的执行顺序由 –enable-admission-plugins 参数指定。</li><li>如果任何 Validating 控制器返回拒绝，请求会被阻止。</li></ul><h2 id="4-常见用例"><a href="#4-常见用例" class="headerlink" title="4. 常见用例"></a>4. 常见用例</h2><p>准入控制在 Kubernetes 中有广泛的应用场景，包括但不限于：</p><ul><li><p><strong>安全性</strong>：</p><ul><li><p>使用 PodSecurity 限制特权容器或不安全的配置。</p></li><li><p>使用 ImagePolicyWebhook 限制 Pod 只能使用来自可信镜像仓库的镜像。</p></li></ul></li><li><p><strong>资源管理</strong>：</p><ul><li><p>使用 ResourceQuota 和 LimitRange 限制命名空间的资源使用。</p></li><li><p>使用 DefaultStorageClass 为 PVC 自动分配存储类。</p></li></ul></li><li><p><strong>自动化配置</strong>：</p><ul><li><p>使用 Mutating Webhook 自动为 Pod 注入 sidecar 容器（如日志收集代理）。</p></li><li><p>自动为资源添加标签或注释。</p></li></ul></li><li><p><strong>合规性</strong>：</p><ul><li><p>使用 Validating Webhook 确保资源符合组织策略（如强制使用特定的标签或命名规范）。</p></li><li><p>使用 ValidatingAdmissionPolicy 检查 Pod 是否满足安全合规要求。</p></li></ul></li><li><p><strong>服务网格</strong>：</p><ul><li>Istio 或 Linkerd 使用 Mutating Webhook 自动为 Pod 注入代理容器。</li></ul></li></ul><p>参考链接：</p><blockquote><p><a href="https://www.cnblogs.com/zhanglianghhh/p/14128332.html">https://www.cnblogs.com/zhanglianghhh/p/14128332.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、K8S认证与授权&quot;&gt;&lt;a href=&quot;#一、K8S认证与授权&quot; class=&quot;headerlink&quot; title=&quot;一、K8S认证与授权&quot;&gt;&lt;/a&gt;一、K8S认证与授权&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubuserconten</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>008-Kubernetes 调度器</title>
    <link href="https://georgechan95.github.io/blog/f2285a2d.html"/>
    <id>https://georgechan95.github.io/blog/f2285a2d.html</id>
    <published>2025-06-02T06:40:00.000Z</published>
    <updated>2025-06-10T12:03:14.864Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、kube-scheduler-详解"><a href="#一、kube-scheduler-详解" class="headerlink" title="一、kube-scheduler 详解"></a>一、kube-scheduler 详解</h1><h2 id="1-kube-scheduler-调度概述"><a href="#1-kube-scheduler-调度概述" class="headerlink" title="1. kube-scheduler 调度概述"></a>1. kube-scheduler 调度概述</h2><p>在 Kubernetes 中，调度是指将 Pod 放置到合适的 Node 节点上，然后对应 Node 上的 Kubelet 才能够运行这些 pod。</p><p><strong>调度器通过 kubernetes 的 watch 机制来发现集群中新创建且尚未被调度到 Node 上的 Pod。</strong>调度器会将发现的每一个未调度的 Pod 调度到一个合适的 Node 上来运行。调度器会依据下文的调度原则来做出调度选择。</p><p>调度是容器编排的重要环节，需要经过严格的监控和控制，现实生产通常对调度有各类限制，譬如某些服务必须在业务独享的机器上运行，或者从灾备的角度考虑尽量把服务调度到不同机器，这些需求在Kubernetes集群依靠调度组件kube-scheduler满足。</p><p>kube-scheduler 是 Kubernetes 中的关键模块，扮演管家的角色遵从一套机制——为Pod提供调度服务，例如基于资源的公平调度、调度Pod到指定节点、或者通信频繁的Pod调度到同一节点等。容器调度本身是一件比较复杂的事，因为要确保以下几个目标：</p><ul><li>公平性：在调度 Pod 时需要公平的进行决策，每个节点都有被分配资源的机会，调度器需要对不同节点的使用作出平衡决策。</li><li>资源高效利用：最大化群集所有资源的利用率，使有限的 CPU、内存等资源服务尽可能更多的 Pod。</li><li>效率问题：能快速的完成对大批量 Pod 的调度工作，在集群规模扩增的情况下，依然保证调度过程的性能。</li><li>灵活性：在实际运作中，用户往往希望Pod的调度策略是可控的，从而处理大量复杂的实际问题。因此平台要允许多个调度器并行工作，同时支持自定义调度器。</li></ul><p>为达到上述目标，kube-scheduler 通过结合 Node 资源、负载情况、数据位置等各种因素进行调度判断，确保在满足场景需求的同时将Pod 分配到最优节点。显然，kube-scheduler 影响着 Kubernetes 集群的可用性与性能，Pod 数量越多集群的调度能力越重要，尤其达到了数千级节点数时，优秀的调度能力将显著提升容器平台性能。</p><h2 id="2-kube-scheduler-调度流程"><a href="#2-kube-scheduler-调度流程" class="headerlink" title="2. kube-scheduler 调度流程"></a>2. kube-scheduler 调度流程</h2><p>kube-scheduler的根本工作任务是根据各种调度算法将Pod绑定（bind）到最合适的工作节点，整个调度流程分为两个阶段：<strong>预选策略（Predicates）</strong>和<strong>优选策略（Priorities）</strong>。</p><ul><li><strong>预选（Predicates）：</strong>输入是所有节点，输出是满足预选条件的节点。kube-scheduler 根据预选策略过滤掉不满足策略的 Nodes。例如，如果某节点的资源不足或者不满足预选策略的条件如 “ Node 的 label 必须与 Pod 的 Selector 一致”时则无法通过预选。</li><li><strong>优选（Priorities）：</strong>输入是预选阶段筛选出的节点，优选会根据优先策略为通过预选的 Nodes 进行打分排名，选择得分最高的Node。例如，资源越富裕、负载越小的 Node 可能具有越高的排名。</li></ul><p>通俗点说，调度的过程就是在回答两个问题：1. 候选有哪些？2. 其中最适合的是哪个？</p><p>值得一提的是，<em>如果在预选阶段没有节点满足条件，Pod会一直处在Pending状态直到出现满足的节点，在此期间调度器会不断的进行重试。</em></p><h3 id="2-1-预选策略（Predicates）"><a href="#2-1-预选策略（Predicates）" class="headerlink" title="2.1 预选策略（Predicates）"></a>2.1 预选策略（Predicates）</h3><p>官网地址：<a href="https://kubernetes.io/docs/reference/scheduling/policies/">调度器预选、优选策略</a></p><p>过滤条件包含如下：</p><ul><li>PodFitsHostPorts：检查 Pod 容器所需的 HostPort 是否已被节点上其它容器或服务占用。如果已被占用，则禁止 Pod 调度到该节点。</li><li>PodFitsHost：检查 Pod 指定的 NodeName 是否匹配当前节点。</li><li>PodFitsResources：检查节点是否有足够空闲资源（例如 CPU 和内存）来满足 Pod 的要求。</li><li>PodMatchNodeSelector：检查 Pod 的节点选择器( nodeSelector )是否与节点( Node )的标签匹配</li><li>NoVolumeZoneConflict：对于给定的某块区域，判断如果在此区域的节点上部署 Pod 是否存在卷冲突。</li><li>NoDiskConflict：根据节点请求的卷和已经挂载的卷，评估 Pod 是否适合该节点。</li><li>MaxCSIVolumeCount：决定应该附加多少 CSI 卷，以及该卷是否超过配置的限制。</li><li>CheckNodeMemoryPressure：如果节点报告内存压力，并且没有配置异常，那么将不会往那里调度 Pod。</li><li>CheckNodePIDPressure：如果节点报告进程 id 稀缺，并且没有配置异常，那么将不会往那里调度 Pod。</li><li>CheckNodeDiskPressure：如果节点报告存储压力(文件系统已满或接近满)，并且没有配置异常，那么将不会往那里调度 Pod。</li><li>CheckNodeCondition：节点可以报告它们有一个完全完整的文件系统，然而网络不可用，或者 kubelet 没有准备好运行 Pods。如果为节点设置了这样的条件，并且没有配置异常，那么将不会往那里调度 Pod。</li><li>PodToleratesNodeTaints：检查 Pod 的容忍度是否能容忍节点的污点。</li><li>CheckVolumeBinding：评估 Pod 是否适合它所请求的容量。这适用于约束和非约束 PVC。</li></ul><p><strong>如果在predicates(预选)过程中没有合适的节点，那么Pod会一直在pending状态，不断重试调度，直到有节点满足条件。</strong></p><p>经过这个步骤，如果有多个节点满足条件，就继续priorities过程，最后按照优先级大小对节点排序。</p><h3 id="2-2-优选策略（Priorities）"><a href="#2-2-优选策略（Priorities）" class="headerlink" title="2.2 优选策略（Priorities）"></a>2.2 优选策略（Priorities）</h3><p>包含如下优选评分条件：</p><ul><li>SelectorSpreadPriority：对于属于同一服务、有状态集或副本集（Service，StatefulSet or ReplicaSet）的Pods，会将Pods尽量分散到不同主机上。</li><li>InterPodAffinityPriority：策略有podAffinity和podAntiAffinity两种配置方式。简单来说，就说根据Node上运行的Pod的Label来进行调度匹配的规则，匹配的表达式有：In, NotIn, Exists, DoesNotExist，通过该策略，可以更灵活地对Pod进行调度。</li><li>LeastRequestedPriority：偏向使用较少请求资源的节点。换句话说，放置在节点上的Pod越多，这些Pod使用的资源越多，此策略给出的排名就越低。</li><li>MostRequestedPriority：偏向具有最多请求资源的节点。这个策略将把计划的Pods放到整个工作负载集所需的最小节点上运行。</li><li>RequestedToCapacityRatioPriority：使用默认的资源评分函数模型创建基于ResourceAllocationPriority的requestedToCapacity。</li><li>BalancedResourceAllocation：偏向具有平衡资源使用的节点。</li><li>NodePreferAvoidPodsPriority：根据节点注释scheduler.alpha.kubernet .io&#x2F;preferAvoidPods为节点划分优先级。可以使用它来示意两个不同的Pod不应在同一Node上运行。</li><li>NodeAffinityPriority：根据preferredduringschedulingignoredingexecution中所示的节点关联调度偏好来对节点排序。</li><li>TaintTolerationPriority：根据节点上无法忍受的污点数量，为所有节点准备优先级列表。此策略将考虑该列表调整节点的排名。</li><li>ImageLocalityPriority：偏向已经拥有本地缓存Pod容器镜像的节点。</li><li>ServiceSpreadingPriority：对于给定的服务，此策略旨在确保Service的Pods运行在不同的节点上。总的结果是，Service对单个节点故障变得更有弹性。</li><li>EqualPriority：赋予所有节点相同的权值1。</li><li>EvenPodsSpreadPriority：实现择优 pod的拓扑扩展约束</li></ul><h3 id="2-3-自定义调度器"><a href="#2-3-自定义调度器" class="headerlink" title="2.3 自定义调度器"></a>2.3 自定义调度器</h3><p>除了Kubernetes自带的调度器，我们也可以编写自己的调度器。通过spec.schedulername参数指定调度器名字，可以为Pod选择某个调度器进行调度。</p><pre><code class="highlight bash"><span class="comment"># 在 kubernetes Master 节点开启 apiServer 的代理</span>$ kubectl proxy --port=8001</code></pre><blockquote><p>基于 shell 编写一个自定义调度器</p></blockquote><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">vi my-scheduler.sh</span><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span>SERVER=&#x27;localhost:8001&#x27;while true;do    for PODNAME in $(kubectl --server $SERVER get pods -o json | jq &#x27;.items[] | select(.spec.schedulerName ==&quot;my-scheduler&quot;) | select(.spec.nodeName == null) | .metadata.name&#x27; | tr -d &#x27;&quot;&#x27;)    do        NODES=($(kubectl --server $SERVER get nodes -o json | jq &#x27;.items[].metadata.name&#x27; | tr -d &#x27;&quot;&#x27;))        NUMNODES=$&#123;#NODES[@]&#125;        CHOSEN=$&#123;NODES[$[ $RANDOM % $NUMNODES]]&#125;        curl --header &quot;Content-Type:application/json&quot; --request POST --data &#x27;&#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Binding&quot;,&quot;metadata&quot;: &#123;&quot;name&quot;:&quot;&#x27;$PODNAME&#x27;&quot;&#125;,&quot;target&quot;: &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;: &quot;Node&quot;, &quot;name&quot;: &quot;&#x27;$CHOSEN&#x27;&quot;&#125;&#125;&#x27; http://$SERVER/api/v1/namespaces/default/pods/$PODNAME/binding/        echo &quot;Assigned $PODNAME to $CHOSEN&quot;    done    sleep 1done</code></pre><blockquote><p>如下Pod选择my-scheduler进行调度，而不是默认的default-scheduler</p></blockquote><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">name:</span> <span class="string">myapp</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">schedulerName:</span> <span class="string">my-scheduler</span>      <span class="attr">containers:</span>      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>        <span class="attr">name:</span> <span class="string">myapp</span></code></pre><p>自定义调度器在日常工作中几乎不会用到。</p><h1 id="二、亲和性和反亲和性"><a href="#二、亲和性和反亲和性" class="headerlink" title="二、亲和性和反亲和性"></a>二、亲和性和反亲和性</h1><p><strong>主机配置规划</strong></p><table><thead><tr><th>服务器名称(hostname)</th><th>系统版本</th><th>配置</th><th>内网IP</th></tr></thead><tbody><tr><td>k8s-master</td><td>Rocky 9.3</td><td>2C&#x2F;4G&#x2F;100G</td><td>192.168.142.199</td></tr><tr><td>k8s-node01</td><td>Rocky 9.3</td><td>2C&#x2F;4G&#x2F;100G</td><td>192.168.142.201</td></tr><tr><td>k8s-node02</td><td>Rocky 9.3</td><td>2C&#x2F;4G&#x2F;100G</td><td>192.168.142.202</td></tr></tbody></table><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>nodeSelector提供了一种非常简单的方法，将pods约束到具有特定标签的节点。而亲和性&#x2F;反亲和性极大地扩展了可表达的约束类型。关键的增强是：</p><ul><li>亲和性&#x2F;反亲和性语言更具表达性。除了使用逻辑AND操作创建的精确匹配之外，该语言还提供了更多的匹配规则；</li><li>可以指示规则是优选项而不是硬要求，因此如果调度器不能满足，pod仍将被调度；</li><li>可以针对节点（或其他拓扑域）上运行的 pods 的标签进行约束，而不是针对节点的自身标签，<strong>这影响哪些 Pod 可以或不可以共处</strong>。</li></ul><p><strong>亲和特性包括两种类型：node节点亲和性&#x2F;反亲和性 和 pod亲和性&#x2F;反亲和性。pod亲和性&#x2F;反亲和性约束针对的是pod标签而不是节点标签。</strong></p><p><strong>拓扑域是什么：多个node节点，拥有相同的label标签【节点标签的键值相同】，那么这些节点就处于同一个拓扑域。</strong></p><h2 id="2-Node-节点亲和性"><a href="#2-Node-节点亲和性" class="headerlink" title="2. Node 节点亲和性"></a>2. Node 节点亲和性</h2><h3 id="2-1-相关概念"><a href="#2-1-相关概念" class="headerlink" title="2.1 相关概念"></a>2.1 相关概念</h3><p>当前有两种类型的节点亲和性，称为 <code>requiredDuringSchedulingIgnoredDuringExecution</code> 和 <code>preferredDuringSchedulingIgnoredDuringExecution</code> ，可以将它们分别视为“硬策略”【必须满足条件】和“软策略”【优选满足条件】要求。</p><p>前者表示Pod要调度到的节点必须满足规则条件，不满足则不会调度，pod会一直处于Pending状态；后者表示优先调度到满足规则条件的节点，如果不能满足再调度到其他节点。</p><p>名称中的 <code>IgnoredDuringExecution</code> 部分意味着，与 nodeSelector 的工作方式类似，如果节点上的标签在 Pod 运行时发生更改，使得pod 上的亲和性规则不再满足，那么 pod 仍将继续在该节点上运行。</p><p>在未来，会计划提供 <code>requiredDuringSchedulingRequiredDuringExecution</code> ，类似 <code>requiredDuringSchedulingIgnoredDuringExecution</code> 。不同之处就是 pod 运行过程中如果节点不再满足 pod 的亲和性，则 pod 会在该节点中逐出。</p><p><strong>节点亲和性语法支持以下运算符：In，NotIn，Exists，DoesNotExist，Gt，Lt。可以使用 NotIn 和 DoesNotExist 实现节点的反亲和行为。</strong></p><p>运算符关系：</p><ul><li>In：label 的值在某个列表中</li><li>NotIn：label 的值不在某个列表中</li><li>Gt：label 的值大于某个值</li><li>Lt：label 的值小于某个值</li><li>Exists：某个label 存在</li><li>DoesNotExist：某个 label 不存在</li></ul><h3 id="2-2-节点亲和性重要说明"><a href="#2-2-节点亲和性重要说明" class="headerlink" title="2.2 节点亲和性重要说明"></a>2.2 节点亲和性重要说明</h3><ol><li><p>如果同时指定 nodeSelector 和 nodeAffinity ，则必须满足两个条件，才能将 Pod 调度到候选节点上。</p></li><li><p>如果在 nodeAffinity 类型下指定了多个 nodeSelectorTerms 对象【对象不能有多个，如果存在多个只有最后一个生效】，那么只有最后一个 nodeSelectorTerms 对象生效。</p></li><li><p>如果在 nodeSelectorTerms 下指定了多个 matchExpressions 列表，那么只要能满足其中一个 matchExpressions ，就可以将 pod 调度到某个节点上【针对节点硬亲和】。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/02/20250602-170832.png" alt="在 nodeSelectorTerms 下指定了多个 matchExpressions 列表"></p></li><li><p>如果在 matchExpressions下有多个 key 列表，那么只有当所有 key 满足时，才能将 pod 调度到某个节点【针对硬亲和】。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/02/20250602-170929.png" alt="在 matchExpressions下有多个 key 列表"></p></li><li><p>在key下的values只要有一个满足条件，那么当前的key就满足条件</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/02/20250602-171010.png" alt="在key下的values只要有一个满足条件，那么当前的key就满足条件"></p></li><li><p>如果 pod 已经调度在该节点，当我们删除或修该节点的标签时，pod 不会被移除。换句话说，亲和性选择只有在 pod 调度期间有效。</p></li><li><p><code>preferredDuringSchedulingIgnoredDuringExecution</code> 中的 weight（权重）字段在1-100范围内。对于每个满足所有调度需求的节点(资源请求、RequiredDuringScheduling 亲和表达式等)，调度器将通过迭代该字段的元素来计算一个总和，如果节点与相应的匹配表达式匹配，则向该总和添加“权重”。然后将该分数与节点的其他优先级函数的分数结合起来。总得分最高的节点是最受欢迎的。</p></li></ol><h3 id="2-3-节点亲和性示例"><a href="#2-3-节点亲和性示例" class="headerlink" title="2.3 节点亲和性示例"></a>2.3 节点亲和性示例</h3><h4 id="2-3-1-准备事项"><a href="#2-3-1-准备事项" class="headerlink" title="2.3.1 准备事项"></a>2.3.1 准备事项</h4><p>给node节点打label标签</p><pre><code class="highlight bash"><span class="comment"># 查看当前集群节点列表</span>$ kubectl get nodesNAME         STATUS   ROLES           AGE   VERSIONk8s-node01   Ready    &lt;none&gt;          76d   v1.29.15k8s-node02   Ready    &lt;none&gt;          76d   v1.29.15node         Ready    control-plane   76d   v1.29.15<span class="comment"># 1.给node01节点打标签</span><span class="comment">### --overwrite覆盖已存在的标签信息</span>$ kubectl label nodes k8s-node01 disk-type=ssd --overwritenode/k8s-node01 labeled$ kubectl label nodes k8s-node01 cpu-num=12node/k8s-node01 labeled<span class="comment"># 2.给node02节点打标签</span>$ kubectl label nodes k8s-node02 disk-type=sata --overwritenode/k8s-node02 labeled$ kubectl label nodes k8s-node02 cpu-num=24node/k8s-node02 labeled</code></pre><p>查询所有节点标签信息</p><pre><code class="highlight bash">$ kubectl get node --show-labelsNAME         STATUS   ROLES           AGE   VERSION    LABELSk8s-node01   Ready    &lt;none&gt;          76d   v1.29.15   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,cpu-num=12,disk-type=ssd,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node01,kubernetes.io/os=linuxk8s-node02   Ready    &lt;none&gt;          76d   v1.29.15   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,cpu-num=24,disk-type=sata,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node02,kubernetes.io/os=linuxnode         Ready    control-plane   76d   v1.29.15   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node.kubernetes.io/exclude-from-external-load-balancers=</code></pre><h4 id="2-3-2-节点硬亲和性示例"><a href="#2-3-2-节点硬亲和性示例" class="headerlink" title="2.3.2 节点硬亲和性示例"></a>2.3.2 节点硬亲和性示例</h4><p><strong>必须满足条件才能调度，否则不会调度</strong></p><p>资源清单：<code>node_required_affinity.yaml</code></p><pre><code class="highlight yaml"><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">node-affinity-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">nodeaffinity-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">5</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">name:</span> <span class="string">web</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">affinity:</span> <span class="comment"># 亲和性</span>        <span class="attr">nodeAffinity:</span> <span class="comment"># 节点亲和性</span>          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 节点硬亲和性</span>            <span class="attr">nodeSelectorTerms:</span>              <span class="bullet">-</span> <span class="attr">matchExpressions:</span>                  <span class="comment"># 表示node标签存在 disk-type=ssd 或 disk-type=sas</span>                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">disk-type</span>                    <span class="attr">operator:</span> <span class="string">In</span>                    <span class="attr">values:</span>                      <span class="bullet">-</span> <span class="string">ssd</span>                      <span class="bullet">-</span> <span class="string">sas</span>                  <span class="comment"># 表示node标签存在 cpu-num且值大于6</span>                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">cpu-num</span>                    <span class="attr">operator:</span> <span class="string">Gt</span>                    <span class="attr">values:</span>                      <span class="bullet">-</span> <span class="string">&quot;6&quot;</span></code></pre><p>执行资源清单，并查看状态</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Deployment 和 Pod</span>$ kubectl apply -f node_required_affinity.yaml<span class="comment"># 查看Deployment控制器</span>$ kubectl get deploy -o wideNAME                   READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                     SELECTORnode-affinity-deploy   5/5     5            5           9s    nginx        wangyanglinux/myapp:v1.0   app=myapp<span class="comment"># 查看Pod</span>$ kubectl get pods -o wideNAME                                    READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESnode-affinity-deploy-7f4f994b48-747jn   1/1     Running   0          31s   192.168.85.244   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-7f4f994b48-8cvx8   1/1     Running   0          31s   192.168.85.243   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-7f4f994b48-9rcs6   1/1     Running   0          31s   192.168.85.240   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-7f4f994b48-dckdb   1/1     Running   0          31s   192.168.85.241   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-7f4f994b48-fmmbf   1/1     Running   0          31s   192.168.85.242   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看rs</span>$ kubectl get rs -o wideNAME                              DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES                     SELECTORnode-affinity-deploy-7f4f994b48   5         5         5       3m46s   nginx        wangyanglinux/myapp:v1.0   app=myapp,pod-template-hash=7f4f994b48</code></pre><p>由上可见，由于节点硬亲和性的限制，Pod 都运行到了 k8s-node01 节点上了，即便是删除 Pod 重新创建新的Pod，依然会运行到 k8s-node01 节点上。</p><pre><code class="highlight bash"><span class="comment"># 删除 Pod</span>$ kubectl delete pod node-affinity-deploy-7f4f994b48-747jnpod <span class="string">&quot;node-affinity-deploy-7f4f994b48-747jn&quot;</span> deleted<span class="comment"># 再次查看Pod</span>$ kubectl get pods -o wideNAME                                    READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATESnode-affinity-deploy-7f4f994b48-8cvx8   1/1     Running   0          5m57s   192.168.85.243   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-7f4f994b48-9rcs6   1/1     Running   0          5m57s   192.168.85.240   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-7f4f994b48-dckdb   1/1     Running   0          5m57s   192.168.85.241   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-7f4f994b48-fmmbf   1/1     Running   0          5m57s   192.168.85.242   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-7f4f994b48-r22mr   1/1     Running   0          6s      192.168.85.245   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h4 id="2-3-3-节点软亲和性示例"><a href="#2-3-3-节点软亲和性示例" class="headerlink" title="2.3.3 节点软亲和性示例"></a>2.3.3 节点软亲和性示例</h4><p><strong>优先调度到满足条件的节点，如果都不满足也会调度到其他节点。</strong></p><p>资源清单：<code>node_preferred_affinity.yaml</code></p><pre><code class="highlight yaml"><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">node-affinity-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">nodeaffinity-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">5</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">name:</span> <span class="string">web</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">affinity:</span> <span class="comment"># 亲和性</span>        <span class="attr">nodeAffinity:</span> <span class="comment"># 节点亲和性</span>          <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 节点软亲和性</span>            <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span> <span class="comment"># 权重，范围 1-100</span>              <span class="attr">preference:</span>                <span class="attr">matchExpressions:</span>                  <span class="comment"># 表示node标签存在 disk-type=ssd 或 disk-type=sas</span>                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">disk-type</span>                    <span class="attr">operator:</span> <span class="string">In</span>                    <span class="attr">values:</span>                      <span class="bullet">-</span> <span class="string">ssd</span>                      <span class="bullet">-</span> <span class="string">sas</span>            <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">50</span> <span class="comment"># 权重，范围 1-100</span>              <span class="attr">preference:</span>                <span class="attr">matchExpressions:</span>                  <span class="comment"># 表示node标签存在 cpu-num且值大于16</span>                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">cpu-num</span>                    <span class="attr">operator:</span> <span class="string">Gt</span>                    <span class="attr">values:</span>                      <span class="bullet">-</span> <span class="string">&quot;16&quot;</span></code></pre><p>执行资源清单，并查看状态</p><pre><code class="highlight bash"><span class="comment"># 运行资源清单，创建Deployment</span>$ kubectl apply -f node_preferred_affinity.yaml<span class="comment"># 查看 Deployment</span>$ kubectl get deployment -o wideNAME                   READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                     SELECTORnode-affinity-deploy   5/5     5            5           6s    nginx        wangyanglinux/myapp:v1.0   app=myapp<span class="comment"># 查看 RS</span>$ kubectl get rs -o wideNAME                              DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES                     SELECTORnode-affinity-deploy-649bb7b9cf   5         5         5       12s   nginx        wangyanglinux/myapp:v1.0   app=myapp,pod-template-hash=649bb7b9cf<span class="comment"># 查看 Pod详情</span>$ kubectl get pods -o wideNAME                                    READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESnode-affinity-deploy-649bb7b9cf-7mj7p   1/1     Running   0          19s   192.168.58.239   k8s-node02   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-649bb7b9cf-9q56z   1/1     Running   0          19s   192.168.58.242   k8s-node02   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-649bb7b9cf-b7gtd   1/1     Running   0          19s   192.168.58.240   k8s-node02   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-649bb7b9cf-qp775   1/1     Running   0          19s   192.168.58.238   k8s-node02   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-649bb7b9cf-ztkl8   1/1     Running   0          19s   192.168.58.241   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>由于 Node 软亲和性的限制，可以推断出 Pod 会运行在 k8s-node02 节点上。</p><h4 id="2-3-4-节点硬亲和性-和-软亲和性联合示例"><a href="#2-3-4-节点硬亲和性-和-软亲和性联合示例" class="headerlink" title="2.3.4 节点硬亲和性 和 软亲和性联合示例"></a>2.3.4 节点硬亲和性 和 软亲和性联合示例</h4><p>资源清单：<code>node_affinity.yaml</code></p><pre><code class="highlight yaml"><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">node-affinity-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">nodeaffinity-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">5</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">name:</span> <span class="string">web</span>              <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">affinity:</span> <span class="comment"># 亲和性</span>        <span class="attr">nodeAffinity:</span> <span class="comment"># 节点亲和性</span>          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 节点硬亲和性</span>            <span class="attr">nodeSelectorTerms:</span>              <span class="bullet">-</span> <span class="attr">matchExpressions:</span>                  <span class="comment"># 表示node标签存在 cpu-num且值大于10</span>                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">cpu-num</span>                    <span class="attr">operator:</span> <span class="string">Gt</span>                    <span class="attr">values:</span>                      <span class="bullet">-</span> <span class="string">&quot;10&quot;</span>          <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 节点软亲和性</span>            <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">50</span> <span class="comment"># 权重，范围 1-100</span>              <span class="attr">preference:</span>                <span class="attr">matchExpressions:</span>                  <span class="comment"># 表示node标签存在 disk-type=ssd 或 disk-type=sas</span>                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">disk-type</span>                    <span class="attr">operator:</span> <span class="string">In</span>                    <span class="attr">values:</span>                      <span class="bullet">-</span> <span class="string">ssd</span>                      <span class="bullet">-</span> <span class="string">sas</span></code></pre><p>执行资源清单并查看状态</p><pre><code class="highlight bash"><span class="comment"># 运行资源清单，创建Deployment</span>$ kubectl apply -f node_affinity.yaml deployment.apps/node-affinity-deploy created<span class="comment"># 查看 Deployment</span>$ kubectl get deployment -o wideNAME                   READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                     SELECTORnode-affinity-deploy   5/5     5            5           6s    nginx        wangyanglinux/myapp:v1.0   app=myapp<span class="comment"># 查看 RS</span>$ kubectl get rs -o wideNAME                              DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES                     SELECTORnode-affinity-deploy-5498f54ffc   5         5         5       10s   nginx        wangyanglinux/myapp:v1.0   app=myapp,pod-template-hash=5498f54ffc<span class="comment"># 查看 Pod 详情</span>$ kubectl get pods -o wideNAME                                    READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESnode-affinity-deploy-5498f54ffc-dcp9v   1/1     Running   0          13s   192.168.85.248   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-5498f54ffc-kkss7   1/1     Running   0          13s   192.168.85.250   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-5498f54ffc-nd6sb   1/1     Running   0          13s   192.168.85.247   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-5498f54ffc-p5x2t   1/1     Running   0          13s   192.168.85.249   k8s-node01   &lt;none&gt;           &lt;none&gt;node-affinity-deploy-5498f54ffc-r5pbd   1/1     Running   0          13s   192.168.85.246   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>从资源清单可以看出，节点的硬亲和要求，k8s-node01 与 k8s-node02 都满足要求，节点的软亲和只有 k8s-node01 满足，所以 Pod 优先调度到 k8s-node01 节点上。</p><h2 id="3-Pod-亲和性-反亲和性"><a href="#3-Pod-亲和性-反亲和性" class="headerlink" title="3. Pod 亲和性 &#x2F; 反亲和性"></a>3. Pod 亲和性 &#x2F; 反亲和性</h2><h3 id="3-1-相关概念"><a href="#3-1-相关概念" class="headerlink" title="3.1 相关概念"></a>3.1 相关概念</h3><p>与节点亲和性一样，当前有Pod亲和性&#x2F;反亲和性都有两种类型，称为 <code>requiredDuringSchedulingIgnoredDuringExecution</code> 和 <code>preferredDuringSchedulingIgnoredDuringExecution</code>，分别表示“硬”与“软”要求。对于硬要求，如果不满足则pod会一直处于Pending状态。</p><p>Pod 的亲和性与反亲和性是基于 Node 节点上已经运行 pod 的标签(而不是节点上的标签)决定的，从而约束哪些节点适合调度你的 pod。</p><p>规则的形式是：如果X已经运行了一个或多个符合规则Y的pod，则此pod应该在X中运行(如果是反亲和的情况下，则不应该在X中运行）。当然pod必须处在同一名称空间，不然亲和性&#x2F;反亲和性无作用。<strong>从概念上讲，X是一个拓扑域。我们可以使用topologyKey来表示它，topologyKey 的值是node节点标签的键以便系统用来表示这样的拓扑域。当然这里也有个隐藏条件，就是node节点标签的键值相同时，才是在同一拓扑域中；如果只是节点标签名相同，但是值不同，那么也不在同一拓扑域。</strong> </p><p>也就是说：<strong>Pod的亲和性&#x2F;反亲和性调度是根据拓扑域来界定调度的，而不是根据node节点。</strong></p><p><strong>注意事项</strong></p><ul><li>Pod 之间亲和性&#x2F;反亲和性需要大量的处理，这会明显降低大型集群中的调度速度。不建议在大于几百个节点的集群中使用它们。</li><li>Pod 反亲和性要求对节点进行一致的标记。换句话说，集群中的每个节点都必须有一个匹配 topologyKey 的适当标签。如果某些或所有节点缺少指定的topologyKey 标签，可能会导致意外行为。</li></ul><p><code>requiredDuringSchedulingIgnoredDuringExecution</code> 中亲和性的一个示例是“将服务A和服务B的Pod放置在同一区域【拓扑域】中，因为它们之间有很多交流”； <code>preferredDuringSchedulingIgnoredDuringExecution</code> 中反亲和性的示例是“将此服务的 pod 跨区域【拓扑域】分布”【此时硬性要求是说不通的，因为你可能拥有的 pod 数多于区域数】。</p><p>Pod 亲和性&#x2F;反亲和性语法支持以下运算符：<code>In</code>，<code>NotIn</code>，<code>Exists</code>，<code>DoesNotExist</code>。</p><p><strong>原则上，topologyKey可以是任何合法的标签键。但是，出于性能和安全方面的原因，topologyKey有一些限制：</strong></p><ol><li>对于 Pod 亲和性，在 requiredDuringSchedulingIgnoredDuringExecution 和 preferredDuringSchedulingIgnoredDuringExecution 中 topologyKey 都不允许为空。</li><li>对于 Pod 反亲和性，在 requiredDuringSchedulingIgnoredDuringExecution 和 preferredDuringSchedulingIgnoredDuringExecution 中 topologyKey 也都不允许为空。</li><li>对于 requiredDuringSchedulingIgnoredDuringExecution 的 pod 反亲和性，引入了允许控制器 LimitPodHardAntiAffinityTopology 来限制 topologyKey 的kubernet.io&#x2F;hostname 。如果你想让它对自定义拓扑可用，你可以修改许可控制器，或者干脆禁用它。</li><li>除上述情况外，topologyKey 可以是任何合法的标签键。</li></ol><p><strong>Pod 间亲和通过 PodSpec 中 affinity 字段下的 podAffinity 字段进行指定。而 pod 间反亲和通过 PodSpec 中 affinity 字段下的 podAntiAffinity 字段进行指定。</strong></p><p><strong>Pod亲和性&#x2F;反亲和性的requiredDuringSchedulingIgnoredDuringExecution所关联的matchExpressions下有多个key列表，那么只有当所有key满足时，才能将pod调度到某个区域【针对Pod硬亲和】。</strong></p><h3 id="3-2-pod亲和性与反亲和性示例"><a href="#3-2-pod亲和性与反亲和性示例" class="headerlink" title="3.2 pod亲和性与反亲和性示例"></a>3.2 pod亲和性与反亲和性示例</h3><p>为了更好的演示Pod亲和性与反亲和性，本次示例我们会将k8s-master节点也加入进来进行演示。</p><h4 id="3-2-1-准备事项"><a href="#3-2-1-准备事项" class="headerlink" title="3.2.1 准备事项"></a>3.2.1 准备事项</h4><p>给 node 节点打 label 标签</p><pre><code class="highlight bash"><span class="comment"># 删除已存在标签</span>kubectl label nodes k8s-node01 cpu-num-kubectl label nodes k8s-node01 disk-type-kubectl label nodes k8s-node02 cpu-num-kubectl label nodes k8s-node02 disk-type-<span class="comment">###  --overwrite覆盖已存在的标签信息</span><span class="comment"># master节点 标签添加(master节点的名称叫做 node)</span>kubectl label nodes node busi-use=www --overwritekubectl label nodes node disk-type=ssd --overwritekubectl label nodes node busi-db=redis<span class="comment"># k8s-node01 标签添加</span>kubectl label nodes k8s-node01 busi-use=wwwkubectl label nodes k8s-node01 disk-type=satakubectl label nodes k8s-node01 busi-db=redis<span class="comment"># k8s-node02 标签添加</span>kubectl label nodes k8s-node02 busi-use=wwwkubectl label nodes k8s-node02 disk-type=ssdkubectl label nodes k8s-node02 busi-db=etcd</code></pre><p>查询所有节点标签信息</p><pre><code class="highlight bash">$ kubectl get node -o wide --show-labelsNAME         STATUS   ROLES           AGE   VERSION    INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                      KERNEL-VERSION                CONTAINER-RUNTIME   LABELSk8s-node01   Ready    &lt;none&gt;          69d   v1.29.15   192.168.6.140   &lt;none&gt;        Rocky Linux 9.3 (Blue Onyx)   5.14.0-362.8.1.el9_3.x86_64   docker://28.0.4     beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,busi-db=redis,busi-use=www,disk-type=sata,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node01,kubernetes.io/os=linuxk8s-node02   Ready    &lt;none&gt;          69d   v1.29.15   192.168.6.141   &lt;none&gt;        Rocky Linux 9.3 (Blue Onyx)   5.14.0-362.8.1.el9_3.x86_64   docker://28.0.4     beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,busi-db=etcd,busi-use=www,disk-type=ssd,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node02,kubernetes.io/os=linuxnode         Ready    control-plane   69d   v1.29.15   192.168.6.139   &lt;none&gt;        Rocky Linux 9.3 (Blue Onyx)   5.14.0-362.8.1.el9_3.x86_64   docker://28.0.4     beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,busi-db=redis,busi-use=www,disk-type=ssd,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master01,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node.kubernetes.io/exclude-from-external-load-balancers=</code></pre><p>master 节点添加了 disk-type&#x3D;ssd, busi-db&#x3D;redis, busi-use&#x3D;www 标签<br>k8s-node01 添加了 disk-type&#x3D;sata, busi-db&#x3D;redis, busi-use&#x3D;www 标签<br>k8s-node02 添加了 disk-type&#x3D;ssd, busi-db&#x3D;etcd, busi-use&#x3D;www 标签</p><p>通过 deployment 运行一个 pod，或者直接运行一个 pod 也可以。为后续的 Pod 亲和性与反亲和性测验做基础。</p><p>演示Pod资源清单：<code>web_deploy.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">web-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myweb-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp-web</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp-web</span>        <span class="attr">version:</span> <span class="string">v1</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></code></pre><p>执行资源清单</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f web_deploy.yaml<span class="comment"># 获取Pod</span>$ kubectl get pod -o wideNAME                          READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESweb-deploy-7b868c54f5-x78hw   1/1     Running   0          17s   172.16.58.243   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 k8s-node02 节点标签</span>$ kubectl get node k8s-node02 -o wide --show-labelsNAME         STATUS   ROLES    AGE   VERSION    INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                      KERNEL-VERSION                CONTAINER-RUNTIME   LABELSk8s-node02   Ready    &lt;none&gt;   69d   v1.29.15   192.168.6.141   &lt;none&gt;        Rocky Linux 9.3 (Blue Onyx)   5.14.0-362.8.1.el9_3.x86_64   docker://28.0.4     beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,busi-db=etcd,busi-use=www,disk-type=ssd,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node02,kubernetes.io/os=linux</code></pre><p>当前 pod 在 k8s-node02 节点；其中 pod 的标签 app&#x3D;myapp-web,version&#x3D;v1 会在后面 pod 亲和性&#x2F;反亲和性示例中使用。</p><h4 id="3-2-2-pod-硬亲和性示例"><a href="#3-2-2-pod-硬亲和性示例" class="headerlink" title="3.2.2 pod 硬亲和性示例"></a>3.2.2 pod 硬亲和性示例</h4><p>资源清单：<code>pod_required_affinity.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-podaffinity-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">podaffinity-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">tolerations:</span> <span class="comment"># 配置容忍，允许运行到 Master 节点上</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/control-plane</span>          <span class="attr">effect:</span> <span class="string">NoSchedule</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">affinity:</span>        <span class="attr">podAffinity:</span>          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span>            <span class="comment"># 由于是Pod亲和性/反亲和性， 因此这里匹配规则写的是Pod的标签信息</span>            <span class="bullet">-</span> <span class="attr">labelSelector:</span>                <span class="attr">matchExpressions:</span>                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span>                    <span class="attr">operator:</span> <span class="string">In</span>                    <span class="attr">values:</span>                      <span class="bullet">-</span> <span class="string">myapp-web</span>              <span class="comment"># 拓扑域  若多个node节点具有相同的标签信息【标签键值相同】，则表示这些node节点就在同一拓扑域</span>              <span class="attr">topologyKey:</span> <span class="string">disk-type</span></code></pre><p>执行资源清单</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f pod_required_affinity.yaml<span class="comment"># 查看 Deployment</span>$ kubectl get deploy NAME                     READY   UP-TO-DATE   AVAILABLE   AGEpod-podaffinity-deploy   6/6     6            6           7sweb-deploy               1/1     1            1           27m<span class="comment"># 查看 Pod</span>$ kubectl get pod -o wideNAME                                      READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESpod-podaffinity-deploy-6b588d4649-2ztpj   1/1     Running   0          13s   172.16.167.133   node         &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-6b588d4649-7pghc   1/1     Running   0          13s   172.16.58.208    k8s-node02   &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-6b588d4649-d68kl   1/1     Running   0          13s   172.16.167.131   node         &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-6b588d4649-dpnzg   1/1     Running   0          13s   172.16.58.228    k8s-node02   &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-6b588d4649-qjbwn   1/1     Running   0          13s   172.16.58.251    k8s-node02   &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-6b588d4649-vcvhg   1/1     Running   0          13s   172.16.167.132   node         &lt;none&gt;           &lt;none&gt;web-deploy-7b868c54f5-x78hw               1/1     Running   0          27m   172.16.58.243    k8s-node02   &lt;none&gt;           &lt;none</code></pre><p>yaml 文件中为 topologyKey: disk-type；虽然 k8s-master、k8s-node01、k8s-node02 都有 disk-type 标签；但是 k8s-master 和 k8s-node02 节点的 disk-type 标签值为 ssd；而 k8s-node01 节点的 disk-type 标签值为 sata。因此 k8s-master 和 k8s-node02 节点属于同一拓扑域，Pod 只会调度到这两个节点上。</p><p>补充说明：因为 设置了 Pod 硬亲和，匹配运行了包含标签为 app: myapp-web 的 Pod 所在的 Node 节点（k8s-node02）,而 k8s-node02 节点 topologyKey disk-type 为 ssd，而 topologyKey 满足 disk-type&#x3D;ssd 的只有 master 节点和 k8s-node02.</p><h4 id="3-2-3-pod-软亲和性示例"><a href="#3-2-3-pod-软亲和性示例" class="headerlink" title="3.2.3 pod 软亲和性示例"></a>3.2.3 pod 软亲和性示例</h4><p>资源清单：<code>pod_preferred_affinity.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-podaffinity-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">podaffinity-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">tolerations:</span> <span class="comment"># 配置容忍，允许运行到 Master 节点上</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/control-plane</span>          <span class="attr">effect:</span> <span class="string">NoSchedule</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">affinity:</span>        <span class="attr">podAffinity:</span>          <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span>            <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">100</span> <span class="comment"># 权重（1-100）</span>              <span class="attr">podAffinityTerm:</span>                <span class="comment"># 由于是Pod亲和性/反亲和性，因此这里匹配规则写的是Pod的标签信息</span>                <span class="attr">labelSelector:</span>                    <span class="attr">matchExpressions:</span>                      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">version</span>                        <span class="attr">operator:</span> <span class="string">In</span>                        <span class="attr">values:</span>                          <span class="bullet">-</span> <span class="string">v1</span>                          <span class="bullet">-</span> <span class="string">v2</span>                <span class="comment"># 拓扑域  若多个node节点具有相同的标签信息【标签键值相同】，则表示这些node节点就在同一拓扑域</span>                <span class="attr">topologyKey:</span> <span class="string">disk-type</span></code></pre><p>运行yaml文件并查看状态</p><pre><code class="highlight bash"><span class="comment"># 运行资源清单，创建deploy 和 Pod</span>$ kubectl apply -f pod_preferred_affinity.yaml<span class="comment"># 查看deploy</span>$ kubectl get deploy -o wideNAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                     SELECTORpod-podaffinity-deploy   6/6     6            6           17s   myapp-pod    wangyanglinux/myapp:v1.0   app=myappweb-deploy               1/1     1            1           13h   myapp-pod    wangyanglinux/myapp:v1.0   app=myapp-web<span class="comment"># 查看 Pod </span>$ kubectl get pods -o wideNAME                                      READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESpod-podaffinity-deploy-6d486b88bf-2lx4m   1/1     Running   0          5s    172.16.167.138   node         &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-6d486b88bf-4n258   1/1     Running   0          5s    172.16.167.137   node         &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-6d486b88bf-7xn7w   1/1     Running   0          5s    172.16.58.235    k8s-node02   &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-6d486b88bf-8f647   1/1     Running   0          5s    172.16.167.139   node         &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-6d486b88bf-92w5r   1/1     Running   0          5s    172.16.58.219    k8s-node02   &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-6d486b88bf-nhnzk   1/1     Running   0          5s    172.16.58.238    k8s-node02   &lt;none&gt;           &lt;none&gt;web-deploy-7b868c54f5-x78hw               1/1     Running   0          13h   172.16.58.243    k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>根据节点的标签信息，可以得出 Pod 会优先调度到 k8s-node2 和 master 节点上。</p><h4 id="3-2-4-pod-硬反亲和性示例"><a href="#3-2-4-pod-硬反亲和性示例" class="headerlink" title="3.2.4 pod 硬反亲和性示例"></a>3.2.4 pod 硬反亲和性示例</h4><p>资源清单：<code>pod_required_AntiAffinity.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-podantiaffinity-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">podantiaffinity-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">tolerations:</span> <span class="comment"># 配置容忍，允许运行到 Master 节点上</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/control-plane</span>          <span class="attr">effect:</span> <span class="string">NoSchedule</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">affinity:</span>        <span class="attr">podAntiAffinity:</span>          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span>            <span class="comment"># 由于是Pod亲和性/反亲和性， 因此这里匹配规则写的是Pod的标签信息</span>            <span class="bullet">-</span> <span class="attr">labelSelector:</span>                <span class="attr">matchExpressions:</span>                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span>                    <span class="attr">operator:</span> <span class="string">In</span>                    <span class="attr">values:</span>                      <span class="bullet">-</span> <span class="string">myapp-web</span>              <span class="comment"># 拓扑域  若多个node节点具有相同的标签信息【标签键值相同】，则表示这些node节点就在同一拓扑域</span>              <span class="attr">topologyKey:</span> <span class="string">disk-type</span></code></pre><p>运行yaml文件并查看状态</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Deployment 和 Pod</span>$ kubectl apply -f pod_required_AntiAffinity.yaml<span class="comment"># 查看 Deployment</span>$ kubectl get deploy -o wideNAME                         READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                     SELECTORpod-podantiaffinity-deploy   6/6     6            6           8s    myapp-pod    wangyanglinux/myapp:v1.0   app=myappweb-deploy                   1/1     1            1           13h   myapp-pod    wangyanglinux/myapp:v1.0   app=myapp-web<span class="comment"># 查看 Pod</span>$ kubectl get pods -o wideNAME                                          READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESpod-podantiaffinity-deploy-54b4fd688f-2jb2x   1/1     Running   0          14s   172.16.85.216   k8s-node01   &lt;none&gt;           &lt;none&gt;pod-podantiaffinity-deploy-54b4fd688f-2lppr   1/1     Running   0          14s   172.16.85.213   k8s-node01   &lt;none&gt;           &lt;none&gt;pod-podantiaffinity-deploy-54b4fd688f-hmwqp   1/1     Running   0          14s   172.16.85.218   k8s-node01   &lt;none&gt;           &lt;none&gt;pod-podantiaffinity-deploy-54b4fd688f-qgt95   1/1     Running   0          14s   172.16.85.217   k8s-node01   &lt;none&gt;           &lt;none&gt;pod-podantiaffinity-deploy-54b4fd688f-tprg4   1/1     Running   0          14s   172.16.85.215   k8s-node01   &lt;none&gt;           &lt;none&gt;pod-podantiaffinity-deploy-54b4fd688f-xz2gt   1/1     Running   0          14s   172.16.85.212   k8s-node01   &lt;none&gt;           &lt;none&gt;web-deploy-7b868c54f5-x78hw                   1/1     Running   0          13h   172.16.58.243   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>调度说明：由于设置了 Pod 反亲和性的硬策略（必须执行），不允许 Pod 调度到已运行了包含标签为 <code>app: myapp-web</code> 的pod所在的节点，以及相同 topologyKey 的其它节点，限制了 topoloyKey key 为 disk-type 。</p><p>运行 <code>app: myapp-web</code> 的Pod 在 k8s-node02 节点上，该节点 topologyKey disk-type&#x3D;ssd，与之相同的节点是 master 节点，由于设置了反亲和性，所以 资源清单运行的 Pod 不会运行在 master 节点和 k8s-node02 节点上，因此产生的Pod只能运行到 k8s-node01 节点上。</p><h4 id="3-2-5-pod-软反亲和性示例"><a href="#3-2-5-pod-软反亲和性示例" class="headerlink" title="3.2.5 pod 软反亲和性示例"></a>3.2.5 pod 软反亲和性示例</h4><p>资源清单：<code>pod_preferred_AntiAffinity.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-podantiaffinity-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">podantiaffinity-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">tolerations:</span> <span class="comment"># 配置容忍，允许运行到 Master 节点上</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/control-plane</span>          <span class="attr">effect:</span> <span class="string">NoSchedule</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">affinity:</span>        <span class="attr">podAntiAffinity:</span> <span class="comment"># Pod 反亲和性</span>          <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 软策略</span>            <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">100</span> <span class="comment"># 权重（1-100）</span>              <span class="attr">podAffinityTerm:</span>                <span class="comment"># 由于是Pod亲和性/反亲和性，因此这里匹配规则写的是Pod的标签信息</span>                <span class="attr">labelSelector:</span>                  <span class="attr">matchExpressions:</span>                    <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">version</span>                      <span class="attr">operator:</span> <span class="string">In</span>                      <span class="attr">values:</span>                        <span class="bullet">-</span> <span class="string">v1</span>                        <span class="bullet">-</span> <span class="string">v2</span>                  <span class="comment"># 拓扑域  若多个node节点具有相同的标签信息【标签键值相同】，则表示这些node节点就在同一拓扑域</span>                <span class="attr">topologyKey:</span> <span class="string">disk-type</span></code></pre><p>运行yaml文件并查看状态</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 Pod</span>$ kubectl apply -f pod_preferred_AntiAffinity.yaml<span class="comment"># 查看Pod详情</span>$ kubectl get pods -o wideNAME                                      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESpod-podaffinity-deploy-67b85c69b9-74s92   1/1     Running   0          6s    172.16.85.228   k8s-node01   &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-67b85c69b9-kzdkj   1/1     Running   0          6s    172.16.85.220   k8s-node01   &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-67b85c69b9-mlnzf   1/1     Running   0          6s    172.16.85.222   k8s-node01   &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-67b85c69b9-n7c4k   1/1     Running   0          6s    172.16.85.221   k8s-node01   &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-67b85c69b9-r6ps6   1/1     Running   0          6s    172.16.85.223   k8s-node01   &lt;none&gt;           &lt;none&gt;pod-podaffinity-deploy-67b85c69b9-wwfld   1/1     Running   0          6s    172.16.85.219   k8s-node01   &lt;none&gt;           &lt;none&gt;web-deploy-7b868c54f5-x78hw               1/1     Running   0          14h   172.16.58.243   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>由于是Pod反亲和测验，再根据 master、k8s-node01、k8s-node02的标签信息；很容易推断出 Pod 会优先调度到 k8s-node01 节点。</p><h4 id="3-2-6-pod-亲和性与反亲和性联合示例"><a href="#3-2-6-pod-亲和性与反亲和性联合示例" class="headerlink" title="3.2.6 pod 亲和性与反亲和性联合示例"></a>3.2.6 pod 亲和性与反亲和性联合示例</h4><p>资源清单：<code>pod_podAffinity_all.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-podaffinity-all-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">podaffinity-all-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">tolerations:</span> <span class="comment"># 配置容忍，允许运行到 Master 节点上</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/control-plane</span>          <span class="attr">effect:</span> <span class="string">NoSchedule</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">affinity:</span>        <span class="attr">podAffinity:</span> <span class="comment"># Pod亲和性</span>          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 硬策略</span>            <span class="comment"># 由于是Pod亲和性/反亲和性， 因此这里匹配规则写的是Pod的标签信息</span>            <span class="bullet">-</span> <span class="attr">labelSelector:</span>                <span class="attr">matchExpressions:</span>                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span>                    <span class="attr">operator:</span> <span class="string">In</span>                    <span class="attr">values:</span>                      <span class="bullet">-</span> <span class="string">myapp-web</span>              <span class="comment"># 拓扑域  若多个node节点具有相同的标签信息【标签键值相同】，则表示这些node节点就在同一拓扑域</span>              <span class="attr">topologyKey:</span> <span class="string">disk-type</span>        <span class="attr">podAntiAffinity:</span> <span class="comment"># Pod反亲和性</span>          <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span> <span class="comment"># 软策略</span>            <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">100</span>              <span class="attr">podAffinityTerm:</span>                <span class="attr">labelSelector:</span>                  <span class="attr">matchExpressions:</span>                    <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">version</span>                      <span class="attr">operator:</span> <span class="string">In</span>                      <span class="attr">values:</span>                        <span class="bullet">-</span> <span class="string">v1</span>                        <span class="bullet">-</span> <span class="string">v2</span>                <span class="attr">topologyKey:</span> <span class="string">disk-type</span></code></pre><p>运行yaml文件并查看状态</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 Deployment 和 Pod</span>$ kubectl apply -f pod_podAffinity_all.yaml<span class="comment"># 查看 Deployment</span>$ kubectl get deploy -o wideNAME                         READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                     SELECTORpod-podaffinity-all-deploy   6/6     6            6           6s    myapp-pod    wangyanglinux/myapp:v1.0   app=myappweb-deploy                   1/1     1            1           14h   myapp-pod    wangyanglinux/myapp:v1.0   app=myapp-web<span class="comment"># 查看 Pod</span>$ kubectl get pods -o wideNAME                                          READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESpod-podaffinity-all-deploy-6d9d4f8fd4-5knr4   1/1     Running   0          11s   172.16.58.233    k8s-node02   &lt;none&gt;           &lt;none&gt;pod-podaffinity-all-deploy-6d9d4f8fd4-9hw46   1/1     Running   0          11s   172.16.167.142   node         &lt;none&gt;           &lt;none&gt;pod-podaffinity-all-deploy-6d9d4f8fd4-csprs   1/1     Running   0          11s   172.16.167.141   node         &lt;none&gt;           &lt;none&gt;pod-podaffinity-all-deploy-6d9d4f8fd4-md5f2   1/1     Running   0          11s   172.16.58.222    k8s-node02   &lt;none&gt;           &lt;none&gt;pod-podaffinity-all-deploy-6d9d4f8fd4-rlm76   1/1     Running   0          11s   172.16.167.140   node         &lt;none&gt;           &lt;none&gt;pod-podaffinity-all-deploy-6d9d4f8fd4-vcmv7   1/1     Running   0          11s   172.16.58.253    k8s-node02   &lt;none&gt;           &lt;none&gt;web-deploy-7b868c54f5-x78hw                   1/1     Running   0          14h   172.16.58.243    k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>调度解析：在这个示例中，Pod 的亲和性和 Pod 的反亲和性是冲突的，因为他们指向的节点都是 k8s-node02, 但是由于Pod 亲和性采用的是硬策略，优先级更高，因此最终产生的 Pod 会调度在 k8s-node02 节点和 master 节点上。</p><h1 id="三、污点与容忍"><a href="#三、污点与容忍" class="headerlink" title="三、污点与容忍"></a>三、污点与容忍</h1><h2 id="1-概述-1"><a href="#1-概述-1" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>节点和 Pod 亲和力，是将 Pod 吸引到一组节点【根据拓扑域】（作为优选或硬性要求）。污点（Taints）则相反，它们允许一个节点排斥一组 Pod。</p><p>容忍（Tolerations）应用于 pod，允许（但不强制要求）pod 调度到具有匹配污点的节点上。</p><p>污点（Taints）和容忍（Tolerations）共同作用，确保 pods 不会被调度到不适当的节点。一个或多个污点应用于节点；这标志着该节点不应该接受任何不容忍污点的 Pod 。</p><p>说明：我们在平常使用中发现pod不会调度到k8s的master节点，就是因为master节点存在污点。</p><h2 id="2-Taints-污点"><a href="#2-Taints-污点" class="headerlink" title="2. Taints 污点"></a>2. Taints 污点</h2><p>使用 kubectl taint 命令可以给某个 Node 节点设置污点，Node 被设置污点之后就和 Pod 之间存在一种相斥的关系，可以让 Node 拒绝Pod的调度执行，甚至将Node 上已经存在的 Pod 驱逐出去。</p><p>每个污点的组成如下：</p><pre><code class="highlight bash">key=value:effect</code></pre><p>每个污点有一个 key 和 value 作为污点的标签，effect描述污点的作用。当前 taint effect 支持如下选项：</p><ul><li>NoSchedule：表示 K8S 将不会把 Pod 调度到具有该污点的 Node 节点上</li><li>PreferNoSchedule：表示 K8S 将尽量避免把 Pod 调度到具有该污点的 Node 节点上</li><li>NoExecute：表示 K8S 将不会把 Pod 调度到具有该污点的 Node 节点上，同时会将 Node 上已经存在的 Pod 驱逐出去</li></ul><h3 id="2-1-污点taint的NoExecute详解"><a href="#2-1-污点taint的NoExecute详解" class="headerlink" title="2.1 污点taint的NoExecute详解"></a>2.1 污点taint的NoExecute详解</h3><p>taint 的 effect 值 NoExecute，它会影响已经在节点上运行的 pod：</p><ul><li>如果 pod 不能容忍 effect 值为 NoExecute 的 taint，那么 pod 将马上被驱逐</li><li>如果 pod 能够容忍 effect 值为 NoExecute 的 taint，且在 toleration 定义中没有指定 tolerationSeconds，则 pod 会一直在这个节点上运行。</li><li>如果 pod 能够容忍 effect 值为 NoExecute 的 taint，但是在toleration定义中指定了 tolerationSeconds，则表示 pod 还能在这个节点上继续运行的时间长度。</li></ul><h3 id="2-2-Taints污点设置"><a href="#2-2-Taints污点设置" class="headerlink" title="2.2 Taints污点设置"></a>2.2 Taints污点设置</h3><h4 id="2-2-1-污点（Taints）查看"><a href="#2-2-1-污点（Taints）查看" class="headerlink" title="2.2.1 污点（Taints）查看"></a>2.2.1 污点（Taints）查看</h4><pre><code class="highlight bash"><span class="comment"># 查看 master 节点的污点（master 节点的名称也叫node）</span>$ kubectl describe node node</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/06/20250606-113704.png" alt="查看master节点的污点"></p><p>查看 k8s-node01 节点的污点</p><pre><code class="highlight bash">$ kubectl describe node k8s-node01</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/06/06/20250606-113844.png" alt="查看 k8s-node01 节点的污点"></p><h4 id="2-2-2-污点（Taints）添加"><a href="#2-2-2-污点（Taints）添加" class="headerlink" title="2.2.2 污点（Taints）添加"></a>2.2.2 污点（Taints）添加</h4><pre><code class="highlight bash"><span class="comment"># 给 k8s-node01 设置污点</span>$ kubectl taint node k8s-node01 check=george:NoSchedulenode/k8s-node01 tainted<span class="comment"># 查看 k8s-node01 节点设置的污点</span>$ kubectl describe node k8s-node01Name:               k8s-node01Roles:              &lt;none&gt;Labels:             beta.kubernetes.io/arch=amd64                    beta.kubernetes.io/os=linux                    busi-db=redis                    busi-use=www                    disk-type=sata                    kubernetes.io/arch=amd64                    kubernetes.io/hostname=k8s-node01                    kubernetes.io/os=linuxAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock                    node.alpha.kubernetes.io/ttl: 0                    projectcalico.org/IPv4Address: 192.168.6.140/24                    projectcalico.org/IPv4IPIPTunnelAddr: 172.16.85.192                    volumes.kubernetes.io/controller-managed-attach-detach: <span class="literal">true</span>CreationTimestamp:  Fri, 28 Mar 2025 17:31:29 +0800Taints:             check=george:NoSchedule <span class="comment"># 已设置污点</span>Unschedulable:      <span class="literal">false</span></code></pre><p>在 k8s-node01 节点添加了一个污点（taint），污点的 key 为 check，value 为 george，污点 effec 为 NoSchedule。这意味着没有 pod 可以调度到 k8s-node01 节点，除非具有相匹配的容忍。</p><h4 id="2-2-3-污点（Taints）删除"><a href="#2-2-3-污点（Taints）删除" class="headerlink" title="2.2.3 污点（Taints）删除"></a>2.2.3 污点（Taints）删除</h4><pre><code class="highlight bash"><span class="comment"># 污点删除：方式一</span>$ kubectl taint nodes k8s-node01 check:NoSchedule-node/k8s-node01 untainted<span class="comment"># 污点删除：方式二</span>$ kubectl taint nodes k8s-node01 check=george:NoSchedule-<span class="comment"># 查看 k8s-node01 污点</span>$ kubectl describe node k8s-node01Name:               k8s-node01Roles:              &lt;none&gt;Labels:             beta.kubernetes.io/arch=amd64                    beta.kubernetes.io/os=linux                    busi-db=redis                    busi-use=www                    disk-type=sata                    kubernetes.io/arch=amd64                    kubernetes.io/hostname=k8s-node01                    kubernetes.io/os=linuxAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock                    node.alpha.kubernetes.io/ttl: 0                    projectcalico.org/IPv4Address: 192.168.6.140/24                    projectcalico.org/IPv4IPIPTunnelAddr: 172.16.85.192                    volumes.kubernetes.io/controller-managed-attach-detach: <span class="literal">true</span>CreationTimestamp:  Fri, 28 Mar 2025 17:31:29 +0800Taints:             &lt;none&gt; <span class="comment"># 污点已删除</span>Unschedulable:      <span class="literal">false</span></code></pre><h2 id="3-Tolerations-容忍"><a href="#3-Tolerations-容忍" class="headerlink" title="3. Tolerations 容忍"></a>3. Tolerations 容忍</h2><p>设置了污点的 Node 将根据 taint 的 effect：NoSchedule、PreferNoSchedule、NoExecute 和 Pod 之间产生互斥的关系，Pod 将在一定程度上不会被调度到 Node上。</p><p>但我们可以在 Pod 上设置容忍（Tolerations），意思是设置了容忍的 Pod 将可以容忍污点的存在，可以被调度到存在污点的 Node 上。</p><h3 id="3-1-容忍设置示例"><a href="#3-1-容忍设置示例" class="headerlink" title="3.1 容忍设置示例"></a>3.1 容忍设置示例</h3><p><strong>pod.spec.tolerations示例</strong></p><pre><code class="highlight yaml"><span class="attr">tolerations:</span><span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;key&quot;</span>  <span class="attr">operator:</span> <span class="string">&quot;Equal&quot;</span>  <span class="attr">value:</span> <span class="string">&quot;value&quot;</span>  <span class="attr">effect:</span> <span class="string">&quot;NoSchedule&quot;</span><span class="meta">---</span><span class="attr">tolerations:</span><span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;key&quot;</span>  <span class="attr">operator:</span> <span class="string">&quot;Exists&quot;</span>  <span class="attr">effect:</span> <span class="string">&quot;NoSchedule&quot;</span><span class="meta">---</span><span class="attr">tolerations:</span><span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;key&quot;</span>  <span class="attr">operator:</span> <span class="string">&quot;Equal&quot;</span>  <span class="attr">value:</span> <span class="string">&quot;value&quot;</span>  <span class="attr">effect:</span> <span class="string">&quot;NoExecute&quot;</span>  <span class="attr">tolerationSeconds:</span> <span class="number">3600</span></code></pre><p><strong>重要说明：</strong></p><ul><li>其中 key、value、effect 要与 Node 上设置的 taint 保持一致</li><li>operator 的值为 Exists 时，将会忽略 value；只要有 key 和 effect 就行</li><li>tolerationSeconds：表示 pod 能够容忍 effect 值为 NoExecute 的 taint；当指定了 tolerationSeconds【容忍时间】，则表示 pod 还能在这个节点上继续运行的时间长度。</li></ul><h3 id="3-2-当不指定key值时"><a href="#3-2-当不指定key值时" class="headerlink" title="3.2 当不指定key值时"></a>3.2 当不指定key值时</h3><p>当不指定 key 值和 effect 值时，且 operator 为 Exists，表示容忍所有的污点【能匹配污点所有的 keys，values 和 effects】</p><pre><code class="highlight yaml"><span class="attr">tolerations:</span><span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">&quot;Exists&quot;</span></code></pre><h3 id="3-3-当不指定effect值时"><a href="#3-3-当不指定effect值时" class="headerlink" title="3.3 当不指定effect值时"></a>3.3 当不指定effect值时</h3><p>当不指定 effect 值时，则能匹配污点 key 对应的所有 effects 情况</p><pre><code class="highlight yaml"><span class="attr">tolerations:</span><span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;key&quot;</span>  <span class="attr">operator:</span> <span class="string">&quot;Exists&quot;</span></code></pre><h3 id="3-4-当有多个Master存在时"><a href="#3-4-当有多个Master存在时" class="headerlink" title="3.4 当有多个Master存在时"></a>3.4 当有多个Master存在时</h3><p>当有多个Master存在时，为了防止资源浪费，可以进行如下设置：</p><pre><code class="highlight bash">kubectl taint nodes Node-name node-role.kubernetes.io/control-plane=:PreferNoSchedule</code></pre><h2 id="4-多个-Taints-污点和多个-Tolerations-容忍怎么判断"><a href="#4-多个-Taints-污点和多个-Tolerations-容忍怎么判断" class="headerlink" title="4. 多个 Taints 污点和多个 Tolerations 容忍怎么判断"></a>4. 多个 Taints 污点和多个 Tolerations 容忍怎么判断</h2><p>可以在同一个 node 节点上设置多个污点（Taints），在同一个 pod 上设置多个容忍（Tolerations）。Kubernetes 处理多个污点和容忍的方式就像一个过滤器：从节点的所有污点开始，然后忽略可以被 Pod 容忍匹配的污点；保留其余不可忽略的污点，污点的 effect 对 Pod 具有显示效果：特别是：</p><ul><li>如果有至少一个不可忽略污点，effect 为 NoSchedule，那么 Kubernetes 将不调度 Pod 到该节点</li><li>如果没有 effect 为 NoSchedule 的不可忽视污点，但有至少一个不可忽视污点，effect 为 PreferNoSchedule，那么 Kubernetes 将尽量不调度 Pod 到该节点</li><li>如果有至少一个不可忽视污点，effect 为 NoExecute，那么 Pod 将被从该节点驱逐（如果 Pod 已经在该节点运行），并且不会被调度到该节点（如果 Pod 还未在该节点运行）</li></ul><h2 id="5-污点和容忍示例"><a href="#5-污点和容忍示例" class="headerlink" title="5. 污点和容忍示例"></a>5. 污点和容忍示例</h2><h3 id="5-1-Node-污点为-NoExecute-的示例"><a href="#5-1-Node-污点为-NoExecute-的示例" class="headerlink" title="5.1 Node 污点为 NoExecute 的示例"></a>5.1 Node 污点为 NoExecute 的示例</h3><p><em>目标：测试给节点添加 effect 为 NoExecute 的污点，是否会驱逐已经运行的 Pod。</em></p><p>注意：在开始测试实验前，将节点添加的污点清除。</p><p><strong>初始状态下</strong></p><ul><li>master 节点污点为：node-role.kubernetes.io&#x2F;control-plane:NoSchedule</li><li>k8s-node01 节点污点为空</li><li>k8s-node02 节点污点为空</li></ul><p><strong>查看污点</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 master 节点的污点设置</span>$ kubectl describe node node | grep <span class="string">&#x27;Taints&#x27;</span> -A 5<span class="comment"># 查看 k8s-node01 节点的污点设置</span>$ kubectl describe node k8s-node01 | grep <span class="string">&#x27;Taints&#x27;</span> -A 5<span class="comment"># 查看 k8s-node02 节点的污点设置</span>$ kubectl describe node k8s-node02 | grep <span class="string">&#x27;Taints&#x27;</span> -A 5</code></pre><p>除了 master 默认的污点，在 k8s-node01、k8s-node02 无污点。</p><p><strong>污点为NoExecute示例</strong></p><p>资源清单：<code>noexecute_tolerations.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">noexec-tolerations-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">noexectolerations-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></code></pre><p>执行资源清单</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 Pod</span>$ kubectl apply -f noexecute_tolerations.yaml<span class="comment"># 查看 Pod 运行详情</span>$ kubectl get pods -o wideNAME                                         READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnoexec-tolerations-deploy-75dbf9dcdc-4vd9c   1/1     Running   0          46s   172.16.58.224   k8s-node02   &lt;none&gt;           &lt;none&gt;noexec-tolerations-deploy-75dbf9dcdc-76k76   1/1     Running   0          46s   172.16.85.227   k8s-node01   &lt;none&gt;           &lt;none&gt;noexec-tolerations-deploy-75dbf9dcdc-nm7xd   1/1     Running   0          46s   172.16.58.196   k8s-node02   &lt;none&gt;           &lt;none&gt;noexec-tolerations-deploy-75dbf9dcdc-pp2f7   1/1     Running   0          46s   172.16.85.230   k8s-node01   &lt;none&gt;           &lt;none&gt;noexec-tolerations-deploy-75dbf9dcdc-x92bz   1/1     Running   0          46s   172.16.85.225   k8s-node01   &lt;none&gt;           &lt;none&gt;noexec-tolerations-deploy-75dbf9dcdc-xfc25   1/1     Running   0          46s   172.16.58.211   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>此时 k8s-node01 与 k8s-node02 节点没有设置 taint，资源清单也没有添加 tolerations ，此时 Pod 在这两个节点上均匀的分布。</p><p><strong>给 k8s-node02 节点添加 effect 为 NoExecute 的污点</strong></p><pre><code class="highlight bash">$ kubectl taint nodes k8s-node02 check-mem=memdb:NoExecute</code></pre><p>此时再查看集群中节点的污点设置情况如下：</p><ul><li>master 节点污点为：node-role.kubernetes.io&#x2F;control-plane:NoSchedule</li><li>k8s-node01 节点污点为空</li><li>k8s-node02 节点污点：check-mem&#x3D;memdb:NoExecute</li></ul><p><strong>再次查看Pod分布</strong></p><pre><code class="highlight bash">$ kubectl get pods -o wideNAME                                         READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnoexec-tolerations-deploy-75dbf9dcdc-76k76   1/1     Running   0          13m   172.16.85.227   k8s-node01   &lt;none&gt;           &lt;none&gt;noexec-tolerations-deploy-75dbf9dcdc-ctj5q   1/1     Running   0          83s   172.16.85.234   k8s-node01   &lt;none&gt;           &lt;none&gt;noexec-tolerations-deploy-75dbf9dcdc-pp2f7   1/1     Running   0          13m   172.16.85.230   k8s-node01   &lt;none&gt;           &lt;none&gt;noexec-tolerations-deploy-75dbf9dcdc-qpsxh   1/1     Running   0          83s   172.16.85.226   k8s-node01   &lt;none&gt;           &lt;none&gt;noexec-tolerations-deploy-75dbf9dcdc-x92bz   1/1     Running   0          13m   172.16.85.225   k8s-node01   &lt;none&gt;           &lt;none&gt;noexec-tolerations-deploy-75dbf9dcdc-z72r2   1/1     Running   0          83s   172.16.85.232   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>所有 Pod 都已转移到 k8s-node01 节点上了，原本运行在 k8s-node02 节点上的 Pod 都被驱逐。</p><h3 id="5-2-Pod-没有容忍时（Tolerations）"><a href="#5-2-Pod-没有容忍时（Tolerations）" class="headerlink" title="5.2 Pod 没有容忍时（Tolerations）"></a>5.2 Pod 没有容忍时（Tolerations）</h3><p>目标：测试在节点设置了污点，且 Pod 没有设置容忍时，观察 k8s 对 Pod 的调度情况</p><p>注意：在实验前，将之前给节点添加的污点删除，避免对后面的实验产生影响。</p><p><strong>给节点设置污点</strong></p><pre><code class="highlight bash"><span class="comment"># 删除 node02 污点</span>$ kubectl taint nodes k8s-node02 check-mem:NoExecute-<span class="comment"># 给 node01 设置污点</span>$ kubectl taint nodes k8s-node01 check-nginx=web:PreferNoSchedule<span class="comment"># 给 node02 设置污点</span>$ kubectl taint nodes k8s-node02 check-nginx=web:NoSchedule</code></pre><p><strong>当前集群节点的污点设置情况</strong></p><ul><li>master 节点污点为：node-role.kubernetes.io&#x2F;control-plane:NoSchedule</li><li>k8s-node01 节点污点为：check-nginx&#x3D;web:PreferNoSchedule</li><li>k8s-node02 节点污点为：check-nginx&#x3D;web:NoSchedule</li></ul><p><strong>资源清单</strong></p><p><code>no_tolerations.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="literal">no</span><span class="string">-tolerations-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">notolerations-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></code></pre><p>执行资源清单</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 Pod</span>$ kubectl apply -f no_tolerations.yaml<span class="comment"># 查看 Pod 详情</span>$ kubectl get pods -o wideNAME                                     READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESno-tolerations-deploy-75dbf9dcdc-2242k   1/1     Running   0          6s    172.16.85.236   k8s-node01   &lt;none&gt;           &lt;none&gt;no-tolerations-deploy-75dbf9dcdc-5q5sd   1/1     Running   0          6s    172.16.85.240   k8s-node01   &lt;none&gt;           &lt;none&gt;no-tolerations-deploy-75dbf9dcdc-b2ztm   1/1     Running   0          6s    172.16.85.239   k8s-node01   &lt;none&gt;           &lt;none&gt;no-tolerations-deploy-75dbf9dcdc-crnp9   1/1     Running   0          6s    172.16.85.235   k8s-node01   &lt;none&gt;           &lt;none&gt;no-tolerations-deploy-75dbf9dcdc-ktcz6   1/1     Running   0          6s    172.16.85.237   k8s-node01   &lt;none&gt;           &lt;none&gt;no-tolerations-deploy-75dbf9dcdc-xjr5f   1/1     Running   0          6s    172.16.85.233   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>因为 k8s-node02 节点的污点 check-nginx 的 effect 为 NoSchedule，说明 pod 不能被调度到该节点。此时 k8s-node01 节点的污点 check-nginx 的 effect 为PreferNoSchedule【尽量不调度到该节点】；但只有该节点满足调度条件，因此都调度到了 k8s-node01 节点。</p><h3 id="5-3-Pod-单个容忍时（Tolerations）"><a href="#5-3-Pod-单个容忍时（Tolerations）" class="headerlink" title="5.3 Pod 单个容忍时（Tolerations）"></a>5.3 Pod 单个容忍时（Tolerations）</h3><p>目标：测试在节点设置了污点，给 Pod 设置一个容忍时，观察 k8s 对 Pod 的调度情况</p><p>注意：在实验前，将之前给节点添加的污点删除，避免对后面的实验产生影响。</p><p><strong>给节点设置污点</strong></p><pre><code class="highlight bash"><span class="comment"># 给 node01 设置污点</span>$ kubectl taint nodes k8s-node01 check-nginx=web:PreferNoSchedule<span class="comment"># 给 node02 设置污点</span>$ kubectl taint nodes k8s-node02 check-nginx=web:NoSchedule</code></pre><p><strong>当前集群节点的污点设置情况</strong></p><ul><li>master 节点污点为：node-role.kubernetes.io&#x2F;control-plane:NoSchedule</li><li>k8s-node01 节点污点为：check-nginx&#x3D;web:PreferNoSchedule</li><li>k8s-node02 节点污点为：check-nginx&#x3D;web:NoSchedule</li></ul><p><strong>单个容忍的示例</strong></p><p>资源清单：<code>one_tolerations.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">one-tolerations-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">onetolerations-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">30</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">tolerations:</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;check-nginx&quot;</span>          <span class="attr">operator:</span> <span class="string">&quot;Equal&quot;</span>          <span class="attr">value:</span> <span class="string">&quot;web&quot;</span>          <span class="attr">effect:</span> <span class="string">&quot;NoSchedule&quot;</span></code></pre><p>执行资源清单</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 Pod</span>$ kubectl apply -f one_tolerations.yaml<span class="comment"># 查看 Pod 调度详情</span>$ kubectl get pods -o wideNAME                                    READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESno-tolerations-deploy-6675cffc9-ccz55   1/1     Running   0          6s    172.16.58.226   k8s-node02   &lt;none&gt;           &lt;none&gt;no-tolerations-deploy-6675cffc9-ff5m4   1/1     Running   0          6s    172.16.58.214   k8s-node02   &lt;none&gt;           &lt;none&gt;no-tolerations-deploy-6675cffc9-mg99m   1/1     Running   0          6s    172.16.58.248   k8s-node02   &lt;none&gt;           &lt;none&gt;no-tolerations-deploy-6675cffc9-pdqvh   1/1     Running   0          6s    172.16.58.242   k8s-node02   &lt;none&gt;           &lt;none&gt;no-tolerations-deploy-6675cffc9-s8bxh   1/1     Running   0          6s    172.16.58.217   k8s-node02   &lt;none&gt;           &lt;none&gt;no-tolerations-deploy-6675cffc9-zjzkl   1/1     Running   0          6s    172.16.58.221   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>由于给 Pod 添加了容忍（针对 node02 节点），因此 Pod 可以运行到 k8s-node02 节点上。但是没有运行到 k8s-node01 节点上，这是由于 node01 节点的 污点 effect 设置为 PreferNoSchedule （尽可能不调度），因此只有当 node02 节点的压力比较大时，才会往 node01 节点调度。</p><p><strong>给Pod添加副本，让Pod调度到 k8s-node01 节点</strong></p><pre><code class="highlight bash"><span class="comment"># Pod 副本数扩展到 120个</span>$ kubectl scale deployment one-tolerations-deploy --replicas 120<span class="comment"># 再次查看 Pod 调度情况</span>$ kubectl get pods -o wideNAME                                     READY   STATUS              RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESone-tolerations-deploy-6675cffc9-2ff55   0/1     ContainerCreating   0          2s      &lt;none&gt;          k8s-node01   &lt;none&gt;           &lt;none&gt;one-tolerations-deploy-6675cffc9-2k7pm   1/1     Running             0          35s     172.16.58.243   k8s-node02   &lt;none&gt;           &lt;none&gt;one-tolerations-deploy-6675cffc9-2tkw9   0/1     ContainerCreating   0          2s      &lt;none&gt;          k8s-node02   &lt;none&gt;           &lt;none&gt;......</code></pre><p>终于让 node01 节点也运行了 Pod 了。</p><h3 id="5-4-Pod多个容忍时（Tolerations）"><a href="#5-4-Pod多个容忍时（Tolerations）" class="headerlink" title="5.4 Pod多个容忍时（Tolerations）"></a>5.4 Pod多个容忍时（Tolerations）</h3><p>目标：测试在节点设置了污点，给 Pod 设置多个容忍时，观察 k8s 对 Pod 的调度情况</p><p>注意：在实验前，将之前给节点添加的污点删除，避免对后面的实验产生影响。</p><p><strong>给节点设置污点</strong></p><pre><code class="highlight bash"><span class="comment"># 给 node01 设置污点</span>$ kubectl taint nodes k8s-node01 check-nginx=web:PreferNoSchedule$ kubectl taint nodes k8s-node01 check-redis=memdb:NoSchedule<span class="comment"># 给 node02 设置污点</span>$ kubectl taint nodes k8s-node02 check-nginx=web:NoSchedule$ kubectl taint nodes k8s-node02 check-redis=database:NoSchedule</code></pre><p><strong>当前集群节点的污点设置情况</strong></p><ul><li>master 节点污点为：node-role.kubernetes.io&#x2F;control-plane:NoSchedule</li><li>k8s-node01 节点污点为：check-nginx&#x3D;web:PreferNoSchedule、check-redis&#x3D;memdb:NoSchedule</li><li>k8s-node02 节点污点为：check-nginx&#x3D;web:NoSchedule、check-redis&#x3D;database:NoSchedule</li></ul><p><strong>污点查看操作如下：</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 master 节点的污点（master节点名称叫 node）</span>kubectl describe node node | grep <span class="string">&#x27;Taints&#x27;</span> -A 5<span class="comment"># 查看 k8s-node01 节点的污点</span>kubectl describe node k8s-node01 | grep <span class="string">&#x27;Taints&#x27;</span> -A 5<span class="comment"># 查看 k8s-node02 节点的污点</span>kubectl describe node k8s-node02 | grep <span class="string">&#x27;Taints&#x27;</span> -A 5</code></pre><p><strong>多个容忍示例</strong></p><p>资源清单：<code>multi_tolerations.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">multi-tolerations-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">multitolerations-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">tolerations:</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;check-nginx&quot;</span>          <span class="attr">operator:</span> <span class="string">&quot;Equal&quot;</span>          <span class="attr">value:</span> <span class="string">&quot;web&quot;</span>          <span class="attr">effect:</span> <span class="string">&quot;NoSchedule&quot;</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">check-redis</span>          <span class="attr">operator:</span> <span class="string">Exists</span>          <span class="attr">effect:</span> <span class="string">NoSchedule</span></code></pre><p>执行资源清单</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f multi_tolerations.yaml <span class="comment"># 查看Pod</span>$ kubectl get pods -o wideNAME                                        READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESmulti-tolerations-deploy-6879db4797-8qqzg   1/1     Running   0          3s    172.16.58.231   k8s-node02   &lt;none&gt;           &lt;none&gt;multi-tolerations-deploy-6879db4797-9hgn9   1/1     Running   0          3s    172.16.58.211   k8s-node02   &lt;none&gt;           &lt;none&gt;multi-tolerations-deploy-6879db4797-gfnwm   1/1     Running   0          3s    172.16.58.241   k8s-node02   &lt;none&gt;           &lt;none&gt;multi-tolerations-deploy-6879db4797-k5twd   1/1     Running   0          3s    172.16.58.205   k8s-node02   &lt;none&gt;           &lt;none&gt;multi-tolerations-deploy-6879db4797-k5z7x   1/1     Running   0          3s    172.16.58.230   k8s-node02   &lt;none&gt;           &lt;none&gt;multi-tolerations-deploy-6879db4797-rhlnx   1/1     Running   0          3s    172.16.58.234   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>示例中的pod容忍为：check-nginx&#x3D;web:NoSchedule；check-redis&#x3D;:NoSchedule。因此 pod 会尽量调度到k8s-node02节点，尽量不调度到 k8s-node01 节点。</p><h3 id="5-5-Pod容忍指定污点key的所有effects情况"><a href="#5-5-Pod容忍指定污点key的所有effects情况" class="headerlink" title="5.5 Pod容忍指定污点key的所有effects情况"></a>5.5 Pod容忍指定污点key的所有effects情况</h3><p>实验目的：测试 Pod 容忍设置了 key 后，将 operator 设置为 Exists 时，节点的调度情况。</p><p>提示：把已有的污点清除，以免影响测验。</p><pre><code class="highlight bash"><span class="comment"># 删除污点</span>kubectl taint nodes k8s-node01 check-redis=memdb:NoSchedule- check-nginx=web:PreferNoSchedule-kubectl taint nodes k8s-node02 check-nginx=web:NoSchedule- check-redis=database:NoSchedule-</code></pre><p><strong>节点上的污点设置（Taints）</strong></p><pre><code class="highlight bash">kubectl taint nodes k8s-node01 check-redis=memdb:NoSchedulekubectl taint nodes k8s-node02 check-redis=database:NoSchedule</code></pre><p><strong>当前集群节点的污点设置情况</strong></p><ul><li>master 节点污点为：node-role.kubernetes.io&#x2F;control-plane:NoSchedule</li><li>k8s-node01 节点污点为：check-redis&#x3D;memdb:NoSchedule</li><li>k8s-node02 节点污点为：check-redis&#x3D;database:NoSchedule</li></ul><p><strong>污点查看操作如下：</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 master 节点的污点（master节点名称叫 node）</span>kubectl describe node node | grep <span class="string">&#x27;Taints&#x27;</span> -A 5<span class="comment"># 查看 k8s-node01 节点的污点</span>kubectl describe node k8s-node01 | grep <span class="string">&#x27;Taints&#x27;</span> -A 5<span class="comment"># 查看 k8s-node02 节点的污点</span>kubectl describe node k8s-node02 | grep <span class="string">&#x27;Taints&#x27;</span> -A 5</code></pre><p><strong>指定污点key的所有effects示例</strong></p><p>资源清单：<code>key_tolerations.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">key-tolerations-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">keytolerations-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">tolerations:</span> <span class="comment"># 容忍指定污点key的所有effects</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">check-redis</span>          <span class="attr">operator:</span> <span class="string">Exists</span></code></pre><p>执行资源清单，查看状态</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建 Pod</span>$ kubectl apply -f key_tolerations.yaml<span class="comment"># 查看 Deployment</span>$ kubectl get deploy -o wideNAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                     SELECTORkey-tolerations-deploy   6/6     6            6           18s   myapp-pod    wangyanglinux/myapp:v1.0   app=myapp<span class="comment"># 查看 Pod </span>$ kubectl get pods -o wideNAME                                     READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESkey-tolerations-deploy-65c6c87cd-k8xdg   1/1     Running   0          24s   172.16.85.214   k8s-node01   &lt;none&gt;           &lt;none&gt;key-tolerations-deploy-65c6c87cd-lvmcv   1/1     Running   0          24s   172.16.58.201   k8s-node02   &lt;none&gt;           &lt;none&gt;key-tolerations-deploy-65c6c87cd-njdhh   1/1     Running   0          24s   172.16.58.228   k8s-node02   &lt;none&gt;           &lt;none&gt;key-tolerations-deploy-65c6c87cd-ppcs5   1/1     Running   0          24s   172.16.58.226   k8s-node02   &lt;none&gt;           &lt;none&gt;key-tolerations-deploy-65c6c87cd-ts7zn   1/1     Running   0          24s   172.16.85.208   k8s-node01   &lt;none&gt;           &lt;none&gt;key-tolerations-deploy-65c6c87cd-x25nb   1/1     Running   0          24s   172.16.58.207   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>Pod 在 k8s-node01 k8s-node02 节点都有运行，虽然两个节点 Taint 设置的 value 不同，Key相同，由于资源清单中设置的 <code>tolerations.operator: Exists</code> 所有两个节点都有机会被调度执行。</p><h3 id="5-6-Pod容忍所有污点"><a href="#5-6-Pod容忍所有污点" class="headerlink" title="5.6 Pod容忍所有污点"></a>5.6 Pod容忍所有污点</h3><p>实验目的：测试 Pod 容忍仅设置：<code>tolerations.operator: Exists</code>  时，节点的调度情况。</p><p>提示：把已有的污点清除，以免影响测验。</p><pre><code class="highlight bash"><span class="comment"># 删除污点</span>kubectl taint nodes k8s-node01 check-redis=memdb:NoSchedule- check-nginx=web:PreferNoSchedule-kubectl taint nodes k8s-node02 check-nginx=web:NoSchedule- check-redis=database:NoSchedule-</code></pre><p><strong>节点上的污点设置（Taints）</strong></p><pre><code class="highlight bash">kubectl taint nodes k8s-node01 check-nginx=web:PreferNoSchedule check-redis=memdb:NoSchedulekubectl taint nodes k8s-node02 check-nginx=web:NoSchedule check-redis=database:NoSchedule</code></pre><p><strong>当前集群节点的污点设置情况</strong></p><ul><li>master 节点污点为：node-role.kubernetes.io&#x2F;control-plane:NoSchedule</li><li>k8s-node01 节点污点为：check-redis&#x3D;memdb:NoSchedule 、check-nginx&#x3D;web:PreferNoSchedule</li><li>k8s-node02 节点污点为：check-redis&#x3D;database:NoSchedule、 check-nginx&#x3D;web:NoSchedule</li></ul><p><strong>污点查看操作如下：</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 master 节点的污点（master节点名称叫 node）</span>kubectl describe node node | grep <span class="string">&#x27;Taints&#x27;</span> -A 5<span class="comment"># 查看 k8s-node01 节点的污点</span>kubectl describe node k8s-node01 | grep <span class="string">&#x27;Taints&#x27;</span> -A 5<span class="comment"># 查看 k8s-node02 节点的污点</span>kubectl describe node k8s-node02 | grep <span class="string">&#x27;Taints&#x27;</span> -A 5</code></pre><p><strong>所有容忍示例</strong></p><p>资源清单：<code>all_tolerations.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">key-tolerations-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">keytolerations-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">tolerations:</span> <span class="comment"># 容忍所有污点</span>        <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">Exists</span></code></pre><p>执行资源清单，查看状态</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f all_tolerations.yaml$ kubectl get pods -o wideNAME                                      READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESkey-tolerations-deploy-7d8d44b494-5r7c9   1/1     Running   0          11s   172.16.167.143   node         &lt;none&gt;           &lt;none&gt;key-tolerations-deploy-7d8d44b494-bmzfq   1/1     Running   0          12s   172.16.58.220    k8s-node02   &lt;none&gt;           &lt;none&gt;key-tolerations-deploy-7d8d44b494-djhpm   1/1     Running   0          11s   172.16.85.210    k8s-node01   &lt;none&gt;           &lt;none&gt;key-tolerations-deploy-7d8d44b494-g4rxp   1/1     Running   0          11s   172.16.85.196    k8s-node01   &lt;none&gt;           &lt;none&gt;key-tolerations-deploy-7d8d44b494-s4qdh   1/1     Running   0          11s   172.16.58.238    k8s-node02   &lt;none&gt;           &lt;none&gt;key-tolerations-deploy-7d8d44b494-txtnq   1/1     Running   0          11s   172.16.167.144   node         &lt;none&gt;           &lt;none&gt;</code></pre><p>pod 在 master 节点、k8s-node01节点、k8s-node02 节点都有运行。</p><h1 id="四、固定节点nodeName和nodeSelector调度"><a href="#四、固定节点nodeName和nodeSelector调度" class="headerlink" title="四、固定节点nodeName和nodeSelector调度"></a>四、固定节点nodeName和nodeSelector调度</h1><p>nodeName 是节点选择约束的最简单形式，但是由于其限制，通常很少使用它。nodeName 是 PodSpec 的领域。</p><p><code>pod.spec.nodeName</code> 将 Pod 直接调度到指定的 Node 节点上，会【跳过 <code>Scheduler</code> 的调度策略】，该匹配规则是【强制】匹配。可以越过 <code>Taints</code> 污点进行调度。</p><p>nodeName用于选择节点的一些限制是：</p><ul><li>如果指定的节点不存在，则容器将不会运行，并且在某些情况下可能会自动删除。</li><li>如果指定的节点没有足够的资源来容纳该Pod，则该Pod将会失败，并且其原因将被指出，例如OutOfmemory或OutOfcpu。</li><li>云环境中的节点名称并非总是可预测或稳定的。</li></ul><h2 id="1-指定-nodeName-示例"><a href="#1-指定-nodeName-示例" class="headerlink" title="1. 指定 nodeName 示例"></a>1. 指定 nodeName 示例</h2><p><strong>当前集群节点如下：</strong></p><pre><code class="highlight bash">$ kubectl get nodeNAME         STATUS   ROLES           AGE   VERSIONk8s-node01   Ready    &lt;none&gt;          71d   v1.29.15k8s-node02   Ready    &lt;none&gt;          71d   v1.29.15node         Ready    control-plane   71d   v1.29.15</code></pre><h3 id="1-1-当-nodeName-指定节点存在"><a href="#1-1-当-nodeName-指定节点存在" class="headerlink" title="1.1 当 nodeName 指定节点存在"></a>1.1 当 nodeName 指定节点存在</h3><p>资源清单：<code>scheduler_nodeName.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">scheduler-nodename-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">nodename-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="comment"># 指定节点运行</span>      <span class="attr">nodeName:</span> <span class="string">node</span> <span class="comment"># 指定 master 节点运行，这里 master 节点的名称为 node</span></code></pre><p>执行资源清单，查看状态</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f scheduler_nodeName.yaml<span class="comment"># 查看 Deployment</span>$ kubectl get deployment -o wideNAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                     SELECTORscheduler-nodename-deploy   6/6     6            6           18s   myapp-pod    wangyanglinux/myapp:v1.0   app=myapp<span class="comment"># 查看 ReplicSet</span>$ kubectl get rs -o wideNAME                                   DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES                     SELECTORscheduler-nodename-deploy-6d6fdcbf6c   6         6         6       15s   myapp-pod    wangyanglinux/myapp:v1.0   app=myapp,pod-template-hash=6d6fdcbf6c<span class="comment"># 查看Pod</span>$ kubectl get pod -o wideNAME                                         READY   STATUS    RESTARTS   AGE   IP               NODE   NOMINATED NODE   READINESS GATESscheduler-nodename-deploy-6d6fdcbf6c-7crw8   1/1     Running   0          27s   172.16.167.147   node   &lt;none&gt;           &lt;none&gt;scheduler-nodename-deploy-6d6fdcbf6c-9kg4p   1/1     Running   0          27s   172.16.167.149   node   &lt;none&gt;           &lt;none&gt;scheduler-nodename-deploy-6d6fdcbf6c-j7qq4   1/1     Running   0          27s   172.16.167.150   node   &lt;none&gt;           &lt;none&gt;scheduler-nodename-deploy-6d6fdcbf6c-kz6n2   1/1     Running   0          28s   172.16.167.145   node   &lt;none&gt;           &lt;none&gt;scheduler-nodename-deploy-6d6fdcbf6c-v9tlk   1/1     Running   0          28s   172.16.167.146   node   &lt;none&gt;           &lt;none&gt;scheduler-nodename-deploy-6d6fdcbf6c-wr6jj   1/1     Running   0          28s   172.16.167.148   node   &lt;none&gt;           &lt;none&gt;</code></pre><p>可以看到 Pod 都运行到了 master 节点上，尽管 master 节点上存在着污点。由于设置了 nodeName, Scheduler 在调度时忽略了污点。</p><h3 id="1-2-当-nodeName-指定节点不存在"><a href="#1-2-当-nodeName-指定节点不存在" class="headerlink" title="1.2 当 nodeName 指定节点不存在"></a>1.2 当 nodeName 指定节点不存在</h3><p>资源清单：<code>scheduler_nodeName_02.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">scheduler-nodename-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">nodename-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="comment"># 指定节点运行</span>      <span class="attr">nodeName:</span> <span class="string">k8s-node05</span> <span class="comment"># 指定一个不存在的节点</span></code></pre><p>执行资源清单，查看状态</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f scheduler_nodeName02.yaml<span class="comment"># 查看 Deployment</span>$ kubectl get deployment -o wideNAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                     SELECTORscheduler-nodename-deploy   0/6     6            0           7s    myapp-pod    wangyanglinux/myapp:v1.0   app=myapp<span class="comment"># 查看 RS</span>$ kubectl get rs -o wideNAME                                   DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES                     SELECTORscheduler-nodename-deploy-765654657f   6         6         0       14s   myapp-pod    wangyanglinux/myapp:v1.0   app=myapp,pod-template-hash=765654657f<span class="comment"># 查看 Pod</span>$ kubectl get pod -o wideNAME                                         READY   STATUS    RESTARTS   AGE   IP       NODE         NOMINATED NODE   READINESS GATESscheduler-nodename-deploy-765654657f-898xn   0/1     Pending   0          22s   &lt;none&gt;   k8s-node05   &lt;none&gt;           &lt;none&gt;scheduler-nodename-deploy-765654657f-dbbqw   0/1     Pending   0          22s   &lt;none&gt;   k8s-node05   &lt;none&gt;           &lt;none&gt;scheduler-nodename-deploy-765654657f-gslks   0/1     Pending   0          22s   &lt;none&gt;   k8s-node05   &lt;none&gt;           &lt;none&gt;scheduler-nodename-deploy-765654657f-j5tnk   0/1     Pending   0          22s   &lt;none&gt;   k8s-node05   &lt;none&gt;           &lt;none&gt;scheduler-nodename-deploy-765654657f-s74wk   0/1     Pending   0          22s   &lt;none&gt;   k8s-node05   &lt;none&gt;           &lt;none&gt;scheduler-nodename-deploy-765654657f-smcmt   0/1     Pending   0          22s   &lt;none&gt;   k8s-node05   &lt;none&gt;           &lt;none&gt;</code></pre><p>由于 nodeName 指定的节点不存在, 因此 Pod 无法被调度。</p><h2 id="2-使用-nodeSelector-调度"><a href="#2-使用-nodeSelector-调度" class="headerlink" title="2. 使用 nodeSelector 调度"></a>2. 使用 nodeSelector 调度</h2><p>nodeSelector 是节点选择约束的最简单推荐形式。nodeSelector 是 PodSpec 的领域。它指定键值对的映射。</p><p><strong>pod.spec.nodeSelector 是通过 kubernetes 的 label-selector 机制选择节点，由调度器调度策略匹配 label，而后调度 Pod 到目标节点，该匹配规则属于【强制】约束。由于是调度器调度，因此不能越过Taints污点进行调度。</strong></p><p><strong>当前集群节点信息</strong></p><pre><code class="highlight bash">$ kubectl get node --show-labelsNAME         STATUS   ROLES           AGE   VERSION    LABELSk8s-node01   Ready    &lt;none&gt;          71d   v1.29.15   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,busi-db=redis,busi-use=www,disk-type=sata,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node01,kubernetes.io/os=linuxk8s-node02   Ready    &lt;none&gt;          71d   v1.29.15   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,busi-db=etcd,busi-use=www,disk-type=ssd,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node02,kubernetes.io/os=linuxnode         Ready    control-plane   71d   v1.29.15   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,busi-db=redis,busi-use=www,disk-type=ssd,kubernetes.io/arch=amd64,kubernetes.io/hostname=node,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node.kubernetes.io/exclude-from-external-load-balancers=</code></pre><h3 id="2-1-当-nodeSelector-标签存在"><a href="#2-1-当-nodeSelector-标签存在" class="headerlink" title="2.1 当 nodeSelector 标签存在"></a>2.1 当 nodeSelector 标签存在</h3><p>资源清单：<code>scheduler_nodeSelector.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">scheduler-nodeselector-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">nodeselector-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="comment"># 指定节点标签的 key: value</span>      <span class="attr">nodeSelector:</span>        <span class="attr">disk-type:</span> <span class="string">ssd</span></code></pre><p>执行资源清单，查看状态</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f scheduler_nodeSelector.yaml<span class="comment"># 查看 Pod </span>$ kubectl get pods -o wideNAME                                             READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESscheduler-nodeselector-deploy-84dccd9bf8-4vwh5   1/1     Running   0          15s   172.16.58.217   k8s-node02   &lt;none&gt;           &lt;none&gt;scheduler-nodeselector-deploy-84dccd9bf8-kbpl9   1/1     Running   0          15s   172.16.58.222   k8s-node02   &lt;none&gt;           &lt;none&gt;scheduler-nodeselector-deploy-84dccd9bf8-mvtp2   1/1     Running   0          15s   172.16.58.196   k8s-node02   &lt;none&gt;           &lt;none&gt;scheduler-nodeselector-deploy-84dccd9bf8-p568f   1/1     Running   0          15s   172.16.58.209   k8s-node02   &lt;none&gt;           &lt;none&gt;scheduler-nodeselector-deploy-84dccd9bf8-rmnf2   1/1     Running   0          15s   172.16.58.203   k8s-node02   &lt;none&gt;           &lt;none&gt;scheduler-nodeselector-deploy-84dccd9bf8-twnjh   1/1     Running   0          15s   172.16.58.195   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>可以看到 Pod 都被调度到了 k8s-node02 节点上了，虽然 k8s-node02 节点与 master 节点都存在标签为 disk-type: ssd，但是由于 master 节点设置了 Taint <code>node-role.kubernetes.io/control-plane:NoSchedule</code> , 因此Pod不能调度到 master 节点上。</p><h3 id="2-2-当-nodeSelector-标签不存在"><a href="#2-2-当-nodeSelector-标签不存在" class="headerlink" title="2.2 当 nodeSelector 标签不存在"></a>2.2 当 nodeSelector 标签不存在</h3><p>资源清单：<code>scheduler_nodeSelector02.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">scheduler-nodeselector-deploy</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">nodeselector-deploy</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">6</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-pod</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="comment"># 指定节点标签的 key: value</span>      <span class="attr">nodeSelector:</span>        <span class="attr">disk-type:</span> <span class="string">abc</span></code></pre><p>执行资源清单，查看状态</p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f scheduler_nodeSelector02.yaml<span class="comment"># 查看 Pod</span>$ kubectl get pods -o wide NAME                                             READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATESscheduler-nodeselector-deploy-686bd46f76-4n8qg   0/1     Pending   0          23s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;scheduler-nodeselector-deploy-686bd46f76-5zsdx   0/1     Pending   0          22s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;scheduler-nodeselector-deploy-686bd46f76-6hmd5   0/1     Pending   0          22s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;scheduler-nodeselector-deploy-686bd46f76-dpzmh   0/1     Pending   0          22s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;scheduler-nodeselector-deploy-686bd46f76-hrhqv   0/1     Pending   0          23s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;scheduler-nodeselector-deploy-686bd46f76-nkd4g   0/1     Pending   0          23s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;</code></pre><p>由于没有节点存在标签为 disk-type: abc， 因此 Pod 无法被调度执行，一直处于Pending 状态。</p><p><strong>参考链接</strong></p><blockquote><p><a href="https://www.cnblogs.com/zhanglianghhh/p/13875203.html">https://www.cnblogs.com/zhanglianghhh/p/13875203.html</a></p><p><a href="https://www.cnblogs.com/zhanglianghhh/p/13922945.html">https://www.cnblogs.com/zhanglianghhh/p/13922945.html</a></p><p><a href="https://www.cnblogs.com/zhanglianghhh/p/14022018.html">https://www.cnblogs.com/zhanglianghhh/p/14022018.html</a></p><p><a href="https://www.cnblogs.com/zhanglianghhh/p/14077078.html">https://www.cnblogs.com/zhanglianghhh/p/14077078.html</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、kube-scheduler-详解&quot;&gt;&lt;a href=&quot;#一、kube-scheduler-详解&quot; class=&quot;headerlink&quot; title=&quot;一、kube-scheduler 详解&quot;&gt;&lt;/a&gt;一、kube-scheduler 详解&lt;/h1&gt;&lt;h2 i</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>007-Kubernetes 存储</title>
    <link href="https://georgechan95.github.io/blog/ef156b88.html"/>
    <id>https://georgechan95.github.io/blog/ef156b88.html</id>
    <published>2025-05-02T02:26:00.000Z</published>
    <updated>2025-05-30T09:55:05.912Z</updated>
    
    <content type="html"><![CDATA[<p>在K8S中，容器的生命周期可能很短，会被频繁地创建和销毁。那么容器在销毁时，保存在容器中的数据也会被清除。这种结果对用户来说，在某些情况下是不乐意看到的。为了持久化保存容器的数据，kubernetes 引入了 Volume 的概念。</p><p>Volume 是 Pod 中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个 Pod 里的多个容器挂载到具体的文件目录下，kubernetes 通过 Volume 实现同一个 Pod 中不同容器之间的数据共享以及数据的持久化存储。Volume 的生命容器不与 Pod 中单个容器的生命周期相关，当容器终止或者重启时，Volume 中的数据也不会丢失。</p><h1 id="一、存储分类"><a href="#一、存储分类" class="headerlink" title="一、存储分类"></a>一、存储分类</h1><p>kubernetes 的 Volume 支持多种类型，比较常见的有下面几个：</p><ul><li>简单存储：EmptyDir、HostPath、NFS</li><li>高级存储：PV、PVC</li><li>配置存储：ConfigMap、Secret</li></ul><h2 id="1-存储各类特性"><a href="#1-存储各类特性" class="headerlink" title="1. 存储各类特性"></a>1. 存储各类特性</h2><ul><li>元数据<ul><li>configMap：用于保存配置数据（明文）</li><li>Secret：用于保存敏感性数据（编码）</li><li>Downward API：容器在运行时从 Kubernetes API 服务器获取有关它们自身的信息</li></ul></li><li>真实数据<ul><li>Volume：用于存储临时或者持久性数据</li><li>PersistentVolume：申请制的持久化存储</li></ul></li></ul><h1 id="二、ConfigMap"><a href="#二、ConfigMap" class="headerlink" title="二、ConfigMap"></a>二、ConfigMap</h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>ConfigMap 是一种 API 对象，用来将非机密性的数据保存到健值对中。使用时可以用作环境变量、命令行参数或者存储卷中的配置文件。</p><p>ConfigMap 将环境配置信息和容器镜像解耦，便于应用配置的修改。当你需要储存机密信息时可以使用 Secret 对象。</p><p><em>备注：ConfigMap 并不提供保密或者加密功能。如果你想存储的数据是机密的，请使用 Secret；或者使用其他第三方工具来保证数据的私密性，而不是用 ConfigMap。</em></p><h2 id="2-ConfigMap创建方式"><a href="#2-ConfigMap创建方式" class="headerlink" title="2. ConfigMap创建方式"></a>2. ConfigMap创建方式</h2><h3 id="2-1-通过目录创建"><a href="#2-1-通过目录创建" class="headerlink" title="2.1 通过目录创建"></a>2.1 通过目录创建</h3><h4 id="2-1-1-文件及目录"><a href="#2-1-1-文件及目录" class="headerlink" title="2.1.1 文件及目录"></a>2.1.1 文件及目录</h4><pre><code class="highlight bash"><span class="comment"># 当前目录位置</span>$ <span class="built_in">pwd</span>/opt/k8s/07/configMap/dir<span class="comment"># 目录下的文件</span>$ lltotal 8-rw-r--r-- 1 root root 158 May 10 14:40 game.properties-rw-r--r-- 1 root root  83 May 10 14:41 ui.properties</code></pre><h4 id="2-1-2-文件内容"><a href="#2-1-2-文件内容" class="headerlink" title="2.1.2 文件内容"></a>2.1.2 文件内容</h4><p><code>game.properties</code></p><pre><code class="highlight properties"><span class="attr">enemies</span>=<span class="string">aliens</span><span class="attr">lives</span>=<span class="string">3</span><span class="attr">enemies.cheat</span>=<span class="string">true</span><span class="attr">enemies.cheat.level</span>=<span class="string">noGoodRotten</span><span class="attr">secret.code.passphrase</span>=<span class="string">UUDDLRLRBABAs</span><span class="attr">secret.code.allowed</span>=<span class="string">true</span><span class="attr">secret.code.lives</span>=<span class="string">30</span></code></pre><p><code>ui.properties</code></p><pre><code class="highlight properties"><span class="attr">color.good</span>=<span class="string">purple</span><span class="attr">color.bad</span>=<span class="string">yellow</span><span class="attr">allow.textmode</span>=<span class="string">true</span><span class="attr">how.nice.to.look</span>=<span class="string">fairlyNice</span></code></pre><h4 id="2-1-3-创建-ConfigMap"><a href="#2-1-3-创建-ConfigMap" class="headerlink" title="2.1.3 创建 ConfigMap"></a>2.1.3 创建 ConfigMap</h4><pre><code class="highlight bash"><span class="comment"># 指定目录创建 ConfigMap</span>$ kubectl create configmap dir-config --from-file=/opt/k8s/07/configMap/dir/<span class="comment"># 查看 ConfigMap</span>$ kubectl get configmapNAME               DATA   AGEdir-config         2      24s</code></pre><h4 id="2-1-4-查看-ConfigMap-数据"><a href="#2-1-4-查看-ConfigMap-数据" class="headerlink" title="2.1.4 查看 ConfigMap 数据"></a>2.1.4 查看 ConfigMap 数据</h4><p><strong>方式一: 以yaml格式展示</strong></p><pre><code class="highlight bash">$ kubectl get configmap dir-config -o yaml<span class="comment"># 内容如下：</span>apiVersion: v1data:  game.properties: |    enemies=aliens    lives=3    enemies.cheat=<span class="literal">true</span>    enemies.cheat.level=noGoodRotten    secret.code.passphrase=UUDDLRLRBABAs    secret.code.allowed=<span class="literal">true</span>    secret.code.lives=30  ui.properties: |    color.good=purple    color.bad=yellow    allow.textmode=<span class="literal">true</span>    how.nice.to.look=fairlyNicekind: ConfigMapmetadata:  creationTimestamp: <span class="string">&quot;2025-05-10T06:46:58Z&quot;</span>  name: dir-config  namespace: default  resourceVersion: <span class="string">&quot;6014969&quot;</span>  uid: b5283e4e-dfbd-466c-bd4f-b4cc6fe2ef2a</code></pre><p><strong>方式二</strong></p><pre><code class="highlight bash">$ kubectl describe configmap dir-config<span class="comment"># 内容如下：</span>Name:         dir-configNamespace:    defaultLabels:       &lt;none&gt;Annotations:  &lt;none&gt;Data====game.properties:----enemies=alienslives=3enemies.cheat=<span class="literal">true</span>enemies.cheat.level=noGoodRottensecret.code.passphrase=UUDDLRLRBABAssecret.code.allowed=<span class="literal">true</span>secret.code.lives=30ui.properties:----color.good=purplecolor.bad=yellowallow.textmode=<span class="literal">true</span>how.nice.to.look=fairlyNiceBinaryData====Events:  &lt;none&gt;</code></pre><h3 id="2-2-通过文件创建"><a href="#2-2-通过文件创建" class="headerlink" title="2.2 通过文件创建"></a>2.2 通过文件创建</h3><h4 id="2-2-1-文件内容"><a href="#2-2-1-文件内容" class="headerlink" title="2.2.1 文件内容"></a>2.2.1 文件内容</h4><p>文件路径：<code>/opt/k8s/07/configMap/dir/game.properties</code></p><pre><code class="highlight properties"><span class="attr">enemies</span>=<span class="string">aliens</span><span class="attr">lives</span>=<span class="string">3</span><span class="attr">enemies.cheat</span>=<span class="string">true</span><span class="attr">enemies.cheat.level</span>=<span class="string">noGoodRotten</span><span class="attr">secret.code.passphrase</span>=<span class="string">UUDDLRLRBABAs</span><span class="attr">secret.code.allowed</span>=<span class="string">true</span><span class="attr">secret.code.lives</span>=<span class="string">30</span></code></pre><h4 id="2-2-2-创建-ConfigMap"><a href="#2-2-2-创建-ConfigMap" class="headerlink" title="2.2.2 创建 ConfigMap"></a>2.2.2 创建 ConfigMap</h4><pre><code class="highlight bash"><span class="comment"># 指定文件创建 ConfigMap</span>$ kubectl create configmap file-config --from-file=/opt/k8s/07/configMap/dir/game.properties<span class="comment"># 查看 ConfigMap</span>$ kubectl get configmapNAME               DATA   AGEdir-config         2      11mfile-config        1      13s</code></pre><h4 id="2-2-3-查看-ConfigMap-数据"><a href="#2-2-3-查看-ConfigMap-数据" class="headerlink" title="2.2.3 查看 ConfigMap 数据"></a>2.2.3 查看 ConfigMap 数据</h4><p><strong>方式一: 以yaml格式展示</strong></p><pre><code class="highlight bash">$ kubectl get configmap file-config -o yaml</code></pre><p><strong>方式二</strong></p><pre><code class="highlight bash">$ kubectl describe configmap file-config</code></pre><h3 id="2-3-通过命令行创建"><a href="#2-3-通过命令行创建" class="headerlink" title="2.3 通过命令行创建"></a>2.3 通过命令行创建</h3><h4 id="2-3-1-创建-ConfigMap"><a href="#2-3-1-创建-ConfigMap" class="headerlink" title="2.3.1 创建 ConfigMap"></a>2.3.1 创建 ConfigMap</h4><pre><code class="highlight bash"><span class="comment"># 通过命令行创建 ConfigMap</span>$ kubectl create configmap cmd-config --from-literal=special.how=very --from-literal=<span class="string">&quot;special.type=charm&quot;</span><span class="comment"># 查看 ConfigMap</span>$ kubectl get configmapNAME               DATA   AGEcmd-config         2      107sdir-config         2      21mfile-config        1      10m</code></pre><p><code>--from-literal=</code> 后面的参数 <code>&quot; &quot;</code> 可加可不加</p><h4 id="2-3-2-查看-ConfigMap"><a href="#2-3-2-查看-ConfigMap" class="headerlink" title="2.3.2 查看 ConfigMap"></a>2.3.2 查看 ConfigMap</h4><p><strong>方式一: 以yaml格式展示</strong></p><pre><code class="highlight bash">$ kubectl get configmap cmd-config -o yaml<span class="comment"># 内容如下：</span>apiVersion: v1data:  special.how: very  special.type: charmkind: ConfigMapmetadata:  creationTimestamp: <span class="string">&quot;2025-05-10T07:07:01Z&quot;</span>  name: cmd-config  namespace: default  resourceVersion: <span class="string">&quot;6016743&quot;</span>  uid: 9cd7d408-d7c1-47f8-99db-ecb4bb33f74f</code></pre><p><strong>方式二</strong></p><pre><code class="highlight bash">$ kubectl describe configmap cmd-config<span class="comment"># 内容如下：</span>Name:         cmd-configNamespace:    defaultLabels:       &lt;none&gt;Annotations:  &lt;none&gt;Data====special.how:----veryspecial.type:----charmBinaryData====Events:  &lt;none&gt;</code></pre><h3 id="2-4-通过yaml文件创建"><a href="#2-4-通过yaml文件创建" class="headerlink" title="2.4 通过yaml文件创建"></a>2.4 通过yaml文件创建</h3><h4 id="2-4-1-文件及目录"><a href="#2-4-1-文件及目录" class="headerlink" title="2.4.1 文件及目录"></a>2.4.1 文件及目录</h4><pre><code class="highlight bash">$ <span class="built_in">pwd</span>/opt/k8s/07/configMap/yaml$ lltotal 4-rw-r--r-- 1 root root 487 May 10 15:58 configmap-demo.yaml</code></pre><h4 id="2-4-2-文件内容"><a href="#2-4-2-文件内容" class="headerlink" title="2.4.2 文件内容"></a>2.4.2 文件内容</h4><p><code>configmap-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">configmap-demo</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">configmap:</span> <span class="string">myconfig</span><span class="attr">data:</span>  <span class="comment"># 类属性键，每个键都映射一个简单的值</span>  <span class="attr">username:</span> <span class="string">&quot;george&quot;</span>  <span class="attr">user_file:</span> <span class="string">&#x27;user.properties&#x27;</span>  <span class="attr">game_file:</span> <span class="string">&#x27;game.properties&#x27;</span>  <span class="comment"># 类文件键，每个键都对应一个文件，| 下是文件的内容</span>  <span class="attr">user.properties:</span> <span class="string">|</span><span class="string">    age=23</span><span class="string">    address=中国</span><span class="string"></span>  <span class="attr">game.propertie:</span> <span class="string">|</span><span class="string">    enemy.types=aliens,monsters</span><span class="string">    player.maximum-lives=5</span></code></pre><h4 id="2-4-3-创建-ConfigMap"><a href="#2-4-3-创建-ConfigMap" class="headerlink" title="2.4.3 创建 ConfigMap"></a>2.4.3 创建 ConfigMap</h4><pre><code class="highlight bash"><span class="comment"># 通过 ConfigMap yaml 资源清单创建</span>$ kubectl apply -f configmap-demo.yaml<span class="comment"># 查看 ConfigMap</span>$ kubectl get configmapNAME               DATA   AGEconfigmap-demo     5      20s</code></pre><h4 id="2-4-4-查看-ConfigMap-数据"><a href="#2-4-4-查看-ConfigMap-数据" class="headerlink" title="2.4.4 查看 ConfigMap 数据"></a>2.4.4 查看 ConfigMap 数据</h4><p><strong>方式一: 以yaml格式展示</strong></p><pre><code class="highlight bash">$ kubectl get configmap configmap-demo -o yaml<span class="comment"># 内容如下</span>apiVersion: v1data:  game.propertie: |    enemy.types=aliens,monsters    player.maximum-lives=5  game_file: game.properties  user.properties: |    age=23    address=中国  user_file: user.properties  username: georgekind: ConfigMapmetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: |      &#123;<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>,<span class="string">&quot;data&quot;</span>:&#123;<span class="string">&quot;game.propertie&quot;</span>:<span class="string">&quot;enemy.types=aliens,monsters\nplayer.maximum-lives=5\n&quot;</span>,<span class="string">&quot;game_file&quot;</span>:<span class="string">&quot;game.properties&quot;</span>,<span class="string">&quot;user.properties&quot;</span>:<span class="string">&quot;age=23\naddress=中国\n&quot;</span>,<span class="string">&quot;user_file&quot;</span>:<span class="string">&quot;user.properties&quot;</span>,<span class="string">&quot;username&quot;</span>:<span class="string">&quot;george&quot;</span>&#125;,<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;ConfigMap&quot;</span>,<span class="string">&quot;metadata&quot;</span>:&#123;<span class="string">&quot;annotations&quot;</span>:&#123;&#125;,<span class="string">&quot;labels&quot;</span>:&#123;<span class="string">&quot;configmap&quot;</span>:<span class="string">&quot;myconfig&quot;</span>&#125;,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;configmap-demo&quot;</span>,<span class="string">&quot;namespace&quot;</span>:<span class="string">&quot;default&quot;</span>&#125;&#125;  creationTimestamp: <span class="string">&quot;2025-05-10T07:59:18Z&quot;</span>  labels:    configmap: myconfig  name: configmap-demo  namespace: default  resourceVersion: <span class="string">&quot;6021397&quot;</span>  uid: f3538c6c-4bd6-41e9-9b48-2c040181e2dc</code></pre><p><strong>方式二</strong></p><pre><code class="highlight bash">$ kubectl describe configmap configmap-demoName:         configmap-demoNamespace:    defaultLabels:       configmap=myconfigAnnotations:  &lt;none&gt;Data====game_file:----game.propertiesuser.properties:----age=23address=中国user_file:----user.propertiesusername:----georgegame.propertie:----enemy.types=aliens,monstersplayer.maximum-lives=5BinaryData====Events:  &lt;none&gt;</code></pre><h2 id="3-Pod中使用ConfigMap"><a href="#3-Pod中使用ConfigMap" class="headerlink" title="3. Pod中使用ConfigMap"></a>3. Pod中使用ConfigMap</h2><h3 id="3-1-使用ConfigMap来替代环境变量"><a href="#3-1-使用ConfigMap来替代环境变量" class="headerlink" title="3.1 使用ConfigMap来替代环境变量"></a>3.1 使用ConfigMap来替代环境变量</h3><h4 id="3-1-1-定义资源清单"><a href="#3-1-1-定义资源清单" class="headerlink" title="3.1.1 定义资源清单"></a>3.1.1 定义资源清单</h4><p>资源清单：<code>pod_configmap_env.yaml</code>， 定义了 2 个 configMap 和 1个 Pod</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">configmap-1</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">data:</span>  <span class="comment"># 类属性键，每个键都映射一个简单的值</span>  <span class="attr">username:</span> <span class="string">&quot;george&quot;</span>  <span class="attr">password:</span> <span class="string">&quot;123456&quot;</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">configmap-2</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">data:</span>  <span class="comment"># 类文件键，每个键都对应一个文件，| 下是文件的内容</span>  <span class="attr">user.properties:</span> <span class="string">|</span><span class="string">    age=23</span><span class="string">    address=中国</span><span class="string"></span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-configmap-env</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">restartPolicy:</span> <span class="string">Never</span> <span class="comment"># Pod 重启策略</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">command:</span> <span class="comment"># 打印完环境变量后休眠3600秒</span>        <span class="bullet">-</span> <span class="string">&quot;/bin/sh&quot;</span>        <span class="bullet">-</span> <span class="string">&quot;-c&quot;</span>        <span class="bullet">-</span> <span class="string">&quot;env &amp;&amp; sleep 3600&quot;</span>      <span class="attr">env:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">USERNAME</span> <span class="comment"># 容器内环境变量的名称</span>          <span class="attr">valueFrom:</span>            <span class="attr">configMapKeyRef:</span>              <span class="attr">name:</span> <span class="string">configmap-1</span> <span class="comment"># configMap名称</span>              <span class="attr">key:</span> <span class="string">username</span> <span class="comment"># configMap中定义的属性键</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PASSWORD</span>          <span class="attr">valueFrom:</span>            <span class="attr">configMapKeyRef:</span>              <span class="attr">name:</span> <span class="string">configmap-1</span>              <span class="attr">key:</span> <span class="string">password</span>      <span class="attr">envFrom:</span>        <span class="bullet">-</span> <span class="attr">configMapRef:</span>            <span class="attr">name:</span> <span class="string">configmap-2</span> <span class="comment"># configMap名称</span></code></pre><h4 id="3-1-2-创建ConfigMap-、Pod"><a href="#3-1-2-创建ConfigMap-、Pod" class="headerlink" title="3.1.2 创建ConfigMap 、Pod"></a>3.1.2 创建ConfigMap 、Pod</h4><pre><code class="highlight bash">$ kubectl apply -f pod_configmap_env.yaml configmap/configmap-1 createdconfigmap/configmap-2 createdpod/pod-configmap-env created</code></pre><p><strong>查看Pod运行状态</strong></p><pre><code class="highlight bash">$ kubectl get pods -o wideNAME                READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESpod-configmap-env   1/1     Running   0          5s    172.16.58.195   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><h4 id="3-1-3-查看Pod日志"><a href="#3-1-3-查看Pod日志" class="headerlink" title="3.1.3 查看Pod日志"></a>3.1.3 查看Pod日志</h4><pre><code class="highlight bash">$ kubectl logs pod-configmap-envKUBERNETES_SERVICE_PORT=443KUBERNETES_PORT=tcp://10.96.0.1:443HOSTNAME=pod-configmap-envSHLVL=1HOME=/rootUSERNAME=georgeKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binKUBERNETES_PORT_443_TCP_PORT=443KUBERNETES_PORT_443_TCP_PROTO=tcpKUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443KUBERNETES_SERVICE_PORT_HTTPS=443KUBERNETES_SERVICE_HOST=10.96.0.1PWD=/user.properties=age=23address=中国PASSWORD=123456</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/05/10/20250510-171757.png" alt="打印环境变量"></p><h4 id="3-1-4-进入Pod容器内查看环境变量"><a href="#3-1-4-进入Pod容器内查看环境变量" class="headerlink" title="3.1.4 进入Pod容器内查看环境变量"></a>3.1.4 进入Pod容器内查看环境变量</h4><pre><code class="highlight bash"><span class="comment"># 进入 Pod 容器内部</span>$ kubectl <span class="built_in">exec</span> -it pod-configmap-env /bin/bash<span class="comment"># 查看环境变量</span>pod-configmap-env:/<span class="comment"># env</span>user.properties=age=23address=中国KUBERNETES_SERVICE_PORT_HTTPS=443KUBERNETES_SERVICE_PORT=443CHARSET=UTF-8HOSTNAME=pod-configmap-envPWD=/HOME=/rootUSERNAME=georgeLANG=C.UTF-8KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443PASSWORD=123456TERM=xtermSHLVL=1KUBERNETES_PORT_443_TCP_PROTO=tcpKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1KUBERNETES_SERVICE_HOST=10.96.0.1KUBERNETES_PORT=tcp://10.96.0.1:443KUBERNETES_PORT_443_TCP_PORT=443LC_COLLATE=CPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin_=/usr/bin/env</code></pre><h3 id="3-2-使用-ConfigMap-设置命令行参数"><a href="#3-2-使用-ConfigMap-设置命令行参数" class="headerlink" title="3.2 使用 ConfigMap 设置命令行参数"></a>3.2 使用 ConfigMap 设置命令行参数</h3><h4 id="3-2-1-定义资源清单"><a href="#3-2-1-定义资源清单" class="headerlink" title="3.2.1 定义资源清单"></a>3.2.1 定义资源清单</h4><p><code>pod_configmap_cmd.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">configmap-3</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">data:</span>  <span class="comment"># 类属性键，每个键都映射一个简单的值</span>  <span class="attr">username:</span> <span class="string">&quot;george&quot;</span>  <span class="attr">password:</span> <span class="string">&quot;123456&quot;</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-configmap-cmd</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">restartPolicy:</span> <span class="string">Never</span> <span class="comment"># Pod 重启策略</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-cmd</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">command:</span> <span class="comment"># 打印环境变量指定的键值</span>        <span class="bullet">-</span> <span class="string">&quot;/bin/sh&quot;</span>        <span class="bullet">-</span> <span class="string">&quot;-c&quot;</span>        <span class="bullet">-</span> <span class="string">&quot;echo $(USERNAME) $(PASSWORD)&quot;</span>      <span class="attr">env:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">USERNAME</span> <span class="comment"># 容器内环境变量的名称</span>          <span class="attr">valueFrom:</span>            <span class="attr">configMapKeyRef:</span>              <span class="attr">name:</span> <span class="string">configmap-3</span> <span class="comment"># configMap名称</span>              <span class="attr">key:</span> <span class="string">username</span> <span class="comment"># configMap中定义的属性键</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PASSWORD</span>          <span class="attr">valueFrom:</span>            <span class="attr">configMapKeyRef:</span>              <span class="attr">name:</span> <span class="string">configmap-3</span>              <span class="attr">key:</span> <span class="string">password</span></code></pre><h4 id="3-2-2-创建-ConfigMap-、Pod"><a href="#3-2-2-创建-ConfigMap-、Pod" class="headerlink" title="3.2.2 创建 ConfigMap 、Pod"></a>3.2.2 创建 ConfigMap 、Pod</h4><pre><code class="highlight bash">$ kubectl apply -f pod_configmap_cmd.yaml configmap/configmap-3 createdpod/pod-configmap-cmd created</code></pre><p><strong>查看Pod运行状态</strong></p><pre><code class="highlight bash">$ kubectl get pod pod-configmap-cmdNAME                READY   STATUS      RESTARTS   AGEpod-configmap-cmd   0/1     Completed   0          59s</code></pre><h4 id="3-2-3-查看Pod日志"><a href="#3-2-3-查看Pod日志" class="headerlink" title="3.2.3 查看Pod日志"></a>3.2.3 查看Pod日志</h4><pre><code class="highlight bash">$ kubectl logs -f pod-configmap-cmdgeorge 123456</code></pre><h3 id="3-3-通过数据卷插件使用ConfigMap【推荐】"><a href="#3-3-通过数据卷插件使用ConfigMap【推荐】" class="headerlink" title="3.3 通过数据卷插件使用ConfigMap【推荐】"></a>3.3 通过数据卷插件使用ConfigMap【推荐】</h3><p>将 ConfigMap 以文件形式挂载到容器内, 在数据卷里面使用ConfigMap，最基本的就是将文件填入数据卷，在这个文件中，键就是文件名【第一层级的键】，键值就是文件内容。</p><h4 id="3-3-1-定义资源清单"><a href="#3-3-1-定义资源清单" class="headerlink" title="3.3.1  定义资源清单"></a>3.3.1  定义资源清单</h4><p><code>pod_configmap_volumn.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">configmap-4</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">data:</span>  <span class="comment"># 类文件键，每个键都对应一个文件，| 下是文件的内容</span>  <span class="attr">user.properties:</span> <span class="string">|</span><span class="string">    age=23</span><span class="string">    address=中国</span><span class="string"></span>  <span class="attr">game.propertie:</span> <span class="string">|</span><span class="string">    enemy.types=aliens,monsters</span><span class="string">    player.maximum-lives=5</span><span class="string"></span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ConfigMap</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">configmap-5</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">data:</span>  <span class="comment"># 类属性键，每个键都映射一个简单的值</span>  <span class="attr">username:</span> <span class="string">&quot;george&quot;</span>  <span class="attr">password:</span> <span class="string">&quot;123456&quot;</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-configmap-volumn</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">restartPolicy:</span> <span class="string">Never</span> <span class="comment"># Pod 重启策略</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-volumn</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">command:</span> <span class="comment"># 打印完环境变量后休眠3600秒</span>        <span class="bullet">-</span> <span class="string">&quot;/bin/sh&quot;</span>        <span class="bullet">-</span> <span class="string">&quot;-c&quot;</span>        <span class="bullet">-</span> <span class="string">&quot;env &amp;&amp; sleep 3600&quot;</span>      <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volumn</span> <span class="comment"># 挂载的volumn名称，必须在 volumes 有定义</span>          <span class="attr">mountPath:</span> <span class="string">/etc/config</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volumn2</span>          <span class="attr">mountPath:</span> <span class="string">/etc/mydir</span> <span class="comment"># 挂载路径不能重复</span>  <span class="attr">volumes:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volumn</span> <span class="comment"># volumn 名称</span>      <span class="attr">configMap:</span>        <span class="attr">name:</span> <span class="string">configmap-4</span> <span class="comment"># ConfigMap 名称</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volumn2</span>      <span class="attr">configMap:</span>        <span class="attr">name:</span> <span class="string">configmap-5</span></code></pre><h4 id="3-3-2-创建-ConfigMap、Pod"><a href="#3-3-2-创建-ConfigMap、Pod" class="headerlink" title="3.3.2 创建 ConfigMap、Pod"></a>3.3.2 创建 ConfigMap、Pod</h4><pre><code class="highlight bash">$ kubectl apply -f pod_configmap_volumn.yaml configmap/configmap-4 unchangedconfigmap/configmap-5 unchangedpod/pod-configmap-volumn created</code></pre><h4 id="3-3-3-进入-Pod，查看挂载文件"><a href="#3-3-3-进入-Pod，查看挂载文件" class="headerlink" title="3.3.3 进入 Pod，查看挂载文件"></a>3.3.3 进入 Pod，查看挂载文件</h4><pre><code class="highlight bash"><span class="comment"># 进入容器</span>$ kubectl <span class="built_in">exec</span> -it pod-configmap-volumn /bin/bash<span class="comment"># 查看挂载目录 /etc/config</span>pod-configmap-volumn:/<span class="comment"># ls -l /etc/config</span>total 0lrwxrwxrwx    1 root     root            21 May 10 17:41 game.propertie -&gt; ..data/game.propertielrwxrwxrwx    1 root     root            22 May 10 17:41 user.properties -&gt; ..data/user.properties<span class="comment"># 查看挂载目录 /etc/mydir</span>pod-configmap-volumn:/<span class="comment"># ls /etc/mydir</span>password  username<span class="comment"># 查看文件内容</span>pod-configmap-volumn:/etc/config<span class="comment"># cat /etc/config/user.properties </span>age=23address=中国<span class="comment"># 查看文件内容</span>pod-configmap-volumn:/etc/config<span class="comment"># cat /etc/mydir/username </span>george</code></pre><h3 id="3-4-ConfigMap-热更新"><a href="#3-4-ConfigMap-热更新" class="headerlink" title="3.4 ConfigMap 热更新"></a>3.4 ConfigMap 热更新</h3><h4 id="3-4-1-创建-ConfigMap"><a href="#3-4-1-创建-ConfigMap" class="headerlink" title="3.4.1 创建 ConfigMap"></a>3.4.1 创建 ConfigMap</h4><pre><code class="highlight bash"><span class="comment"># 创建配置文件</span>$ <span class="built_in">cat</span> default.conf server &#123;    listen 80 default_server;    server_name example.com www.example.com;    location / &#123;        root   /usr/share/nginx/html;        index  index.html index.htm;    &#125;&#125;<span class="comment"># 将文件生成为 ConfigMap</span>$ kubectl create configmap default-nginx --from-file=default.conf<span class="comment"># 查看 configmap状态</span>$ kubectl get cmNAME               DATA   AGEdefault-nginx      1      25s<span class="comment"># 查看configmap 详情</span>$ kubectl describe cm default-nginxName:         default-nginxNamespace:    defaultLabels:       &lt;none&gt;Annotations:  &lt;none&gt;Data====default.conf:----server &#123;\r    listen 80 default_server;\r    server_name example.com www.example.com;\r    location / &#123;\r        root   /usr/share/nginx/html;\r        index  index.html index.htm;\r    &#125;\r&#125;BinaryData====Events:  &lt;none&gt;</code></pre><h4 id="3-4-2-定义资源清单"><a href="#3-4-2-定义资源清单" class="headerlink" title="3.4.2 定义资源清单"></a>3.4.2 定义资源清单</h4><p><code>hotUpdate-nginx.yml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">hotupdate-deployment</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">3</span>  <span class="attr">selector:</span> <span class="comment"># 标签选择器</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">hotupdate-deploy</span>      <span class="attr">version:</span> <span class="string">v1</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">hotupdate-deploy</span>        <span class="attr">version:</span> <span class="string">v1</span>        <span class="attr">env:</span> <span class="string">test</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:1.28.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span> <span class="comment"># 挂载的volumn名称，必须 volumes 中定义存在</span>              <span class="attr">mountPath:</span> <span class="string">/etc/nginx/conf.d/</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span> <span class="comment"># 挂在卷名称</span>          <span class="attr">configMap:</span>            <span class="attr">name:</span> <span class="string">default-nginx</span> <span class="comment"># 创建的configmap名称</span></code></pre><h4 id="3-4-3-创建容器"><a href="#3-4-3-创建容器" class="headerlink" title="3.4.3 创建容器"></a>3.4.3 创建容器</h4><pre><code class="highlight bash"><span class="comment"># 创建 Deployment</span>$ kubectl apply -f hotUpdate-nginx.yml deployment.apps/hotupdate-deployment created<span class="comment"># 查看 Deployment 状态</span>$ kubectl get deployment -o wideNAME                   READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES         SELECTORhotupdate-deployment   3/3     3            3           3m27s   nginx        nginx:1.28.0   app=hotupdate-deploy,version=v1<span class="comment"># 查看Pod</span>$ kubectl get pods -o wideNAME                                   READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATEShotupdate-deployment-9ff5b5b8b-27frw   1/1     Running   0          3m46s   192.168.85.225   k8s-node01   &lt;none&gt;           &lt;none&gt;hotupdate-deployment-9ff5b5b8b-c8k42   1/1     Running   0          3m46s   192.168.58.220   k8s-node02   &lt;none&gt;           &lt;none&gt;hotupdate-deployment-9ff5b5b8b-cjwlh   1/1     Running   0          3m46s   192.168.58.221   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p><strong>访问pod</strong></p><pre><code class="highlight bash">$ curl http://192.168.85.225:80/index.html&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt;html &#123; color-scheme: light dark; &#125;body &#123; width: 35em; margin: 0 auto;font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=<span class="string">&quot;http://nginx.org/&quot;</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=<span class="string">&quot;http://nginx.com/&quot;</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><p>Pod 可以正常访问</p><h4 id="3-4-4-编辑修改-ConfigMap"><a href="#3-4-4-编辑修改-ConfigMap" class="headerlink" title="3.4.4 编辑修改 ConfigMap"></a>3.4.4 编辑修改 ConfigMap</h4><pre><code class="highlight bash">$ kubectl edit configmap default-nginx<span class="comment"># 将 default-nginx 内容的端口，从 80 改为 90，然后保存</span></code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/05/11/20250511-113403.png" alt="编辑修改 ConfigMap"></p><p><strong>进入 Pod 容器内，查看挂载配置文件是否修改</strong></p><pre><code class="highlight bash"><span class="comment"># 进入pod容器内容</span>$ kubectl <span class="built_in">exec</span> -it hotupdate-deployment-9ff5b5b8b-27frw /bin/bash<span class="comment"># 查看配置文件（配置已成功修改）</span>hotupdate-deployment-747786dd9b-72wz8:/<span class="comment"># cat /etc/nginx/conf.d/default.conf </span>server &#123;    listen 90 default_server;    server_name example.com www.example.com;    location / &#123;        root   /usr/share/nginx/html;        index  index.html index.htm;    &#125;&#125;</code></pre><p><strong>使用 90 端口访问 Pod</strong></p><pre><code class="highlight bash">$ curl http://192.168.85.225:90/index.htmlcurl: (7) Failed to connect to 192.168.85.225 port 90: Connection refused</code></pre><p>可以看到，使用 90端口访问失败，Pod依然使用的是80端口，也就是 ConfigMap 没能触发容器的热更新。</p><p>这里需要手动触发热更新。</p><h4 id="3-4-5-手动触发热更新"><a href="#3-4-5-手动触发热更新" class="headerlink" title="3.4.5 手动触发热更新"></a>3.4.5 手动触发热更新</h4><p>更新 ConfigMap 目前并不会触发相关 Pod 的滚动更新，可以通过修改 pod annotations 的方式强制触发滚动更新</p><pre><code class="highlight bash"><span class="comment"># 手动更新 Deployment 的 annotations 版本号，触发Deployment 滚动升级</span>$ kubectl patch deployment hotupdate-deployment --patch <span class="string">&#x27;&#123;&quot;spec&quot;: &#123;&quot;template&quot;: &#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;: &#123;&quot;version/config&quot;: &quot;123&quot; &#125;&#125;&#125;&#125;&#125;&#x27;</span></code></pre><p><strong>访问Pod</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 滚动更新后的 Pod</span>$ kubectl get pods -o wideNAME                                    READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATEShotupdate-deployment-76d6c6b684-v5wcl   1/1     Running   0          14s   192.168.58.222   k8s-node02   &lt;none&gt;           &lt;none&gt;hotupdate-deployment-76d6c6b684-v96hq   1/1     Running   0          16s   192.168.85.226   k8s-node01   &lt;none&gt;           &lt;none&gt;hotupdate-deployment-76d6c6b684-xgbxb   1/1     Running   0          11s   192.168.58.223   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 访问Pod</span>$ curl http://192.168.85.226:90/index.html&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;<span class="built_in">head</span>&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt;html &#123; color-scheme: light dark; &#125;body &#123; width: 35em; margin: 0 auto;font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=<span class="string">&quot;http://nginx.org/&quot;</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=<span class="string">&quot;http://nginx.com/&quot;</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h4 id="3-4-6-热更新注意事项"><a href="#3-4-6-热更新注意事项" class="headerlink" title="3.4.6 热更新注意事项"></a>3.4.6 热更新注意事项</h4><p>更新 ConfigMap 后：</p><ul><li>使用该 ConfigMap 挂载的 Env 不会同步更新</li><li>使用该 ConfigMap 挂载的 Volume 中的数据需要一段时间（实测大概10秒）才能同步更新</li></ul><h3 id="3-5-configmap-不可改变"><a href="#3-5-configmap-不可改变" class="headerlink" title="3.5 configmap-不可改变"></a>3.5 configmap-不可改变</h3><p>Kubernetes 给不可变的 ConfigMap 和 Secret 提供了一种可选配置， 可以设置各个 Secret 和 ConfigMap 为不可变的。 对于大量使用 configmap 的集群（至少有成千上万各不相同的 configmap 供 Pod 挂载）， 禁止变更它们的数据有下列好处：</p><ul><li>防止意外（或非预期的）更新导致应用程序中断</li><li>通过将 configmap 标记为不可变来关闭 kube-apiserver 对其的监视，从而显著降低 kube-apiserver 的负载，提升集群性能。</li></ul><pre><code class="highlight bash">$ kubectl explain configmap.immutableKIND:       ConfigMapVERSION:    v1FIELD: immutable &lt;boolean&gt;DESCRIPTION:    Immutable, <span class="keyword">if</span> <span class="built_in">set</span> to <span class="literal">true</span>, ensures that data stored <span class="keyword">in</span> the ConfigMap cannot    be updated (only object metadata can be modified). If not <span class="built_in">set</span> to <span class="literal">true</span>, the    field can be modified at any time. Defaulted to nil.</code></pre><p><strong>添加 immutable 参数</strong></p><pre><code class="highlight bash">$ kubectl edit cm default-nginx -o yamlapiVersion: v1data:  default.conf: <span class="string">&quot;server &#123;\r\n    listen 90 default_server;\r\n    server_name example.com</span><span class="string">    www.example.com;\r\n    location / &#123;\r\n        root   /usr/share/nginx/html;\r\n</span><span class="string">    \       index  index.html index.htm;\r\n    &#125;\r\n&#125;&quot;</span>immutable: <span class="literal">true</span>kind: ConfigMapmetadata:  creationTimestamp: <span class="string">&quot;2025-05-11T13:09:40Z&quot;</span>  name: default-nginx  namespace: default  resourceVersion: <span class="string">&quot;161330&quot;</span>  uid: a75df079-ef0d-499c-9769-13bbc76606ad</code></pre><p>保存后，这个configmap将不能再被修改</p><h1 id="三、Secret"><a href="#三、Secret" class="headerlink" title="三、Secret"></a>三、Secret</h1><h2 id="1-Secret-定义"><a href="#1-Secret-定义" class="headerlink" title="1. Secret - 定义"></a>1. Secret - 定义</h2><p>Secret 对象类型用来保存敏感信息，例如密码、OAuth 令牌和 SSH 密钥。 将这些信息放在 secret 中比放在 Pod 的定义或者 容器镜像 中来说更加安全和灵活。</p><h2 id="2-Secret-特性"><a href="#2-Secret-特性" class="headerlink" title="2. Secret - 特性"></a>2. Secret - 特性</h2><ul><li><p>Kubernetes 通过仅仅将 Secret 分发到需要访问 Secret 的 Pod 所在的机器节点来保障其安全性</p></li><li><p>Secret 只会存储在节点的内存中，永不写入物理存储，这样从节点删除 secret 时就不需要擦除磁盘数据</p></li><li><p>从 Kubernetes1.7 版本开始，etcd 会以加密形式存储 Secret，一定程度的保证了 Secret 安全性</p></li></ul><h2 id="3-Secret-类型"><a href="#3-Secret-类型" class="headerlink" title="3. Secret - 类型"></a>3. Secret - 类型</h2><table><thead><tr><th>内置类型</th><th>用法</th><th>使用示例</th></tr></thead><tbody><tr><td>Opaque</td><td>base64编码格式的Secret，用来存储密码、秘钥等。</td><td>kubectl create secret generic mysecret  –from-literal&#x3D;username&#x3D;admin  –from-literal&#x3D;password&#x3D;123456</td></tr><tr><td>kubernetes.io&#x2F;service-account-token</td><td>服务账号令牌，用来访问Kubernetes API，由Kubernetes自动创建，并且会自动挂载到Pod的 &#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount 目录中。</td><td></td></tr><tr><td>kubernetes.io&#x2F;dockercfg</td><td>~&#x2F;.dockercfg 文件序列化形式（老版本Docker），用来存储私有docker registry的认证信息。</td><td></td></tr><tr><td>kubernetes.io&#x2F;dockerconfigjson</td><td>~&#x2F;.docker&#x2F;config.json 文件序列化形式（新版本Docker），用来存储私有docker registry的认证信息。</td><td>kubectl create secret docker-registry myregistry \   –docker-server&#x3D;registry.example.com \   –docker-username&#x3D;admin \   –docker-password&#x3D;123456</td></tr><tr><td>kubernetes.io&#x2F;basic-auth</td><td>用于基本身份认证凭据</td><td>kubectl create secret generic my-basic-auth  –type&#x3D;kubernetes.io&#x2F;basic-auth  –from-literal&#x3D;username&#x3D;admin  –from-literal&#x3D;password&#x3D;123456</td></tr><tr><td>kubernetes.io&#x2F;ssh-auth</td><td>用户SSH身份认证凭据</td><td>kubectl create secret generic my-ssh  –type&#x3D;kubernetes.io&#x2F;ssh-auth  –from-file&#x3D;ssh-privatekey&#x3D;~&#x2F;.ssh&#x2F;id_rsa</td></tr><tr><td>kubernetes.io&#x2F;tls</td><td>用于TLS客户端或者服务端的数据</td><td>kubectl create secret tls my-tls  –cert&#x3D;.&#x2F;tls.crt  –key&#x3D;.&#x2F;tls.key</td></tr><tr><td>bootstrap.kubernetes.io&#x2F;token</td><td>启动引导令牌数据</td><td></td></tr></tbody></table><p><code>kubernetes.io/service-account-token</code> 类型创建示例</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Secret</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">example-service-account-token</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">annotations:</span>    <span class="attr">kubernetes.io/service-account.name:</span> <span class="string">example-service-account</span>    <span class="attr">kubernetes.io/service-account.uid:</span> <span class="string">&quot;12345678-1234-1234-1234-1234567890ab&quot;</span><span class="attr">type:</span> <span class="string">kubernetes.io/service-account-token</span><span class="attr">data:</span>  <span class="attr">token:</span> <span class="string">eyJhbGciOiJSUzI1NiIsImtpZCI6InRlc3Qta2V5In0...</span> <span class="comment"># Base64 encoded JWT token</span>  <span class="attr">ca.crt:</span> <span class="string">LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0t...</span> <span class="comment"># Base64 encoded CA certificate</span>  <span class="attr">namespace:</span> <span class="string">ZGVmYXVsdA==</span> <span class="comment"># Base64 encoded namespace</span></code></pre><p><code>bootstrap.kubernetes.io/token</code> 类型创建示例</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Secret</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">bootstrap-token-abcdef</span>  <span class="attr">namespace:</span> <span class="string">kube-system</span><span class="attr">type:</span> <span class="string">bootstrap.kubernetes.io/token</span><span class="attr">data:</span>  <span class="attr">token-id:</span> <span class="string">YWJjZGVm</span> <span class="comment"># Base64 encoded &quot;abcdef&quot;</span>  <span class="attr">token-secret:</span> <span class="string">MTIzNDU2Nzg5MGFiY2RlZg==</span> <span class="comment"># Base64 encoded &quot;1234567890abcdef&quot;</span>  <span class="attr">usage-bootstrap-authentication:</span> <span class="string">dHJ1ZQ==</span> <span class="comment"># Base64 encoded &quot;true&quot;</span>  <span class="attr">usage-bootstrap-signing:</span> <span class="string">dHJ1ZQ==</span> <span class="comment"># Base64 encoded &quot;true&quot;</span>  <span class="attr">description:</span> <span class="string">dG9rZW4gZm9yIG5vZGUgYm9vdHN0cmFwcGluZw==</span> <span class="comment"># Base64 encoded &quot;token for node bootstrapping&quot;</span>  <span class="attr">expiration:</span> <span class="string">MjAyNi0wNS0xM1QxMjowMDowMFo=</span> <span class="comment"># Base64 encoded &quot;2026-05-13T12:00:00Z&quot;</span></code></pre><h2 id="4-Secret-Opaque"><a href="#4-Secret-Opaque" class="headerlink" title="4. Secret-Opaque"></a>4. Secret-Opaque</h2><h3 id="4-1-Opaque-概念"><a href="#4-1-Opaque-概念" class="headerlink" title="4.1 Opaque - 概念"></a>4.1 Opaque - 概念</h3><p>当 Secret 配置文件中未作显式设定时，默认的 Secret 类型是 Opaque。 当你使用 kubectl 来创建一个 Secret 时，你会使用 generic 子命令来标明要创建的是一个 Opaque 类型 Secret。</p><h3 id="4-2-Opaque-创建"><a href="#4-2-Opaque-创建" class="headerlink" title="4.2 Opaque - 创建"></a>4.2 Opaque - 创建</h3><h4 id="4-2-1-手动加密，基于Base64加密"><a href="#4-2-1-手动加密，基于Base64加密" class="headerlink" title="4.2.1 手动加密，基于Base64加密"></a>4.2.1 手动加密，基于Base64加密</h4><pre><code class="highlight bash"><span class="comment"># 对用户名 admin 进行base64编码</span>$ <span class="built_in">echo</span> -n <span class="string">&#x27;admin&#x27;</span> | <span class="built_in">base64</span>YWRtaW4=<span class="comment"># 对密码 abc123456 进行base64编码</span>$ <span class="built_in">echo</span> -n <span class="string">&#x27;abc123456&#x27;</span> | <span class="built_in">base64</span>YWJjMTIzNDU2<span class="comment"># 对base64加密后的用户名进行解密</span>$ <span class="built_in">echo</span> -n <span class="string">&#x27;YWRtaW4=&#x27;</span> | <span class="built_in">base64</span> -dadmin<span class="comment"># 对base64加密后的密码进行解密</span>$ <span class="built_in">echo</span> -n <span class="string">&#x27;YWJjMTIzNDU2&#x27;</span> | <span class="built_in">base64</span> -dabc123456</code></pre><h4 id="4-2-2-使用-yml-文件创建-Opaque"><a href="#4-2-2-使用-yml-文件创建-Opaque" class="headerlink" title="4.2.2 使用 yml 文件创建 Opaque"></a>4.2.2 使用 yml 文件创建 Opaque</h4><p><code>Opaque-Secret.yml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Secret</span> <span class="comment"># 资源类型 Secret</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">mysecret</span> <span class="comment"># 自定义 Secret 名称</span><span class="attr">type:</span> <span class="string">Opaque</span> <span class="comment"># Secret类型指定为 Opaque</span><span class="attr">data:</span>  <span class="attr">password:</span> <span class="string">YWJjMTIzNDU2</span> <span class="comment"># base64 编码后的密码</span>  <span class="attr">username:</span> <span class="string">YWRtaW4=</span> <span class="comment"># base64编码后的用户名</span></code></pre><p><strong>执行文件，创建 Opaque</strong></p><pre><code class="highlight bash">$ kubectl get Secret mysecret -o yaml</code></pre><h4 id="4-2-3-使用命令行创建-Opaque"><a href="#4-2-3-使用命令行创建-Opaque" class="headerlink" title="4.2.3 使用命令行创建 Opaque"></a>4.2.3 使用命令行创建 Opaque</h4><pre><code class="highlight bash"><span class="comment"># generic的默认类型是 Opaque， </span><span class="comment"># username=admin 是一个键值对，Secret 会自动进行 Base64 加密</span>$ kubectl create secret generic db-user-pass --from-literal=username=admin --from-literal=password=abc123456</code></pre><h3 id="4-3-查看-Opaque"><a href="#4-3-查看-Opaque" class="headerlink" title="4.3 查看 Opaque"></a>4.3 查看 Opaque</h3><pre><code class="highlight bash"><span class="comment"># 查看方式一：</span>$ kubectl get Secret mysecret -o yamlapiVersion: v1data:  password: YWJjMTIzNDU2 <span class="comment"># 显示编码后的内容</span>  username: YWRtaW4=kind: Secretmetadata:  creationTimestamp: <span class="string">&quot;2025-05-13T11:30:44Z&quot;</span>  name: mysecret  namespace: default  resourceVersion: <span class="string">&quot;6423295&quot;</span>  uid: fbdb3db6-e47f-4eb2-863a-e6a8eb11c616<span class="built_in">type</span>: Opaque<span class="comment"># 查看方式二：</span>$ kubectl describe Secret mysecretName:         mysecretNamespace:    defaultLabels:       &lt;none&gt;Annotations:  &lt;none&gt;Type:  OpaqueData====password:  9 bytes <span class="comment"># 只显示编码后的字符串的长度</span>username:  5 bytes</code></pre><h3 id="4-4-Opaque-用于环境变量"><a href="#4-4-Opaque-用于环境变量" class="headerlink" title="4.4 Opaque 用于环境变量"></a>4.4 Opaque 用于环境变量</h3><p>资源清单：<code>pod-opaque-env.yml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Secret</span> <span class="comment"># 资源类型 Secret</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">mysecret</span> <span class="comment"># 自定义 Secret 名称</span><span class="attr">type:</span> <span class="string">Opaque</span> <span class="comment"># Secret类型指定为 Opaque</span><span class="attr">data:</span>  <span class="attr">password:</span> <span class="string">YWJjMTIzNDU2</span> <span class="comment"># base64 编码后的密码</span>  <span class="attr">username:</span> <span class="string">YWRtaW4=</span> <span class="comment"># base64编码后的用户名</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-opaque-env</span><span class="attr">spec:</span>  <span class="attr">restartPolicy:</span> <span class="string">Never</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">env:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SECRET_USERNAME</span> <span class="comment"># 环境变量Key</span>          <span class="attr">valueFrom:</span>            <span class="attr">secretKeyRef:</span>              <span class="attr">key:</span> <span class="string">username</span> <span class="comment"># Secret中定义的key</span>              <span class="attr">name:</span> <span class="string">mysecret</span> <span class="comment"># Secret名称</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SECRET_PASSWORD</span>          <span class="attr">valueFrom:</span>            <span class="attr">secretKeyRef:</span>              <span class="attr">key:</span> <span class="string">password</span>              <span class="attr">name:</span> <span class="string">mysecret</span></code></pre><p><strong>创建Secret 和 Pod</strong></p><pre><code class="highlight bash">$ kubectl apply -f pod-opaque-env.yml secret/mysecret createdpod/pod-opaque-env created</code></pre><p><strong>查看环境变量</strong></p><pre><code class="highlight bash"><span class="comment"># 查看Pod</span>$ kubectl get pods -o wideNAME             READY   STATUS    RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATESpod-opaque-env   1/1     Running   0          2m1s   172.16.58.220   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 进入Pod</span>$ kubectl <span class="built_in">exec</span> -it pod-opaque-env -- /bin/bash<span class="comment"># 查看环境变量</span>pod-opaque-env:/<span class="comment"># env</span>KUBERNETES_SERVICE_PORT_HTTPS=443KUBERNETES_SERVICE_PORT=443CHARSET=UTF-8HOSTNAME=pod-opaque-envPWD=/HOME=/rootLANG=C.UTF-8KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443SECRET_USERNAME=admin <span class="comment"># 用户名被自动base64解密</span>TERM=xtermSHLVL=1KUBERNETES_PORT_443_TCP_PROTO=tcpKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1KUBERNETES_SERVICE_HOST=10.96.0.1KUBERNETES_PORT=tcp://10.96.0.1:443KUBERNETES_PORT_443_TCP_PORT=443LC_COLLATE=CPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binSECRET_PASSWORD=abc123456 <span class="comment"># 密码被自动 base64 解密</span>_=/usr/bin/env</code></pre><p>由上可见，在pod中的secret信息实际已经被解密。</p><h3 id="4-4-Opaque-用于-Volume-卷"><a href="#4-4-Opaque-用于-Volume-卷" class="headerlink" title="4.4 Opaque 用于 Volume 卷"></a>4.4 Opaque 用于 Volume 卷</h3><p><code>pod-opaque-volume.yml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Secret</span> <span class="comment"># 资源类型 Secret</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">mysecret</span> <span class="comment"># 自定义 Secret 名称</span><span class="attr">type:</span> <span class="string">Opaque</span> <span class="comment"># Secret类型指定为 Opaque</span><span class="attr">data:</span>  <span class="attr">password:</span> <span class="string">YWJjMTIzNDU2</span> <span class="comment"># base64 编码后的密码</span>  <span class="attr">username:</span> <span class="string">YWRtaW4=</span> <span class="comment"># base64编码后的用户名</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-opaque-env</span><span class="attr">spec:</span>  <span class="attr">restartPolicy:</span> <span class="string">Never</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/secret</span> <span class="comment"># 挂载到容器内的目录</span>          <span class="attr">name:</span> <span class="string">secret-volume</span> <span class="comment"># 挂载的 volume 名称</span>          <span class="attr">readOnly:</span> <span class="literal">true</span> <span class="comment"># 设置容器 /etc/secret 只读</span>  <span class="attr">volumes:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">secret-volume</span> <span class="comment"># 生成的挂在卷名称</span>      <span class="attr">secret:</span> <span class="comment"># 挂载 Secret</span>        <span class="attr">secretName:</span> <span class="string">mysecret</span> <span class="comment"># Secret名称</span></code></pre><p><strong>创建Secret 和 Pod</strong></p><pre><code class="highlight bash">$ kubectl apply -f pod-opaque-volume.yml secret/mysecret createdpod/pod-opaque-env created</code></pre><p><strong>查看Pod挂载的目录</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 Pod</span>$ kubectl get podsNAME             READY   STATUS    RESTARTS   AGEpod-opaque-env   1/1     Running   0          85s<span class="comment"># 进入 Pod 容器</span>$ kubectl <span class="built_in">exec</span> -it pod-opaque-env -- /bin/bash<span class="comment"># 查看挂载目录</span><span class="comment"># ls -l /etc/secret</span>total 0lrwxrwxrwx    1 root     root            15 May 13 20:07 password -&gt; ..data/passwordlrwxrwxrwx    1 root     root            15 May 13 20:07 username -&gt; ..data/username<span class="comment"># 查看username</span><span class="comment"># cat /etc/secret/username </span>admin<span class="comment"># 查看password</span><span class="comment"># cat /etc/secret/password</span>abc123456</code></pre><p>Pod 内 Secret 自动使用 Base64 解密。</p><p><strong>Volume 特殊挂载方式</strong></p><pre><code class="highlight yaml"><span class="comment"># 方式一：设置文件权限，</span><span class="attr">volumes:</span><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volumes12</span>  <span class="attr">secret:</span>    <span class="attr">secretName:</span> <span class="string">mysecret</span>    <span class="attr">defaultMode:</span> <span class="number">256</span> <span class="comment"># 256的8进制是 400， 表示挂载的文件权限为 400</span>    <span class="comment"># 方式二：只挂载 Secret 的部分字段，比如下面，只用了 Secret 的 username 字段</span><span class="attr">volumes:</span><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volumes12</span>  <span class="attr">secret:</span>    <span class="attr">secretName:</span> <span class="string">mysecret</span>    <span class="attr">items:</span>    <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">username</span>      <span class="attr">path:</span> <span class="string">my-group/my-username</span></code></pre><h3 id="4-5-Opaque-Volume-热更新"><a href="#4-5-Opaque-Volume-热更新" class="headerlink" title="4.5 Opaque - Volume - 热更新"></a>4.5 Opaque - Volume - 热更新</h3><p>当已经存储于卷中被使用的 Secret 被更新时，被映射的键也将终将被更新。 组件 kubelet 在周期性同步时检查被挂载的 Secret 是不是最新的。 但是，它会使用其本地缓存的数值作为 Secret 的当前值。使用 Secret 作为子路径卷挂载的容器不会收到 Secret 更新。</p><ul><li>当Opaque 挂载为 Volume 时支持热更新（编辑Secret 保存后，需要过大约1分钟），pod内挂载的目录内容会更新，无需手动重启Pod</li></ul><p>作为子路径挂载容器不支持热更新，示例如下：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">containers:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-app</span>    <span class="attr">image:</span> <span class="string">nginx</span>    <span class="attr">volumeMounts:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">secret-volume</span>      <span class="attr">mountPath:</span> <span class="string">/etc/secret/username</span>      <span class="attr">subPath:</span> <span class="string">username</span>      <span class="attr">readOnly:</span> <span class="literal">true</span>  <span class="attr">volumes:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">secret-volume</span>    <span class="attr">secret:</span>      <span class="attr">secretName:</span> <span class="string">my-secret</span></code></pre><p><code>subPath: username</code>，使用 subPath 只挂载 username，将不会触发热更新。</p><h3 id="4-6-Opaque-Volume-不可更改"><a href="#4-6-Opaque-Volume-不可更改" class="headerlink" title="4.6 Opaque - Volume - 不可更改"></a>4.6 Opaque - Volume - 不可更改</h3><p>Kubernetes 给不可变的 Secret 和 ConfigMap 提供了一种可选配置， 可以设置各个 Secret 和 ConfigMap 为不可变的。 对于大量使用 Secret 的集群（至少有成千上万各不相同的 Secret 供 Pod 挂载）， 禁止变更它们的数据有下列好处：</p><ul><li>防止意外（或非预期的）更新导致应用程序中断</li><li>通过将 Secret 标记为不可变来关闭 kube-apiserver 对其的监视，从而显著降低 kube-apiserver 的负载，提升集群性能</li></ul><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Secret</span> <span class="comment"># 资源类型 Secret</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">mysecret</span> <span class="comment"># 自定义 Secret 名称</span><span class="attr">type:</span> <span class="string">Opaque</span> <span class="comment"># Secret类型指定为 Opaque</span><span class="attr">data:</span>  <span class="attr">password:</span> <span class="string">YWJjMTIzNDU2</span> <span class="comment"># base64 编码后的密码</span>  <span class="attr">username:</span> <span class="string">YWRtaW4=</span> <span class="comment"># base64编码后的用户名</span><span class="attr">immutable:</span> <span class="literal">true</span></code></pre><h2 id="5-Secret-docker-registry"><a href="#5-Secret-docker-registry" class="headerlink" title="5. Secret - docker-registry"></a>5. Secret - docker-registry</h2><p>存储私有docker registry的认证信息</p><h3 id="5-1-搭建-Harbor-镜像仓库"><a href="#5-1-搭建-Harbor-镜像仓库" class="headerlink" title="5.1 搭建 Harbor 镜像仓库"></a>5.1 搭建 Harbor 镜像仓库</h3><p>搭建过程参考：<a href="https://note.youdao.com/s/3YcLzcM1">Harbor企业级部署</a></p><p><strong>Harbor 部分配置文件信息</strong></p><pre><code class="highlight bash">$ vim harbor.ymlhostname: 192.168.6.201http:  <span class="comment"># port for http, default is 80. If https enabled, this port will redirect to https port</span>  port: 5000<span class="comment"># https related config</span>https:  <span class="comment"># https port for harbor, default is 443</span>  <span class="comment">#port: 443</span>  <span class="comment"># The path of cert and key files for nginx</span>  <span class="comment">#certificate: /your/certificate/path</span>  <span class="comment">#private_key: /your/private/key/path</span>harbor_admin_password: Harbor12345<span class="comment"># Harbor DB configuration</span>database:  password: root123  max_idle_conns: 100  max_open_conns: 900  conn_max_lifetime: 5m  conn_max_idle_time: 0<span class="comment"># The default data volume</span>data_volume: /data/harbortrivy:  <span class="comment"># ignoreUnfixed The flag to display only fixed vulnerabilities</span>  ignore_unfixed: <span class="literal">false</span>  skip_update: <span class="literal">false</span>  offline_scan: <span class="literal">false</span>  <span class="comment">#</span>  <span class="comment"># Comma-separated list of what security issues to detect. Possible values are `vuln`, `config` and `secret`. Defaults to `vuln`.</span>  security_check: vuln  insecure: <span class="literal">false</span>jobservice:  <span class="comment"># Maximum number of job workers in job service</span>  max_job_workers: 10notification:  <span class="comment"># Maximum retry count for webhook job</span>  webhook_job_max_retry: 10chart:  <span class="comment"># Change the value of absolute_url to enabled can enable absolute url in chart</span>  absolute_url: disabled<span class="comment"># Log configurations</span><span class="built_in">log</span>:  <span class="comment"># options are debug, info, warning, error, fatal</span>  level: info  <span class="comment"># configs for logs in local storage</span>  <span class="built_in">local</span>:    rotate_count: 50    <span class="comment"># are all valid.</span>    rotate_size: 200M    <span class="comment"># The directory on your host that store log</span>    location: /var/log/harbor<span class="comment">#This attribute is for migrator to detect the version of the .cfg file, DO NOT MODIFY!</span>_version: 2.7.0<span class="comment"># uaa:</span><span class="comment">#   ca_file: /path/to/ca</span>proxy:  http_proxy:  https_proxy:  no_proxy:  components:    - core    - jobservice    - trivy<span class="comment"># enable purge _upload directories</span>upload_purging:  enabled: <span class="literal">true</span>  <span class="comment"># remove files in _upload directories which exist for a period of time, default is one week.</span>  age: 168h  <span class="comment"># the interval of the purge operations</span>  interval: 24h  dryrun: <span class="literal">false</span>cache:  <span class="comment"># not enabled by default</span>  enabled: <span class="literal">false</span>  <span class="comment"># keep cache for one day by default</span>  expire_hours: 24</code></pre><h3 id="5-2-配置-Docker"><a href="#5-2-配置-Docker" class="headerlink" title="5.2 配置 Docker"></a>5.2 配置 Docker</h3><p><strong>集群内所有服务器都需要配置</strong></p><pre><code class="highlight bash">$ vim /etc/docker/daemon.json&#123;  <span class="string">&quot;log-driver&quot;</span>: <span class="string">&quot;json-file&quot;</span>,  <span class="string">&quot;log-opts&quot;</span>: &#123;        <span class="string">&quot;max-size&quot;</span>: <span class="string">&quot;100m&quot;</span>,        <span class="string">&quot;max-file&quot;</span>: <span class="string">&quot;10&quot;</span>  &#125;,  <span class="string">&quot;data-root&quot;</span>:<span class="string">&quot;/data/docker&quot;</span>,  <span class="string">&quot;exec-opts&quot;</span>: [<span class="string">&quot;native.cgroupdriver=systemd&quot;</span>],  <span class="string">&quot;registry-mirrors&quot;</span>: [   <span class="string">&quot;https://kfp63jaj.mirror.aliyuncs.com&quot;</span>,    <span class="string">&quot;https://hub-mirror.c.163.com&quot;</span>,    <span class="string">&quot;https://mirror.baidubce.com&quot;</span>  ],  <span class="string">&quot;insecure-registries&quot;</span>: [<span class="string">&quot;192.168.6.201:5000&quot;</span>]&#125;</code></pre><p><code>192.168.6.201:5000</code> 是harbor服务内网IP和端口</p><h3 id="5-3-创建Harbor私有仓库"><a href="#5-3-创建Harbor私有仓库" class="headerlink" title="5.3 创建Harbor私有仓库"></a>5.3 创建Harbor私有仓库</h3><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/05/14/20250514-084700.png" alt="创建Harbor私有仓库"></p><p><strong>重启集群内的Docker服务</strong></p><p>集群内所有机器，在配置完：<code>/etc/docker/daemon.json</code> 都需要重启Docker服务才能生效</p><pre><code class="highlight bash">$ systemctl restart docker</code></pre><h3 id="5-4-上传镜像到-Harbor-私服"><a href="#5-4-上传镜像到-Harbor-私服" class="headerlink" title="5.4 上传镜像到 Harbor 私服"></a>5.4 上传镜像到 Harbor 私服</h3><pre><code class="highlight bash"><span class="comment"># 拉取镜像（需要科学上网，参考：https://georgechan95.github.io/blog/b01d5c62.html）</span>$ docker pull wangyanglinux/myapp:v1.0<span class="comment"># 给镜像打标签</span>$ docker tag wangyanglinux/myapp:v1.0 192.168.6.201:5000/k8s-secret/myapp:v1<span class="comment"># 登录Harbor</span>$ docker login 192.168.6.201:5000 -u admin -p Harbor12345<span class="comment"># 将镜像推送到Harbor中</span>$ docker push 192.168.6.201:5000/k8s-secret/myapp:v1</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/05/14/20250514-090615.png" alt="上传镜像到 Harbor 私服"></p><p><strong>退出Harbor登录</strong></p><p>这里退出登录，目的是为了演示使用Secret完成Harbor登录</p><pre><code class="highlight bash"><span class="comment"># 退出登录 Harbor</span>$ docker <span class="built_in">logout</span> 192.168.6.201:5000Removing login credentials <span class="keyword">for</span> 192.168.6.201:5000<span class="comment"># 从Harbor中拉取镜像权限异常</span>$ docker pull 192.168.6.201:5000/k8s-secret/myapp:v1</code></pre><h3 id="5-5-Pod-直接拉取镜像"><a href="#5-5-Pod-直接拉取镜像" class="headerlink" title="5.5  Pod 直接拉取镜像"></a>5.5  Pod 直接拉取镜像</h3><p>资源清单：<code>pod-secret-registry.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-secret-registry</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp</span>      <span class="attr">image:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.201</span><span class="string">:5000/k8s-secret/myapp:v1</span></code></pre><p><strong>启动Pod并查看状态</strong></p><pre><code class="highlight bash"><span class="comment"># 启动Pod</span>$ kubectl apply -f pod-secret-registry.yaml pod/pod-secret-registry created<span class="comment"># 查看Pod状态</span>$ kubectl get podsNAME                  READY   STATUS             RESTARTS   AGEpod-secret-registry   0/1     ImagePullBackOff   0          16s<span class="comment"># 查看Pod详情</span>$ kubectl describe pod pod-secret-registryName:             pod-secret-registryEvents:  Type     Reason     Age                 From               Message  ----     ------     ----                ----               -------  Normal   Scheduled  2m5s                default-scheduler  Successfully assigned default/pod-secret-registry to k8s-node02  Normal   Pulling    43s (x4 over 2m4s)  kubelet            Pulling image <span class="string">&quot;192.168.6.201:5000/k8s-secret/myapp:v1&quot;</span>  Warning  Failed     43s (x4 over 2m4s)  kubelet            Failed to pull image <span class="string">&quot;192.168.6.201:5000/k8s-secret/myapp:v1&quot;</span>: Error response from daemon: unauthorized: unauthorized to access repository: k8s-secret/myapp, action: pull: unauthorized to access repository: k8s-secret/myapp, action: pull  Warning  Failed     43s (x4 over 2m4s)  kubelet            Error: ErrImagePull  Warning  Failed     29s (x6 over 2m4s)  kubelet            Error: ImagePullBackOff  Normal   BackOff    14s (x7 over 2m4s)  kubelet            Back-off pulling image <span class="string">&quot;192.168.6.201:5000/k8s-secret/myapp:v1&quot;</span></code></pre><p>镜像拉取失败，未登录Harbor私服，没有拉取权限</p><h3 id="5-6-Pod-通过-Secret-拉取镜像"><a href="#5-6-Pod-通过-Secret-拉取镜像" class="headerlink" title="5.6 Pod 通过 Secret 拉取镜像"></a>5.6 Pod 通过 Secret 拉取镜像</h3><p>资源清单：<code>pod-secret-registry.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Secret</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">harbor-secret</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">type:</span> <span class="string">kubernetes.io/dockerconfigjson</span><span class="attr">stringData:</span> <span class="comment"># stringData 会自动对内容进行base64编码，并存储在data 字段中</span>  <span class="string">.dockerconfigjson:</span> <span class="string">|</span><span class="string">    &#123;</span><span class="string">      &quot;auths&quot;: &#123;</span><span class="string">        &quot;192.168.6.201:5000&quot;: &#123;</span><span class="string">            &quot;username&quot;: &quot;admin&quot;,</span><span class="string">            &quot;password&quot;: &quot;Harbor12345&quot;</span><span class="string">        &#125;</span><span class="string">      &#125;</span><span class="string">    &#125;</span><span class="string"></span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pod-secret-registry</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp</span>      <span class="attr">image:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.201</span><span class="string">:5000/k8s-secret/myapp:v1</span>  <span class="attr">imagePullSecrets:</span> <span class="comment"># 镜像拉取密钥</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">harbor-secret</span> <span class="comment"># Secret 名称</span></code></pre><p><strong>补充：手动创建 kubernetes.io&#x2F;dockerconfigjson 类型的 Secret 方式</strong></p><pre><code class="highlight bash">kubectl create secret docker-registry harbor-secret --docker-server=<span class="string">&#x27;192.168.6.201:5000&#x27;</span> --docker-username=<span class="string">&#x27;admin&#x27;</span> --docker-password=<span class="string">&#x27;Harbor12345&#x27;</span></code></pre><p><strong>启动 Pod</strong></p><pre><code class="highlight bash">$ kubectl apply -f pod-secret-registry.yaml secret/harbor-secret createdpod/pod-secret-registry created</code></pre><p><strong>查看Secret</strong></p><pre><code class="highlight bash"><span class="comment"># 查看方式1</span>$ kubectl describe secret harbor-secretName:         harbor-secretNamespace:    defaultLabels:       &lt;none&gt;Annotations:  &lt;none&gt;Type:  kubernetes.io/dockerconfigjsonData====.dockerconfigjson:  118 bytes<span class="comment"># 查看方式2</span>$ kubectl get secret harbor-secret -o yamlapiVersion: v1data:  .dockerconfigjson: ewogICJhdXRocyI6IHsKICAgICIxOTIuMTY4LjYuMjAxOjUwMDAiOiB7CiAgICAgICAgInVzZXJuYW1lIjogImFkbWluIiwKICAgICAgICAicGFzc3dvcmQiOiAiSGFyYm9yMTIzNDUiCiAgICB9CiAgfQp9Cg==kind: Secretmetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: |      &#123;<span class="string">&quot;apiVersion&quot;</span>:<span class="string">&quot;v1&quot;</span>,<span class="string">&quot;kind&quot;</span>:<span class="string">&quot;Secret&quot;</span>,<span class="string">&quot;metadata&quot;</span>:&#123;<span class="string">&quot;annotations&quot;</span>:&#123;&#125;,<span class="string">&quot;name&quot;</span>:<span class="string">&quot;harbor-secret&quot;</span>,<span class="string">&quot;namespace&quot;</span>:<span class="string">&quot;default&quot;</span>&#125;,<span class="string">&quot;stringData&quot;</span>:&#123;<span class="string">&quot;.dockerconfigjson&quot;</span>:<span class="string">&quot;&#123;\n  \&quot;auths\&quot;: &#123;\n    \&quot;192.168.6.201:5000\&quot;: &#123;\n        \&quot;username\&quot;: \&quot;admin\&quot;,\n        \&quot;password\&quot;: \&quot;Harbor12345\&quot;\n    &#125;\n  &#125;\n&#125;\n&quot;</span>&#125;,<span class="string">&quot;type&quot;</span>:<span class="string">&quot;kubernetes.io/dockerconfigjson&quot;</span>&#125;  creationTimestamp: <span class="string">&quot;2025-05-14T01:41:01Z&quot;</span>  name: harbor-secret  namespace: default  resourceVersion: <span class="string">&quot;6500261&quot;</span>  uid: 8d70288d-5a40-413a-94dc-4dcc6e5c405e<span class="built_in">type</span>: kubernetes.io/dockerconfigjson</code></pre><p><strong>查看Pod状态</strong></p><pre><code class="highlight bash"><span class="comment"># 查看Pod状态</span>$ kubectl get pods -o wideNAME                  READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESpod-secret-registry   1/1     Running   0          20s   172.16.58.244   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看Pod详情</span>$ kubectl describe pod pod-secret-registryName:             pod-secret-registryNamespace:        default......Events:  Type    Reason     Age    From               Message  ----    ------     ----   ----               -------  Normal  Scheduled  8m26s  default-scheduler  Successfully assigned default/pod-secret-registry to k8s-node02  Normal  Pulling    8m26s  kubelet            Pulling image <span class="string">&quot;192.168.6.201:5000/k8s-secret/myapp:v1&quot;</span>  Normal  Pulled     8m25s  kubelet            Successfully pulled image <span class="string">&quot;192.168.6.201:5000/k8s-secret/myapp:v1&quot;</span> <span class="keyword">in</span> 94ms (94ms including waiting)  Normal  Created    8m25s  kubelet            Created container: myapp  Normal  Started    8m25s  kubelet            Started container myapp</code></pre><p>从 Harbor 私服中成功拉取镜像并运行了容器。</p><h1 id="四、Downward-API"><a href="#四、Downward-API" class="headerlink" title="四、Downward API"></a>四、Downward API</h1><p>Downward API 是 Kubernetes 中的一个功能，它允许容器在运行时从 Kubernetes API 服务器获取有关它们自身的信息。这些信息可以作为容器内部的环境变量或文件注入到容器中，以便容器可以获取有关其运行环境的各种信息，如 Pod 名称、命名空间、标签等。</p><p>对于容器来说，有时候拥有自己的信息是很有用的，可避免与Kubernetes过度耦合。Downward API使得容器使用自己或者集群的信息，而不必通过Kubernetes客户端或API服务器。</p><p>举个例子：有一个现有的应用假定要用一个非常熟悉的环境变量来保存一个唯一标识。一种可能是给应用增加处理层，但这样是冗余和易出错的，而且它违反了低耦合的目标。更好的选择是使用Pod名称作为标识，把Pod名称注入这个环境变量中。</p><p><strong>主要作用</strong></p><ul><li>提供容器元数据</li><li>动态配置</li><li>与 Kubernetes 环境集成</li></ul><h2 id="1-将-Pod-字段应用到环境变量中"><a href="#1-将-Pod-字段应用到环境变量中" class="headerlink" title="1. 将 Pod 字段应用到环境变量中"></a>1. 将 Pod 字段应用到环境变量中</h2><h3 id="1-1-资源清单"><a href="#1-1-资源清单" class="headerlink" title="1.1 资源清单"></a>1.1 资源清单</h3><p>资源清单：<code>dapi-pod-env.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">dapi-pod-env</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox-container</span>      <span class="attr">image:</span> <span class="string">busybox:latest</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>] <span class="comment"># 容器启动后，每 10秒打印一次环境变量</span>      <span class="attr">args:</span>        <span class="bullet">-</span> <span class="string">while</span> <span class="literal">true</span><span class="string">;</span> <span class="string">do</span>            <span class="string">echo</span> <span class="string">-en</span> <span class="string">&#x27;\n&#x27;</span><span class="string">;</span>            <span class="string">printenv</span> <span class="string">MY_NODE_NAME</span> <span class="string">MY_POD_NAMESPACE</span> <span class="string">MY_POD_NAME;</span>            <span class="string">printenv</span> <span class="string">MY_POD_IP</span> <span class="string">MY_POD_SERVICE_ACCOUNT;</span>            <span class="string">sleep</span> <span class="number">10</span><span class="string">;</span>          <span class="string">done;</span>      <span class="attr">env:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MY_NODE_NAME</span> <span class="comment"># 环境变量，获取服务器节点名称</span>          <span class="attr">valueFrom:</span>            <span class="attr">fieldRef:</span>              <span class="attr">fieldPath:</span> <span class="string">spec.nodeName</span> <span class="comment"># Pod 所在服务器节点的名称，例如：k8s-node01、k8s-node02</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MY_POD_NAME</span> <span class="comment"># 环境变量，获取 Pod 名称</span>          <span class="attr">valueFrom:</span>            <span class="attr">fieldRef:</span>              <span class="attr">fieldPath:</span> <span class="string">metadata.name</span> <span class="comment"># 读取 Pod 名称属性</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MY_POD_NAMESPACE</span> <span class="comment"># 环境变量，获取 POD 所在的名称空间</span>          <span class="attr">valueFrom:</span>            <span class="attr">fieldRef:</span>              <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span> <span class="comment"># 读取名称空间属性</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MY_POD_IP</span> <span class="comment"># 读取Pod Ip</span>          <span class="attr">valueFrom:</span>            <span class="attr">fieldRef:</span>              <span class="attr">fieldPath:</span> <span class="string">status.podIP</span> <span class="comment"># 读取当前 Pod ip，由于IP是Pod运行后才生成的，属于状态信息，从 status 字段读取</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MY_POD_SERVICE_ACCOUNT</span>          <span class="attr">valueFrom:</span>            <span class="attr">fieldRef:</span>              <span class="attr">fieldPath:</span> <span class="string">spec.serviceAccountName</span> <span class="comment"># Pod 服务账户</span>  <span class="attr">restartPolicy:</span> <span class="string">Never</span></code></pre><p>这个配置文件中，你可以看到五个环境变量。<code>env</code>字段是一个<a href="https://kubernetes.io/docs/resources-reference/v1.18/#envvar-v1-core">EnvVars</a>类型的数组。 数组中第一个元素指定<code>MY_NODE_NAME</code>这个环境变量从Pod的<code>spec.nodeName</code>字段获取变量值。同样，其它环境变量也是从Pod的字段获取它们的变量值。</p><h3 id="1-2-创建-Pod"><a href="#1-2-创建-Pod" class="headerlink" title="1.2 创建 Pod"></a>1.2 创建 Pod</h3><pre><code class="highlight bash">$ kubectl apply -f dapi-pod-env.yaml</code></pre><h3 id="1-3-查看-Pod-状态"><a href="#1-3-查看-Pod-状态" class="headerlink" title="1.3 查看 Pod 状态"></a>1.3 查看 Pod 状态</h3><pre><code class="highlight bash"><span class="comment"># 查看 Pod 状态</span>$ kubectl get pods -o wide NAME           READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESdapi-pod-env   1/1     Running   0          7s    172.16.58.205   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 Pod 详情</span>$ kubectl get pod dapi-pod-env -o yamlapiVersion: v1kind: Podmetadata:  ......  name: dapi-pod-env  namespace: default  resourceVersion: <span class="string">&quot;6534780&quot;</span>  uid: e8856c8b-340f-4080-823c-89c0353e05e6spec:  containers:  - args:    - <span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span> <span class="built_in">echo</span> -en <span class="string">&#x27;\n&#x27;</span>; <span class="built_in">printenv</span> MY_NODE_NAME MY_POD_NAMESPACE MY_POD_NAME;      <span class="built_in">printenv</span> MY_POD_IP MY_POD_SERVICE_ACCOUNT; <span class="built_in">sleep</span> 10; <span class="keyword">done</span>;    <span class="built_in">command</span>:    - sh    - -c    <span class="built_in">env</span>:    - name: MY_NODE_NAME      valueFrom:        fieldRef:          apiVersion: v1          fieldPath: spec.nodeName    - name: MY_POD_NAME      valueFrom:        fieldRef:          apiVersion: v1          fieldPath: metadata.name    - name: MY_POD_NAMESPACE      valueFrom:        fieldRef:          apiVersion: v1          fieldPath: metadata.namespace    - name: MY_POD_IP      valueFrom:        fieldRef:          apiVersion: v1          fieldPath: status.podIP    - name: MY_POD_SERVICE_ACCOUNT      valueFrom:        fieldRef:          apiVersion: v1          fieldPath: spec.serviceAccountName    image: busybox:latest    imagePullPolicy: IfNotPresent    name: busybox-container    ......  dnsPolicy: ClusterFirst  enableServiceLinks: <span class="literal">true</span>  nodeName: k8s-node02  ......  serviceAccount: default  serviceAccountName: default  ......  volumes:  - name: kube-api-access-wknrw    ......status:  conditions:  - lastProbeTime: null    ......  containerStatuses:  - containerID: docker://d8efb6784802d645e67bfaa2fc3708a42b06a15b2356c346786876ed9119538f    ......  hostIP: 192.168.6.141  hostIPs:  - ip: 192.168.6.141  phase: Running  podIP: 172.16.58.205  podIPs:  - ip: 172.16.58.205  qosClass: BestEffort  startTime: <span class="string">&quot;2025-05-14T08:03:58Z&quot;</span></code></pre><h3 id="1-4-查看-Pod-运行日志"><a href="#1-4-查看-Pod-运行日志" class="headerlink" title="1.4 查看 Pod 运行日志"></a>1.4 查看 Pod 运行日志</h3><pre><code class="highlight bash">$ kubectl logs -f --<span class="built_in">tail</span>=100 dapi-pod-env busybox-container<span class="comment"># 打印结果：</span>k8s-node02 <span class="comment"># Pod 所在服务器节点名称</span>default <span class="comment"># Pod 所在名称空间</span>dapi-pod-env <span class="comment"># Pod名称</span>172.16.58.205 <span class="comment"># Pod启动后分配的IP</span>default <span class="comment"># Pod 的服务账户</span>k8s-node02defaultdapi-pod-env172.16.58.205default......</code></pre><h3 id="1-5-进入Pod容器，查看环境变量"><a href="#1-5-进入Pod容器，查看环境变量" class="headerlink" title="1.5 进入Pod容器，查看环境变量"></a>1.5 进入Pod容器，查看环境变量</h3><pre><code class="highlight bash"><span class="comment"># 进入 Pod 容器</span>$ kubectl <span class="built_in">exec</span> -it dapi-pod-env -c busybox-container -- sh<span class="comment"># 打印环境变量</span>/ <span class="comment"># env</span>MY_POD_SERVICE_ACCOUNT=defaultKUBERNETES_SERVICE_PORT=443KUBERNETES_PORT=tcp://10.96.0.1:443HOSTNAME=dapi-pod-envSHLVL=1HOME=/rootMY_POD_NAMESPACE=defaultTERM=xtermMY_POD_IP=172.16.58.205KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binKUBERNETES_PORT_443_TCP_PORT=443KUBERNETES_PORT_443_TCP_PROTO=tcpMY_NODE_NAME=k8s-node02KUBERNETES_SERVICE_PORT_HTTPS=443KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443KUBERNETES_SERVICE_HOST=10.96.0.1PWD=/MY_POD_NAME=dapi-pod-env</code></pre><p><strong>结论：通过 Downward API 可以将Pod的属性、状态信息设置为容器的环境变量</strong></p><h2 id="2-将容器字段应用到环境变量中"><a href="#2-将容器字段应用到环境变量中" class="headerlink" title="2. 将容器字段应用到环境变量中"></a>2. 将容器字段应用到环境变量中</h2><h3 id="2-1-资源清单"><a href="#2-1-资源清单" class="headerlink" title="2.1 资源清单"></a>2.1 资源清单</h3><p><code>dapi-container-env.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">dapi-container-env</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox-container</span>      <span class="attr">image:</span> <span class="string">busybox:latest</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>] <span class="comment"># 容器启动后，每 10秒打印一次环境变量</span>      <span class="attr">args:</span>        <span class="bullet">-</span> <span class="string">while</span> <span class="literal">true</span><span class="string">;</span> <span class="string">do</span>            <span class="string">echo</span> <span class="string">-en</span> <span class="string">&#x27;\n&#x27;</span><span class="string">;</span>            <span class="string">printenv</span> <span class="string">MY_CPU_REQUEST</span> <span class="string">MY_CPU_LIMIT;</span>            <span class="string">printenv</span> <span class="string">MY_MEMORY_REQUEST</span> <span class="string">MY_MEMORY_LIMIT;</span>            <span class="string">sleep</span> <span class="number">10</span><span class="string">;</span>          <span class="string">done;</span>      <span class="attr">resources:</span> <span class="comment"># 定义容器使用的资源</span>        <span class="attr">requests:</span>          <span class="attr">memory:</span> <span class="string">&quot;32Mi&quot;</span> <span class="comment"># 请求 32 MiB 内存，保证 Pod 调度时节点有足够内存。</span>          <span class="attr">cpu:</span> <span class="string">&quot;125m&quot;</span> <span class="comment"># 请求 125 毫核（0.125 CPU 核心），保证 CPU 资源</span>        <span class="attr">limits:</span>          <span class="attr">memory:</span> <span class="string">&quot;64Mi&quot;</span> <span class="comment"># 限制内存使用不超过 64 MiB，防止过度消耗</span>          <span class="attr">cpu:</span> <span class="string">&quot;250m&quot;</span> <span class="comment"># 限制 CPU 使用不超过 250 毫核（0.25 核心）</span>      <span class="attr">env:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MY_CPU_REQUEST</span> <span class="comment"># 容器请求的CPU资源大小</span>          <span class="attr">valueFrom:</span>            <span class="attr">resourceFieldRef:</span>              <span class="attr">containerName:</span> <span class="string">busybox-container</span> <span class="comment"># 指定容器</span>              <span class="attr">resource:</span> <span class="string">requests.cpu</span>              <span class="attr">divisor:</span> <span class="string">1m</span> <span class="comment"># 指定资源值的单位转换因子，用于将 Kubernetes 内部的资源值（如 CPU 或内存）转换为用户期望的单位，并在注入到文件或环境变量时以该单位表示。支持如 1、1m（毫）、1Mi（Mebibyte）、1k（千）等单位</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MY_CPU_LIMIT</span> <span class="comment"># 容器请求的CPU资源上限</span>          <span class="attr">valueFrom:</span>            <span class="attr">resourceFieldRef:</span>              <span class="attr">containerName:</span> <span class="string">busybox-container</span>              <span class="attr">resource:</span> <span class="string">limits.cpu</span>              <span class="attr">divisor:</span> <span class="string">1m</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MY_MEMORY_REQUEST</span> <span class="comment"># 容器请求的内存资源大小</span>          <span class="attr">valueFrom:</span>            <span class="attr">resourceFieldRef:</span>              <span class="attr">containerName:</span> <span class="string">busybox-container</span>              <span class="attr">resource:</span> <span class="string">requests.memory</span>              <span class="attr">divisor:</span> <span class="string">1Mi</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MY_MEMORY_LIMIT</span> <span class="comment"># 容器请求的内存资源上限</span>          <span class="attr">valueFrom:</span>            <span class="attr">resourceFieldRef:</span>              <span class="attr">containerName:</span> <span class="string">busybox-container</span>              <span class="attr">resource:</span> <span class="string">limits.memory</span>              <span class="attr">divisor:</span> <span class="string">1Mi</span>  <span class="attr">restartPolicy:</span> <span class="string">Never</span></code></pre><p>这个配置文件中，你可以看到四个环境变量。<code>env</code>字段是一个 <a href="https://kubernetes.io/docs/resources-reference/v1.18/#envvar-v1-core">EnvVars</a> 类型的数组。数组中第一个元素指定<code>MY_CPU_REQUEST</code>这个环境变量从容器的<code>requests.cpu</code>字段获取变量值。同样，其它环境变量也是从容器的字段获取它们的变量值。</p><h3 id="2-2-创建-Pod"><a href="#2-2-创建-Pod" class="headerlink" title="2.2 创建 Pod"></a>2.2 创建 Pod</h3><pre><code class="highlight bash">$ kubectl apply -f dapi-container-env.yaml</code></pre><h3 id="2-3-查看-Pod-状态"><a href="#2-3-查看-Pod-状态" class="headerlink" title="2.3 查看 Pod 状态"></a>2.3 查看 Pod 状态</h3><pre><code class="highlight bash">$ kubectl get pods -o wideNAME                 READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESdapi-container-env   1/1     Running   0          11s   172.16.58.241   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><h3 id="2-4-查看-Pod-运行日志"><a href="#2-4-查看-Pod-运行日志" class="headerlink" title="2.4 查看 Pod 运行日志"></a>2.4 查看 Pod 运行日志</h3><pre><code class="highlight bash">$ kubectl logs -f --<span class="built_in">tail</span>=100 dapi-container-env 12525032641252503264</code></pre><p>注意，<code>divisor</code> 显式指定 CPU 和内存的单位，如果不添加此参数，日志显示会有异常。</p><h3 id="2-5-进入-Pod容器，查看环境变量"><a href="#2-5-进入-Pod容器，查看环境变量" class="headerlink" title="2.5 进入 Pod容器，查看环境变量"></a>2.5 进入 Pod容器，查看环境变量</h3><pre><code class="highlight bash">$ kubectl <span class="built_in">exec</span> -it dapi-container-env -c busybox-container -- <span class="built_in">env</span>PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binHOSTNAME=dapi-container-envTERM=xtermMY_CPU_REQUEST=125MY_CPU_LIMIT=250MY_MEMORY_REQUEST=32MY_MEMORY_LIMIT=64KUBERNETES_PORT_443_TCP_PORT=443KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1KUBERNETES_SERVICE_HOST=10.96.0.1KUBERNETES_SERVICE_PORT=443KUBERNETES_SERVICE_PORT_HTTPS=443KUBERNETES_PORT=tcp://10.96.0.1:443KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443KUBERNETES_PORT_443_TCP_PROTO=tcpHOME=/root</code></pre><h2 id="3-挂载-Pod-字段到-Volume"><a href="#3-挂载-Pod-字段到-Volume" class="headerlink" title="3. 挂载 Pod 字段到 Volume"></a>3. 挂载 Pod 字段到 Volume</h2><h3 id="3-1-资源清单"><a href="#3-1-资源清单" class="headerlink" title="3.1 资源清单"></a>3.1 资源清单</h3><p><code>dapi-pod-volume.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">dapi-pod-volume</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">zone:</span> <span class="string">us-est-coast</span>    <span class="attr">cluster:</span> <span class="string">test-cluster1</span>    <span class="attr">env:</span> <span class="string">test</span>  <span class="attr">annotations:</span>    <span class="attr">build:</span> <span class="string">two</span>    <span class="attr">builder:</span> <span class="string">George</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox-container</span>      <span class="attr">image:</span> <span class="string">busybox:latest</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">command:</span> [ <span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span> ] <span class="comment"># 容器启动后，每 10秒打印一次环境变量</span>      <span class="attr">args:</span>        <span class="bullet">-</span> <span class="string">while</span> <span class="literal">true</span><span class="string">;</span> <span class="string">do</span>            <span class="string">if</span> [[ <span class="string">-e</span> <span class="string">/etc/podinfo/labels</span> ]]<span class="string">;</span> <span class="string">then</span>              <span class="string">echo</span> <span class="string">-en</span> <span class="string">&#x27;\n\n&#x27;</span><span class="string">;</span> <span class="string">cat</span> <span class="string">/etc/podinfo/labels;</span> <span class="string">fi;</span>            <span class="string">if</span> [[ <span class="string">-e</span> <span class="string">/etc/podinfo/annotations</span> ]]<span class="string">;</span> <span class="string">then</span>              <span class="string">echo</span> <span class="string">-en</span> <span class="string">&#x27;\n\n&#x27;</span><span class="string">;</span> <span class="string">cat</span> <span class="string">/etc/podinfo/annotations;</span> <span class="string">fi;</span>            <span class="string">sleep</span> <span class="number">5</span><span class="string">;</span>          <span class="string">done;</span>      <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">podinfo</span>          <span class="attr">mountPath:</span> <span class="string">/etc/podinfo</span>  <span class="attr">volumes:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">podinfo</span>      <span class="attr">downwardAPI:</span>        <span class="attr">items:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">&quot;labels&quot;</span>            <span class="attr">fieldRef:</span>              <span class="attr">fieldPath:</span> <span class="string">metadata.labels</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">&quot;annotations&quot;</span>            <span class="attr">fieldRef:</span>              <span class="attr">fieldPath:</span> <span class="string">metadata.annotations</span></code></pre><p>Pod有一个<code>downwardAPI</code>类型的Volume，并且挂载到容器中的<code>/etc/podinfo</code> 目录下</p><p>查看<code>downwardAPI</code>下面的<code>items</code>数组。每个数组元素都是一个 <a href="https://kubernetes.io/docs/resources-reference/v1.18/#downwardapivolumefile-v1-core">DownwardAPIVolumeFile</a>。 第一个元素指示Pod的<code>metadata.labels</code>字段的值保存在名为<code>labels</code>的文件中。 第二个元素指示Pod的<code>annotations</code>字段的值保存在名为<code>annotations</code>的文件中。</p><h3 id="3-2-创建-Pod"><a href="#3-2-创建-Pod" class="headerlink" title="3.2 创建 Pod"></a>3.2 创建 Pod</h3><pre><code class="highlight bash">$ kubectl apply -f dapi-pod-volume.yaml</code></pre><h3 id="3-3-查看-Pod-状态"><a href="#3-3-查看-Pod-状态" class="headerlink" title="3.3 查看 Pod 状态"></a>3.3 查看 Pod 状态</h3><pre><code class="highlight bash">$ kubectl get podsNAME              READY   STATUS    RESTARTS   AGEdapi-pod-volume   1/1     Running   0          59s</code></pre><h3 id="3-4-查看-Pod-挂载目录"><a href="#3-4-查看-Pod-挂载目录" class="headerlink" title="3.4 查看 Pod 挂载目录"></a>3.4 查看 Pod 挂载目录</h3><pre><code class="highlight bash"><span class="comment"># 进入Pod容器</span>$ kubectl <span class="built_in">exec</span> -it dapi-pod-volume -- sh<span class="comment"># 进入挂载目录</span>/ <span class="comment"># cd /etc/podinfo/</span><span class="comment"># 挂载目录下有两个文件，正是 volume 挂载的路径</span>/etc/podinfo <span class="comment"># ls</span>annotations  labels<span class="comment"># 查看 labes 文件</span>/etc/podinfo <span class="comment"># cat labels </span>cluster=<span class="string">&quot;test-cluster1&quot;</span><span class="built_in">env</span>=<span class="string">&quot;test&quot;</span><span class="comment"># 查看 annotations 文件</span>/etc/podinfo <span class="comment"># cat annotations</span>build=<span class="string">&quot;two&quot;</span>builder=<span class="string">&quot;George&quot;</span>cni.projectcalico.org/containerID=<span class="string">&quot;31eef5f93dca9ee1b124d4974e8522c31d291fabf43178009b9c4ccb8fb2ebd6&quot;</span>cni.projectcalico.org/podIP=<span class="string">&quot;172.16.58.255/32&quot;</span>cni.projectcalico.org/podIPs=<span class="string">&quot;172.16.58.255/32&quot;</span>kubectl.kubernetes.io/last-applied-configuration=<span class="string">&quot;&#123;\&quot;apiVersion\&quot;:\&quot;v1\&quot;,\&quot;kind\&quot;:\&quot;Pod\&quot;,\&quot;metadata\&quot;:&#123;\&quot;annotations\&quot;:&#123;\&quot;build\&quot;:\&quot;two\&quot;,\&quot;builder\&quot;:\&quot;George\&quot;&#125;,\&quot;labels\&quot;:&#123;\&quot;cluster\&quot;:\&quot;test-cluster1\&quot;,\&quot;env\&quot;:\&quot;test\&quot;,\&quot;zone\&quot;:\&quot;us-est-coast\&quot;&#125;,\&quot;name\&quot;:\&quot;dapi-pod-volume\&quot;,\&quot;namespace\&quot;:\&quot;default\&quot;&#125;,\&quot;spec\&quot;:&#123;\&quot;containers\&quot;:[&#123;\&quot;args\&quot;:[\&quot;while true; do if [[ -e /etc/podinfo/labels ]]; then echo -en &#x27;\\\\n\\\\n&#x27;; cat /etc/podinfo/labels; fi; if [[ -e /etc/podinfo/annotations ]]; then echo -en &#x27;\\\\n\\\\n&#x27;; cat /etc/podinfo/annotations; fi; sleep 5; done;\&quot;],\&quot;command\&quot;:[\&quot;sh\&quot;,\&quot;-c\&quot;],\&quot;image\&quot;:\&quot;busybox:latest\&quot;,\&quot;imagePullPolicy\&quot;:\&quot;IfNotPresent\&quot;,\&quot;name\&quot;:\&quot;busybox-container\&quot;,\&quot;volumeMounts\&quot;:[&#123;\&quot;mountPath\&quot;:\&quot;/etc/podinfo\&quot;,\&quot;name\&quot;:\&quot;podinfo\&quot;&#125;]&#125;],\&quot;volumes\&quot;:[&#123;\&quot;downwardAPI\&quot;:&#123;\&quot;items\&quot;:[&#123;\&quot;fieldRef\&quot;:&#123;\&quot;fieldPath\&quot;:\&quot;metadata.labels\&quot;&#125;,\&quot;path\&quot;:\&quot;labels\&quot;&#125;,&#123;\&quot;fieldRef\&quot;:&#123;\&quot;fieldPath\&quot;:\&quot;metadata.annotations\&quot;&#125;,\&quot;path\&quot;:\&quot;annotations\&quot;&#125;]&#125;,\&quot;name\&quot;:\&quot;podinfo\&quot;&#125;]&#125;&#125;\n&quot;</span>kubernetes.io/config.seen=<span class="string">&quot;2025-05-15T09:15:54.979291949+08:00&quot;</span>kubernetes.io/config.source=<span class="string">&quot;api&quot;</span>/etc/podinfo <span class="comment">#</span></code></pre><p>​</p><p><strong>查看<code>/etc</code>目录下的文件：</strong></p><pre><code class="highlight plaintext">ls -laR /etc/etc:total 32drwxrwxrwt    3 root     root           120 May 15 01:15 podinfo-rw-r--r--    1 root     root           103 May 15 01:15 resolv.conf-rw-------    1 root     root           136 Sep 26  2024 shadow/etc/podinfo:drwxr-xr-x    2 root     root            80 May 15 01:15 ..2025_05_15_01_15_56.854842629lrwxrwxrwx    1 root     root            31 May 15 01:15 ..data -&gt; ..2025_05_15_01_15_56.854842629lrwxrwxrwx    1 root     root            18 May 15 01:15 annotations -&gt; ..data/annotationslrwxrwxrwx    1 root     root            13 May 15 01:15 labels -&gt; ..data/labels/etc/podinfo/..2025_05_15_01_15_56.854842629:-rw-r--r--    1 root     root          1313 May 15 01:15 annotations-rw-r--r--    1 root     root            54 May 15 01:15 labels</code></pre><p>在输出中可以看到，<code>labels</code> 和 <code>annotations</code>文件都在一个临时子目录中：这个例子，<code>..2025_05_15_01_15_56.854842629</code>。在<code>/etc</code>目录中，<code>..data</code>是一个指向临时子目录 的符号链接。<code>/etc</code>目录中，<code>labels</code> 和 <code>annotations</code>也是符号链接。</p><p>用符号链接可实现元数据的动态原子刷新；更新将写入一个新的临时目录，然后<code>..data</code>符号链接完成原子更新，通过使用<a href="http://man7.org/linux/man-pages/man2/rename.2.html">rename(2)</a>。</p><p><strong>查看临时子目录</strong></p><pre><code class="highlight bash"><span class="built_in">cat</span> /etc/podinfo/..2025_05_15_01_15_56.854842629/labels <span class="comment"># 内容如下：</span>cluster=<span class="string">&quot;test-cluster1&quot;</span><span class="built_in">env</span>=<span class="string">&quot;test&quot;</span></code></pre><h2 id="4-挂载容器字段到-Volume"><a href="#4-挂载容器字段到-Volume" class="headerlink" title="4. 挂载容器字段到 Volume"></a>4. 挂载容器字段到 Volume</h2><h3 id="4-1-资源清单"><a href="#4-1-资源清单" class="headerlink" title="4.1 资源清单"></a>4.1 资源清单</h3><p><code>dapi-container-volume.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">dapi-container-volume</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox-container</span>      <span class="attr">image:</span> <span class="string">busybox:latest</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>] <span class="comment"># 容器启动后，每 10秒打印一次环境变量</span>      <span class="attr">args:</span>        <span class="bullet">-</span> <span class="string">while</span> <span class="literal">true</span><span class="string">;</span> <span class="string">do</span>            <span class="string">echo</span> <span class="string">-en</span> <span class="string">&#x27;\n&#x27;</span><span class="string">;</span>            <span class="string">if</span> [[ <span class="string">-e</span> <span class="string">/etc/container/cpu_limit</span> ]]<span class="string">;</span> <span class="string">then</span>              <span class="string">echo</span> <span class="string">-en</span> <span class="string">&#x27;\n&#x27;</span><span class="string">;</span> <span class="string">cat</span> <span class="string">/etc/container/cpu_limit;</span> <span class="string">fi;</span>            <span class="string">if</span> [[ <span class="string">-e</span> <span class="string">/etc/container/cpu_request</span> ]]<span class="string">;</span> <span class="string">then</span>              <span class="string">echo</span> <span class="string">-en</span> <span class="string">&#x27;\n&#x27;</span><span class="string">;</span> <span class="string">cat</span> <span class="string">/etc/container/cpu_request;</span> <span class="string">fi;</span>            <span class="string">if</span> [[ <span class="string">-e</span> <span class="string">/etc/container/memory_limit</span> ]]<span class="string">;</span> <span class="string">then</span>              <span class="string">echo</span> <span class="string">-en</span> <span class="string">&#x27;\n&#x27;</span><span class="string">;</span> <span class="string">cat</span> <span class="string">/etc/container/memory_limit;</span> <span class="string">fi;</span>            <span class="string">if</span> [[ <span class="string">-e</span> <span class="string">/etc/container/memory_request</span> ]]<span class="string">;</span> <span class="string">then</span>              <span class="string">echo</span> <span class="string">-en</span> <span class="string">&#x27;\n&#x27;</span><span class="string">;</span> <span class="string">cat</span> <span class="string">/etc/container/memory_request;</span> <span class="string">fi;</span>            <span class="string">sleep</span> <span class="number">5</span><span class="string">;</span>          <span class="string">done;</span>      <span class="attr">resources:</span> <span class="comment"># 定义容器使用的资源</span>        <span class="attr">requests:</span>          <span class="attr">memory:</span> <span class="string">&quot;32Mi&quot;</span> <span class="comment"># 请求 32 MiB 内存，保证 Pod 调度时节点有足够内存。</span>          <span class="attr">cpu:</span> <span class="string">&quot;125m&quot;</span> <span class="comment"># 请求 125 毫核（0.125 CPU 核心），保证 CPU 资源</span>        <span class="attr">limits:</span>          <span class="attr">memory:</span> <span class="string">&quot;64Mi&quot;</span> <span class="comment"># 限制内存使用不超过 64 MiB，防止过度消耗</span>          <span class="attr">cpu:</span> <span class="string">&quot;250m&quot;</span> <span class="comment"># 限制 CPU 使用不超过 250 毫核（0.25 核心）</span>      <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">container-volume</span>          <span class="attr">mountPath:</span> <span class="string">/etc/container</span>  <span class="attr">volumes:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">container-volume</span>      <span class="attr">downwardAPI:</span>        <span class="attr">items:</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">&quot;cpu_request&quot;</span>            <span class="attr">resourceFieldRef:</span>              <span class="attr">containerName:</span> <span class="string">busybox-container</span>              <span class="attr">resource:</span> <span class="string">requests.cpu</span>              <span class="attr">divisor:</span> <span class="string">1m</span> <span class="comment"># 指定资源值的单位转换因子，用于将 Kubernetes 内部的资源值（如 CPU 或内存）转换为用户期望的单位，并在注入到文件或环境变量时以该单位表示。支持如 1、1m（毫）、1Mi（Mebibyte）、1k（千）等单位</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">&quot;cpu_limit&quot;</span>            <span class="attr">resourceFieldRef:</span>              <span class="attr">containerName:</span> <span class="string">busybox-container</span>              <span class="attr">resource:</span> <span class="string">limits.cpu</span>              <span class="attr">divisor:</span> <span class="string">1m</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">&quot;memory_request&quot;</span>            <span class="attr">resourceFieldRef:</span>              <span class="attr">containerName:</span> <span class="string">busybox-container</span>              <span class="attr">resource:</span> <span class="string">requests.memory</span>              <span class="attr">divisor:</span> <span class="string">1Mi</span>          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">&quot;memory_limit&quot;</span>            <span class="attr">resourceFieldRef:</span>              <span class="attr">containerName:</span> <span class="string">busybox-container</span>              <span class="attr">resource:</span> <span class="string">limits.memory</span>              <span class="attr">divisor:</span> <span class="string">1Mi</span>  <span class="attr">restartPolicy:</span> <span class="string">Never</span></code></pre><h3 id="4-2-创建-Pod"><a href="#4-2-创建-Pod" class="headerlink" title="4.2 创建 Pod"></a>4.2 创建 Pod</h3><pre><code class="highlight bash">$ kubectl apply -f dapi-container-volume.yaml</code></pre><h3 id="4-3-查看-Pod-状态"><a href="#4-3-查看-Pod-状态" class="headerlink" title="4.3 查看 Pod 状态"></a>4.3 查看 Pod 状态</h3><pre><code class="highlight bash">$ kubectl get podsNAME                    READY   STATUS    RESTARTS   AGEdapi-container-volume   1/1     Running   0          4s</code></pre><h3 id="4-4-查看-Pod-日志"><a href="#4-4-查看-Pod-日志" class="headerlink" title="4.4 查看 Pod 日志"></a>4.4 查看 Pod 日志</h3><pre><code class="highlight bash">$ kubectl logs -f --<span class="built_in">tail</span>=100 dapi-container-volume250 <span class="comment"># limits.cpu</span>125 <span class="comment"># requests.cpu</span>64  <span class="comment"># limits.memory</span>32  <span class="comment"># requests.memory</span>2501256432</code></pre><h3 id="4-5-进入-Pod-目录，查看挂载文件"><a href="#4-5-进入-Pod-目录，查看挂载文件" class="headerlink" title="4.5 进入 Pod 目录，查看挂载文件"></a>4.5 进入 Pod 目录，查看挂载文件</h3><pre><code class="highlight bash"><span class="comment"># 进入 Pod 容器</span>$ kubectl <span class="built_in">exec</span> -it dapi-container-volume -- sh/ <span class="comment"># 进入就挂载目录</span><span class="comment"># cd /etc/container/</span><span class="comment"># 查看挂载文件</span>/etc/container <span class="comment"># ls</span>cpu_limit       cpu_request     memory_limit    memory_request<span class="comment"># 查看 cpu_limit </span>/etc/container <span class="comment"># cat cpu_limit </span>250</code></pre><h2 id="5-Downward-API-常用属性"><a href="#5-Downward-API-常用属性" class="headerlink" title="5. Downward API 常用属性"></a>5. Downward API 常用属性</h2><p>下面这些信息可以通过环境变量和DownwardAPIVolumeFiles提供给容器：</p><p><strong>能通过<code>fieldRef</code>获得的：</strong></p><ul><li><code>metadata.name</code> - Pod名称</li><li><code>metadata.namespace</code> - Pod名字空间</li><li><code>metadata.uid</code> - Pod的UID, 版本要求 v1.8.0-alpha.2</li><li><code>metadata.labels[&#39;&lt;KEY&gt;&#39;]</code> - 单个 pod 标签值 <code>&lt;KEY&gt;</code> (例如, <code>metadata.labels[&#39;mylabel&#39;]</code>); 版本要求 Kubernetes 1.9+</li><li><code>metadata.annotations[&#39;&lt;KEY&gt;&#39;]</code> - 单个 pod 的标注值 <code>&lt;KEY&gt;</code> (例如, <code>metadata.annotations[&#39;myannotation&#39;]</code>); 版本要求 Kubernetes 1.9+</li><li><code>status.podIP</code> - 节点IP</li><li><code>spec.serviceAccountName</code> - Pod服务帐号名称, 版本要求 v1.4.0-alpha.3</li><li><code>spec.nodeName</code> - 节点名称, 版本要求 v1.4.0-alpha.3</li><li><code>status.hostIP</code> - 节点IP, 版本要求 v1.7.0-alpha.1</li></ul><p><em>说明： 如果容器未指定CPU和memory limits，则Downward API默认为节点可分配值。</em></p><p><strong>能通过<code>resourceFieldRef</code>获得的：</strong></p><ul><li>容器的CPU约束值</li><li>容器的CPU请求值</li><li>容器的内存约束值</li><li>容器的内存请求值</li><li>容器的临时存储约束值, 版本要求 v1.8.0-beta.0</li><li>容器的临时存储请求值, 版本要求 v1.8.0-beta.0</li></ul><h2 id="6-volume-相较于-env-优势"><a href="#6-volume-相较于-env-优势" class="headerlink" title="6. volume 相较于 env 优势"></a>6. volume 相较于 env 优势</h2><ul><li>会保持热更新的特性</li><li>传递一个容器的资源字段到另一个容器中</li></ul><h1 id="五、Volume"><a href="#五、Volume" class="headerlink" title="五、Volume"></a>五、Volume</h1><h2 id="1-Volume概述"><a href="#1-Volume概述" class="headerlink" title="1. Volume概述"></a>1. Volume概述</h2><p>在容器中的文件在磁盘上是临时存放的，当容器关闭时这些临时文件也会被一并清除。这给容器中运行的特殊应用程序带来一些问题。首先，当容器崩溃时，kubelet 将重新启动容器，容器中的文件将会丢失——因为容器会以干净的状态重建。其次，当在一个 Pod 中同时运行多个容器时，常常需要在这些容器之间共享文件。</p><p>Kubernetes 抽象出 Volume 对象来解决这两个问题。</p><p>Kubernetes <strong>Volume卷具有明确的生命周期——与包裹它的 Pod 相同</strong>。 因此，Volume比 Pod 中运行的任何容器的存活期都长，在容器重新启动时数据也会得到保留。 当然，<strong>当一个 Pod 不再存在时，Volume也将不再存在</strong>。更重要的是，Kubernetes 可以支持许多类型的Volume卷，Pod 也能同时使用任意数量的Volume卷。</p><p>使用卷时，Pod 声明中需要提供卷的类型 (.spec.volumes 字段)和卷挂载的位置 (.spec.containers.volumeMounts 字段).</p><h2 id="2-Volume类型"><a href="#2-Volume类型" class="headerlink" title="2. Volume类型"></a>2. Volume类型</h2><p>Kubernetes 支持下列类型的卷：</p><ul><li>awsElasticBlockStore</li><li>azureDisk</li><li>azureFile</li><li>cephfs</li><li>cinder</li><li>configMap</li><li>csi</li><li>downwardAPI</li><li>emptyDir</li><li>fc (fibre channel)</li><li>flexVolume</li><li>flocker</li><li>gcePersistentDisk</li><li>gitRepo (deprecated)</li><li>glusterfs</li><li>hostPath</li><li>iscsi</li><li>local</li><li>nfs</li><li>persistentVolumeClaim</li><li>projected</li><li>portworxVolume</li><li>quobyte</li><li>rbd</li><li>scaleIO</li><li>secret</li><li>storageos</li><li>vsphereVolume</li></ul><p>其中 Secret、ConfigMap 前面已经介绍过了，这里再介绍三种，分别是：emptyDir、hostPath、nfs</p><h2 id="3-EmptyDir-卷"><a href="#3-EmptyDir-卷" class="headerlink" title="3. EmptyDir 卷"></a>3. EmptyDir 卷</h2><p>当 Pod 指定到某个节点上时，首先创建的是一个 emptyDir 卷，并且只要 Pod 在该节点上运行，卷就一直存在。就像它的名称表示的那样，卷最初是空的。</p><p>尽管 <strong>Pod 中每个容器挂载 emptyDir 卷的路径可能相同也可能不同，但是这些容器都可以读写 emptyDir 卷中相同的文件</strong>。</p><p>如果Pod中有多个容器，其中某个容器重启，不会影响emptyDir 卷中的数据。当 Pod 因为某些原因被删除时，emptyDir 卷中的数据也会永久删除。</p><p><strong>注意：容器崩溃并不会导致 Pod 被从节点上移除，因此容器崩溃时 emptyDir 卷中的数据是安全的。</strong></p><h3 id="3-1-emptyDir的一些用途"><a href="#3-1-emptyDir的一些用途" class="headerlink" title="3.1 emptyDir的一些用途"></a>3.1 emptyDir的一些用途</h3><ul><li>缓存空间，例如基于磁盘的归并排序</li><li>为耗时较长的计算任务提供检查点，以便任务能方便地从崩溃前状态恢复执行</li><li>在 Web 服务器容器服务数据时，保存内容管理器容器获取的文件</li></ul><h3 id="3-2-emptyDir-使用案例"><a href="#3-2-emptyDir-使用案例" class="headerlink" title="3.2 emptyDir 使用案例"></a>3.2 emptyDir 使用案例</h3><h4 id="3-2-1-资源清单"><a href="#3-2-1-资源清单" class="headerlink" title="3.2.1 资源清单"></a>3.2.1 资源清单</h4><p><code>001-volume-emptydir-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">emptydir-deployment</span>  <span class="attr">labels:</span>    <span class="attr">name:</span> <span class="string">volumn-dep</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># Deployment控制器管理具有如下标签的Pod</span>      <span class="attr">type:</span> <span class="string">emptydir</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span> <span class="comment"># Pod模板设定生成的Pod有这些标签项</span>        <span class="attr">app:</span> <span class="string">myapp</span>        <span class="attr">type:</span> <span class="string">emptydir</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-container</span> <span class="comment"># Pod1，nginx</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>          <span class="attr">volumeMounts:</span> <span class="comment"># 设置 pod 挂载的容器卷</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span>              <span class="attr">mountPath:</span> <span class="string">/usr/local/nginx/logs</span> <span class="comment"># 镜像日志输出目录，必须存在</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox-container</span> <span class="comment"># Pod2，busybox</span>          <span class="attr">image:</span> <span class="string">busybox:latest</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span> <span class="comment"># 设置 pod 挂载的容器卷</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span>              <span class="attr">mountPath:</span> <span class="string">/logs</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&#x27;/bin/sh&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;-c&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;tail -f /logs/access.log&#x27;</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span> <span class="comment"># 设置自定义容器卷的名称</span>          <span class="attr">emptyDir:</span> &#123;&#125; <span class="comment"># 容器卷类型：emptyDir</span></code></pre><h4 id="3-2-2-创建-Deployment"><a href="#3-2-2-创建-Deployment" class="headerlink" title="3.2.2 创建 Deployment"></a>3.2.2 创建 Deployment</h4><pre><code class="highlight bash"><span class="comment"># 使用资源清单创建 Deployment</span>$ kubectl apply -f 001-volume-emptydir-01.yaml<span class="comment"># 查看 Pod</span>$ kubectl get pods -o wide NAME                                   READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESemptydir-deployment-6cf749f46f-fb8ww   2/2     Running   0          6s    172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>成功创建Pod，两个容器已就绪。</p><p>**访问 nginx-container **</p><pre><code class="highlight bash">$ curl 172.16.58.197www.xinxianghf.com | hello MyAPP | version v1.0</code></pre><h4 id="3-2-3-查看-Pod-详情"><a href="#3-2-3-查看-Pod-详情" class="headerlink" title="3.2.3 查看 Pod 详情"></a>3.2.3 查看 Pod 详情</h4><pre><code class="highlight bash">$ kubectl describe pod emptydir-deployment-6cf749f46f-fb8wwName:             emptydir-deployment-6cf749f46f-fb8wwNamespace:        defaultContainers:  nginx-container:    Container ID:   docker://56c2112d34006320b474374d8e385c61b9d4a0402d1d5ad89d83d83d5a256ba0......    Mounts:      /usr/local/nginx/logs from log-volume (rw)      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-lp4hs (ro)  busybox-container:    Container ID:  docker://7f0a784a4e5cd47cc1efe0bc16749e29b38bfababa33f6be3cbda676d38f53c8    Command:      /bin/sh      -c      <span class="built_in">tail</span> -f /logs/access.log    ......    Mounts:      /logs from log-volume (rw)      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-lp4hs (ro)</code></pre><p>两个容器内不同的目录挂载了同一个 Volume （log-volume）</p><h4 id="3-2-4-进入-nginx-container-容器查看日志"><a href="#3-2-4-进入-nginx-container-容器查看日志" class="headerlink" title="3.2.4 进入 nginx-container 容器查看日志"></a>3.2.4 进入 nginx-container 容器查看日志</h4><pre><code class="highlight bash">$ kubectl <span class="built_in">exec</span> -it emptydir-deployment-6cf749f46f-fb8ww -c nginx-container -- <span class="built_in">tail</span> -f /usr/local/nginx/logs/access.log172.16.167.128 - - [15/May/2025:15:00:13 +0800] <span class="string">&quot;GET / HTTP/1.1&quot;</span> 200 48 <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.76.1&quot;</span>172.16.167.128 - - [15/May/2025:15:01:50 +0800] <span class="string">&quot;GET / HTTP/1.1&quot;</span> 200 48 <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.76.1&quot;</span></code></pre><h4 id="3-2-5-进入-busybox-container-容器查看日志"><a href="#3-2-5-进入-busybox-container-容器查看日志" class="headerlink" title="3.2.5 进入 busybox-container 容器查看日志"></a>3.2.5 进入 busybox-container 容器查看日志</h4><pre><code class="highlight bash">$ kubectl <span class="built_in">exec</span> -it emptydir-deployment-6cf749f46f-fb8ww -c busybox-container -- <span class="built_in">tail</span> -f /logs/access.log172.16.167.128 - - [15/May/2025:15:00:13 +0800] <span class="string">&quot;GET / HTTP/1.1&quot;</span> 200 48 <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.76.1&quot;</span>172.16.167.128 - - [15/May/2025:15:01:50 +0800] <span class="string">&quot;GET / HTTP/1.1&quot;</span> 200 48 <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.76.1&quot;</span></code></pre><p>总结：通过 emptyDir 可以实现在一个 Pod 内，多个容器挂载到同一个 Volume，共享挂载文件。且容器可以将 Volume 挂载到不同的路径下。</p><h2 id="4-HostPath"><a href="#4-HostPath" class="headerlink" title="4. HostPath"></a>4. HostPath</h2><p>EmptyDir 中数据不会被持久化，它会随着 Pod 的结束而销毁，如果想简单的将数据持久化到主机中，可以选择 HostPath。</p><p>HostPath 就是将 Node 主机中一个实际目录挂在到 Pod 中，以供容器使用，这样的设计就可以保证 Pod 销毁了，但是数据依据可以存在于 Node 主机上。</p><h3 id="4-1-hostPath-的一些用法"><a href="#4-1-hostPath-的一些用法" class="headerlink" title="4.1 hostPath 的一些用法"></a>4.1 hostPath 的一些用法</h3><ul><li>运行一个需要访问 Docker 引擎内部机制的容器；请使用 hostPath 挂载 &#x2F;var&#x2F;lib&#x2F;docker 路径。</li><li>在容器中运行 cAdvisor 时，以 hostPath 方式挂载 &#x2F;sys。</li><li>允许 Pod 指定给定的 hostPath 在运行 Pod 之前是否应该存在，是否应该创建以及应该以什么方式存在。</li></ul><h3 id="4-2-支持类型"><a href="#4-2-支持类型" class="headerlink" title="4.2 支持类型"></a>4.2 支持类型</h3><p>除了必需的 path 属性之外，用户可以选择性地为 hostPath 卷指定 type。支持的 type 值如下：</p><table><thead><tr><th>取值</th><th>行为</th></tr></thead><tbody><tr><td></td><td>空字符串（默认）用于向后兼容，这意味着在安装 hostPath 卷之前不会执行任何检查</td></tr><tr><td>DirectoryOrCreate</td><td>如果指定的路径不存在，那么将根据需要创建空目录，权限设置为 0755，具有与 Kubelet 相同的组和所有权</td></tr><tr><td>Directory</td><td>给定的路径必须存在</td></tr><tr><td>FileOrCreate</td><td>如果给定路径的文件不存在，那么将在那里根据需要创建空文件，权限设置为 0644，具有与 Kubelet 相同的组和所有权【前提：文件所在目录必须存在；目录不存在则不能创建文件】</td></tr><tr><td>File</td><td>给定路径上的文件必须存在</td></tr><tr><td>Socket</td><td>在给定路径上必须存在的 UNIX 套接字</td></tr><tr><td>CharDevice</td><td>在给定路径上必须存在的字符设备</td></tr><tr><td>BlockDevice</td><td>在给定路径上必须存在的块设备</td></tr></tbody></table><h3 id="4-3-注意事项"><a href="#4-3-注意事项" class="headerlink" title="4.3 注意事项"></a>4.3 注意事项</h3><p>当使用这种类型的卷时要小心，因为：</p><ul><li>具有相同配置（例如从 podTemplate 创建）的多个 Pod 会由于节点上文件的不同而在不同节点上有不同的行为。</li><li>当 Kubernetes 按照计划添加资源感知的调度时，这类调度机制将无法考虑由 hostPath 卷使用的资源。</li><li>基础主机上创建的文件或目录只能由 root 用户写入。需要在 特权容器 中以 root 身份运行进程，或者修改主机上的文件权限以便容器能够写入 hostPath 卷。</li></ul><h3 id="4-4-hostPath-使用案例"><a href="#4-4-hostPath-使用案例" class="headerlink" title="4.4 hostPath 使用案例"></a>4.4 hostPath 使用案例</h3><h4 id="4-4-1-资源清单"><a href="#4-4-1-资源清单" class="headerlink" title="4.4.1 资源清单"></a>4.4.1 资源清单</h4><p><code>002-volume-hostpath-01.yaml</code></p><pre><code class="highlight bash">apiVersion: apps/v1kind: Deploymentmetadata:  namespace: default  name: hostpath-deployment  labels:    name: volumn-depspec:  replicas: 1  selector:    matchLabels: <span class="comment"># Deployment控制器管理具有如下标签的Pod</span>      <span class="built_in">type</span>: hostpath  template:    metadata:      labels: <span class="comment"># Pod模板设定生成的Pod有这些标签项</span>        app: myapp        <span class="built_in">type</span>: hostpath    spec:      containers:        - name: nginx-container <span class="comment"># Pod1，nginx</span>          image: wangyanglinux/myapp:v1.0          imagePullPolicy: IfNotPresent          ports:            - containerPort: 80          volumeMounts: <span class="comment"># 设置 pod 挂载的容器卷</span>            - name: log-volume              mountPath: /usr/local/nginx/logs <span class="comment"># 镜像日志输出目录，必须存在</span>        - name: busybox-container <span class="comment"># Pod2，busybox</span>          image: busybox:latest          imagePullPolicy: IfNotPresent          volumeMounts: <span class="comment"># 设置 pod 挂载的容器卷</span>            - name: log-volume              mountPath: /logs          <span class="built_in">command</span>:            - <span class="string">&#x27;/bin/sh&#x27;</span>            - <span class="string">&#x27;-c&#x27;</span>            - <span class="string">&#x27;tail -f /logs/access.log&#x27;</span>      volumes:        - name: log-volume <span class="comment"># 设置自定义容器卷的名称</span>          hostPath: <span class="comment"># 容器卷类型：hostPath</span>            path: /root/logs            <span class="built_in">type</span>: DirectoryOrCreate <span class="comment"># 目录存在就使用，不存在就先创建后使用</span></code></pre><h4 id="4-4-2-创建-Deployment"><a href="#4-4-2-创建-Deployment" class="headerlink" title="4.4.2 创建 Deployment"></a>4.4.2 创建 Deployment</h4><pre><code class="highlight bash"><span class="comment"># 加载资源清单，创建 Deployment</span>$ kubectl apply -f 002-volume-hostpath-01.yaml --record<span class="comment"># 查看 Pod 状态</span>$ kubectl get pods -o wideNAME                                   READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATEShostpath-deployment-774b569d9f-ntpqp   2/2     Running   0          41s   172.16.58.247   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 访问 nginx 容器</span>$ curl 172.16.58.247www.xinxianghf.com | hello MyAPP | version v1.0</code></pre><h4 id="4-4-3-进入-busybox-container-容器查看日志"><a href="#4-4-3-进入-busybox-container-容器查看日志" class="headerlink" title="4.4.3 进入 busybox-container 容器查看日志"></a>4.4.3 进入 busybox-container 容器查看日志</h4><pre><code class="highlight bash">$ kubectl <span class="built_in">exec</span> -it hostpath-deployment-774b569d9f-ntpqp -c busybox-container -- <span class="built_in">tail</span> -f /logs/access.log172.16.167.128 - - [30/Apr/2025:14:17:15 +0800] <span class="string">&quot;GET / HTTP/1.1&quot;</span> 200 48 <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.76.1&quot;</span>172.16.167.128 - - [30/Apr/2025:14:17:20 +0800] <span class="string">&quot;GET / HTTP/1.1&quot;</span> 200 48 <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.76.1&quot;</span></code></pre><h4 id="4-4-4-查看宿主机挂载目录"><a href="#4-4-4-查看宿主机挂载目录" class="headerlink" title="4.4.4 查看宿主机挂载目录"></a>4.4.4 查看宿主机挂载目录</h4><p>当前 Pod 运行在 k8s-node02 节点上，挂载目录为 &#x2F;root&#x2F;logs （资源清单配置挂载目录）</p><pre><code class="highlight bash">[root@k8s-node02 /]$ <span class="built_in">tail</span> -f /root/logs/access.log 172.16.167.128 - - [30/Apr/2025:14:17:15 +0800] <span class="string">&quot;GET / HTTP/1.1&quot;</span> 200 48 <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.76.1&quot;</span>172.16.167.128 - - [30/Apr/2025:14:17:20 +0800] <span class="string">&quot;GET / HTTP/1.1&quot;</span> 200 48 <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.76.1&quot;</span></code></pre><h2 id="5-NFS"><a href="#5-NFS" class="headerlink" title="5. NFS"></a>5. NFS</h2><p>HostPath可以解决数据持久化的问题，但是一旦Node节点故障了，Pod如果转移到了别的节点，又会出现问题了，此时需要准备单独的网络存储系统，比较常用的用NFS、CIFS。</p><p>NFS是一个网络文件存储系统，可以搭建一台NFS服务器，然后将Pod中的存储直接连接到NFS系统上，这样的话，无论Pod在节点上怎么转移，只要Node跟NFS的对接没问题，数据就可以成功访问。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/05/15/20250515-154921.png" alt="NFS文件存储"></p><h3 id="5-1-安装-NFS-文件服务器"><a href="#5-1-安装-NFS-文件服务器" class="headerlink" title="5.1 安装 NFS 文件服务器"></a>5.1 安装 NFS 文件服务器</h3><p>NFS 文件服务器与 FTP 类似，都有服务端和客户端。这里为了简单，以 Master 节点作为 NFS 服务端，其它 Node 节点作为 NFS 客户端。</p><h4 id="5-1-1-安装-NFS-服务"><a href="#5-1-1-安装-NFS-服务" class="headerlink" title="5.1.1 安装 NFS 服务"></a>5.1.1 安装 NFS 服务</h4><p><strong>在所有节点都要执行</strong></p><pre><code class="highlight bash">$ yum install -y nfs-utils rpcbind</code></pre><h4 id="5-1-2-创建共享目录"><a href="#5-1-2-创建共享目录" class="headerlink" title="5.1.2 创建共享目录"></a>5.1.2 创建共享目录</h4><p>仅在 Master 节点执行</p><pre><code class="highlight bash"><span class="comment"># 创建 共享目录</span>$ <span class="built_in">mkdir</span> -p /root/data/nfs/<span class="comment"># 目录提权</span><span class="built_in">chmod</span> 777 /root/data/nfs/<span class="comment"># 变更用户组</span><span class="built_in">chown</span> nobody /root/data/nfs/</code></pre><h4 id="5-1-3-编辑共享目录读写配置"><a href="#5-1-3-编辑共享目录读写配置" class="headerlink" title="5.1.3 编辑共享目录读写配置"></a>5.1.3 编辑共享目录读写配置</h4><p>仅在 NFS 服务端节点操作</p><pre><code class="highlight bash">$ vim /etc/exports<span class="comment"># 内容如下：</span>/root/data/nfs     192.168.6.0/24(rw,no_root_squash,no_all_squash,<span class="built_in">sync</span>)</code></pre><p>表示 192.168.6. 网段的ip 都可以与 nfs 主服务器共享  <code>/root/data/nfs</code> 目录内容</p><p><strong>参数说明：</strong></p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>ro</td><td>只读访问</td></tr><tr><td>rw</td><td>读写访问</td></tr><tr><td>sync</td><td>所有数据在请求时写入共享目录</td></tr><tr><td>async</td><td>nfs 在写入大数据时可以回应请求</td></tr><tr><td>secure</td><td>nfs 通过 1024 以下的安全 TCP&#x2F;IP 端口发送</td></tr><tr><td>insecure</td><td>nfs 通过 1024 以上的端口发送</td></tr><tr><td>wdelay</td><td>如果多个用户要写入 nfs 目录，则归组写入（默认）</td></tr><tr><td>no_wdelay</td><td>如果多个用户要写入 nfs 目录，则立即写入，当使用 async 时，无需此设置</td></tr><tr><td>hide</td><td>在 nfs 共享目录中不共享其子目录</td></tr><tr><td>no_hide</td><td>共享 nfs 目录的子目录</td></tr><tr><td>subtree_check</td><td>如果共享子目录如 &#x2F;usr&#x2F;bin 之类子目录，则强制检查子目录的权限（默认）</td></tr><tr><td>no_subtree_check</td><td>不检查子目录权限</td></tr><tr><td>all_squash</td><td>共享文件的 UID 和 GID 映射匿名用户 anonymous，通常会用匿名用户</td></tr><tr><td>no_all_squash</td><td>保留共享文件的 UID 和 GID（默认）</td></tr><tr><td>root_squash</td><td>root 用户的所有请求映射成 anonymous 用户一样的权限（默认）</td></tr><tr><td>no_root_squash</td><td>root 用户具有根目录的完全管理访问权限</td></tr><tr><td>anonuid&#x3D;xxx</td><td>指定 nfs 服务器 &#x2F;etc&#x2F;passwd 文件中匿名用户的 UID</td></tr><tr><td>anongid&#x3D;xxx</td><td>指定 nfs 服务器 &#x2F;etc&#x2F;passwd 文件中匿名用户的 GID</td></tr></tbody></table><h4 id="5-1-4-启动NFS服务"><a href="#5-1-4-启动NFS服务" class="headerlink" title="5.1.4 启动NFS服务"></a>5.1.4 启动NFS服务</h4><p>在集群内所有节点操作</p><pre><code class="highlight bash"> <span class="comment"># 启动服务</span>$ systemctl start rpcbind$ systemctl restart nfs-server.service<span class="comment"># 设置开机自启</span>$ systemctl <span class="built_in">enable</span> rpcbind$ systemctl <span class="built_in">enable</span> nfs-server.service</code></pre><h4 id="5-1-5-测试NFS服务"><a href="#5-1-5-测试NFS服务" class="headerlink" title="5.1.5 测试NFS服务"></a>5.1.5 测试NFS服务</h4><pre><code class="highlight bash"><span class="comment"># 在Node01节点测试一下，是否能够正确挂载:</span>root@k8s-node01 ~]$ showmount -e 192.168.6.139Export list <span class="keyword">for</span> 192.168.6.139:/root/data/nfs 192.168.6.0/24<span class="comment"># 在客户端创建挂在目录</span>[root@k8s-node01 ~]$ <span class="built_in">mkdir</span> /data/testnfs<span class="comment"># 挂载远端目录到本地 /data/testnfs 目录</span>[root@k8s-node01 ~]<span class="comment"># mount 192.168.6.139:/root/data/nfs /data/testnfs</span><span class="comment"># NFS服务端写入</span>[root@k8s-master01 ~]<span class="comment"># echo &quot;This is NFS server.&quot; &gt; /root/data/nfs/nfs.txt</span><span class="comment"># 客户端读取</span>[root@k8s-node01 ~]<span class="comment"># cat /data/testnfs/nfs.txt</span>This is NFS server.<span class="comment"># 客户端写入</span>[root@k8s-node01 ~]<span class="comment"># echo &quot;This is NFS client.&quot; &gt;&gt; /data/testnfs/nfs.txt</span><span class="comment"># 服务端读取</span>[root@k8s-master01 ~]<span class="comment"># cat /root/data/nfs/nfs.txt</span>This is NFS server.This is NFS client.都是没问题的，这是因为上边设置了 NFS 远端目录权限为 rw 拥有读写权限，如果设置为 ro，那么客户端只能读取，不能写入，根据实际应用场景合理配置，这里就不在演示了。这里提一下，NFS 默认使用 UDP 协议来进行挂载，为了提高 NFS 的稳定性，可以使用 TCP 协议挂载，那么客户端挂载命令可使用如下命令mount 192.168.6.139:/root/data/nfs /data/testnfs -o proto=tcp -o nolock</code></pre><h4 id="5-1-6-客户端卸载-NFS-挂载目录"><a href="#5-1-6-客户端卸载-NFS-挂载目录" class="headerlink" title="5.1.6 客户端卸载 NFS 挂载目录"></a>5.1.6 客户端卸载 NFS 挂载目录</h4><pre><code class="highlight bash">umount /data/testnfs<span class="comment"># 强制卸载</span>umount -l /data/testnfs</code></pre><h4 id="5-1-7-使用-NFS4-服务"><a href="#5-1-7-使用-NFS4-服务" class="headerlink" title="5.1.7 使用 NFS4 服务"></a>5.1.7 使用 NFS4 服务</h4><p>相较于 NFS v2 v3 版本更新安全和高效</p><ul><li><p>修改 NFS 服务端配置</p><pre><code class="highlight bash">$ vim /etc/exports/root/data/nfs     192.168.6.0/24(rw,fsid=0,no_root_squash)</code></pre><p>配置 &#x2F;etc&#x2F;exports 使用 NFSv4 伪文件系统（fsid&#x3D;0）</p></li><li><p>客户端使用 NFS4 挂载</p><pre><code class="highlight bash"><span class="comment"># 在客户端创建挂在目录</span>[root@k8s-node01 ~]$ <span class="built_in">mkdir</span> /data/testnfs<span class="comment"># 挂载远端目录到本地 /data/testnfs 目录</span>[root@k8s-node01 ~]<span class="comment"># mount -t nfs4 192.168.6.139:/root/data/nfs /data/testnfs</span></code></pre></li></ul><h3 id="5-2-使用-NFS-挂载-Pod-目录"><a href="#5-2-使用-NFS-挂载-Pod-目录" class="headerlink" title="5.2 使用 NFS 挂载 Pod 目录"></a>5.2 使用 NFS 挂载 Pod 目录</h3><h4 id="5-2-1-资源清单"><a href="#5-2-1-资源清单" class="headerlink" title="5.2.1 资源清单"></a>5.2.1 资源清单</h4><p><code>003-volume-nfs-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">nfs-deployment</span>  <span class="attr">labels:</span>    <span class="attr">name:</span> <span class="string">volumn-dep</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># Deployment控制器管理具有如下标签的Pod</span>      <span class="attr">type:</span> <span class="string">nfs</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span> <span class="comment"># Pod模板设定生成的Pod有这些标签项</span>        <span class="attr">app:</span> <span class="string">myapp</span>        <span class="attr">type:</span> <span class="string">nfs</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-container</span> <span class="comment"># Pod1，nginx</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>          <span class="attr">volumeMounts:</span> <span class="comment"># 设置 pod 挂载的容器卷</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span>              <span class="attr">mountPath:</span> <span class="string">/usr/local/nginx/logs</span> <span class="comment"># 镜像日志输出目录，必须存在</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox-container</span> <span class="comment"># Pod2，busybox</span>          <span class="attr">image:</span> <span class="string">busybox:latest</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span> <span class="comment"># 设置 pod 挂载的容器卷</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span>              <span class="attr">mountPath:</span> <span class="string">/logs</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&#x27;/bin/sh&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;-c&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;tail -f /logs/access.log&#x27;</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span> <span class="comment"># 设置自定义容器卷的名称</span>          <span class="attr">nfs:</span> <span class="comment"># 容器卷类型：hostPath</span>            <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span> <span class="comment"># NFS 服务端</span>            <span class="attr">path:</span> <span class="string">/root/data/nfs</span></code></pre><h4 id="5-2-2-创建-Deployment"><a href="#5-2-2-创建-Deployment" class="headerlink" title="5.2.2 创建 Deployment"></a>5.2.2 创建 Deployment</h4><pre><code class="highlight bash"><span class="comment"># 加载资源清单，创建 Deployment</span>$ kubectl apply -f 003-volume-nfs-01.yaml<span class="comment"># 查看 Pod 状态</span>$ kubectl get pods -o wideNAME                                   READY   STATUS    RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATESnfs-deployment-5c6b9ccfd-c2szn         2/2     Running   0          2m6s   172.16.85.201   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 访问 nginx 容器</span>$ curl 172.16.85.201www.xinxianghf.com | hello MyAPP | version v1.0</code></pre><h4 id="5-2-3-查看-NFS-挂载目录"><a href="#5-2-3-查看-NFS-挂载目录" class="headerlink" title="5.2.3 查看 NFS 挂载目录"></a>5.2.3 查看 NFS 挂载目录</h4><pre><code class="highlight bash">[root@k8s-master01 ~]$ <span class="built_in">cat</span> /root/data/nfs/access.log 172.16.167.128 - - [15/May/2025:17:01:59 +0800] <span class="string">&quot;GET / HTTP/1.1&quot;</span> 200 48 <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.76.1&quot;</span>172.16.167.128 - - [15/May/2025:17:02:01 +0800] <span class="string">&quot;GET / HTTP/1.1&quot;</span> 200 48 <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.76.1&quot;</span>172.16.167.128 - - [15/May/2025:17:02:01 +0800] <span class="string">&quot;GET / HTTP/1.1&quot;</span> 200 48 <span class="string">&quot;-&quot;</span> <span class="string">&quot;curl/7.76.1&quot;</span></code></pre><p>pod 容器日志，通过 NFS 挂载到了 宿主机 Master 节点上，即便Pod删除，数据也不会丢失。</p><h1 id="六、PV-PVC"><a href="#六、PV-PVC" class="headerlink" title="六、PV&#x2F;PVC"></a>六、PV&#x2F;PVC</h1><h2 id="1-概述-1"><a href="#1-概述-1" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>与管理计算实例相比，管理存储是一个明显的问题。PersistentVolume 子系统为用户和管理员提供了一个API，该API从如何使用存储中，抽象出如何提供存储的详细信息。为此，我们引入了两个新的API资源：PersistentVolume 和 PersistentVolumeClaim。</p><h2 id="2-PV概述"><a href="#2-PV概述" class="headerlink" title="2. PV概述"></a>2. PV概述</h2><p>PersistentVolume (PV) 是集群中由管理员提供或使用存储类动态提供的一块存储。它是集群中的资源，就像节点是集群资源一样。</p><p>PV 是与 Volumes 类似的卷插件，<strong>但其生命周期与使用PV的任何单个Pod无关</strong>。此API对象捕获存储实现的详细信息，包括NFS，<code>iSCSI</code>或特定于云提供程序的存储系统。</p><h2 id="3-PVC概述"><a href="#3-PVC概述" class="headerlink" title="3. PVC概述"></a>3. PVC概述</h2><p>PersistentVolumeClaim (PVC) 是用户对存储的请求。它类似于Pod；Pods消耗节点资源，而PVC消耗PV资源。Pods可以请求特定级别的资源(CPU和内存)。Claim可以请求特定的存储大小和访问模式(例如，它们可以挂载一次读写或多次只读)。</p><p>但是通过 PVC 请求到一定的存储空间也很有可能不足以满足应用对于存储设备的各种需求，而且不同的应用程序对于存储性能的要求可能也不尽相同，比如读写速度、并发性能等，为了解决这一问题，Kubernetes 又为我们引入了一个新的资源对象：<code>StorageClass</code>，通过 StorageClass 的定义，管理员可以将存储资源定义为某种类型的资源，比如快速存储、慢速存储等，用户根据 StorageClass 的描述就可以非常直观的知道各种存储资源的具体特性了，这样就可以根据应用的特性去申请合适的存储资源了。</p><h2 id="4-PV-和-PVC-的生命周期"><a href="#4-PV-和-PVC-的生命周期" class="headerlink" title="4. PV 和 PVC 的生命周期"></a>4. PV 和 PVC 的生命周期</h2><p>在 Kubernetes 中，Persistent Volume (PV) 和 Persistent Volume Claim (PVC) 是管理持久存储的核心组件。它们的生命周期与存储的分配、使用和释放密切相关。</p><h3 id="4-1-Persistent-Volume-PV-的生命周期"><a href="#4-1-Persistent-Volume-PV-的生命周期" class="headerlink" title="4.1 Persistent Volume (PV) 的生命周期"></a>4.1 Persistent Volume (PV) 的生命周期</h3><p>PV 是一个集群级别的存储资源，表示一块具体的存储（如 NFS、云存储卷等）。其生命周期包括以下阶段：</p><p><strong>1. 创建（Provisioning）</strong></p><ul><li><p>静态分配：管理员手动创建 PV，定义容量、访问模式（如 ReadWriteOnce、ReadOnlyMany）、存储类型等。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolume</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-pv</span><span class="attr">spec:</span>  <span class="attr">capacity:</span>    <span class="attr">storage:</span> <span class="string">1Gi</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span>  <span class="attr">storageClassName:</span> <span class="string">standard</span>  <span class="attr">hostPath:</span>    <span class="attr">path:</span> <span class="string">/mnt/data</span></code></pre></li><li><p><strong>动态分配</strong>：通过 PVC 和 StorageClass 自动创建 PV，无需管理员手动干预。</p></li></ul><p><strong>2. 绑定（Binding）</strong></p><ul><li>PV 与符合其条件的 PVC 绑定（匹配容量、访问模式、StorageClass 等）。</li><li>绑定后，PV 状态变为 Bound，并记录绑定的 PVC 信息。</li><li>如果没有合适的 PVC，PV 保持 Available 状态。</li></ul><p><strong>3. 使用（Usage）</strong></p><ul><li>绑定的 PV 被 Pod 通过 PVC 引用，挂载到容器中的指定路径。</li><li>Pod 运行期间，容器可以读写 PV 提供的存储。</li><li>PV 的底层存储（如云卷、NFS）决定数据的持久性和性能。</li></ul><p><strong>4. 释放（Releasing）</strong></p><ul><li><p>当绑定的 PVC 被删除时，PV 进入释放阶段。</p></li><li><p>PV 的回收策略（persistentVolumeReclaimPolicy）决定后续行为：</p><ul><li><strong>Retain</strong>：PV 保留，数据和元数据不删除，需手动清理。</li><li><strong>Delete</strong>：PV 和底层存储资源自动删除（常见于云存储）。</li><li><strong>Recycle</strong>（已弃用）：数据被擦除，PV 可被复用。（只有NFS、HostPath支持回收）</li></ul></li></ul><p><strong>5. 删除（Deletion）</strong></p><ul><li>如果回收策略为 Delete，PV 和底层存储被销毁。</li><li>如果为 Retain，管理员需手动删除 PV 或重新绑定到新 PVC。</li></ul><h3 id="4-2-Persistent-Volume-Claim-PVC-的生命周期"><a href="#4-2-Persistent-Volume-Claim-PVC-的生命周期" class="headerlink" title="4.2 Persistent Volume Claim (PVC) 的生命周期"></a>4.2 Persistent Volume Claim (PVC) 的生命周期</h3><p>PVC 是命名空间级别的存储请求，充当 Pod 和 PV 之间的抽象层。其生命周期包括以下阶段：</p><p><strong>1. 创建（Request）</strong></p><ul><li><p>用户创建 PVC，指定存储需求（如容量、访问模式、StorageClass）</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-pvc</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">resources:</span>    <span class="attr">requests:</span>      <span class="attr">storage:</span> <span class="string">1Gi</span>  <span class="attr">storageClassName:</span> <span class="string">standard</span></code></pre></li><li><p>PVC 进入 Pending 状态，等待绑定。</p></li></ul><p><strong>2. 绑定（Binding）</strong></p><ul><li>Kubernetes 控制器寻找匹配的 PV（容量、访问模式等）。</li><li><strong>静态分配</strong>：绑定到现有的 PV。</li><li><strong>动态分配</strong>：通过 StorageClass 自动创建 PV 并绑定。</li><li>绑定成功后，PVC 状态变为 Bound，记录绑定的 PV 名称。</li></ul><p><strong>3. 使用（Usage）</strong></p><ul><li><p>Pod 通过 PVC 引用存储，配置在 spec.volumes 和 spec.containers.volumeMounts 中。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-pod</span><span class="attr">spec:</span>  <span class="attr">containers:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span>    <span class="attr">image:</span> <span class="string">nginx</span>    <span class="attr">volumeMounts:</span>    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/data&quot;</span>      <span class="attr">name:</span> <span class="string">my-volume</span>  <span class="attr">volumes:</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-volume</span>    <span class="attr">persistentVolumeClaim:</span>      <span class="attr">claimName:</span> <span class="string">my-pvc</span></code></pre></li><li><p>PVC 提供与底层 PV 无关的接口，Pod 直接访问存储。</p></li></ul><p><strong>4. 释放（Releasing）</strong></p><ul><li>当用户删除 PVC 时，Kubernetes 解除 PVC 与 PV 的绑定。</li><li>PV 根据回收策略（Retain、Delete）进入相应处理流程。</li></ul><p><strong>5. 删除（Deletion）</strong></p><ul><li>PVC 删除后，其资源被销毁。</li><li>如果 PV 的回收策略为 Delete，底层存储可能被销毁；如果为 Retain，PV 可重新绑定到新 PVC。</li></ul><h2 id="5-持久化声明保护"><a href="#5-持久化声明保护" class="headerlink" title="5. 持久化声明保护"></a>5. 持久化声明保护</h2><p>“使用中的存储对象保护” ：该功能的目的是确保在Pod活动时使用的PersistentVolumeClaims (PVC)和绑定到PVC的PersistentVolume (PV)不会从系统中删除，因为这可能会导致数据丢失。</p><p><strong>如果用户删除了Pod正在使用的PVC，则不会立即删除该PVC；PVC的清除被推迟，直到任何Pod不再主动使用PVC。另外，如果管理员删除绑定到PVC的PV，则不会立即删除该PV；PV的去除被推迟，直到PV不再与PVC结合。</strong></p><h2 id="6-回收策略"><a href="#6-回收策略" class="headerlink" title="6. 回收策略"></a>6. 回收策略</h2><p>当用户处理完他们的卷时，他们可以从允许回收资源的API中删除PVC对象。PersistentVolume 的回收策略告诉集群在释放卷的声明后该如何处理它。目前，卷可以被保留、回收或删除。</p><h3 id="6-1-Retain-保留"><a href="#6-1-Retain-保留" class="headerlink" title="6.1 Retain (保留)"></a>6.1 Retain (保留)</h3><p>保留回收策略允许手动回收资源。当 PersistentVolumeClaim 被删除时，PersistentVolume 仍然存在，并且该卷被认为是“释放”的。但是，由于之前声明的数据仍然存在，因此另一个声明尚无法得到。管理员可以手动回收卷。</p><h3 id="6-2-Delete-删除"><a href="#6-2-Delete-删除" class="headerlink" title="6.2 Delete (删除)"></a>6.2 Delete (删除)</h3><p>对于支持 Delete 回收策略的卷插件，删除操作会同时从 Kubernetes 中删除 PersistentVolume 对象以及外部基础架构中的关联存储资产，例如 AWS EBS，GCE PD，Azure Disk 或 Cinder 卷。动态配置的卷将继承其 StorageClass 的回收策略，默认为 Delete。管理员应根据用户的期望配置 StorageClass。</p><h3 id="6-3-Recycle-回收"><a href="#6-3-Recycle-回收" class="headerlink" title="6.3 Recycle (回收)"></a>6.3 Recycle (回收)</h3><p>如果基础卷插件支持，Recycle 回收策略将 <code>rm -rf /thevolume/*</code> 对该卷执行基本的擦除并使其可用于新的声明。</p><h2 id="7-Persistent-Volumes-类型"><a href="#7-Persistent-Volumes-类型" class="headerlink" title="7. Persistent Volumes 类型"></a>7. Persistent Volumes 类型</h2><p>PersistentVolume类型作为插件实现。Kubernetes当前支持以下插件：</p><ul><li>GCEPersistentDisk</li><li>AWSElasticBlockStore</li><li>AzureFile</li><li>AzureDisk</li><li>CSI</li><li>FC (Fibre Channel)</li><li>FlexVolume</li><li>Flocker</li><li>NFS</li><li>iSCSI</li><li>RBD (Ceph Block Device)</li><li>CephFS</li><li>Cinder (OpenStack block storage)</li><li>Glusterfs</li><li>VsphereVolume</li><li>Quobyte Volumes</li><li>HostPath (仅用于单节点测试——本地存储不受任何方式的支持，也不能在多节点集群中工作)</li><li>Portworx Volumes</li><li>ScaleIO Volumes</li><li>StorageOS</li></ul><h2 id="8-PV示例与参数说明"><a href="#8-PV示例与参数说明" class="headerlink" title="8. PV示例与参数说明"></a>8. PV示例与参数说明</h2><h3 id="8-1-PV示例"><a href="#8-1-PV示例" class="headerlink" title="8.1 PV示例"></a>8.1 PV示例</h3><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolume</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pv-demo1</span><span class="attr">spec:</span>  <span class="attr">capacity:</span>    <span class="attr">storage:</span> <span class="string">5Gi</span> <span class="comment"># PV的容量大小 5G</span>  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span>  <span class="attr">accessModes:</span> <span class="comment"># PV 访问模式</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Delete</span> <span class="comment"># 回收策略</span>  <span class="attr">storageClassName:</span> <span class="string">slow</span>  <span class="attr">mountOptions:</span>    <span class="bullet">-</span> <span class="string">hard</span> <span class="comment"># 指定挂载选项为 hard，表示 NFS 挂载是硬挂载，客户端会在连接中断时不断重试。</span>    <span class="bullet">-</span> <span class="string">nfsvers=4.1</span> <span class="comment"># 指定使用 NFS 协议版本 4.1。</span>  <span class="attr">nfs:</span>    <span class="attr">path:</span> <span class="string">/root/data/nfs/</span>    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.142</span><span class="number">.199</span></code></pre><p><strong>Capacity：</strong>通常，PV将具有特定的存储容量设置。当前，存储大小是可以设置或请求的唯一资源。将来的属性可能包括IOPS，吞吐量等。</p><p><strong>volumeMode：</strong>可选参数，为Filesystem或Block。Filesystem是volumeMode省略参数时使用的默认模式。</p><p><strong>accessModes：</strong>PersistentVolume可以通过资源提供者支持的任何方式安装在主机上。如下文表中所示，提供商将具有不同的功能，并且每个PV的访问模式都将设置为该特定卷支持的特定模式。例如，NFS可以支持多个读&#x2F;写客户端，但是特定的NFS PV可能以只读方式在服务器上导出。每个PV都有自己的一组访问模式，用于描述该特定PV的功能。</p><p><strong>访问方式为：</strong></p><ul><li>ReadWriteOnce-该卷可以被单个节点以读写方式挂载</li><li>ReadOnlyMany-该卷可以被许多节点以只读方式挂载</li><li>ReadWriteMany-该卷可以被多个节点以读写方式挂载</li></ul><p>在CLI命令行中，访问模式缩写为：</p><ul><li>RWO-ReadWriteOnce</li><li>ROX-ReadOnlyMany</li><li>RWX-ReadWriteMany</li></ul><p><strong>说明：一个卷一次只能使用一种访问模式挂载，即使它支持多种访问模式。</strong></p><p><strong>storageClassName：</strong>PV可以有一个类，通过将 storageClassName 属性设置为一个 StorageClass 的名称来指定这个类。特定类的 PV只能绑定到请求该类的 PVC。没有 storageClassName 的 PV 没有类，只能绑定到不请求特定类的PVC。</p><p><strong>persistentVolumeReclaimPolicy：</strong>当前的回收政策是：Retain (保留)-手动回收、Recycle (回收)-基本擦除（rm -rf &#x2F;thevolume&#x2F;*）、Delete (删除)-删除相关的存储资产 (例如 AWS EBS，GCE PD，Azure Disk 或 OpenStack Cinder 卷)。</p><p><strong>备注：当前，仅NFS和HostPath支持回收。AWS EBS，GCE PD，Azure Disk和Cinder卷支持删除。</strong></p><h3 id="8-2-PV卷状态"><a href="#8-2-PV卷状态" class="headerlink" title="8.2 PV卷状态"></a>8.2 PV卷状态</h3><p>卷将处于以下某种状态：</p><ul><li>Available：尚未绑定到声明(claim)的空闲资源</li><li>Bound：卷已被声明绑定</li><li>Released：声明已被删除，但群集尚未回收该资源</li><li>Failed：该卷自动回收失败</li></ul><p>CLI 将显示绑定到 PV 的 PVC 的名称。</p><h3 id="8-3-PV-类型与支持的访问模式"><a href="#8-3-PV-类型与支持的访问模式" class="headerlink" title="8.3 PV 类型与支持的访问模式"></a>8.3 PV 类型与支持的访问模式</h3><table><thead><tr><th>Volume Plugin</th><th>ReadWriteOnce</th><th>ReadOnlyMany</th><th>ReadWriteMany</th></tr></thead><tbody><tr><td>AWSElasticBlockStore</td><td>✓</td><td>-</td><td>-</td></tr><tr><td>AzureFile</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>AzureDisk</td><td>✓</td><td>-</td><td>-</td></tr><tr><td>CephFS</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Cinder</td><td>✓</td><td>-</td><td>-</td></tr><tr><td>CSI</td><td>depends on the driver</td><td>depends on the driver</td><td>depends on the driver</td></tr><tr><td>FC</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>FlexVolume</td><td>✓</td><td>✓</td><td>depends on the driver</td></tr><tr><td>Flocker</td><td>✓</td><td>-</td><td>-</td></tr><tr><td>GCEPersistentDisk</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>Glusterfs</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>HostPath</td><td>✓</td><td>-</td><td>-</td></tr><tr><td>iSCSI</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>Quobyte</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>NFS</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>RBD</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>VsphereVolume</td><td>✓</td><td>-</td><td>- (works when Pods are collocated)</td></tr><tr><td>PortworxVolume</td><td>✓</td><td>-</td><td>✓</td></tr><tr><td>ScaleIO</td><td>✓</td><td>✓</td><td>-</td></tr><tr><td>StorageOS</td><td>✓</td><td>-</td><td>-</td></tr></tbody></table><h2 id="9-PV-PVC示例"><a href="#9-PV-PVC示例" class="headerlink" title="9. PV-PVC示例"></a>9. PV-PVC示例</h2><h3 id="9-1-主机信息"><a href="#9-1-主机信息" class="headerlink" title="9.1 主机信息"></a>9.1 主机信息</h3><table><thead><tr><th>服务器名称(hostname)</th><th>系统版本</th><th>配置</th><th>内网IP</th><th>部署模块</th></tr></thead><tbody><tr><td>k8s-master</td><td>Rocky 9.3</td><td>2C&#x2F;4G&#x2F;100G</td><td>192.168.204.199</td><td>k8s-master,NFS</td></tr><tr><td>k8s-node01</td><td>Rocky 9.3</td><td>2C&#x2F;4G&#x2F;100G</td><td>192.168.204.201</td><td>k8s-node</td></tr><tr><td>k8s-node02</td><td>Rocky 9.3</td><td>2C&#x2F;4G&#x2F;100G</td><td>192.168.204.202</td><td>k8s-node</td></tr></tbody></table><h3 id="9-2-NFS服务部署"><a href="#9-2-NFS服务部署" class="headerlink" title="9.2 NFS服务部署"></a>9.2 NFS服务部署</h3><p>部署及测试过程，参考上一段。</p><p><strong>创建共享目录</strong></p><pre><code class="highlight bash"><span class="comment"># 创建共享目录</span>[root@k8s-master01 ~]$ <span class="built_in">mkdir</span> -p /root/data/nfs&#123;1..6&#125;<span class="comment"># 给目录授权</span>[root@k8s-master01 ~]$ <span class="built_in">chown</span> -R nobody:nobody /root/data/<span class="comment"># 查看目录权限</span>[root@k8s-master01 ~]$ ll /root/data/total 0drwxr-xr-x 2 nobody nobody 6 May 20 22:48 nfs1drwxr-xr-x 2 nobody nobody 6 May 20 22:48 nfs2drwxr-xr-x 2 nobody nobody 6 May 20 22:48 nfs3drwxr-xr-x 2 nobody nobody 6 May 20 22:48 nfs4drwxr-xr-x 2 nobody nobody 6 May 20 22:48 nfs5drwxr-xr-x 2 nobody nobody 6 May 20 22:48 nfs6<span class="comment"># 编辑 NFS 配置文件</span>[root@k8s-master01 ~]$ vim /etc/exports<span class="comment"># 添加如下内容</span>/root/data     192.168.142.0/24(rw,fsid=0,no_root_squash)/root/data/nfs1     192.168.142.0/24(rw,no_root_squash,no_all_squash,<span class="built_in">sync</span>)/root/data/nfs2     192.168.142.0/24(rw,no_root_squash,no_all_squash,<span class="built_in">sync</span>)/root/data/nfs3     192.168.142.0/24(rw,no_root_squash,no_all_squash,<span class="built_in">sync</span>)/root/data/nfs4     192.168.142.0/24(rw,no_root_squash,no_all_squash,<span class="built_in">sync</span>)/root/data/nfs5     192.168.142.0/24(rw,no_root_squash,no_all_squash,<span class="built_in">sync</span>)/root/data/nfs6     192.168.142.0/24(rw,no_root_squash,no_all_squash,<span class="built_in">sync</span>)<span class="comment"># 重启 NFS 服务</span>[root@k8s-master01 ~]$ systemctl restart rpcbind.service[root@k8s-master01 ~]$ systemctl restart nfs-server<span class="comment"># 检查NFS服务 ， 其中 192.168.142.199 为服务端IP</span>[root@k8s-master01 ~]$ showmount -e 192.168.142.199Export list <span class="keyword">for</span> 192.168.142.199:/root/data/nfs6 192.168.142.0/24/root/data/nfs5 192.168.142.0/24/root/data/nfs4 192.168.142.0/24/root/data/nfs3 192.168.142.0/24/root/data/nfs2 192.168.142.0/24/root/data/nfs1 192.168.142.0/24/root/data      192.168.142.0/24</code></pre><p><strong>NFS客户端验证</strong></p><p>在k8s-node02机器验证</p><pre><code class="highlight bash"><span class="comment"># 查看rpcbind服务，默认是启动的，如果没有启动则启动并加入开机自启动</span> [root@k8s-node02 ~]$ systemctl status rpcbind.service  <span class="comment"># 查看NFS服务信息</span> [root@k8s-node02 ~]$ showmount -e 192.168.142.199Export list <span class="keyword">for</span> 192.168.142.199:/root/data/nfs6 192.168.142.0/24/root/data/nfs5 192.168.142.0/24/root/data/nfs4 192.168.142.0/24/root/data/nfs3 192.168.142.0/24/root/data/nfs2 192.168.142.0/24/root/data/nfs1 192.168.142.0/24/root/data      192.168.142.0/24<span class="comment"># 挂载，并进行读写验证</span>[root@k8s-node02 ~]$ mount -t nfs 192.168.142.199:/root/data/nfs1 /mnt/<span class="comment"># 验证完毕，去掉NFS挂载</span>[root@k8s-node02 ~]$ umount -lf 192.168.142.199:/root/data/nfs1</code></pre><h3 id="9-3-PV-部署"><a href="#9-3-PV-部署" class="headerlink" title="9.3 PV 部署"></a>9.3 PV 部署</h3><p>资源清单：<code>pv.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolume</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pv-nfs1</span><span class="attr">spec:</span>  <span class="attr">capacity:</span>    <span class="attr">storage:</span> <span class="string">1Gi</span> <span class="comment"># 1G磁盘容量</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span> <span class="comment"># 自动回收的策略</span>  <span class="attr">storageClassName:</span> <span class="string">nfs</span> <span class="comment"># 使用NFS</span>  <span class="attr">nfs:</span>    <span class="attr">path:</span> <span class="string">/root/data/nfs1</span>    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.142</span><span class="number">.199</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolume</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pv-nfs2</span><span class="attr">spec:</span>  <span class="attr">capacity:</span>    <span class="attr">storage:</span> <span class="string">3Gi</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span> <span class="comment"># 自动回收的策略</span>  <span class="attr">storageClassName:</span> <span class="string">nfs</span> <span class="comment"># 使用NFS</span>  <span class="attr">nfs:</span>    <span class="attr">path:</span> <span class="string">/root/data/nfs2</span>    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.142</span><span class="number">.199</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolume</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pv-nfs3</span><span class="attr">spec:</span>  <span class="attr">capacity:</span>    <span class="attr">storage:</span> <span class="string">5Gi</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span> <span class="comment"># 自动回收的策略</span>  <span class="attr">storageClassName:</span> <span class="string">nfs</span> <span class="comment"># 使用NFS</span>  <span class="attr">nfs:</span>    <span class="attr">path:</span> <span class="string">/root/data/nfs3</span>    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.142</span><span class="number">.199</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolume</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pv-nfs4</span><span class="attr">spec:</span>  <span class="attr">capacity:</span>    <span class="attr">storage:</span> <span class="string">10Gi</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span> <span class="comment"># 自动回收的策略</span>  <span class="attr">storageClassName:</span> <span class="string">nfs</span> <span class="comment"># 使用NFS</span>  <span class="attr">nfs:</span>    <span class="attr">path:</span> <span class="string">/root/data/nfs4</span>    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.142</span><span class="number">.199</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolume</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pv-nfs5</span><span class="attr">spec:</span>  <span class="attr">capacity:</span>    <span class="attr">storage:</span> <span class="string">5Gi</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteMany</span>  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span> <span class="comment"># 自动回收的策略</span>  <span class="attr">storageClassName:</span> <span class="string">nfs</span> <span class="comment"># 使用NFS</span>  <span class="attr">nfs:</span>    <span class="attr">path:</span> <span class="string">/root/data/nfs5</span>    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.142</span><span class="number">.199</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolume</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">pv-nfs6</span><span class="attr">spec:</span>  <span class="attr">capacity:</span>    <span class="attr">storage:</span> <span class="string">5Gi</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span> <span class="comment"># 自动回收的策略</span>  <span class="attr">storageClassName:</span> <span class="string">nfs</span> <span class="comment"># 使用NFS</span>  <span class="attr">nfs:</span>    <span class="attr">path:</span> <span class="string">/root/data/nfs6</span>    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.142</span><span class="number">.199</span></code></pre><p>启动PV，并查看状态</p><pre><code class="highlight bash"><span class="comment"># 创建PV</span>$ kubectl create -f pv.yaml<span class="comment"># 查看PV详情</span>$ kubectl get pv -o wideNAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE     VOLUMEMODEpv-nfs1   1Gi        RWO            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          3m14s   Filesystempv-nfs2   3Gi        RWO            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          3m14s   Filesystempv-nfs3   5Gi        RWO            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          3m14s   Filesystempv-nfs4   10Gi       RWO            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          3m14s   Filesystempv-nfs5   5Gi        RWX            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          3m13s   Filesystempv-nfs6   5Gi        RWO            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          3m13s   Filesystem</code></pre><h3 id="9-4-StatefulSet-创建并使用-PVC"><a href="#9-4-StatefulSet-创建并使用-PVC" class="headerlink" title="9.4 StatefulSet 创建并使用 PVC"></a>9.4 StatefulSet 创建并使用 PVC</h3><h4 id="9-4-1-资源清单"><a href="#9-4-1-资源清单" class="headerlink" title="9.4.1 资源清单"></a>9.4.1 资源清单</h4><p><code>sts-pod-pvc.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx</span> <span class="comment"># 服务的名称为 nginx</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># 给服务打一个标签</span><span class="attr">spec:</span>  <span class="attr">ports:</span> <span class="comment"># 指定服务暴露的端口</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># 服务监听在 80 端口，外部请求通过该端口访问</span>  <span class="attr">clusterIP:</span> <span class="string">None</span> <span class="comment"># 设置为 None，表示这是一个 Headless Service。Headless Service 不会分配集群 IP，而是直接通过 DNS 解析到后端的 Pod。</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># 服务通过标签选择器 app: nginx 找到匹配的 Pod，将流量路由到这些 Pod。</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">StatefulSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">web</span> <span class="comment"># StatefulSet 名称为 web，用于管理一组 Pod。</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 通过标签 app: nginx 选择要管理的 Pod，确保 StatefulSet 只控制带有该标签的 Pod。</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">serviceName:</span> <span class="string">nginx</span> <span class="comment"># 指定关联的 Service 的名称为 nginx， StatefulSet 使用此 Service 来为每个 Pod 提供稳定的 DNS 名称（例如 web-0.nginx.default.svc.cluster.local.）</span>  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># 创建 3 个 Pod 副本，分别命名为 web-0、web-1 和 web-2</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span> <span class="comment"># 为 Pod 添加标签 app: nginx，与 Service 的选择器匹配。</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">name:</span> <span class="string">web</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">www</span> <span class="comment"># 挂载的卷名称为 www</span>              <span class="attr">mountPath:</span> <span class="string">/usr/local/nginx/html</span>  <span class="attr">volumeClaimTemplates:</span>    <span class="bullet">-</span> <span class="attr">metadata:</span>        <span class="attr">name:</span> <span class="string">www</span> <span class="comment"># PVC 名称为 www，与 volumeMounts 中的名称对应</span>      <span class="attr">spec:</span>        <span class="attr">accessModes:</span>          <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>        <span class="attr">storageClassName:</span> <span class="string">nfs</span>        <span class="attr">resources:</span>          <span class="attr">requests:</span>            <span class="attr">storage:</span> <span class="string">3Gi</span></code></pre><h4 id="9-4-2-启动pod并查看状态"><a href="#9-4-2-启动pod并查看状态" class="headerlink" title="9.4.2 启动pod并查看状态"></a>9.4.2 启动pod并查看状态</h4><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Service 和 StatufulSet 和 Pod</span>$ kubectl apply -f sts-pod-pvc.yaml<span class="comment"># 查看 Service 详情</span>$ kubectl get svc -o wideNAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTORkubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   66d   &lt;none&gt;nginx        ClusterIP   None         &lt;none&gt;        80/TCP    6s    app=nginx<span class="comment"># 查看 StatefulSet 详情</span>$ kubectl get statefulSet -o wideNAME   READY   AGE   CONTAINERS   IMAGESweb    3/3     52s   nginx        wangyanglinux/myapp:v1.0<span class="comment"># 查看 Pod详情</span>$ kubectl get pods -o wideNAME    READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESweb-0   1/1     Running   0          61s   192.168.85.228   k8s-node01   &lt;none&gt;           &lt;none&gt;web-1   1/1     Running   0          56s   192.168.58.226   k8s-node02   &lt;none&gt;           &lt;none&gt;web-2   1/1     Running   0          50s   192.168.58.227   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><h4 id="9-4-3-PV和PVC状态信息查看"><a href="#9-4-3-PV和PVC状态信息查看" class="headerlink" title="9.4.3 PV和PVC状态信息查看"></a>9.4.3 PV和PVC状态信息查看</h4><pre><code class="highlight bash"><span class="comment"># PV 明细</span>$ kubectl get pods -o wideNAME    READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESweb-0   1/1     Running   0          30m   192.168.58.233   k8s-node02   &lt;none&gt;           &lt;none&gt;web-1   1/1     Running   0          30m   192.168.85.237   k8s-node01   &lt;none&gt;           &lt;none&gt;web-2   1/1     Running   0          30m   192.168.58.234   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># PVC 明细</span>$ kubectl get pvc -o wideNAME        STATUS   VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE   VOLUMEMODEwww-web-0   Bound    pv-nfs2   3Gi        RWO            nfs            &lt;<span class="built_in">unset</span>&gt;                 31m   Filesystemwww-web-1   Bound    pv-nfs3   5Gi        RWO            nfs            &lt;<span class="built_in">unset</span>&gt;                 31m   Filesystemwww-web-2   Bound    pv-nfs6   5Gi        RWO            nfs            &lt;<span class="built_in">unset</span>&gt;                 31m   Filesystem</code></pre><p><strong>PVC与PV绑定时会根据storageClassName（存储类名称）和accessModes（访问模式）判断哪些PV符合绑定需求。然后再根据存储量大小判断，首先存PV储量必须大于或等于PVC声明量；其次就是PV存储量越接近PVC声明量，那么优先级就越高（PV量越小优先级越高）。</strong></p><p>从上面的信息可以看到 web-0 对应的集群内的IP是 192.168.58.233， 运行在 k8s-node02 节点上，对应的 PVC 是 www-web-0, 绑定的PV 是 pv-nfs2</p><h4 id="9-4-4-curl访问验证"><a href="#9-4-4-curl访问验证" class="headerlink" title="9.4.4 curl访问验证"></a>9.4.4 curl访问验证</h4><p>在NFS服务端对应NFS共享目录创建文件</p><p>pv-nfs2、pv-nfs3、pv-nfs6 被绑定，只需要在这三个pv对应的目录写入文件即可</p><pre><code class="highlight bash">$ <span class="built_in">echo</span> <span class="string">&quot;hello nfs2&quot;</span> &gt;&gt; /root/data/nfs2/index.html$ <span class="built_in">echo</span> <span class="string">&quot;hello nfs3&quot;</span> &gt;&gt; /root/data/nfs3/index.html$ <span class="built_in">echo</span> <span class="string">&quot;hello nfs6&quot;</span> &gt;&gt; /root/data/nfs6/index.html</code></pre><p>curl 访问 pod</p><pre><code class="highlight bash">NAME    READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESweb-0   1/1     Running   0          40m   192.168.58.233   k8s-node02   &lt;none&gt;           &lt;none&gt;web-1   1/1     Running   0          40m   192.168.85.237   k8s-node01   &lt;none&gt;           &lt;none&gt;web-2   1/1     Running   0          39m   192.168.58.234   k8s-node02   &lt;none&gt;           &lt;none&gt;[root@k8s-master01 /opt/k8s/07/pv-pvc]$ curl 192.168.58.233hello nfs2[root@k8s-master01 /opt/k8s/07/pv-pvc]$ curl 192.168.58.234hello nfs6[root@k8s-master01 /opt/k8s/07/pv-pvc]$ curl 192.168.85.237hello nfs3</code></pre><p>即使删除其中一个pod，pod被拉起来后也能正常访问。</p><h3 id="9-5-删除-StatefulSet-并回收-PV"><a href="#9-5-删除-StatefulSet-并回收-PV" class="headerlink" title="9.5 删除 StatefulSet 并回收 PV"></a>9.5 删除 StatefulSet 并回收 PV</h3><h4 id="9-5-1-删除-StatefulSet"><a href="#9-5-1-删除-StatefulSet" class="headerlink" title="9.5.1 删除 StatefulSet"></a>9.5.1 删除 StatefulSet</h4><pre><code class="highlight bash">$ kubectl delete -f sts-pod-pvc.yaml service <span class="string">&quot;nginx&quot;</span> deletedstatefulset.apps <span class="string">&quot;web&quot;</span> deleted$ kubectl get svc NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGEkubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   70d$ kubectl get pod No resources found <span class="keyword">in</span> default namespace.</code></pre><h4 id="9-5-2-查看PVC和PV，并删除PVC"><a href="#9-5-2-查看PVC和PV，并删除PVC" class="headerlink" title="9.5.2 查看PVC和PV，并删除PVC"></a>9.5.2 查看PVC和PV，并删除PVC</h4><pre><code class="highlight bash"><span class="comment"># 查看PVC</span>$ kubectl get pvc -o wideNAME        STATUS   VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE   VOLUMEMODEwww-web-0   Bound    pv-nfs2   3Gi        RWO            nfs            &lt;<span class="built_in">unset</span>&gt;                 61m   Filesystemwww-web-1   Bound    pv-nfs3   5Gi        RWO            nfs            &lt;<span class="built_in">unset</span>&gt;                 61m   Filesystemwww-web-2   Bound    pv-nfs6   5Gi        RWO            nfs            &lt;<span class="built_in">unset</span>&gt;                 61m   Filesystem<span class="comment"># 查看PV</span>$ kubectl get pv -o wideNAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM               STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE   VOLUMEMODEpv-nfs1   1Gi        RWO            Recycle          Available                       nfs            &lt;<span class="built_in">unset</span>&gt;                          62m   Filesystempv-nfs2   3Gi        RWO            Recycle          Bound       default/www-web-0   nfs            &lt;<span class="built_in">unset</span>&gt;                          62m   Filesystempv-nfs3   5Gi        RWO            Recycle          Bound       default/www-web-1   nfs            &lt;<span class="built_in">unset</span>&gt;                          62m   Filesystempv-nfs4   10Gi       RWO            Recycle          Available                       nfs            &lt;<span class="built_in">unset</span>&gt;                          62m   Filesystempv-nfs5   5Gi        RWX            Recycle          Available                       nfs            &lt;<span class="built_in">unset</span>&gt;                          62m   Filesystempv-nfs6   5Gi        RWO            Recycle          Bound       default/www-web-2   nfs            &lt;<span class="built_in">unset</span>&gt;                          62m   Filesystem</code></pre><h4 id="9-5-3-回收-PV"><a href="#9-5-3-回收-PV" class="headerlink" title="9.5.3 回收 PV"></a>9.5.3 回收 PV</h4><p>删除PVC后再次查看PV，发现PV从 Bound 状态变成了 Released 状态，没有真正释放掉（变回Available状态），这时有两种办法，一是等待，让PV自动释放掉，第二种方式是手动释放PV</p><pre><code class="highlight bash"><span class="comment"># 再次查看PV</span>$ kubectl get pv -o wideNAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM               STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE   VOLUMEMODEpv-nfs1   1Gi        RWO            Recycle          Available                       nfs            &lt;<span class="built_in">unset</span>&gt;                          67m   Filesystempv-nfs2   3Gi        RWO            Recycle          Released    default/www-web-0   nfs            &lt;<span class="built_in">unset</span>&gt;                          67m   Filesystempv-nfs3   5Gi        RWO            Recycle          Released    default/www-web-1   nfs            &lt;<span class="built_in">unset</span>&gt;                          67m   Filesystempv-nfs4   10Gi       RWO            Recycle          Available                       nfs            &lt;<span class="built_in">unset</span>&gt;                          67m   Filesystempv-nfs5   5Gi        RWX            Recycle          Available                       nfs            &lt;<span class="built_in">unset</span>&gt;                          67m   Filesystempv-nfs6   5Gi        RWO            Recycle          Released    default/www-web-2   nfs            &lt;<span class="built_in">unset</span>&gt;                          67m   Filesystem<span class="comment"># 编辑，手动释放PV, 将 spec.claimRef 部分删除</span>$ kubectl edit pv pv-nfs2$ kubectl edit pv pv-nfs3$ kubectl edit pv pv-nfs6</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/05/27/20250527-221115.png" alt="手动释放PV"></p><p>手动修改完成后，再次查看PV状态</p><pre><code class="highlight bash">$ kubectl get pv -o wideNAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE   VOLUMEMODEpv-nfs1   1Gi        RWO            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          72m   Filesystempv-nfs2   3Gi        RWO            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          72m   Filesystempv-nfs3   5Gi        RWO            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          72m   Filesystempv-nfs4   10Gi       RWO            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          72m   Filesystempv-nfs5   5Gi        RWX            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          72m   Filesystempv-nfs6   5Gi        RWO            Recycle          Available           nfs            &lt;<span class="built_in">unset</span>&gt;                          72m   Filesystem</code></pre><p>结论： PV 已成功释放。</p><h2 id="10-StatefulSet网络标识与PVC"><a href="#10-StatefulSet网络标识与PVC" class="headerlink" title="10. StatefulSet网络标识与PVC"></a>10. StatefulSet网络标识与PVC</h2><ul><li><p>匹配 StatefulSet 的 Pod name (网络标识)的模式为：<code>$(statefulset名称)-$(序号)</code>，比如 StatefulSet 名称为web，副本数为3。则为：web-0、web-1、web-2</p></li><li><p>StatefulSet 为每个Pod副本创建了一个DNS域名，这个域名的格式为：<code>$(podname).(headless service name)</code>，也就意味着服务之间是通过Pod域名来通信而非Pod IP。当Pod所在Node发生故障时，Pod会被漂移到其他Node上，Pod IP会发生改变，但Pod域名不会变化</p></li><li><p>StatefulSet 使用 Headless 服务来控制 Pod 的域名，这个 Headless 服务域名的为：<code>$(service name).$(namespace).svc.cluster.local</code>，其中 cluster.local 指定的集群的域名</p></li><li><p>根据 volumeClaimTemplates，为每个 Pod 创建一个 PVC，PVC的命令规则为：<code>$(volumeClaimTemplates name)-$(pod name)</code>，比如 volumeClaimTemplates 为 www，pod name 为 web-0、web-1、web-2；那么创建出来的PVC为：www-web-0、www-web-1、www-web-2</p></li><li><p>删除 Pod 不会删除对应的 PVC，手动删除 PVC 将自动释放 PV。</p></li></ul><h1 id="七、StorageClass"><a href="#七、StorageClass" class="headerlink" title="七、StorageClass"></a>七、StorageClass</h1><h2 id="1-理论"><a href="#1-理论" class="headerlink" title="1. 理论"></a>1. 理论</h2><p>在动态资源供应模式下，通过StorageClass和PVC完成资源动态绑定（系统自动生成PV），并供Pod使用的存储管理机制。</p><p>volumeClaimTemplates 实现了pvc 的自动化，StorageClass 实现了 pv 的自动化</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/05/29/20250529-160448.png" alt="存储"></p><h3 id="1-1-什么是-StorageClass"><a href="#1-1-什么是-StorageClass" class="headerlink" title="1.1 什么是 StorageClass"></a>1.1 什么是 StorageClass</h3><p>Kubernetes 提供了一套可以自动创建PV的机制，即：Dynamic Provisioning。而这个机制的核心在于StorageClass这个API对象。</p><p>StorageClass 对象会定义下面两部分内容:</p><ul><li>PV 的属性。比如，存储类型，Volume 的大小等。</li><li>创建这种 PV 需要用到的存储插件，即存储制备器。</li></ul><p>有了这两个信息之后，Kubernetes 就能够根据用户提交的 PVC，找到一个对应的 StorageClass，之后 Kubernetes 就会调用该 StorageClass 声明的存储插件，进而创建出需要的PV。</p><p>但是其实使用起来是一件很简单的事情，你只需要根据自己的需求，编写YAML文件即可，然后使用 <code>kubectl create</code> 命令执行即可。</p><blockquote><p>StorageClass 为管理员提供了描述存储 “类” 的方法。不同的类型可能会映射到不同的服务质量等级或备份策略，或是由集群管理员制定的任意策略。 Kubernetes 本身并不清楚各种类代表的什么。这个类的概念在其他存储系统中有时被称为 “配置文件”。</p></blockquote><h3 id="1-2-为什么需要-StorageClass"><a href="#1-2-为什么需要-StorageClass" class="headerlink" title="1.2 为什么需要 StorageClass"></a>1.2 为什么需要 StorageClass</h3><p>在一个大规模的 Kubernetes 集群里，可能有成千上万个 PVC，这就意味着运维人员必须实现创建出这个多个 PV，此外，随着项目的需要，会有新的 PVC 不断被提交，那么运维人员就需要不断的添加新的，满足要求的 PV，否则新的Pod就会因为 PVC 绑定不到PV而导致创建失败。而且通过 PVC 请求到一定的存储空间也很有可能不足以满足应用对于存储设备的各种需求。</p><p>而且不同的应用程序对于存储性能的要求可能也不尽相同，比如读写速度、并发性能等，为了解决这一问题，Kubernetes 又为我们引入了一个新的资源对象：StorageClass，通过 StorageClass 的定义，管理员可以将存储资源定义为某种类型的资源，比如快速存储、慢速存储等，用户根据 StorageClass 的描述就可以非常直观的知道各种存储资源的具体特性了，这样就可以根据应用的特性去申请合适的存储资源了。</p><h3 id="1-3-运行原理"><a href="#1-3-运行原理" class="headerlink" title="1.3  运行原理"></a>1.3  运行原理</h3><p>要使用 StorageClass，我们就得安装对应的自动配置程序，比如我们这里存储后端使用的是 nfs，那么我们就需要使用到一个 nfs-client 的自动配置程序，我们也叫它 <code>Provisioner</code>（制备器），这个程序使用我们已经配置好的 nfs 服务器，来自动创建持久卷，也就是自动帮我们创建 PV。</p><ul><li>自动创建的 PV 以 <code>$&#123;namespace&#125;-$&#123;pvcName&#125;-$&#123;pvName&#125;</code> 这样的命名格式创建在 NFS 服务器上的共享数据目录中</li><li>而当这个 PV 被回收后会以 <code>archieved-$&#123;namespace&#125;-$&#123;pvcName&#125;-$&#123;pvName&#125;</code> 这样的命名格式存在 NFS 服务器上。</li></ul><h2 id="2-StorageClass-资源"><a href="#2-StorageClass-资源" class="headerlink" title="2. StorageClass 资源"></a>2. StorageClass 资源</h2><p>StorageClass 资源清单示例：</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">StorageClass</span> <span class="comment"># 资源的类型为 StorageClass</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">standard</span> <span class="comment"># 存储类的名称</span><span class="attr">provisioner:</span> <span class="string">kubernetes.io/aws-ebs</span> <span class="comment"># 指定了存储的提供者（Provisioner）,使用 AWS EBS（Elastic Block Store）作为存储后端</span><span class="attr">parameters:</span>  <span class="attr">type:</span> <span class="string">gp2</span> <span class="comment"># 指定了 AWS EBS 卷的类型为 gp2。gp2 是 AWS EBS 的通用 SSD（General Purpose SSD）卷类型</span><span class="attr">reclaimPolicy:</span> <span class="string">Retain</span> <span class="comment"># 定义了存储卷的回收策略为 Retain。当 PVC 被删除时，与之关联的持久卷（PV）不会被自动删除，而是保留下来，需要手动清理。这可以防止意外删除重要数据。</span><span class="attr">allowVolumeExpansion:</span> <span class="literal">true</span> <span class="comment"># 允许对使用此 StorageClass 创建的卷进行扩展, 如果 PVC 请求更大的容量，Kubernetes 允许动态扩展卷（前提是底层存储支持，例如 AWS EBS 的 gp2 支持扩展）。</span><span class="attr">mountOptions:</span>  <span class="bullet">-</span> <span class="string">debug</span> <span class="comment"># 指定了挂载选项为 debug, 在挂载存储卷时启用调试模式，可能用于记录详细的挂载日志，便于排查问题。注意：生产环境中通常不建议使用 debug，因为它可能会增加日志输出</span><span class="attr">volumeBindingMode:</span> <span class="string">Immediate</span> <span class="comment"># 指定了卷绑定模式为 Immediate, 表示一旦 PVC 创建，Kubernetes 将立即尝试为它绑定一个持久卷（PV），而不等待 Pod 调度。这适用于大多数场景，但可能导致存储资源分配不灵活（相比 WaitForFirstConsumer 模式）。</span></code></pre><p>每个 StorageClass 都包含 <code>provisioner</code>、<code>parameters</code> 和 <code>reclaimPolicy</code> 字段， 这些字段会在 StorageClass 需要动态分配 PersistentVolume 时会使用到。</p><p>StorageClass 对象的命名很重要，用户使用这个命名来请求生成一个特定的类。 当创建 StorageClass 对象时，管理员设置 StorageClass 对象的命名和其他参数，一旦创建了对象就不能再对其更新。</p><p>管理员可以为没有申请绑定到特定 StorageClass 的 PVC 指定一个默认的存储类。</p><h3 id="2-1-存储制备器"><a href="#2-1-存储制备器" class="headerlink" title="2.1 存储制备器"></a>2.1 存储制备器</h3><p>每个 StorageClass 都有一个制备器（Provisioner），用来决定使用哪个卷插件制备 PV。 该字段必须指定。</p><table><thead><tr><th align="left">卷插件</th><th>内置制备器</th><th>配置例子</th></tr></thead><tbody><tr><td align="left">AWSElasticBlockStore</td><td>✓</td><td><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#aws-ebs">AWS EBS</a></td></tr><tr><td align="left">AzureFile</td><td>✓</td><td>Azure File</td></tr><tr><td align="left">AzureDisk</td><td>✓</td><td>Azure Disk</td></tr><tr><td align="left">CephFS</td><td>-</td><td>-</td></tr><tr><td align="left">Cinder</td><td>✓</td><td><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#openstack-cinder">OpenStack Cinder</a></td></tr><tr><td align="left">FC</td><td>-</td><td>-</td></tr><tr><td align="left">FlexVolume</td><td>-</td><td>-</td></tr><tr><td align="left">Flocker</td><td>✓</td><td>-</td></tr><tr><td align="left">GCEPersistentDisk</td><td>✓</td><td><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#gce-pd">GCE PD</a></td></tr><tr><td align="left">Glusterfs</td><td>✓</td><td><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#glusterfs">Glusterfs</a></td></tr><tr><td align="left">iSCSI</td><td>-</td><td>-</td></tr><tr><td align="left">Quobyte</td><td>✓</td><td><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#quobyte">Quobyte</a></td></tr><tr><td align="left">NFS</td><td>-</td><td>-</td></tr><tr><td align="left">RBD</td><td>✓</td><td><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#ceph-rbd">Ceph RBD</a></td></tr><tr><td align="left">VsphereVolume</td><td>✓</td><td><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#vsphere">vSphere</a></td></tr><tr><td align="left">PortworxVolume</td><td>✓</td><td>Portworx Volume</td></tr><tr><td align="left">ScaleIO</td><td>✓</td><td><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#scaleio">ScaleIO</a></td></tr><tr><td align="left">StorageOS</td><td>✓</td><td><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#storageos">StorageOS</a></td></tr><tr><td align="left">Local</td><td>-</td><td>Local</td></tr></tbody></table><p>除了列出的 “内置” 制备器（其名称前缀为 “kubernetes.io” 并打包在 Kubernetes 中）。 还可以运行和指定外部制备器，这些独立的程序遵循由 Kubernetes 定义的 规范。 外部供应商的作者完全可以自由决定他们的代码保存于何处、打包方式、运行方式、使用的插件（包括 Flex）等。例如，NFS 没有内部制备器，但可以使用外部制备器。 也有第三方存储供应商提供自己的外部制备器。</p><h3 id="2-2-回收策略"><a href="#2-2-回收策略" class="headerlink" title="2.2 回收策略"></a>2.2 回收策略</h3><p>由 StorageClass 动态创建的 PersistentVolume 会在类的 <code>reclaimPolicy</code> 字段中指定回收策略，可以是 Delete 或者 Retain。如果 StorageClass 对象被创建时没有指定 <code>reclaimPolicy</code>，它将默认为 <code>Delete</code>。</p><p>通过 <code>StorageClass</code> 手动创建并管理的 <code>PersistentVolume</code> 会使用它们被创建时指定的回收政策。</p><h3 id="2-3-允许卷扩展"><a href="#2-3-允许卷扩展" class="headerlink" title="2.3 允许卷扩展"></a>2.3 允许卷扩展</h3><p>PersistentVolume 可以配置为可扩展。将此功能设置为 <code>true</code> 时，允许用户通过编辑相应的 PVC 对象来调整卷大小。</p><p>当下层 StorageClass 的 <code>allowVolumeExpansion</code> 字段设置为 true 时，以下类型的卷支持卷扩展。</p><table><thead><tr><th>卷类型</th><th>Kubernetes 版本要求</th></tr></thead><tbody><tr><td>gcePersistentDisk</td><td>1.11</td></tr><tr><td>awsElasticBlockStore</td><td>1.11</td></tr><tr><td>Cinder</td><td>1.11</td></tr><tr><td>glusterfs</td><td>1.11</td></tr><tr><td>rbd</td><td>1.11</td></tr><tr><td>Azure File</td><td>1.11</td></tr><tr><td>Azure Disk</td><td>1.11</td></tr><tr><td>Portworx</td><td>1.11</td></tr><tr><td>FlexVolume</td><td>1.13</td></tr><tr><td>CSI</td><td>1.14 (alpha), 1.16 (beta)</td></tr></tbody></table><p><strong>说明： 此功能仅可用于扩容卷，不能用于缩小卷。</strong></p><h3 id="2-4-挂载选项"><a href="#2-4-挂载选项" class="headerlink" title="2.4 挂载选项"></a>2.4 挂载选项</h3><p>由 StorageClass 动态创建的 PersistentVolume 将使用类中 <code>mountOptions</code> 字段指定的挂载选项。</p><p>如果卷插件不支持挂载选项，却指定了该选项，则制备操作会失败。 挂载选项在 StorageClass 和 PV 上都不会做验证，所以如果挂载选项无效，那么这个 PV 就会失败。</p><h3 id="2-5-卷绑定模式"><a href="#2-5-卷绑定模式" class="headerlink" title="2.5 卷绑定模式"></a>2.5 卷绑定模式</h3><p><code>volumeBindingMode</code> 字段控制了卷绑定和动态制备 应该发生在什么时候。</p><p>默认情况下，<code>Immediate</code> 模式表示一旦创建了 PersistentVolumeClaim 也就完成了卷绑定和动态制备。 对于由于拓扑限制而非集群所有节点可达的存储后端，PersistentVolume 会在不知道 Pod 调度要求的情况下绑定或者制备。</p><p>集群管理员可以通过指定 WaitForFirstConsumer 模式来解决此问题。 该模式将延迟 PersistentVolume 的绑定和制备，直到使用该 PersistentVolumeClaim 的 Pod 被创建。 PersistentVolume 会根据 Pod 调度约束指定的拓扑来选择或制备。这些包括但不限于 资源需求、 节点筛选器、 pod 亲和性和互斥性、 以及污点和容忍度。</p><p>以下插件支持动态供应的 <code>WaitForFirstConsumer</code> 模式:</p><ul><li><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#aws-ebs">AWSElasticBlockStore</a></li><li><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#gce-pd">GCEPersistentDisk</a></li><li><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#azure-disk">AzureDisk</a></li></ul><p>以下插件支持预创建绑定 PersistentVolume 的 WaitForFirstConsumer 模式：</p><ul><li>上述全部</li><li><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#local">Local</a></li></ul><h3 id="2-6-允许的拓扑结构"><a href="#2-6-允许的拓扑结构" class="headerlink" title="2.6 允许的拓扑结构"></a>2.6 允许的拓扑结构</h3><p>当集群操作人员使用了 <code>WaitForFirstConsumer</code> 的卷绑定模式， 在大部分情况下就没有必要将制备限制为特定的拓扑结构。 然而，如果还有需要的话，可以使用 <code>allowedTopologies</code>。</p><p>这个例子描述了如何将供应卷的拓扑限制在特定的区域，在使用时应该根据插件 支持情况替换 <code>zone</code> 和 <code>zones</code> 参数。</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span><span class="attr">kind:</span> <span class="string">StorageClass</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">standard</span><span class="attr">provisioner:</span> <span class="string">kubernetes.io/gce-pd</span><span class="attr">parameters:</span>  <span class="attr">type:</span> <span class="string">pd-standard</span><span class="attr">volumeBindingMode:</span> <span class="string">WaitForFirstConsumer</span> <span class="comment"># 指定了卷绑定模式为 WaitForFirstConsumer。</span><span class="attr">allowedTopologies:</span> <span class="comment"># 定义了存储卷可以被分配的拓扑范围。</span>  <span class="bullet">-</span> <span class="attr">matchLabelExpressions:</span> <span class="comment"># 使用标签选择器来限制存储卷的拓扑。</span>      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">failure-domain.beta.kubernetes.io/zone</span> <span class="comment"># Kubernetes 内置标签，用于表示节点的可用区（Zone）</span>        <span class="attr">values:</span> <span class="comment"># 限制存储卷只能在 Google Cloud 的 us-central1-a 和 us-central1-b 两个可用区中创建。</span>          <span class="bullet">-</span> <span class="string">us-central1-a</span>          <span class="bullet">-</span> <span class="string">us-central1-b</span></code></pre><p>这个 StorageClass 配置定义了一个名为 standard 的存储类，适用于 Google Cloud Platform 的 Persistent Disk（GCE PD）存储，磁盘类型为 pd-standard（标准硬盘）。它使用 WaitForFirstConsumer 绑定模式，确保存储卷的分配与 Pod 的调度位置一致，并且限制存储卷只能在 us-central1-a 和 us-central1-b 两个可用区中创建。</p><h2 id="3-案例演示"><a href="#3-案例演示" class="headerlink" title="3. 案例演示"></a>3. 案例演示</h2><h3 id="3-1-部署流程"><a href="#3-1-部署流程" class="headerlink" title="3.1 部署流程"></a>3.1 部署流程</h3><p>搭建StorageClass + NFS，大致有以下几个步骤：</p><ol><li>创建一个可用的 NFS Server</li><li>创建 Service Account，这是用来管控 NFS Provisioner 在 k8s 集群中运行的权限</li><li>创建 StorageClass，负责建立PVC并调用 NFS provisioner 进行预定的工作，并让 PV 与 PVC 建立关联</li><li>创建 NFS provisioner，有两个功能，一个是在NFS共享目录下创建挂载点( volume )，另一个则是建了 PV 并将 PV 与 NFS 的挂载点建立关联</li><li>创建 Pod 测试</li></ol><h3 id="3-2-搭建-NFS-服务"><a href="#3-2-搭建-NFS-服务" class="headerlink" title="3.2 搭建 NFS 服务"></a>3.2 搭建 NFS 服务</h3><p>见 5.5 章节</p><h3 id="3-3-创建命名空间"><a href="#3-3-创建命名空间" class="headerlink" title="3.3 创建命名空间"></a>3.3 创建命名空间</h3><p>创建新的命名空间，用于测试</p><pre><code class="highlight bash">$ kubectl create ns nfs-storageclass</code></pre><h3 id="3-4-创建-Service-Account"><a href="#3-4-创建-Service-Account" class="headerlink" title="3.4 创建 Service Account"></a>3.4 创建 Service Account</h3><h4 id="3-4-1-ServiceAccount"><a href="#3-4-1-ServiceAccount" class="headerlink" title="3.4.1 ServiceAccount"></a>3.4.1 ServiceAccount</h4><p><code>ServiceAccount-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ServiceAccount</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span>  <span class="attr">namespace:</span> <span class="string">nfs-storageclass</span></code></pre><p><strong>解读</strong>：</p><ul><li><strong>类型</strong>：ServiceAccount 是 Kubernetes 中的一种资源，用于为 Pod 或其他资源提供身份认证。</li><li><strong>用途</strong>：这里创建了一个名为 nfs-client-provisioner 的 ServiceAccount，运行在 nfs-storageclass 命名空间中。这个 ServiceAccount 将被后续的 Deployment 使用，允许 NFS 客户端动态配置器（Provisioner）以指定的身份与 Kubernetes API 交互。</li><li><strong>命名空间</strong>：nfs-storageclass，表示该 ServiceAccount 仅在该命名空间内有效。</li></ul><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f ServiceAccount-01.yaml<span class="comment"># 查看 SA</span>$ kubectl get sa -n nfs-storageclassNAME                     SECRETS   AGEdefault                  0         3m36snfs-client-provisioner   0         20s</code></pre><h4 id="3-4-2-ClusterRole"><a href="#3-4-2-ClusterRole" class="headerlink" title="3.4.2 ClusterRole"></a>3.4.2 ClusterRole</h4><p><code>ClusterRole-02.yaml</code></p><pre><code class="highlight yaml"><span class="attr">kind:</span> <span class="string">ClusterRole</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span><span class="attr">rules:</span>  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;nodes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumes&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumeclaims&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;storage.k8s.io&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;storageclasses&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]    <span class="attr">resources:</span> [<span class="string">&quot;events&quot;</span>]    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]</code></pre><p><strong>解读</strong>：</p><ul><li><strong>类型</strong>：ClusterRole 是 Kubernetes 的 RBAC（基于角色的访问控制）资源，定义了<strong>集群级别的权限规则</strong>。</li><li><strong>apiGroups: [“”]</strong><ul><li>空字符串表示核心 API 组（core API group），包含 Kubernetes 的基本资源（如 nodes、pods 等）。</li></ul></li><li>用途：为 nfs-client-provisioner 定义了操作权限，允许其对以下资源执行指定操作：<ul><li><strong>Nodes</strong>：获取、列出和监听节点信息（get, list, watch）。</li><li>**PersistentVolumes (PV)**：获取、列出、监听、创建和删除持久卷（get, list, watch, create, delete）。</li><li>**PersistentVolumeClaims (PVC)**：获取、列出、监听和更新持久卷声明（get, list, watch, update）。</li><li><strong>StorageClasses</strong>：获取、列出和监听存储类（get, list, watch）。</li><li><strong>Events</strong>：创建、更新和修补事件（create, update, patch），用于记录动态配置过程中的事件。</li></ul></li><li><strong>集群级别</strong>：ClusterRole 的权限是集群范围的，适用于所有命名空间。</li></ul><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f ClusterRole-02.yaml<span class="comment"># 查看 集群角色</span>$ kubectl get ClusterRole -n nfs-storageclassNAME                                                                   CREATED ATnfs-client-provisioner-runner                                          2025-05-30T02:12:39Z</code></pre><h4 id="3-4-3-ClusterRoleBinding"><a href="#3-4-3-ClusterRoleBinding" class="headerlink" title="3.4.3 ClusterRoleBinding"></a>3.4.3 ClusterRoleBinding</h4><p><code>ClusterRoleBinding-03.yaml</code></p><pre><code class="highlight yaml"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-nfs-client-provisioner</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定类型 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># ServiceAccount 的名称</span>    <span class="attr">namespace:</span> <span class="string">nfs-storageclass</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">ClusterRole</span> <span class="comment"># 绑定的角色类型</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span> <span class="comment"># 集群角色名称 nfs-client-provisioner-runner</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></code></pre><p><strong>解读</strong>：</p><ul><li><strong>类型</strong>：ClusterRoleBinding 将 ClusterRole 绑定到特定的主体（Subject）。</li><li><strong>用途</strong>：将前面定义的 nfs-client-provisioner-runner ClusterRole 绑定到 nfs-client-provisioner ServiceAccount 上，授予其相应的权限。</li><li><strong>主体</strong>：nfs-client-provisioner ServiceAccount，位于 nfs-storageclass 命名空间。</li><li><strong>作用</strong>：确保 nfs-client-provisioner ServiceAccount 能够以 ClusterRole 定义的权限操作 Kubernetes 资源。</li></ul><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f ClusterRoleBinding-03.yaml<span class="comment"># 查看 集群角色绑定</span>$ kubectl get ClusterRoleBinding -n nfs-storageclassNAME                         ROLE                                                              AGErun-nfs-client-provisioner   ClusterRole/nfs-client-provisioner-runner                         22s</code></pre><h4 id="3-4-4-Role"><a href="#3-4-4-Role" class="headerlink" title="3.4.4 Role"></a>3.4.4 Role</h4><p><code>Role-04.yaml</code></p><pre><code class="highlight bash">kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata:  name: leader-locking-nfs-client-provisioner <span class="comment"># 角色的名称，表明它与 NFS 客户端存储提供者的领导者选举（leader election）机制相关。</span>  namespace: nfs-storageclassrules:  - apiGroups: [<span class="string">&quot;&quot;</span>] <span class="comment"># 空字符串表示核心 API 组（core API group），包含 Kubernetes 的基本资源，如 endpoints。</span>    resources: [<span class="string">&quot;endpoints&quot;</span>]    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]</code></pre><p><strong>解读</strong>：</p><ul><li><strong>类型</strong>：Role 是命名空间级别的 RBAC 资源，定义了特定命名空间内的权限规则。</li><li><strong>用途</strong>：为 nfs-client-provisioner 定义了在 nfs-storageclass 命名空间内操作 endpoints 资源的权限，包括获取、列出、监听、创建、更新和修补（get, list, watch, create, update, patch）。</li><li><strong>背景</strong>：endpoints 资源通常用于实现领导者选举（Leader Election），确保只有一个 Provisioner 实例在动态配置存储时处于活动状态。</li></ul><pre><code class="highlight bash"><span class="comment"># 创建角色</span>$ kubectl apply -f Role-04.yaml<span class="comment"># 在指定名称空间内查看角色</span>$ kubectl get Role -n nfs-storageclassNAME                                    CREATED ATleader-locking-nfs-client-provisioner   2025-05-30T02:39:47Z</code></pre><h4 id="3-4-5-RoleBinding"><a href="#3-4-5-RoleBinding" class="headerlink" title="3.4.5 RoleBinding"></a>3.4.5 RoleBinding</h4><p><code>RoleBinding-05.yaml</code></p><pre><code class="highlight yaml"><span class="attr">kind:</span> <span class="string">RoleBinding</span><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">run-leader-locking-nfs-client-provisioner</span>  <span class="attr">namespace:</span> <span class="string">nfs-storageclass</span><span class="attr">subjects:</span>  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span> <span class="comment"># 绑定资源类型为 ServiceAccount</span>    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 绑定的ServiceAccount 名称</span>    <span class="attr">namespace:</span> <span class="string">nfs-storageclass</span><span class="attr">roleRef:</span>  <span class="attr">kind:</span> <span class="string">Role</span> <span class="comment"># 绑定角色（nfs-storageclass名称空间的角色）</span>  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span>  <span class="attr">name:</span> <span class="string">leader-locking-nfs-client-provisioner</span> <span class="comment"># 角色的名称</span></code></pre><p><strong>解读</strong>：</p><ul><li><strong>类型</strong>：RoleBinding 将 Role 绑定到特定主体。</li><li><strong>用途</strong>：将 <code>leader-locking-nfs-client-provisioner</code> Role 绑定到 <code>nfs-client-provisioner</code> ServiceAccount，授予其在 nfs-storageclass 命名空间内操作 endpoints 的权限。</li><li><strong>作用</strong>：支持领导者选举机制，确保 NFS 客户端 Provisioner 的高可用性和一致性。</li></ul><pre><code class="highlight bash"><span class="comment"># 执行角色绑定</span>$ kubectl apply -f RoleBinding-05.yaml<span class="comment"># 查看角色绑定详情</span>$ kubectl get RoleBinding -n nfs-storageclass -o wideNAME                                        ROLE                                         AGE     USERS   GROUPS   SERVICEACCOUNTSrun-leader-locking-nfs-client-provisioner   Role/leader-locking-nfs-client-provisioner   2m45s                    nfs-storageclass/nfs-client-provisioner</code></pre><h4 id="3-4-6-StorageClass"><a href="#3-4-6-StorageClass" class="headerlink" title="3.4.6 StorageClass"></a>3.4.6 StorageClass</h4><p><code>StorageClass-06.yaml</code></p><pre><code class="highlight yaml"><span class="attr">kind:</span> <span class="string">StorageClass</span><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client</span> <span class="comment"># StorageClass 的名称</span>  <span class="attr">namespace:</span> <span class="string">nfs-storageclass</span><span class="attr">provisioner:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span><span class="attr">parameters:</span>  <span class="attr">pathPattern:</span> <span class="string">$&#123;.PVC.namespace&#125;/$&#123;.PVC.name&#125;</span>  <span class="attr">onDelete:</span> <span class="string">delete</span></code></pre><p><strong>解读</strong>：</p><ul><li><strong>类型</strong>：StorageClass 定义了动态存储配置的模板。</li><li><strong>用途</strong>：定义了一个名为 nfs-client 的存储类，位于 nfs-storageclass 命名空间，用于动态创建 NFS 持久卷。</li><li>配置：<ul><li><strong>provisioner</strong>：指定了动态配置器为 k8s-sigs.io&#x2F;nfs-subdir-external-provisioner，即 NFS 子目录外部配置器。</li><li><strong>parameters</strong>：<ul><li>pathPattern：动态生成的 NFS 路径，格式为 <code>&lt;PVC 命名空间&gt;/&lt;PVC 名称&gt;</code>，例如 nfs-storageclass&#x2F;test-claim。</li><li>onDelete: delete：当 PVC 被删除时，关联的 NFS 存储路径也会被删除。</li></ul></li></ul></li><li><strong>作用</strong>：当用户创建使用 nfs-client 存储类的 PVC 时，Provisioner 会自动在 NFS 服务器上创建对应的子目录。</li></ul><pre><code class="highlight bash"><span class="comment"># 创建 StorageClass</span>$ kubectl apply -f StorageClass-06.yaml<span class="comment"># 查看 StorageClass</span>$ kubectl get StorageClass -n nfs-storageclassNAME         PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGEnfs-client   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  12s</code></pre><h4 id="3-4-7-Deployment"><a href="#3-4-7-Deployment" class="headerlink" title="3.4.7 Deployment"></a>3.4.7 Deployment</h4><p><code>Deployment-07.yaml</code></p><pre><code class="highlight yaml"><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span>  <span class="attr">namespace:</span> <span class="string">nfs-storageclass</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># 3个nfs客户端副本</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>  <span class="attr">strategy:</span>    <span class="attr">type:</span> <span class="string">Recreate</span> <span class="comment"># 更新策略为重新创建，即先删除旧 Pod 再创建新 Pod，适合单一实例场景。</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span>    <span class="attr">spec:</span>      <span class="attr">serviceAccountName:</span> <span class="string">nfs-client-provisioner</span> <span class="comment"># 使用 nfs-client-provisioner ServiceAccount，赋予其 RBAC 权限。</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span>          <span class="attr">image:</span> <span class="string">k8s.dockerproxy.com/sig-storage/nfs-subdir-external-provisioner:v4.0.2</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 挂载的卷名称，与 volumes 部分定义的卷对应</span>              <span class="attr">mountPath:</span> <span class="string">/persistentvolumes</span> <span class="comment"># 将 NFS 卷挂载到容器内的 /persistentvolumes 路径，供容器读写 NFS 共享数据。</span>          <span class="attr">env:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PROVISIONER_NAME</span>              <span class="attr">value:</span> <span class="string">k8s-sigs.io/nfs-subdir-external-provisioner</span> <span class="comment"># 指定配置器名称，与 StorageClass 保持一致</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_SERVER</span>              <span class="attr">value:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span> <span class="comment"># NFS 服务器地址</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_PATH</span>              <span class="attr">value:</span> <span class="string">/root/data</span> <span class="comment"># NFS 共享路径</span>      <span class="attr">volumes:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span> <span class="comment"># 挂载卷的名称</span>          <span class="attr">nfs:</span>            <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span>            <span class="attr">path:</span> <span class="string">/root/data</span></code></pre><p><strong>解读</strong>：</p><ul><li><strong>类型</strong>：Deployment 用于管理 Pod 的部署和运行。</li><li><strong>用途</strong>：部署 NFS 客户端 Provisioner，确保动态存储配置服务运行。</li><li><strong>配置</strong>：<ul><li><strong>replicas: 3</strong>：运行3个 Pod 副本。</li><li><strong>strategy: Recreate</strong>：更新策略为重新创建，即先删除旧 Pod 再创建新 Pod，适合单一实例场景。</li><li><strong>serviceAccountName</strong>：使用 nfs-client-provisioner ServiceAccount，赋予其 RBAC 权限。</li><li><strong>容器</strong>：<ul><li><strong>镜像</strong>：k8s.dockerproxy.com&#x2F;sig-storage&#x2F;nfs-subdir-external-provisioner:v4.0.2，NFS 子目录外部配置器的镜像。</li><li><strong>volumeMounts</strong>：将 NFS 卷挂载到容器内路径 &#x2F;persistentvolumes。</li><li><strong>环境变量</strong>：<ul><li>PROVISIONER_NAME：指定配置器名称，与 StorageClass 保持一致。</li><li>NFS_SERVER：NFS 服务器地址（192.168.66.11）。</li><li>NFS_PATH：NFS 共享路径（&#x2F;root&#x2F;data）。</li></ul></li></ul></li><li><strong>volumes</strong>：定义了一个 NFS 卷，连接到 NFS 服务器 192.168.6.139 的 &#x2F;root&#x2F;data 路径。</li></ul></li><li><strong>作用</strong>：运行 NFS Provisioner，监听 PVC 请求并动态创建 NFS 子目录。</li></ul><pre><code class="highlight bash"><span class="comment"># 执行资源清单，部署 NFS 客户端 Provisioner</span>$ kubectl apply -f Deployment-07.yaml<span class="comment"># 查看 Deployment 控制器</span>$ kubectl get deployment -n nfs-storageclassNAME                     READY   UP-TO-DATE   AVAILABLE   AGEnfs-client-provisioner   3/3     3            3           5s<span class="comment"># 查看Pod</span>$ kubectl get pods -o wide -n nfs-storageclassNAME                                      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnfs-client-provisioner-5896c4d9d4-8cqwm   1/1     Running   0          18s   172.16.58.193   k8s-node02   &lt;none&gt;           &lt;none&gt;nfs-client-provisioner-5896c4d9d4-8wnnm   1/1     Running   0          18s   172.16.85.205   k8s-node01   &lt;none&gt;           &lt;none&gt;nfs-client-provisioner-5896c4d9d4-nds6r   1/1     Running   0          18s   172.16.58.204   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><h4 id="3-4-8-PersistentVolumeClaim-PVC"><a href="#3-4-8-PersistentVolumeClaim-PVC" class="headerlink" title="3.4.8 PersistentVolumeClaim (PVC)"></a>3.4.8 PersistentVolumeClaim (PVC)</h4><p><code>PersistentVolumeClaim-08.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">test-claim</span>  <span class="attr">annotations:</span> <span class="comment"># 注解部分为空（annotations: ），通常用于存储非关键的元数据信息（如描述、工具标记等）</span><span class="attr">spec:</span>  <span class="attr">accessModes:</span>    <span class="bullet">-</span> <span class="string">ReadWriteMany</span>  <span class="attr">resources:</span>    <span class="attr">requests:</span>      <span class="attr">storage:</span> <span class="string">1Mi</span> <span class="comment"># 请求 1MiB 的存储空间（实际存储大小由 NFS 服务器控制）</span>  <span class="attr">storageClassName:</span> <span class="string">nfs-client</span> <span class="comment"># StorageClass(存储类) 的名称</span></code></pre><p><strong>解读</strong>：</p><ul><li><strong>类型</strong>：PersistentVolumeClaim 是用户请求存储资源的声明。</li><li><strong>用途</strong>：定义一个名为 test-claim 的 PVC，请求使用 nfs-client 存储类动态分配存储。</li><li><strong>配置</strong>：<ul><li><strong>accessModes: ReadWriteMany</strong>：支持多个节点读写访问（适合 NFS 的共享存储特性）。</li><li><strong>resources.requests.storage: 1Mi</strong>：请求 1MiB 的存储空间（实际存储大小由 NFS 服务器控制）。</li><li><strong>storageClassName: nfs-client</strong>：指定使用 nfs-client 存储类。</li></ul></li><li><strong>作用</strong>：触发 NFS Provisioner 创建一个对应的 PV，并分配 NFS 服务器上的子目录（路径为 nfs-storageclass&#x2F;test-claim）。</li></ul><p>注意：PVC的资源清单没有指定命名空间，当执行资源清单时会在 default 命名空间下创建一个目录，后续会更新 Pod 所在命名空间，自动创建对应的目录。</p><pre><code class="highlight bash"><span class="comment"># 创建PVC</span>$ kubectl apply -f PersistentVolumeClaim-08.yaml<span class="comment"># 指定 命名空间查看 PVC</span>$ kubectl get pvc -o wide -n nfs-storageclassNAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE   VOLUMEMODEtest-claim   Bound    pvc-3b195b57-522a-49c5-badc-32e07fd37f88   1Mi        RWX            nfs-client     &lt;<span class="built_in">unset</span>&gt;                 15s   Filesystem<span class="comment"># 查看 PVC 自动创建的目录， 按照存储类定义的路径格式：$&#123;.PVC.namespace&#125;/$&#123;.PVC.name&#125;</span>$ ll /root/data/nfs-storageclass/total 0drwxrwxrwx 2 root root 6 May 30 17:12 test-claim</code></pre><h4 id="3-4-9-测试-Pod"><a href="#3-4-9-测试-Pod" class="headerlink" title="3.4.9 测试 Pod"></a>3.4.9 测试 Pod</h4><p><code>test-pod-09.yaml</code></p><pre><code class="highlight yaml"><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">test-pod</span>  <span class="attr">namespace:</span> <span class="string">nfs-storageclass</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-pod</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">volumeMounts:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-pvc</span> <span class="comment"># 使用的挂在卷名</span>          <span class="attr">mountPath:</span> <span class="string">/usr/local/nginx/html</span> <span class="comment"># 挂载到容器内的路径</span>  <span class="attr">volumes:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-pvc</span> <span class="comment"># 挂在卷名</span>      <span class="attr">persistentVolumeClaim:</span>        <span class="attr">claimName:</span> <span class="string">test-claim</span> <span class="comment"># 使用的PVC名称</span></code></pre><p><strong>创建Pod，测试存储类</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单，创建Pod</span>$ kubectl apply -f test-pod-09.yaml<span class="comment"># 查看Pod列表</span>$ kubectl get pods -o wide -n nfs-storageclassNAME                                      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESnfs-client-provisioner-5896c4d9d4-8cqwm   1/1     Running   0          37m   172.16.58.193   k8s-node02   &lt;none&gt;           &lt;none&gt;nfs-client-provisioner-5896c4d9d4-8wnnm   1/1     Running   0          37m   172.16.85.205   k8s-node01   &lt;none&gt;           &lt;none&gt;nfs-client-provisioner-5896c4d9d4-nds6r   1/1     Running   0          37m   172.16.58.204   k8s-node02   &lt;none&gt;           &lt;none&gt;test-pod                                  1/1     Running   0          36s   172.16.58.249   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 测试文件到PVC挂载目录</span>$ <span class="built_in">echo</span> <span class="string">&quot;hello test pod&quot;</span> &gt;&gt; /root/data/nfs-storageclass/test-claim/index.html<span class="comment"># 访问Pod</span>$ curl 172.16.58.249hello <span class="built_in">test</span> pod</code></pre><h4 id="3-4-10-测试-Service"><a href="#3-4-10-测试-Service" class="headerlink" title="3.4.10 测试 Service"></a>3.4.10 测试 Service</h4><p><code>test-sts-pod-10.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nginx</span> <span class="comment"># 服务的名称为 nginx</span>  <span class="attr">namespace:</span> <span class="string">nfs-storageclass</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># 给服务打一个标签</span><span class="attr">spec:</span>  <span class="attr">ports:</span> <span class="comment"># 指定服务暴露的端口</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># 服务监听在 80 端口，外部请求通过该端口访问</span>  <span class="attr">clusterIP:</span> <span class="string">None</span> <span class="comment"># 设置为 None，表示这是一个 Headless Service。Headless Service 不会分配集群 IP，而是直接通过 DNS 解析到后端的 Pod。</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># 服务通过标签选择器 app: nginx 找到匹配的 Pod，将流量路由到这些 Pod。</span><span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">StatefulSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">web</span> <span class="comment"># StatefulSet 名称为 web，用于管理一组 Pod。</span>  <span class="attr">namespace:</span> <span class="string">nfs-storageclass</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 通过标签 app: nginx 选择要管理的 Pod，确保 StatefulSet 只控制带有该标签的 Pod。</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">serviceName:</span> <span class="string">nginx</span> <span class="comment"># 指定关联的 Service 的名称为 nginx， StatefulSet 使用此 Service 来为每个 Pod 提供稳定的 DNS 名称（例如 web-0.nginx.default.svc.cluster.local）</span>  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># 创建 3 个 Pod 副本，分别命名为 web-0、web-1 和 web-2</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span> <span class="comment"># 为 Pod 添加标签 app: nginx，与 Service 的选择器匹配。</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>              <span class="attr">name:</span> <span class="string">web</span>          <span class="attr">volumeMounts:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">www</span> <span class="comment"># 挂载的卷名称为 www</span>              <span class="attr">mountPath:</span> <span class="string">/usr/local/nginx/html</span>  <span class="attr">volumeClaimTemplates:</span>    <span class="bullet">-</span> <span class="attr">metadata:</span>        <span class="attr">name:</span> <span class="string">www</span> <span class="comment"># PVC 名称为 www，与 volumeMounts 中的名称对应</span>      <span class="attr">spec:</span>        <span class="attr">accessModes:</span>          <span class="bullet">-</span> <span class="string">ReadWriteOnce</span>        <span class="attr">storageClassName:</span> <span class="string">nfs-client</span> <span class="comment"># StorageClass(存储类) 的名称</span>        <span class="attr">resources:</span>          <span class="attr">requests:</span>            <span class="attr">storage:</span> <span class="string">1Gi</span></code></pre><p><strong>执行资源清单，测试Service</strong></p><pre><code class="highlight bash"><span class="comment"># 执行资源清单</span>$ kubectl apply -f test-sts-pod-10.yaml<span class="comment"># 查看 Service</span>$ kubectl get svc -o wide -n nfs-storageclassNAME    TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTORnginx   ClusterIP   None         &lt;none&gt;        80/TCP    30s   app=nginx<span class="comment"># 查看 StatefulSet 控制器</span>$ kubectl get sts -o wide -n nfs-storageclassNAME   READY   AGE   CONTAINERS   IMAGESweb    3/3     40s   nginx        wangyanglinux/myapp:v1.0<span class="comment"># 查看 Pod</span>$ kubectl get pods -o wide -n nfs-storageclassNAME                                      READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESnfs-client-provisioner-5896c4d9d4-8cqwm   1/1     Running   0          43m     172.16.58.193   k8s-node02   &lt;none&gt;           &lt;none&gt;nfs-client-provisioner-5896c4d9d4-8wnnm   1/1     Running   0          43m     172.16.85.205   k8s-node01   &lt;none&gt;           &lt;none&gt;nfs-client-provisioner-5896c4d9d4-nds6r   1/1     Running   0          43m     172.16.58.204   k8s-node02   &lt;none&gt;           &lt;none&gt;test-pod                                  1/1     Running   0          6m54s   172.16.58.249   k8s-node02   &lt;none&gt;           &lt;none&gt;web-0                                     1/1     Running   0          58s     172.16.85.204   k8s-node01   &lt;none&gt;           &lt;none&gt;web-1                                     1/1     Running   0          55s     172.16.58.245   k8s-node02   &lt;none&gt;           &lt;none&gt;web-2                                     1/1     Running   0          52s     172.16.85.209   k8s-node01   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 PV</span>$ kubectl get pv -o wide -n nfs-storageclassNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                         STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE     VOLUMEMODEpvc-3b195b57-522a-49c5-badc-32e07fd37f88   1Mi        RWX            Delete           Bound    nfs-storageclass/test-claim   nfs-client     &lt;<span class="built_in">unset</span>&gt;                          17m     Filesystempvc-42a8b9df-f53d-4cd4-92e4-47c46ea07e17   1Gi        RWO            Delete           Bound    nfs-storageclass/www-web-2    nfs-client     &lt;<span class="built_in">unset</span>&gt;                          69s     Filesystempvc-8a8cefe1-00f1-4639-a1d4-d72e616b084b   1Gi        RWO            Delete           Bound    nfs-storageclass/www-web-1    nfs-client     &lt;<span class="built_in">unset</span>&gt;                          72s     Filesystempvc-be68e955-0d6c-4f4b-8422-2158a89a833b   1Gi        RWO            Delete           Bound    nfs-storageclass/www-web-0    nfs-client     &lt;<span class="built_in">unset</span>&gt;                          75s     Filesystem<span class="comment"># 查看PVC</span>$ kubectl get pvc -o wide -n nfs-storageclassNAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE   VOLUMEMODEtest-claim   Bound    pvc-3b195b57-522a-49c5-badc-32e07fd37f88   1Mi        RWX            nfs-client     &lt;<span class="built_in">unset</span>&gt;                 18m   Filesystemwww-web-0    Bound    pvc-be68e955-0d6c-4f4b-8422-2158a89a833b   1Gi        RWO            nfs-client     &lt;<span class="built_in">unset</span>&gt;                 92s   Filesystemwww-web-1    Bound    pvc-8a8cefe1-00f1-4639-a1d4-d72e616b084b   1Gi        RWO            nfs-client     &lt;<span class="built_in">unset</span>&gt;                 89s   Filesystemwww-web-2    Bound    pvc-42a8b9df-f53d-4cd4-92e4-47c46ea07e17   1Gi        RWO            nfs-client     &lt;<span class="built_in">unset</span>&gt;                 86s   Filesystem<span class="comment"># 查看存储类</span>$ kubectl get storageclass -n nfs-storageclassNAME         PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGEnfs-client   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           <span class="literal">false</span>                  6h18m<span class="comment"># 查看PVC自动创建的目录</span>$ ll /root/data/nfs-storageclass/total 0drwxrwxrwx 2 root root 45 May 30 17:23 test-claimdrwxrwxrwx 2 root root 27 May 30 17:28 www-web-0drwxrwxrwx 2 root root 27 May 30 17:28 www-web-1drwxrwxrwx 2 root root 27 May 30 17:28 www-web-2<span class="comment"># 测试文件到PVC挂载目录</span>$ <span class="built_in">echo</span> <span class="string">&quot;hello test svc pod&quot;</span> &gt;&gt; /root/data/nfs-storageclass/www-web-0/index.html<span class="comment"># 访问Pod</span>$ curl 172.16.85.204hello <span class="built_in">test</span> svc pod<span class="comment"># 进入Pod测试</span>$ kubectl <span class="built_in">exec</span> -it web-0 -n nfs-storageclass -- /bin/bashweb-0:/<span class="comment"># curl web-0.nginx.nfs-storageclass.svc.cluster.local.</span>hello <span class="built_in">test</span> svc pod</code></pre><p><strong>参考链接</strong></p><blockquote><p><a href="https://www.cnblogs.com/timelesszhuang/p/k8s.html">https://www.cnblogs.com/timelesszhuang/p/k8s.html</a></p><p><a href="https://www.cnblogs.com/zhanglianghhh/p/13818190.html">https://www.cnblogs.com/zhanglianghhh/p/13818190.html</a></p><p><a href="https://www.cnblogs.com/zhanglianghhh/p/13743024.html">https://www.cnblogs.com/zhanglianghhh/p/13743024.html</a></p><p><a href="https://www.cnblogs.com/fengjian2016/p/13337686.html">https://www.cnblogs.com/fengjian2016/p/13337686.html</a></p><p><a href="https://www.cnblogs.com/zhanglianghhh/p/13844062.html">https://www.cnblogs.com/zhanglianghhh/p/13844062.html</a></p><p><a href="https://www.cnblogs.com/zhanglianghhh/p/13861817.html">https://www.cnblogs.com/zhanglianghhh/p/13861817.html</a></p><p><a href="https://blog.csdn.net/weixin_41947378/article/details/111509849">https://blog.csdn.net/weixin_41947378/article/details/111509849</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在K8S中，容器的生命周期可能很短，会被频繁地创建和销毁。那么容器在销毁时，保存在容器中的数据也会被清除。这种结果对用户来说，在某些情况下是不乐意看到的。为了持久化保存容器的数据，kubernetes 引入了 Volume 的概念。&lt;/p&gt;
&lt;p&gt;Volume 是 Pod </summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>006-Kubernetes Service</title>
    <link href="https://georgechan95.github.io/blog/970719d6.html"/>
    <id>https://georgechan95.github.io/blog/970719d6.html</id>
    <published>2025-04-28T14:10:00.000Z</published>
    <updated>2025-04-30T03:23:45.528Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、Service-工作原理"><a href="#一、Service-工作原理" class="headerlink" title="一、Service 工作原理"></a>一、Service 工作原理</h1><h2 id="1-Service-简介"><a href="#1-Service-简介" class="headerlink" title="1. Service 简介"></a>1. Service 简介</h2><p>在kubernetes中，pod 是应用程序的载体，我们可以通过 pod 的 ip 来访问应用程序，但是 pod 的 ip 地址不是固定的，这也就意味着不方便直接采用 pod 的 ip 对服务进行访问。</p><p>为了解决这个问题，kubernetes 提供了 Service 资源，Service 会对提供同一个服务的多个 pod 进行聚合，并且提供一个统一的入口地址。通过访问 Service 的入口地址就能访问到后面的pod服务。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/28/20250428-135851.png" alt="Service"></p><p>如下关系图：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/28/20250428-140138.png" alt="Service原理"></p><p>Service 在很多情况下只是一个概念，真正起作用的其实是 kube-proxy 服务进程，每个Node节点上都运行着一个 kube-proxy 服务进程。当创建 Service 的时候会通过 api-server 向 etcd 写入创建的 service 的信息，而 kube-proxy 会基于监听的机制发现这种 Service 的变动，然后<strong>它会将最新的Service信息转换成对应的访问规则</strong>。</p><p>当<strong>通过 API 创建&#x2F;修改 Service</strong> 对象时，<strong>EndpointsController</strong> 的 Informer 机制 Listen 到 Service 对象，然后根据 Service 的配置的选择器<strong>创建一个 Endpoints 对象</strong>，此对象将 Pod 的 IP、容器端口做记录并<strong>存储到 etcd</strong>，这样 Service 只要看一下自己名下的 Endpoints 就可以知道所对应 Pod 信息了。</p><p>当 Pod 发生变更（如新的 Pod 被调度、现有 Pod 的状态变为非 Running 或者 Pod 数量伸缩）时，<strong>API Server 会将这些变化以事件的形式通知给 EndpointsController</strong>。EndpointsController 随即根据最新的 Pod 状态和 Service 的 Label Selector 重新计算 Endpoints 对象的端点列表，并更新存储在 etcd 中的 Endpoints 资源对象。这样，<strong>Service 所关联的 Endpoints 就会动态地反映出当前所有符合 Selector 的 Running 状态 Pod 的 IP 地址和端口信息</strong>。</p><p><strong>针对 EndpointsController：</strong>是负责生成和维护所有 Endpoints 对象的控制器，<strong>监听 Service 和对应 Pod 的变化，更新对应 Service 的 Endpoints 对象</strong>。当用户创建 Service 后 EndpointsController 会监听 Pod 的状态，当 Pod 处于 Running 且准备就绪时，EndpointsController 会将 Pod IP 记录到 Endpoints 对象中，因此，Service 的容器发现是通过 Endpoints 来实现的。而 <strong>kube-proxy 会监听 Service 和 Endpoints 的更新，并调用其代理模块在主机上刷新路由转发规则</strong>。</p><p>另外，k8s 中的 <strong>Informer 是一个核心组件</strong>，专门用于监控 API 资源的变化，并在资源发生变化时通知相关的客户端。</p><h2 id="2-案例一：通过选择器自动将Sevice与Pod绑定"><a href="#2-案例一：通过选择器自动将Sevice与Pod绑定" class="headerlink" title="2. 案例一：通过选择器自动将Sevice与Pod绑定"></a>2. 案例一：通过选择器自动将Sevice与Pod绑定</h2><h3 id="2-1-部署Deployment"><a href="#2-1-部署Deployment" class="headerlink" title="2.1 部署Deployment"></a>2.1 部署Deployment</h3><p><code>001-deployment-demo-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">deployment-demo</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 选择所有标签为 app: nginx 的 Pod</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># 指定需要维持的Pod副本数量为3</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span> <span class="comment"># 配置Pod元数据模板，例如 labels</span>      <span class="attr">labels:</span> <span class="comment"># # 为 Pod 打上 app: nginx 标签（与 selector.matchLabels 匹配）</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">mirrorgooglecontainers/serve_hostname:v1.4</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9376</span> <span class="comment"># 指定容器的内部端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span></code></pre><p>serve_hostname 是 k8s 官方提供的 debug 镜像，一个返回 hostname 的 web server。</p><p><strong>部署Deployment</strong></p><pre><code class="highlight bash">kubectl apply -f 001-deployment-demo-01.yaml</code></pre><p><strong>查看Pod</strong></p><pre><code class="highlight bash"><span class="comment"># 查看Pod列表</span>$ kubectl get pods -o wideNAME                               READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESdeployment-demo-5f8599d578-4zb7l   1/1     Running   0          33s   172.16.58.247   k8s-node02   &lt;none&gt;           &lt;none&gt;deployment-demo-5f8599d578-nbtj9   1/1     Running   0          33s   172.16.85.250   k8s-node01   &lt;none&gt;           &lt;none&gt;deployment-demo-5f8599d578-zg8tr   1/1     Running   0          33s   172.16.58.218   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 访问Pod</span>$ curl 172.16.58.247:9376deployment-demo-5f8599d578-4zb7l$ curl 172.16.85.250:9376deployment-demo-5f8599d578-nbtj9$ curl 172.16.58.218:9376deployment-demo-5f8599d578-zg8tr</code></pre><p>Deployment 创建了 3 个 Pod 副本，通过 curl 访问，打印了对应的host名称。</p><h3 id="2-2-部署-Service"><a href="#2-2-部署-Service" class="headerlink" title="2.2 部署 Service"></a>2.2 部署 Service</h3><p><code>001-service-demo-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">service-demo</span><span class="attr">spec:</span>  <span class="attr">selector:</span> <span class="comment"># 选择具有标签 app: nginx 的 Pod绑定到Service</span>    <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx80</span> <span class="comment"># 给端口命名，方便后续引用</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴漏的端口</span>      <span class="attr">targetPort:</span> <span class="number">9376</span> <span class="comment"># 流量转发到后端Pod的端口</span></code></pre><p><strong>部署Service</strong></p><pre><code class="highlight bash">kubectl apply -f 001-service-demo-01.yaml</code></pre><p><strong>查看Service</strong></p><pre><code class="highlight bash">$ kubectl get svc -o wide -n defaultNAME           TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE     SELECTORkubernetes     ClusterIP   10.96.0.1     &lt;none&gt;        443/TCP   17m     &lt;none&gt;service-demo   ClusterIP   10.97.64.44   &lt;none&gt;        80/TCP    7m36s   app=nginx</code></pre><p>创建了名为：<code>service-demo</code> 的服务，ip为 10.97.64.44，对外暴露端口：80.<br> <em><code>kubernetes</code> 是默认的Service</em></p><p>这样就获得不变的 CLUSTER-IP 10.97.64.44 的 Service</p><p><strong>查看Service详情</strong></p><pre><code class="highlight bash">$ kubectl describe svc service-demoName:              service-demoNamespace:         defaultLabels:            &lt;none&gt;Annotations:       &lt;none&gt;Selector:          app=nginxType:              ClusterIPIP Family Policy:  SingleStackIP Families:       IPv4IP:                10.97.64.44IPs:               10.97.64.44Port:              nginx80  80/TCPTargetPort:        9376/TCPEndpoints:         172.16.58.218:9376,172.16.58.247:9376,172.16.85.250:9376Session Affinity:  NoneEvents:            &lt;none&gt;</code></pre><p>EndpointsController 自动为Service （service-demo）创建了 Endpoints，内容为：172.16.58.218:9376,172.16.58.247:9376,172.16.85.250:9376， 这正是上面创建Deployment生成的3个 Pod 副本的 ip 端口。</p><p><strong>查看Endpoints</strong></p><pre><code class="highlight bash">$ kubectl get endpointsNAME           ENDPOINTS                                                  AGEservice-demo   172.16.58.218:9376,172.16.58.247:9376,172.16.85.250:9376   18m</code></pre><p>在创建Service的同时，自动创建了与Service同名的Endpoints</p><p><strong>访问Service</strong></p><pre><code class="highlight bash">$ curl 10.97.64.44:80deployment-demo-5f8599d578-4zb7l$ curl 10.97.64.44:80deployment-demo-5f8599d578-zg8tr$ curl 10.97.64.44:80deployment-demo-5f8599d578-nbtj9</code></pre><p>结论：通过访问Service，自动以负载均衡的方式访问到了Service管理的一组Pod。</p><h2 id="3-案例二：手动创建-Endpoints-将Service与Pod关联"><a href="#3-案例二：手动创建-Endpoints-将Service与Pod关联" class="headerlink" title="3. 案例二：手动创建 Endpoints, 将Service与Pod关联"></a>3. 案例二：手动创建 Endpoints, 将Service与Pod关联</h2><p>上面的案例 Service 资源清单中 spec.selector.app&#x3D;nginx 的设置，自动匹配了满足条件的 Pod，自动创建了同名的 Endpoints，实现负载均衡的网络请求。如果Pod没有自动与Service匹配，应该如何手动创建Endpoints，将Service与Pod关联，实现负载均衡请求？下面的案例将会演示。</p><p><strong>清理案例一创建的Service、Deployment</strong></p><pre><code class="highlight bash">$ kubectl delete -f 001-deployment-demo-01.yaml$ kubectl delete -f 001-service-demo-01.yaml</code></pre><h3 id="3-1-部署-Deployment"><a href="#3-1-部署-Deployment" class="headerlink" title="3.1 部署 Deployment"></a>3.1 部署 Deployment</h3><p><code>001-deployment-demo-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">deployment-demo</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 选择所有标签为 app: nginx 的 Pod</span>      <span class="attr">app:</span> <span class="string">nginx</span>  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># 指定需要维持的Pod副本数量为3</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span> <span class="comment"># 配置Pod元数据模板，例如 labels</span>      <span class="attr">labels:</span> <span class="comment"># # 为 Pod 打上 app: nginx 标签（与 selector.matchLabels 匹配）</span>        <span class="attr">app:</span> <span class="string">nginx</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">mirrorgooglecontainers/serve_hostname:v1.4</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9376</span> <span class="comment"># 指定容器的内部端口</span>              <span class="attr">protocol:</span> <span class="string">TCP</span></code></pre><p><strong>部署Deployment</strong></p><pre><code class="highlight bash">kubectl apply -f 001-deployment-demo-01.yaml</code></pre><h3 id="3-2-部署-Service"><a href="#3-2-部署-Service" class="headerlink" title="3.2 部署 Service"></a>3.2 部署 Service</h3><p><code>001-service-demo-02.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">endpoints-demo</span><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx80</span> <span class="comment"># 给端口命名，方便后续引用</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service 对外暴漏的端口</span>      <span class="attr">targetPort:</span> <span class="number">9376</span> <span class="comment"># 流量转发到后端Pod的端口</span></code></pre><p>注意：Service 的资源清单中没有定义标签选择器：<code>spec.selector.app: nginx</code> , 也就表明创建的这个 endpoints-demo Service 不会自动关联 Pod。</p><p><strong>部署Service</strong></p><pre><code class="highlight bash">$ kubectl apply -f 001-service-demo-02.yaml</code></pre><p><strong>查看Service</strong></p><pre><code class="highlight bash">$ kubectl get svc -o wideNAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTORendpoints-demo   ClusterIP   10.98.152.19   &lt;none&gt;        80/TCP    41s   &lt;none&gt;</code></pre><p><strong>查看Service详情</strong></p><pre><code class="highlight bash">$ kubectl describe svc endpoints-demoName:              endpoints-demoNamespace:         defaultLabels:            &lt;none&gt;Annotations:       &lt;none&gt;Selector:          &lt;none&gt;Type:              ClusterIPIP Family Policy:  SingleStackIP Families:       IPv4IP:                10.98.152.19IPs:               10.98.152.19Port:              nginx80  80/TCPTargetPort:        9376/TCPEndpoints:         &lt;none&gt;Session Affinity:  NoneEvents:            &lt;none&gt;</code></pre><p>创建了名为：endpoints-demo 的 Service，没有自动创建 Endpoints, 无法通过访问 Service 来负载均衡的访问Pod</p><p><strong>访问Service</strong></p><pre><code class="highlight bash">$ curl 10.98.152.19:80curl: (7) Failed to connect to 10.98.152.19 port 80: Connection refused</code></pre><p>由于 Service 没有关联的 Endpoints，无法通过访问 Service 从而访问Pod</p><h3 id="3-3-部署-Endpoints"><a href="#3-3-部署-Endpoints" class="headerlink" title="3.3 部署 Endpoints"></a>3.3 部署 Endpoints</h3><p><code>001-endpoints-demo-02.yaml</code></p><pre><code class="highlight bash">apiVersion: v1kind: Endpointsmetadata:  name: endpoints-demo <span class="comment"># endpoints 名称必须与 Service名称完全一致，k8s 才会将 endpoints与service关联起来</span>subsets: <span class="comment"># 定义 Endpoints 的子集，每个子集对应一个后端服务实例</span>  - addresses: <span class="comment"># 列出后端服务实例的 IP 地址列表，通过 kubectl get pods -o wide -l app=nginx 查看</span>      - ip: 172.16.58.246      - ip: 172.16.58.216      - ip: 172.16.85.246    ports: <span class="comment"># 定义后端服务实例监听的端口列表</span>      - port: 9376        name: nginx80 <span class="comment"># 端口名称，必须要与Service中的port名称一致</span></code></pre><p><strong>部署Endpoints</strong></p><pre><code class="highlight bash">$ kubectl apply -f 001-endpoints-demo-02.yaml</code></pre><p><strong>查看Endpoints</strong></p><pre><code class="highlight bash">$ kubectl get endpointsNAME             ENDPOINTS                                                  AGEendpoints-demo   172.16.58.246:9376,172.16.58.216:9376,172.16.85.246:9376   32s</code></pre><p>创建名称为 endpoints-demo 的 endpoints，并管理了 3 个Pod的ip和端口</p><p><strong>再次查看Service endpoints-demo 详情</strong></p><pre><code class="highlight bash">$ kubectl describe svc endpoints-demoName:              endpoints-demoNamespace:         defaultLabels:            &lt;none&gt;Annotations:       &lt;none&gt;Selector:          &lt;none&gt;Type:              ClusterIPIP Family Policy:  SingleStackIP Families:       IPv4IP:                10.98.152.19IPs:               10.98.152.19Port:              nginx80  80/TCPTargetPort:        9376/TCPEndpoints:         172.16.58.246:9376,172.16.58.216:9376,172.16.85.246:9376Session Affinity:  NoneEvents:            &lt;none&gt;</code></pre><p>此时Service的 Endpoints 不再为空</p><p><strong>访问 Service</strong></p><pre><code class="highlight bash">$ curl 10.98.152.19:80deployment-demo-5f8599d578-g6v2g$ curl 10.98.152.19:80deployment-demo-5f8599d578-wl4jk$ curl 10.98.152.19:80deployment-demo-5f8599d578-zxlfv</code></pre><p>结论：通过手动创建Endpoints, 也可以将Service与Pod关联起来，实现了通过Service负载均衡访问Pod。</p><h1 id="二、Service-的负载均衡"><a href="#二、Service-的负载均衡" class="headerlink" title="二、Service 的负载均衡"></a>二、Service 的负载均衡</h1><p>上面已经提到 Service 实际的路由转发都是由 kube-proxy 组件来实现的，service 仅以一种 VIP（ClusterIP） 的形式存在，kube-proxy 主要实现了集群内部从 Pod 到 Service 和集群外部从 nodePort 到 Service 的访问，kube-proxy 的路由转发规则是通过其后端的代理模块实现的。</p><p>kube-proxy 的代理模块目前有四种实现方案，<strong>userspace（不常用）、iptables（默认）、ipvs（使用于大规模集群）、kernelspace（适用于 Windows 环境）</strong>，其发展历程如下所示：</p><ul><li>kubernetes v1.0：services 仅是一个“4层”代理，代理模块只有 userspace</li><li>kubernetes v1.1：Ingress API 出现，其代理“7层”服务，并且增加了 iptables 代理模块</li><li>kubernetes v1.2：iptables 成为默认代理模式</li><li>kubernetes v1.8：引入 ipvs 代理模块</li><li>kubernetes v1.9：ipvs 代理模块成为 beta 版本</li><li>kubernetes v1.11：ipvs 代理模式 GA</li></ul><p>在 Kubernetes v1.0 版本，代理完全在 userspace。在 Kubernetes v1.1 版本，新增了 iptables 代理，但并不是默认的运行模式。 从 Kubernetes v1.2 起，默认就是 iptables 代理。 在 Kubernetes v1.8.0-beta.0 中，添加了 ipvs 代理。在每种模式下都有自己的负载均衡策略，下文会详解介绍。</p><h2 id="1-userspace-模式（不常用）"><a href="#1-userspace-模式（不常用）" class="headerlink" title="1. userspace 模式（不常用）"></a>1. userspace 模式（不常用）</h2><p>userspace模式下，kube-proxy会为每一个Service创建一个监听端口，发向Cluster IP的请求被Iptables规则重定向到kube-proxy监听的端口上，kube-proxy根据LB算法选择一个提供服务的Pod并和其建立链接，以将请求转发到Pod上。 该模式下，kube-proxy充当了一个四层负责均衡器的角色。由于kube-proxy运行在userspace中，在进行转发处理时会增加内核和用户空间之间的数据拷贝，虽然比较稳定，但是效率比较低。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/28/20250428-161817.png" alt="userspace 模式"></p><h2 id="2-iptables-模式（默认方式）"><a href="#2-iptables-模式（默认方式）" class="headerlink" title="2. iptables 模式（默认方式）"></a>2. iptables 模式（默认方式）</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/28/20250428-170312.png" alt="iptables 模式"></p><p>iptables 模式是<strong>目前默认的代理方式</strong>，基于 netfilter 实现。当客户端请求 Service 的 ClusterIP 时，根据 iptables 规则路由到各 Pod 上，iptables 使用 DNAT 来完成转发，其采用了随机数实现负载均衡。</p><pre><code class="highlight plaintext">Netfilter 是 Linux 内核中的一个框架，用于在网络层处理数据包。它提供了一种机制，允许用户空间程序通过一系列的钩子（hooks）来监控和修改网络流量。这些钩子可以插入到数据包的生命周期的各个阶段，例如在进入、离开或经过网络堆栈时。DNAT（Destination Network Address Translation）模块：是一种网络功能，用于将到达集群内部服务的流量重定向到正确的目标IP地址和端口。DNAT通常与负载均衡器一起使用，以便在多个后端服务之间分发流量。</code></pre><p>iptables 模式与 userspace 模式最大的区别在于，<strong>iptables 模块使用 DNAT 模块实现了 Service 入口地址到 Pod 实际地址的转换</strong>，免去了一次内核态到用户态的切换；另一个与 userspace 代理模式不同的是，如果 iptables 代理最初选择的那个 Pod 没有响应，它不会自动重试其他 Pod 。</p><p>iptables 模式最主要的问题是在 Service 数量大的时候会产生太多的 iptables 规则，使用非增量式更新会引入一定的时延，大规模情况下有明显的性能问题。</p><h2 id="3-ipvs-模式（适用于大规模集群）"><a href="#3-ipvs-模式（适用于大规模集群）" class="headerlink" title="3. ipvs 模式（适用于大规模集群）"></a>3. ipvs 模式（适用于大规模集群）</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/28/20250428-170403.png" alt="ipvs 模式"></p><p>当集群规模比较大时，iptables 规则刷新会非常慢，难以支持大规模集群，因其底层路由表的实现是链表，对路由规则的增删改查都要涉及遍历一次链表，ipvs 的问世正是解决此问题的。</p><p>ipvs 是 LVS 的负载均衡模块，与 iptables 比较像的是，ipvs 的实现虽然也基于 netfilter 的钩子函数，但是它却使用<strong>哈希表</strong>作为底层的数据结构并且<strong>工作在内核态</strong>，也就是说 <strong>ipvs 在重定向流量和同步代理规则有着更好的性能，几乎允许无限的规模扩张</strong>。</p><p>ipvs 支持三种负载均衡模式：DR 模式（Direct Routing）、NAT 模式（Network Address Translation）、Tunneling（也称 ipip 模式）。三种模式中只有 NAT 支持端口映射，所以 <strong>ipvs 使用 NAT 模式</strong>。</p><p>linux 内核原生的 ipvs 只支持 DNAT，当在数据包过滤，SNAT 和支持 NodePort 类型的服务这几个场景中 ipvs 还是会使用 iptables。</p><p>此外，ipvs 也支持更多的负载均衡算法，例如：</p><ul><li>rr：round-robin&#x2F;轮询</li><li>lc：least connection&#x2F;最少连接</li><li>dh：destination hashing&#x2F;目标哈希</li><li>sh：source hashing&#x2F;源哈希</li><li>sed：shortest expected delay&#x2F;预计延迟时间最短</li><li>nq：never queue&#x2F;从不排队</li></ul><p>userspace、iptables、ipvs 三种模式中，<strong>默认的策略都是 round-robin</strong>。</p><p>在 Service 中可以通过设置 Service .spec.sessionAffinity 的值实现基于客户端 ip 的会话亲和性，其默认值为”None”，可以设置为 “ClientIP”。此外也可以使用 Service .spec.sessionAffinityConfig.clientIP.timeoutSeconds 设置会话保持时间。</p><p>另外，<strong>kernelspace 模式</strong> 主要是在 windows 下使用的，本文略过。</p><h2 id="4-修改-kube-proxy-模式"><a href="#4-修改-kube-proxy-模式" class="headerlink" title="4. 修改 kube-proxy 模式"></a>4. 修改 kube-proxy 模式</h2><p>kube-proxy 默认为 iptables 模式，修改为 ipvs 模式</p><pre><code class="highlight bash"><span class="comment"># 修改集群 configmap</span>$ kubectl edit configmap kube-proxy -n kube-system<span class="comment"># 将mode修改为 ipvs</span>mode: <span class="string">&quot;ipvs&quot;</span><span class="comment"># 保存后重建 kube-proxy</span>$ kubectl delete pod -n kube-system -l k8s-app=kube-proxy<span class="comment"># 验证 1、安装 ipvsadm 工具</span>sudo yum install ipvsadm -y<span class="comment"># 验证 2、 查看dns解析插件pod所属的service的ip</span>ipvsadm -Ln</code></pre><h1 id="三、Service-的类型"><a href="#三、Service-的类型" class="headerlink" title="三、Service 的类型"></a>三、Service 的类型</h1><p>service 支持的类型也就是 k8s 中服务暴露的方式，默认有四种 ClusterIP、NodePort、LoadBalancer、ExternelName</p><ul><li>ClusterIp：默认类型，自动分配一个仅 Cluster 内部可以访问的虚拟 IP</li><li>NodePort：在 ClusterIP 基础上为 Service 在每台机器上绑定一个端口，这样就可以通过 <NodeIP>: NodePort 来访问该服务</li><li>LoadBalancer：在 NodePort 的基础上，借助 cloud provider 创建一个外部负载均衡器，并将请求转发到<NodeIP>: NodePort</li><li>ExternalName：把集群外部的服务引入到集群内部来，在集群内部直接使用。没有任何类型代理被创建，这只有 kubernetes 1.7 或更高版本的 kube-dns 才支持</li></ul><h2 id="1-ClusterIp-集群内访问"><a href="#1-ClusterIp-集群内访问" class="headerlink" title="1. ClusterIp 集群内访问"></a>1. ClusterIp 集群内访问</h2><p>ClusterIP 类型的 Service 是 kubernetes 集群<strong>默认的服务暴露方式</strong>，它<strong>只能用于集群内部通信</strong>，可以被各 Pod 访问，其访问方式为：</p><pre><code class="highlight bash">pod ---&gt; ClusterIP:ServicePort --&gt; (iptables)DNAT --&gt; PodIP:containePort</code></pre><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/28/20250428-192512.png" alt="ClusterIp"></p><h3 id="1-1-案例实操1：部署-Service"><a href="#1-1-案例实操1：部署-Service" class="headerlink" title="1.1 案例实操1：部署 Service"></a>1.1 案例实操1：部署 Service</h3><p>Service资源清单：<code>002-clusterip-service-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">myapp-clusterip-service</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">clusterIP:</span> <span class="number">10.96</span><span class="number">.120</span><span class="number">.10</span> <span class="comment"># 手动指定Service的Ip地址，不指定默认自动生成</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span> <span class="comment"># Service类型，默认为 ClusterIp，集群内部访问</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx-pod</span>    <span class="attr">release:</span> <span class="string">stable</span>    <span class="attr">svc:</span> <span class="string">clusterip</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service对外暴露的端口</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># 转发到Pod的端口</span></code></pre><p>类型为 ClusterIP 的 Service 有一个 Cluster-IP，其实就一个 VIP。具体实现原理依靠 kube-proxy 组件，通过 iptables 或是 ipvs 实现。</p><p>在创建 Service 的请求中，你可以通过设置 spec.clusterIP 字段来指定自己的集群 IP 地址。 如果在 Service 中将 .spec.clusterIP 设置为 “None”，则 Kubernetes 不会为其分配 IP 地址。</p><p>所配置的 IP 地址必须是合法的 IPv4 或者 IPv6 地址，并且这个 IP 地址在 API 服务器上所配置的 service-cluster-ip-range CIDR 范围内。配置了非法 clusterIP 地址的 Service，API 服务器会返回 HTTP 状态码 422，表示值不合法。</p><pre><code class="highlight bash"><span class="comment"># 查看 service-cluster-ip-range CIDR 范围内</span><span class="comment"># 方式一</span>ps -ef | grep kube-apiserver | grep service-cluster-ip-range<span class="comment"># 方式二</span>$ <span class="built_in">cat</span> /etc/kubernetes/manifests/kube-apiserver.yaml | grep cluster-ip-range    - --service-cluster-ip-range=10.96.0.0/12</code></pre><ul><li><strong><code>10.96.0.0/12</code></strong> 就是 Service 的 CIDR 范围（涵盖 <code>10.96.0.1</code> 到 <code>10.111.255.254</code>）。</li></ul><p><strong>部署 Service</strong></p><pre><code class="highlight bash"><span class="comment"># 部署 Service</span>$ kubectl apply -f 002-clusterip-service-01.yaml<span class="comment"># 查看 Service 列表</span>$ kubectl get svc -o wide NAME                      TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE     SELECTORkubernetes                ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP   5h36m   &lt;none&gt;myapp-clusterip-service   ClusterIP   10.96.120.10   &lt;none&gt;        80/TCP    106s    app=nginx-pod,release=stable,svc=clusterip</code></pre><h3 id="1-2-案例实操1：部署-Deployment"><a href="#1-2-案例实操1：部署-Deployment" class="headerlink" title="1.2 案例实操1：部署 Deployment"></a>1.2 案例实操1：部署 Deployment</h3><p>Deployment 资源清单：<code>002-clusterip-deployment-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">myapp-deployment-demo</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">3</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 标签选择器，管理具有包含以下标签的Pod</span>      <span class="attr">app:</span> <span class="string">nginx-pod</span>      <span class="attr">release:</span> <span class="string">stable</span>      <span class="attr">svc:</span> <span class="string">clusterip</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span> <span class="comment"># Pod模板定义标签，需完全包含 spec.selector.matchLabels 定义的标签</span>        <span class="attr">app:</span> <span class="string">nginx-pod</span>        <span class="attr">release:</span> <span class="string">stable</span>        <span class="attr">svc:</span> <span class="string">clusterip</span>        <span class="attr">env:</span> <span class="string">test</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span>          <span class="attr">readinessProbe:</span> <span class="comment"># 定义就绪探测</span>            <span class="attr">httpGet:</span>              <span class="attr">port:</span> <span class="number">80</span>              <span class="attr">path:</span> <span class="string">/index.html</span>            <span class="attr">initialDelaySeconds:</span> <span class="number">1</span>            <span class="attr">periodSeconds:</span> <span class="number">3</span></code></pre><p><em><strong>注意：</strong></em> <em>deployment 资源清单中定义了 readinessProbe 就绪监测，Service 管理 Pod 的前提是 Pod 启动成功，并且已就绪状态，如果就绪监测不通过，就无法通过 Service 访问 Pod.</em> </p><p><strong>部署 Deployment</strong></p><pre><code class="highlight bash"><span class="comment"># 部署 Deployment</span>$ kubectl apply -f 002-clusterip-deployment-01.yaml</code></pre><p><strong>查看资源</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 pod</span>$ kubectl get pods -o wide -l app=nginx-podNAME                                    READY   STATUS    RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATESmyapp-deployment-demo-d8d46cbc4-4qgs8   1/1     Running   0          118s   172.16.58.245   k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-deployment-demo-d8d46cbc4-5th77   1/1     Running   0          118s   172.16.85.249   k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-deployment-demo-d8d46cbc4-cp75p   1/1     Running   0          119s   172.16.58.250   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 service详情（此时Service关联了Endpoints）</span>$ kubectl describe svc myapp-clusterip-serviceName:              myapp-clusterip-serviceNamespace:         defaultLabels:            &lt;none&gt;Annotations:       &lt;none&gt;Selector:          app=nginx-pod,release=stable,svc=clusteripType:              ClusterIPIP Family Policy:  SingleStackIP Families:       IPv4IP:                10.96.120.10IPs:               10.96.120.10Port:              http  80/TCPTargetPort:        80/TCPEndpoints:         172.16.58.245:80,172.16.58.250:80,172.16.85.249:80Session Affinity:  NoneEvents:            &lt;none&gt;<span class="comment"># 查看ipvs（查看dns解析插件pod所属的service的ip）</span>$ ipvsadm -LnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn      TCP  10.96.120.10:80 rr  -&gt; 172.16.58.245:80             Masq    1      0          0           -&gt; 172.16.58.250:80             Masq    1      0          0           -&gt; 172.16.85.249:80             Masq    1      0          0</code></pre><p>ipvs自动创建了路由规则，通过 Service 的 IP 和端口（10.96.120.10:80）使用 rr 策略(round-robin&#x2F;轮询) 访问3个 Pod </p><p><strong>测试Service</strong></p><pre><code class="highlight bash">$ curl http://10.96.120.10:80/hostname.htmlmyapp-deployment-demo-d8d46cbc4-cp75p$ curl http://10.96.120.10:80/hostname.htmlmyapp-deployment-demo-d8d46cbc4-4qgs8$ curl http://10.96.120.10:80/hostname.htmlmyapp-deployment-demo-d8d46cbc4-5th77</code></pre><p>通过Service实现了轮询访问Pod</p><h3 id="1-3-IPVS-持久化连接"><a href="#1-3-IPVS-持久化连接" class="headerlink" title="1.3 IPVS 持久化连接"></a>1.3 IPVS 持久化连接</h3><p>ClusterIP 默认情况下会基于 RR 策略轮询访问 Pod，如果需要同一客户端的请求始终转发到同一个 Pod，则需要给Service开启持久化链接。</p><h4 id="1-3-1-核心作用"><a href="#1-3-1-核心作用" class="headerlink" title="1.3.1 核心作用"></a>1.3.1 核心作用</h4><ul><li><strong>会话保持</strong>：将同一客户端的连续请求固定转发到同一个 Pod。</li><li><strong>适用场景</strong>：<ul><li>需要维护会话状态的应用（如用户登录、购物车）。</li><li>依赖本地缓存或内存数据的服务（如 Redis、数据库连接池）。</li></ul></li></ul><h4 id="1-3-2-工作原理"><a href="#1-3-2-工作原理" class="headerlink" title="1.3.2 工作原理"></a>1.3.2 工作原理</h4><table><thead><tr><th align="left">机制</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left"><strong>哈希算法</strong></td><td align="left">对客户端 <strong>源 IP + 源端口</strong> 计算哈希值，映射到后端 Pod。</td></tr><tr><td align="left"><strong>超时控制</strong></td><td align="left">默认会话保持 <strong>3 小时</strong>（可通过 <code>sessionAffinityConfig</code> 调整）。</td></tr><tr><td align="left"><strong>负载均衡</strong></td><td align="left">仅在首次请求时计算哈希，后续请求直接复用结果。</td></tr></tbody></table><p><strong>配置示例</strong></p><pre><code class="highlight yaml"><span class="attr">spec.sessionAffinity:</span> <span class="string">ClientIP</span><span class="comment"># 完整资源清单配置 002-clusterip-service-02.yaml</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-service</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">my-app</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">9376</span>  <span class="attr">sessionAffinity:</span> <span class="string">ClientIP</span>  <span class="comment"># 启用会话保持</span>  <span class="comment"># 可选：调整会话超时时间（默认10800秒=3小时）</span>  <span class="attr">sessionAffinityConfig:</span>    <span class="attr">clientIP:</span>      <span class="attr">timeoutSeconds:</span> <span class="number">3600</span>  <span class="comment"># 改为1小时</span></code></pre><p><strong>部署 Service</strong></p><pre><code class="highlight bash">$ kubectl apply -f 002-clusterip-service-02.yaml</code></pre><p><strong>测试持久化链接配置</strong></p><pre><code class="highlight bash">$ curl http://10.96.120.10:80/hostname.htmlmyapp-deployment-demo-d8d46cbc4-5th77$ curl http://10.96.120.10:80/hostname.htmlmyapp-deployment-demo-d8d46cbc4-5th77$ curl http://10.96.120.10:80/hostname.htmlmyapp-deployment-demo-d8d46cbc4-5th77</code></pre><p>客户端在指定时间段内每次请求，都会落到同一个Pod上</p><h3 id="1-4-internalTrafficPolicy"><a href="#1-4-internalTrafficPolicy" class="headerlink" title="1.4 internalTrafficPolicy"></a>1.4 internalTrafficPolicy</h3><p><code>internalTrafficPolicy</code> 是 Kubernetes Service 的一个关键配置项，用于<strong>控制集群内部流量（Pod-to-Service 通信）的路由策略</strong>。它主要解决跨节点访问导致的额外网络跳转和延迟问题，尤其在需要优化网络性能或保证本地性时非常有用。</p><p><strong>可选值及行为</strong></p><table><thead><tr><th align="left">值</th><th align="left">作用</th><th align="left">适用场景</th></tr></thead><tbody><tr><td align="left"><strong><code>Cluster</code></strong> (默认)</td><td align="left">流量随机转发到所有匹配的 Pod（可能跨节点）</td><td align="left">通用场景，无需特殊优化</td></tr><tr><td align="left"><strong><code>Local</code></strong></td><td align="left">流量仅转发到<strong>当前节点</strong>上运行的 Pod</td><td align="left">需要低延迟、避免跨节点流量</td></tr></tbody></table><p><strong>核心功能</strong></p><ul><li><p>Local 模式的优势</p><ul><li><p><strong>减少网络跳转</strong>：避免流量绕行到其他节点，降低延迟。</p></li><li><p><strong>保留客户端 IP</strong>：真实客户端 IP 可直接传递给 Pod（无需 SNAT）。</p></li><li><p><strong>适配本地缓存</strong>：适合需要利用 Pod 本地缓存的应用（如内存缓存）。</p></li></ul></li><li><p>Cluster  模式的特点</p><ul><li><strong>默认行为</strong>：流量均匀分布到所有 Pod（无论是否在相同节点）。</li><li><strong>可能增加延迟</strong>：如果 Pod 分布在其他节点，需额外网络跳转。</li></ul></li></ul><p><strong>工作原理</strong></p><ul><li><p><code>Local</code> 模式下的流量路由</p><ul><li><p><strong>请求到达 Service</strong>：客户端 Pod 访问 Service 的 ClusterIP。</p></li><li><p><strong>kube-proxy 过滤</strong>：仅选择<strong>当前节点</strong>上运行的 Pod 作为后端。</p></li><li><p><strong>直接转发</strong>：流量不离开节点，直接发给本地 Pod。</p></li></ul></li><li><p><code>Cluster</code> 模式下的流量路由</p><ul><li><strong>请求到达 Service</strong>：客户端 Pod 访问 Service 的 ClusterIP。</li><li><strong>kube-proxy 轮询</strong>：选择所有匹配的 Pod（可能跨节点）。</li><li><strong>可能跨节点转发</strong>：流量可能被发送到其他节点上的 Pod。</li></ul></li></ul><p><strong>配置示例</strong></p><pre><code class="highlight yaml"><span class="attr">spec.internalTrafficPolicy:</span> <span class="string">Local</span><span class="comment"># 完整资源清单配置 002-clusterip-service-03.yaml</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">myapp-clusterip-service</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">clusterIP:</span> <span class="number">10.96</span><span class="number">.120</span><span class="number">.10</span> <span class="comment"># 手动指定Service的Ip地址，不指定默认自动生成</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span> <span class="comment"># Service类型，默认为 ClusterIp，集群内部访问</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx-pod</span>    <span class="attr">release:</span> <span class="string">stable</span>    <span class="attr">svc:</span> <span class="string">clusterip</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service对外暴露的端口</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># 转发到Pod的端口</span>  <span class="attr">internalTrafficPolicy:</span> <span class="string">Local</span> <span class="comment"># 流量仅转发到**当前节点**上运行的 Pod， 默认为：Cluster</span></code></pre><p>**验证 internalTrafficPolicy **</p><pre><code class="highlight bash"><span class="comment"># 部署 Service</span>$ kubectl apply -f 002-clusterip-service-03.yaml<span class="comment"># 查看 Pods（可以看到Node1节点只有一个Pod，Node2节点有两个）</span>$ kubectl get pods -o wideNAME                                    READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESmyapp-deployment-demo-d8d46cbc4-4qgs8   1/1     Running   0          44m   172.16.58.245   k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-deployment-demo-d8d46cbc4-5th77   1/1     Running   0          44m   172.16.85.249   k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-deployment-demo-d8d46cbc4-cp75p   1/1     Running   0          44m   172.16.58.250   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 在Master节点访问Service（连接失败，因为设置了本地访问策略，而master节点没有Pod）</span>$ curl 10.96.120.10:80/hostname.htmlcurl: (7) Failed to connect to 10.96.120.10 port 80: Connection refused<span class="comment"># 在node1节点访问Service（每次都只访问到Node1节点的Pod）</span>$ curl 10.96.120.10:80/hostname.htmlmyapp-deployment-demo-d8d46cbc4-5th77$ curl 10.96.120.10:80/hostname.htmlmyapp-deployment-demo-d8d46cbc4-5th77$ curl 10.96.120.10:80/hostname.htmlmyapp-deployment-demo-d8d46cbc4-5th77</code></pre><h2 id="2-NodePort-集群外访问"><a href="#2-NodePort-集群外访问" class="headerlink" title="2. NodePort 集群外访问"></a>2. NodePort 集群外访问</h2><p>若要在集群外访问集群内部的服务，可以使用这种类型的 Service 。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/28/20250428-211712.png" alt="NodePort结构"></p><p>NodePort 类型的 Service 会在集群内部署了 kube-proxy 的物理节点，打开一个指定的物理端口，之后所有的流量直接发送到这个端口，然后会被转发到 Service 后端真实的服务进行访问。</p><p>Nodeport 构建在 ClusterIP 上，其访问链路如下所示：</p><pre><code class="highlight bash">client ---&gt; NodeIP(物理节点IP):NodePort ---&gt; ClusterIP:ServicePort ---&gt; (iptables)DNAT ---&gt; PodIP:containePort</code></pre><h3 id="2-1-案例实操：部署Service"><a href="#2-1-案例实操：部署Service" class="headerlink" title="2.1 案例实操：部署Service"></a>2.1 案例实操：部署Service</h3><p>资源清单：<code>003-nodeport-service-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nodeport-service-demo</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">type:</span> <span class="string">nodeport</span><span class="attr">spec:</span>  <span class="attr">type:</span> <span class="string">NodePort</span>  <span class="attr">clusterIP:</span> <span class="number">10.100</span><span class="number">.1</span><span class="number">.1</span> <span class="comment"># 手动指定Service的Ip地址，不指定默认自动生成</span>  <span class="attr">selector:</span> <span class="comment"># 标签选择器，只管理包含下面标签的Pod</span>    <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">release:</span> <span class="string">stabel</span>    <span class="attr">svc:</span> <span class="string">nodeport</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># service对外暴露的端口</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># 转发到容器内部的端口</span>      <span class="attr">nodePort:</span> <span class="number">30008</span> <span class="comment"># 手动指定NodePort端口，默认范围：30000-32767 ，不指定则默认分配一个端口</span></code></pre><p><strong>部署Service</strong></p><pre><code class="highlight bash"><span class="comment"># 部署Service</span>$ kubectl apply -f 003-nodeport-service-01.yaml<span class="comment"># 查看 Service 列表</span>$ kubectl get svc -o wide --show-labels -l <span class="built_in">type</span>=nodeportNAME                    TYPE       CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE    SELECTOR                                LABELSnodeport-service-demo   NodePort   10.100.1.1   &lt;none&gt;        80:30008/TCP   4m8s   app=myapp,release=stabel,svc=nodeport   <span class="built_in">type</span>=nodeport</code></pre><h3 id="2-2-案例实操：部署Deployment"><a href="#2-2-案例实操：部署Deployment" class="headerlink" title="2.2 案例实操：部署Deployment"></a>2.2 案例实操：部署Deployment</h3><p>资源清单：<code>003-nodeport-deployment-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">myapp-deployment-demo</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">3</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># Deployment控制器匹配管理具有下面标签的Pod</span>      <span class="attr">app:</span> <span class="string">myapp</span>      <span class="attr">release:</span> <span class="string">stabel</span>      <span class="attr">svc:</span> <span class="string">nodeport</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span> <span class="comment"># 定义Pod模板元数据，Pod具有如下标签</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>        <span class="attr">release:</span> <span class="string">stabel</span>        <span class="attr">svc:</span> <span class="string">nodeport</span>        <span class="attr">env:</span> <span class="string">test</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span></code></pre><p><strong>部署Deployment</strong></p><pre><code class="highlight bash"><span class="comment"># 部署Deployment</span>$ kubectl apply -f 003-nodeport-deployment-01.yaml<span class="comment"># 查看Pod</span>$ kubectl get pods -o wide -l app=myapp -n defaultNAME                                     READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESmyapp-deployment-demo-685dcc6ddf-j2vp5   1/1     Running   0          4m10s   172.16.85.255   k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-deployment-demo-685dcc6ddf-p4xrf   1/1     Running   0          4m10s   172.16.58.208   k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-deployment-demo-685dcc6ddf-tmkr9   1/1     Running   0          4m10s   172.16.58.243   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p><strong>测试NodePort</strong></p><p>此时 Service 设置的Ip是：10.100.1.1，对外暴露端口：80</p><pre><code class="highlight bash"><span class="comment"># 1.测试通过Service IP端口负载均衡的访问Pod</span>$ curl 10.100.1.1:80/hostname.htmlmyapp-deployment-demo-685dcc6ddf-p4xrf$ curl 10.100.1.1:80/hostname.htmlmyapp-deployment-demo-685dcc6ddf-j2vp5$ curl 10.100.1.1:80/hostname.htmlmyapp-deployment-demo-685dcc6ddf-tmkr9<span class="comment"># 2.测试通过物理节点IP和设置的NodePort端口，负载均衡的访问Pod</span><span class="comment">### 2.1 在Master节点测试</span>$ curl 192.168.6.139:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-p4xrf$ curl 192.168.6.139:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-j2vp5$ curl 192.168.6.139:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-tmkr9<span class="comment">### 2.2 在node节点测试</span>$ curl 192.168.6.140:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-tmkr9$ curl 192.168.6.140:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-p4xrf$ curl 192.168.6.140:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-j2vp5</code></pre><p>此时就可以通过服务器物理节点和物理端口访问Pod了， <strong>注意：手动指定NodePort要避免端口冲突</strong></p><p>该端口有一定的范围，比如默认 k8s 控制平面将在 <code>--service-node-port-range</code> 标志指定的范围内分配端口（<strong>默认值：30000-32767</strong>）。</p><p>为 NodePort 服务分配端口的策略<strong>既适用于自动分配</strong>的情况，<strong>也适用于手动分配</strong>的场景。当某个用于希望创建一个使用特定端口的 NodePort 服务时，该目标端口可能与另一个已经被分配的端口冲突。为了避免这个问题，用于 NodePort 服务的端口范围被分为两段。<strong>动态端口分配默认使用较高的端口段，并且在较高的端口段耗尽时也可以使用较低的端口段。用户可以从较低端口段中分配端口，降低端口冲突的风险。</strong></p><h3 id="2-3-externalTrafficPolicy"><a href="#2-3-externalTrafficPolicy" class="headerlink" title="2.3 externalTrafficPolicy"></a>2.3 externalTrafficPolicy</h3><p><code>externalTrafficPolicy</code> 是 Kubernetes Service 的一个关键配置项，用于控制外部流量如何路由到 Pod，特别是对于 <code>LoadBalancer</code> 和 <code>NodePort</code> 类型的服务。它的与前面提到的 <code>internalTrafficPolicy</code> 很相似，只是 <code>internalTrafficPolicy</code> 控制的是内部的流量转发策略。</p><p><strong>两种模式：</strong></p><ul><li><p>Cluster (默认值)</p><pre><code class="highlight yaml"><span class="attr">externalTrafficPolicy:</span> <span class="string">Cluster</span></code></pre><p><strong>特点</strong>：</p><ul><li>流量可以路由到集群中任何节点上的 Pod（即使 Pod 不在该节点上）</li><li>会做 SNAT（源网络地址转换），客户端 IP 会被隐藏</li><li>提供更好的负载均衡，因为流量可以分布到所有节点</li><li>可能导致额外的网络跳转（跨节点流量）</li></ul><p><strong>适用场景</strong>：</p><ul><li>需要均匀分布流量时</li><li>不关心保留客户端源 IP 时</li><li>集群内节点间网络性能良好时</li></ul></li><li><p>Local</p><pre><code class="highlight yaml"><span class="attr">externalTrafficPolicy:</span> <span class="string">Local</span></code></pre><p><strong>特点</strong>：</p><ul><li>流量只会路由到接收流量的节点上运行的 Pod</li><li>保留原始客户端 IP 地址（不做 SNAT）</li><li>如果节点上没有 Pod，连接会挂起（不会转发到其他节点）</li><li>需要配合 Pod 反亲和性确保 Pod 分布均匀</li></ul><p><strong>适用场景</strong>：</p><ul><li>需要保留客户端源 IP 时</li><li>希望避免跨节点流量时</li><li>配合节点本地缓存等场景</li></ul></li></ul><p><strong>测试 externalTrafficPolicy</strong></p><p>资源清单 <code>003-nodeport-service-02.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">nodeport-service-demo</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">type:</span> <span class="string">nodeport</span><span class="attr">spec:</span>  <span class="attr">type:</span> <span class="string">NodePort</span>  <span class="attr">clusterIP:</span> <span class="number">10.100</span><span class="number">.1</span><span class="number">.1</span> <span class="comment"># 手动指定Service的Ip地址，不指定默认自动生成</span>  <span class="attr">externalTrafficPolicy:</span> <span class="string">Local</span> <span class="comment"># 流量只会路由到接收流量的节点上运行的 Pod</span>  <span class="attr">selector:</span> <span class="comment"># 标签选择器，只管理包含下面标签的Pod</span>    <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">release:</span> <span class="string">stabel</span>    <span class="attr">svc:</span> <span class="string">nodeport</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># service对外暴露的端口</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># 转发到容器内部的端口</span>      <span class="attr">nodePort:</span> <span class="number">30008</span> <span class="comment"># 手动指定NodePort端口，默认范围：30000-32767 ，不指定则默认分配一个端口</span></code></pre><p><strong>部署 Service</strong></p><pre><code class="highlight bash">$ kubectl apply -f 003-nodeport-service-02.yaml<span class="comment"># 查看Pod部署节点</span>$ kubectl get pods -o wide -l app=myappNAME                                     READY   STATUS    RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATESmyapp-deployment-demo-685dcc6ddf-j2vp5   1/1     Running   0          173m   172.16.85.255   k8s-node01   &lt;none&gt;           &lt;none&gt;myapp-deployment-demo-685dcc6ddf-p4xrf   1/1     Running   0          173m   172.16.58.208   k8s-node02   &lt;none&gt;           &lt;none&gt;myapp-deployment-demo-685dcc6ddf-tmkr9   1/1     Running   0          173m   172.16.58.243   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 在node1节点访问Service</span>$ curl 192.168.6.140:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-j2vp5$ curl 192.168.6.140:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-j2vp5$ curl 192.168.6.140:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-j2vp5<span class="comment"># 在master节点访问Service</span>$ curl 192.168.6.139:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-j2vp5$ curl 192.168.6.139:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-tmkr9$ curl 192.168.6.139:30008/hostname.htmlmyapp-deployment-demo-685dcc6ddf-p4xrf</code></pre><p>设置 <code>externalTrafficPolicy: Local</code> ，当通过master节点访问service时，依然是负载均衡访问Pod，当通过Pod所在节点访问Service时，请求只会落到请求节点运行的Pod上。</p><h2 id="3-LoadBalancer-负载均衡"><a href="#3-LoadBalancer-负载均衡" class="headerlink" title="3. LoadBalancer 负载均衡"></a>3. LoadBalancer 负载均衡</h2><p>参考：<a href="https://help.aliyun.com/zh/ack/ack-managed-and-ack-dedicated/user-guide/use-an-existing-slb-instance-to-expose-an-application">https://help.aliyun.com/zh/ack/ack-managed-and-ack-dedicated/user-guide/use-an-existing-slb-instance-to-expose-an-application</a></p><p>LoadBalancer 和 NodePort 很相似，目的都是向外部暴露一个端口，区别在于 LoadBalancer 会在集群的外部再来做一个负载均衡设备，而这个设备需要外部环境支持的，外部服务发送到这个设备上的请求，会被设备负载之后转发到集群中。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/29/20250429-143020.png" alt="LoadBalancerLoadBalancer"></p><h3 id="3-1-LoadBalancer-Service-的工作原理"><a href="#3-1-LoadBalancer-Service-的工作原理" class="headerlink" title="3.1 LoadBalancer Service 的工作原理"></a>3.1 LoadBalancer Service 的工作原理</h3><ul><li><strong>LoadBalancer Service</strong> 会创建一个外部负载均衡器（由云提供商管理），并为服务分配一个外部 IP 地址。</li><li>外部客户端通过该 IP 访问服务，负载均衡器将流量分发到后端的 Pod。</li><li>它基于 <strong>ClusterIP</strong> 和 <strong>NodePort</strong>，但额外提供外部访问能力。</li><li>适用于需要在公网或云环境中暴露服务的场景。</li></ul><h3 id="3-2-创建-LoadBalancer-Service"><a href="#3-2-创建-LoadBalancer-Service" class="headerlink" title="3.2 创建 LoadBalancer Service"></a>3.2 创建 LoadBalancer Service</h3><p>资源清单：<code>004-loadBalancer-service-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loadbalancer-service</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">my-service</span><span class="attr">spec:</span>  <span class="attr">type:</span> <span class="string">LoadBalancer</span> <span class="comment"># 指定Service类型为 LoadBalancer</span>  <span class="attr">clusterIP:</span> <span class="number">10.100</span><span class="number">.1</span><span class="number">.1</span> <span class="comment"># 手动指定Service的Ip地址，不指定默认自动生成</span>  <span class="attr">selector:</span> <span class="comment"># 标签选择器，只管理包含下面标签的Pod</span>    <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># service对外暴露的端口</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># 转发到容器内部的端口</span>      <span class="attr">nodePort:</span> <span class="number">30010</span> <span class="comment"># 手动指定NodePort端口，默认范围：30000-32767 ，不指定则默认分配一个端口</span></code></pre><p><strong>关键字段说明</strong>：</p><ul><li><strong>metadata.name</strong>: 服务的名称。</li><li><strong>spec.selector</strong>: 选择后端 Pod 的标签（如 app: my-app）。</li><li>spec.ports: 定义服务监听的端口。<ul><li>port: 服务暴露的端口（外部访问的端口）。</li><li>targetPort: 后端 Pod 的容器端口。</li></ul></li><li><strong>spec.type</strong>: 设置为 LoadBalancer。</li></ul><p><strong>部署Service</strong></p><pre><code class="highlight bash">$ kubectl apply -f 004-loadBalancer-service-01.yaml</code></pre><h3 id="3-3-验证-LoadBalancer-Service"><a href="#3-3-验证-LoadBalancer-Service" class="headerlink" title="3.3 验证 LoadBalancer Service"></a>3.3 验证 LoadBalancer Service</h3><pre><code class="highlight bash">$ kubectl get svc -o wide -w -l app=my-serviceNAME                   TYPE           CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE   SELECTORloadbalancer-service   LoadBalancer   10.100.1.1   &lt;pending&gt;     80:30010/TCP   28s   app=myapp</code></pre><p>EXTERNAL-IP 是负载均衡器的外部 IP（可能需要几分钟分配）。显示 <pending>，说明负载均衡器仍在创建。</p><p><strong>访问服务</strong>：</p><ul><li>使用 EXTERNAL-IP（如 <a href="http://203.0.113.10)通过浏览器或/">http://203.0.113.10）通过浏览器或</a> curl 访问。</li><li>如果外部 IP 未分配，检查云提供商的负载均衡器配置或权限。</li></ul><p><strong>查看负载均衡器详情</strong>： </p><p>在云提供商的控制台（如 AWS、GCP、Azure）中，检查负载均衡器的状态和配置。</p><h3 id="3-4-高级配置"><a href="#3-4-高级配置" class="headerlink" title="3.4 高级配置"></a>3.4 高级配置</h3><h4 id="3-4-1-指定外部-IP（可选）"><a href="#3-4-1-指定外部-IP（可选）" class="headerlink" title="3.4 1 指定外部 IP（可选）"></a>3.4 1 指定外部 IP（可选）</h4><p>某些云提供商允许指定静态 IP：</p><pre><code class="highlight bash">spec:  loadBalancerIP: 203.0.113.100</code></pre><h4 id="3-4-2-自定义负载均衡器行为"><a href="#3-4-2-自定义负载均衡器行为" class="headerlink" title="3.4.2 自定义负载均衡器行为"></a>3.4.2 自定义负载均衡器行为</h4><p>使用 <strong>Annotations</strong> 配置特定云提供商的功能，例如：</p><ul><li><p>AWS ELB 的健康检查：</p><pre><code class="highlight yaml"><span class="attr">metadata:</span>  <span class="attr">annotations:</span>    <span class="attr">service.beta.kubernetes.io/aws-load-balancer-healthcheck-path:</span> <span class="string">/health</span></code></pre></li><li><p>GCP 启用 HTTPS：</p><pre><code class="highlight yaml"><span class="attr">metadata:</span>  <span class="attr">annotations:</span>    <span class="attr">cloud.google.com/neg:</span> <span class="string">&quot;true&quot;</span></code></pre><p>查看云提供商的文档以获取支持的 Annotations。</p></li></ul><h4 id="3-4-3-限制源-IP（白名单）"><a href="#3-4-3-限制源-IP（白名单）" class="headerlink" title="3.4.3 限制源 IP（白名单）"></a>3.4.3 限制源 IP（白名单）</h4><p>限制访问的源 IP 范围：</p><pre><code class="highlight yaml"><span class="attr">spec:</span>  <span class="attr">loadBalancerSourceRanges:</span>    <span class="bullet">-</span> <span class="string">&quot;203.0.113.0/24&quot;</span></code></pre><h4 id="3-4-4-多端口服务"><a href="#3-4-4-多端口服务" class="headerlink" title="3.4.4 多端口服务"></a>3.4.4 多端口服务</h4><p>支持多个端口：</p><pre><code class="highlight yaml"><span class="attr">spec:</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">targetPort:</span> <span class="number">8080</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">port:</span> <span class="number">443</span>      <span class="attr">targetPort:</span> <span class="number">8443</span></code></pre><h3 id="3-5-使用场景"><a href="#3-5-使用场景" class="headerlink" title="3.5 使用场景"></a>3.5 使用场景</h3><ul><li><strong>Web 应用</strong>：暴露 HTTP&#x2F;HTTPS 服务。</li><li><strong>API 网关</strong>：提供统一的外部访问入口。</li><li><strong>微服务架构</strong>：将特定服务暴露给外部客户端。</li></ul><h3 id="3-6-注意事项"><a href="#3-6-注意事项" class="headerlink" title="3.6 注意事项"></a>3.6 注意事项</h3><ol><li>云提供商依赖：<ul><li>LoadBalancer Service 依赖云提供商的负载均衡器支持。如果在本地集群（如 Minikube）运行，可能需要使用 MetalLB 等工具模拟。</li></ul></li><li>成本：<ul><li>云提供商的负载均衡器通常会产生费用，注意监控使用情况。</li></ul></li><li>延迟：<ul><li>负载均衡器创建可能需要几分钟，EXTERNAL-IP 可能暂时显示为 <pending>。</li></ul></li><li>安全性：<ul><li>默认情况下，LoadBalancer 暴露到公网，建议配置 loadBalancerSourceRanges 或使用防火墙规则限制访问。</li></ul></li><li>Ingress 替代：<ul><li>如果需要更复杂的路由规则（基于域名或路径），考虑使用 <strong>Ingress</strong> 资源结合 Ingress Controller（如 Nginx、Traefik）。</li></ul></li></ol><h3 id="3-7-示例：部署一个简单的应用"><a href="#3-7-示例：部署一个简单的应用" class="headerlink" title="3.7 示例：部署一个简单的应用"></a>3.7 示例：部署一个简单的应用</h3><p>资源清单：<code>004-loadBalancer-deployment-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">loadbalancer-deployment</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">3</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span>          <span class="attr">image:</span> <span class="string">nginx:latest</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></code></pre><p><strong>验证</strong></p><ul><li><p>部署完成后，获取 EXTERNAL-IP 并访问：</p><pre><code class="highlight bash">curl http://&lt;EXTERNAL-IP&gt;</code></pre><p>应该返回 Nginx 的欢迎页面。</p></li></ul><h2 id="4-ExternalName-指定外部访问域名"><a href="#4-ExternalName-指定外部访问域名" class="headerlink" title="4. ExternalName 指定外部访问域名"></a>4. ExternalName 指定外部访问域名</h2><p>ExternalName Service 是 Service 的特例，它没有 selector，也没有定义任何的端口和 Endpoint。相反的，对于运行在集群外部的服务，它通过返回该外部服务的别名这种方式来提供服务。用于将外部服务（即集群外部的资源）映射到 Kubernetes 集群内部的 DNS 名称，而无需在集群内创建实际的代理或负载均衡器。它主要通过 DNS 解析将请求直接重定向到外部端点。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/29/20250429-171928.png" alt="ExternalName"></p><h3 id="4-1-主要特点"><a href="#4-1-主要特点" class="headerlink" title="4.1 主要特点"></a>4.1 主要特点</h3><ol><li><strong>无代理转发</strong>：与 ClusterIP、NodePort 或 LoadBalancer 类型的服务不同，ExternalName 不创建集群内的代理，而是通过 DNS CNAME 记录直接指向外部域名。</li><li><strong>简化外部服务访问</strong>：集群内的 Pod 可以通过 Kubernetes DNS 名称访问外部服务，而无需直接使用外部服务的完整域名。</li><li><strong>无 IP 分配</strong>：ExternalName 服务不会分配 ClusterIP 或其他内部 IP，仅依赖 DNS 解析。</li></ol><h3 id="4-2-使用场景"><a href="#4-2-使用场景" class="headerlink" title="4.2 使用场景"></a>4.2 使用场景</h3><ul><li><strong>访问外部 API 或服务</strong>：例如，集群内的应用需要调用外部的数据库、云服务（如 AWS S3）或第三方 API。</li><li><strong>服务迁移</strong>：在迁移服务时，可以通过 ExternalName 指向外部服务，逐步过渡而无需修改应用代码。</li><li><strong>多集群或混合云环境</strong>：在跨集群或混合云环境中，通过 ExternalName 统一访问外部资源。</li></ul><h3 id="4-3-配置示例"><a href="#4-3-配置示例" class="headerlink" title="4.3 配置示例"></a>4.3 配置示例</h3><p>资源清单：<code>005-externalName-Service-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">externalname-service</span><span class="attr">spec:</span>  <span class="attr">type:</span> <span class="string">ExternalName</span> <span class="comment"># 指定Service类型</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span>      <span class="attr">protocol:</span> <span class="string">TCP</span>      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="attr">externalName:</span> <span class="string">www.baidu.com</span></code></pre><ul><li><strong>metadata.name</strong>：集群内用于访问服务的名称，例如 externalname-service.default.svc.cluster.local 。</li><li><strong>spec.type</strong>：指定服务类型为 ExternalName。</li><li><strong>spec.externalName</strong>：外部服务的实际域名，例如 <a href="http://www.baidu.com./">www.baidu.com。</a></li></ul><h3 id="4-4-测试-Pod-访问-External-Service"><a href="#4-4-测试-Pod-访问-External-Service" class="headerlink" title="4.4 测试 Pod 访问 External Service"></a>4.4 测试 Pod 访问 External Service</h3><p><strong>在 Pod 中测试 DNS 解析</strong>： 创建一个测试 Pod 并检查 DNS 解析：</p><p>Pod资源清单：<code>005-externalName-Depolyment-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">myapp-deployment-demo</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># Deployment控制器匹配管理具有下面标签的Pod</span>      <span class="attr">app:</span> <span class="string">myapp</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span> <span class="comment"># 定义Pod模板元数据，Pod具有如下标签</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-busybox</span>          <span class="attr">image:</span> <span class="string">busybox:latest</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="comment"># 启动Pod后探测域名：externalname-service.default.svc.cluster.local，探测到域名后停止运行Pod</span>          <span class="attr">args:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup externalname-service.default.svc.cluster.local; do echo waiting for externalname-service; sleep 2; done;&#x27;</span>]</code></pre><p><strong>部署Pod</strong></p><pre><code class="highlight bash"><span class="comment"># 部署Pod</span>$ kubectl apply -f 005-externalName-Depolyment-01.yaml<span class="comment"># 查看Pod</span>$ kubectl get podsNAME                                     READY   STATUS    RESTARTS   AGEmyapp-deployment-demo-78f57f7d7b-c6rkn   1/1     Running   0          10s<span class="comment"># 查看Pod日志</span>$ kubectl logs myapp-deployment-demo-78f57f7d7b-c6rkn -fServer:10.96.0.10Address:10.96.0.10:53externalname-service.default.svc.cluster.localcanonical name = www.baidu.comwww.baidu.comcanonical name = www.a.shifen.comName:www.a.shifen.comAddress: 183.2.172.177Name:www.a.shifen.comAddress: 183.2.172.17externalname-service.default.svc.cluster.localcanonical name = www.baidu.comwww.baidu.comcanonical name = www.a.shifen.comName:www.a.shifen.comAddress: 240e:ff:e020:99b:0:ff:b099:cff1Name:www.a.shifen.comAddress: 240e:ff:e020:98c:0:ff:b061:c306</code></pre><p>Pod通过 External Service 的域名 <code>externalname-service.default.svc.cluster.local</code> 成功解析到 <a href="http://www.baidu.com/">www.baidu.com</a> 这个外部域名</p><h3 id="4-5-工作原理"><a href="#4-5-工作原理" class="headerlink" title="4.5 工作原理"></a>4.5 工作原理</h3><ol><li>当 Pod 访问 externalname-service.default.svc.cluster.local 时，Kubernetes 的 DNS 解析器返回一个 CNAME 记录，指向 <a href="http://www.baidu.com./">www.baidu.com。</a></li><li>请求直接发送到外部服务，Kubernetes 不进行任何代理或流量转发。</li></ol><h3 id="4-6-注意事项"><a href="#4-6-注意事项" class="headerlink" title="4.6 注意事项"></a>4.6 注意事项</h3><ul><li><strong>无端口映射</strong>：ExternalName 服务不定义端口，因为它仅处理 DNS 级别重定向。如果需要特定端口，需在外部服务端配置。</li><li><strong>依赖外部服务可用性</strong>：如果外部域名不可用，服务访问会失败，Kubernetes 不会提供额外的容错机制。</li><li><strong>不支持复杂路由</strong>：ExternalName 不适合需要负载均衡或高级路由的场景，建议使用其他服务类型或 Ingress。</li></ul><h3 id="4-7-局限性"><a href="#4-7-局限性" class="headerlink" title="4.7 局限性"></a>4.7 局限性</h3><ul><li>不支持在 ExternalName 服务上定义 selector 或 ports，因为它不关联任何 Pod 或代理。</li><li>如果需要更复杂的外部服务集成（例如负载均衡或健康检查），可以考虑使用 Endpoints 或 Ingress 资源。</li></ul><h1 id="四、Endpoints-Service-的底层模型"><a href="#四、Endpoints-Service-的底层模型" class="headerlink" title="四、Endpoints-Service 的底层模型"></a>四、Endpoints-Service 的底层模型</h1><p>在 Kubernetes 中，Endpoint是一个关键的核心对象，它承担着连接Service和后端Pod的重要角色。Endpoint提供了对服务后端的抽象，允许用户在集群中动态地管理服务的网络终端。</p><h2 id="1-什么是-Endpoint？"><a href="#1-什么是-Endpoint？" class="headerlink" title="1. 什么是 Endpoint？"></a>1. 什么是 Endpoint？</h2><p>Endpoint代表了Service后端的一组<a href="https://so.csdn.net/so/search?q=IP%E5%9C%B0%E5%9D%80&spm=1001.2101.3001.7020">IP地址</a>和端口号，用于将流量从Service引导到实际运行应用程序的Pod。每个Service都关联着一个对应的Endpoint，这个Endpoint动态地维护了所有Service所选择的Pod的网络终端信息。</p><p>简而言之，Endpoint是Service的一种实现，是Service背后真实运行的Pod的地址和端口的集合。通过Endpoint，K8s可以实现服务的动态发现和负载均衡</p><h2 id="2-Endpoint-的结构"><a href="#2-Endpoint-的结构" class="headerlink" title="2. Endpoint 的结构"></a>2. Endpoint 的结构</h2><p>Endpoint主要由以下几个部分组成：</p><ul><li><strong>IP地址：</strong> 指定Pod的IP地址，用于标识网络上的唯一位置。</li><li><strong>端口号：</strong> 指定Pod中运行应用程序的端口，用于标识应用程序的通信端口。</li></ul><p>一个Endpoint可以包含多个IP地址和端口号的组合，这取决于与Service相关联的Pod的数量。Endpoint的结构使得它能够适应不同Service的需求，实现对多个Pod的动态管理。</p><h2 id="3-Endpoint-与-Service-的关系"><a href="#3-Endpoint-与-Service-的关系" class="headerlink" title="3. Endpoint 与 Service 的关系"></a>3. Endpoint 与 Service 的关系</h2><p>在K8s中，每个 Service 都有一个相应的 Endpoint 。当 Service 被创建时，K8s会自动创建对应的 Endpoint，并将 Service 选择的 Pod 的 IP 地址和端口号添加到Endpoint 中。这种关系保证了 Service 与 Pod 之间的正确通信。</p><p>在 Service 和 Endpoint 之间的关系中，S ervice 充当了一种抽象，为应用程序提供了一个稳定的入口点，而 Endpoint 则提供了 Service 后端的真实网络终端。这种分离使得用户能够更加灵活地管理和维护后端 Pod 的变化，而不需要改变 Service 的定义。</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/29/20250429-181021.png" alt="Endpoint 与 Service 和 Pod 间的关联"></p><h2 id="4-Endpoint-的使用"><a href="#4-Endpoint-的使用" class="headerlink" title="4. Endpoint 的使用"></a>4. Endpoint 的使用</h2><h3 id="4-1-自动创建-Endpoints"><a href="#4-1-自动创建-Endpoints" class="headerlink" title="4.1 自动创建 Endpoints"></a>4.1 自动创建 Endpoints</h3><p>见本文第一章节：Service 工作原理 –&gt; 案例一：通过选择器自动将 Service与 Pod 绑定</p><h3 id="4-2-手动创建-Endpoints"><a href="#4-2-手动创建-Endpoints" class="headerlink" title="4.2 手动创建 Endpoints"></a>4.2 手动创建 Endpoints</h3><p>见本文第一章节：Service 工作原理 –&gt; 案例二：手动创建 Endpoints, 将 Service 与 Pod 关联</p><h2 id="5-动态管理Endpoint"><a href="#5-动态管理Endpoint" class="headerlink" title="5. 动态管理Endpoint"></a>5. 动态管理Endpoint</h2><p>在K8s中，Endpoint的管理是动态的。当Service的相关Pod发生变化时，Endpoint会相应地更新。例如，当我们扩展了前端Pod的数量时，Endpoint会自动添加新的IP地址和端口号。</p><p><strong>资源清单：</strong><code>006-endpoints-01.yaml</code></p><pre><code class="highlight bash">apiVersion: apps/v1kind: Deploymentmetadata:  namespace: default  name: deployment-demospec:  selector:    matchLabels: <span class="comment"># 选择所有标签为 app: nginx 的 Pod</span>      app: nginx  replicas: 3 <span class="comment"># 指定需要维持的Pod副本数量为3</span>  template:    metadata: <span class="comment"># 配置Pod元数据模板，例如 labels</span>      labels: <span class="comment"># # 为 Pod 打上 app: nginx 标签（与 selector.matchLabels 匹配）</span>        app: nginx    spec:      containers:        - name: nginx          image: mirrorgooglecontainers/serve_hostname:v1.4          imagePullPolicy: IfNotPresent          ports:            - containerPort: 9376 <span class="comment"># 指定容器的内部端口</span>              protocol: TCP---apiVersion: v1kind: Servicemetadata:  name: service-demospec:  selector: <span class="comment"># 选择具有标签 app: nginx 的 Pod绑定到Service</span>    app: nginx  ports:    - name: nginx80 <span class="comment"># 给端口命名，方便后续引用</span>      protocol: TCP      port: 80 <span class="comment"># Service 对外暴漏的端口</span>      targetPort: 9376 <span class="comment"># 流量转发到后端Pod的端口</span></code></pre><p><strong>部署资源清单</strong></p><pre><code class="highlight bash">$ kubectl apply -f 006-endpoints-01.yaml</code></pre><p><strong>查看 Service、Pod、Endpoints</strong></p><pre><code class="highlight bash"><span class="comment"># 查看Service</span>$ kubectl get svcNAME           TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGEservice-demo   ClusterIP   10.108.117.152   &lt;none&gt;        80/TCP    7s<span class="comment"># 查看Pod</span>$ kubectl get pods -o wideNAME                               READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESdeployment-demo-5f8599d578-2llvx   1/1     Running   0          92s   172.16.58.222   k8s-node02   &lt;none&gt;           &lt;none&gt;deployment-demo-5f8599d578-4wvhn   1/1     Running   0          92s   172.16.85.252   k8s-node01   &lt;none&gt;           &lt;none&gt;deployment-demo-5f8599d578-b72j2   1/1     Running   0          93s   172.16.58.196   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看Endpoints</span>$ kubectl get endpointsNAME           ENDPOINTS                                                  AGEservice-demo   172.16.58.196:9376,172.16.58.222:9376,172.16.85.252:9376   107s</code></pre><p><strong>扩展Pod数量实例</strong></p><pre><code class="highlight bash"><span class="comment"># Pod数量扩展到5个</span>$ kubectl scale deployment deployment-demo --replicas=5<span class="comment"># 查看Endpoints（管理的Pod也扩展到5个）</span>$ kubectl describe endpoints service-demoName:         service-demoNamespace:    defaultLabels:       &lt;none&gt;Annotations:  endpoints.kubernetes.io/last-change-trigger-time: 2025-04-29T11:59:57ZSubsets:  Addresses:          172.16.58.196,172.16.58.222,172.16.58.233,172.16.85.251,172.16.85.252  NotReadyAddresses:  &lt;none&gt;  Ports:    Name     Port  Protocol    ----     ----  --------    nginx80  9376  TCPEvents:  &lt;none&gt;</code></pre><p>扩展了 Pod 的数量，Endpoint 相应地添加了新的IP地址和端口号，确保了与 Service 相关联的所有 Pod 都能够被正确地服务。</p><h2 id="6-Endpoint-增删改查"><a href="#6-Endpoint-增删改查" class="headerlink" title="6. Endpoint 增删改查"></a>6. Endpoint 增删改查</h2><h3 id="6-1-创建-Endpoint"><a href="#6-1-创建-Endpoint" class="headerlink" title="6.1 创建 Endpoint"></a>6.1 创建 Endpoint</h3><h4 id="6-1-1-自动创建-Endpoint"><a href="#6-1-1-自动创建-Endpoint" class="headerlink" title="6.1.1 自动创建 Endpoint"></a>6.1.1 自动创建 Endpoint</h4><p>在 Kubernetes 中，Endpoint 的定义会随着 Service 的创建自动生成与 Service 同名的 Endpoints</p><pre><code class="highlight bash">apiVersion: v1kind: Servicemetadata:  name: service-demospec:  selector: <span class="comment"># 选择具有标签 app: nginx 的 Pod绑定到Service</span>    app: nginx  ports:    - name: nginx80 <span class="comment"># 给端口命名，方便后续引用</span>      protocol: TCP      port: 80 <span class="comment"># Service 对外暴漏的端口</span>      targetPort: 9376 <span class="comment"># 流量转发到后端Pod的端口</span></code></pre><h4 id="6-1-2-手动创建-Endpoint"><a href="#6-1-2-手动创建-Endpoint" class="headerlink" title="6.1.2 手动创建 Endpoint"></a>6.1.2 手动创建 Endpoint</h4><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Endpoints</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">endpoints-demo</span> <span class="comment"># endpoints 名称必须与 Service名称完全一致，k8s 才会将 endpoints与service关联起来</span><span class="attr">subsets:</span> <span class="comment"># 定义 Endpoints 的子集，每个子集对应一个后端服务实例</span>  <span class="bullet">-</span> <span class="attr">addresses:</span> <span class="comment"># 列出后端服务实例的 IP 地址列表，通过 kubectl get pods -o wide -l app=nginx 查看</span>      <span class="bullet">-</span> <span class="attr">ip:</span> <span class="number">172.16</span><span class="number">.58</span><span class="number">.246</span>      <span class="bullet">-</span> <span class="attr">ip:</span> <span class="number">172.16</span><span class="number">.58</span><span class="number">.216</span>      <span class="bullet">-</span> <span class="attr">ip:</span> <span class="number">172.16</span><span class="number">.85</span><span class="number">.246</span>    <span class="attr">ports:</span> <span class="comment"># 定义后端服务实例监听的端口列表</span>      <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">9376</span>        <span class="attr">name:</span> <span class="string">nginx80</span> <span class="comment"># 端口名称，必须要与Service中的port名称一致</span></code></pre><h3 id="6-2-Endpoint-更新"><a href="#6-2-Endpoint-更新" class="headerlink" title="6.2 Endpoint 更新"></a>6.2 Endpoint 更新</h3><p>在 Kubernetes 中，当 Endpoint 中的某些 Pod 不可用时，Kubernetes 会自动地从 Endpoint 中删除这些 Pod，并将 Endpoint 更新为不可用状态。新的 Endpoint 会在缺失 Pod 的同一端口上生成一个新的地址，并将服务转发到可用的 Pod。</p><p>为了避免 Endpoint 的数据丢失，Kubernetes 具有自动和手动两种更新 Endpoint 的方式。</p><h4 id="6-2-1-自动更新-Endpoint"><a href="#6-2-1-自动更新-Endpoint" class="headerlink" title="6.2.1 自动更新 Endpoint"></a>6.2.1 自动更新 Endpoint</h4><p>当 Pod 恢复正常时，Kubernetes 会自动更新 Endpoint 并将该 Pod 重新添加到 Endpoint 中，从而使该 Service 再次可用。这种自动更新是 Kubernetes Endpoint 更改监控机制的一部分。</p><h4 id="6-2-2-手动更新-Endpoint"><a href="#6-2-2-手动更新-Endpoint" class="headerlink" title="6.2.2 手动更新 Endpoint"></a>6.2.2 手动更新 Endpoint</h4><p>在某些情况下，特别是在进行操作系统多次启动后，Kubernetes 可能无法监视 Endpoint 中的所有更改。此时，可以手动更新 Endpoint。</p><p>我们可以使用以下命令手动更新 Endpoint：</p><pre><code class="highlight bash">$ kubectl get endpoints -n &lt;名称空间&gt; &lt;endpoint名称&gt; -o yaml | kubectl apply -f -<span class="comment"># 例如</span>$ kubectl get endpoints -n default service-demo -o yaml | kubectl apply -f -</code></pre><p>执行上面的命令，Kubernetes 将自动更新 Endpoint 并重新加载流量。</p><h3 id="6-3-Endpoint-的删除"><a href="#6-3-Endpoint-的删除" class="headerlink" title="6.3 Endpoint 的删除"></a>6.3 Endpoint 的删除</h3><p>Endpoint 可以通过以下命令进行删除：</p><pre><code class="highlight bash">$ kubectl delete endpoints &lt;endpoint名称&gt; -n &lt;名称空间&gt;</code></pre><p>执行上述命令后，Endpoint 会被删除，但 Service 仍然存在。如果需要同时删除 Service，请执行以下命令：</p><pre><code class="highlight bash">$ kubectl delete service &lt;Service名称&gt; -n &lt;名称空间&gt;</code></pre><h2 id="7-Endpoint-controlor"><a href="#7-Endpoint-controlor" class="headerlink" title="7. Endpoint controlor"></a>7. Endpoint controlor</h2><p>endpoint controlor 是 k8s 集群的其中一个组件，主要是维护 endpoint，保证 endpoint 内 ip:port 能够提供正常服务，其功能如下：</p><ul><li>endpoint controller 建立 service 与 pod 的 list-watch</li><li>轮询 service 队列，查询属于对应 service 的 pods</li><li>判断 pods 状态以及 port 情况，生成 endpoint 对象<ul><li>过滤掉状态为 not ready 的 pods</li><li>过滤掉不满足 <code>service.spec.targetPort</code> 的 pods</li><li>获取 pods 的 ip 以及 <code>service.spec.ports</code> ，生成 endpoint 对象</li></ul></li><li>比较该 endpoint 对象与当前 endpoint ，若当前 endpoint 不存在，则发送给 apiserver 创建请求，若与当前 endpoint 不一致，则发送给 apiserver 更新请求</li></ul><h2 id="8-Endpoint参数解释"><a href="#8-Endpoint参数解释" class="headerlink" title="8. Endpoint参数解释"></a>8. Endpoint参数解释</h2><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Endpoint</span><span class="attr">metadata:</span>  <span class="comment"># 对象元数据</span>  <span class="attr">name:</span>  <span class="attr">namespace:</span><span class="attr">subsets:</span>      <span class="comment"># 端点对象的列表</span><span class="bullet">-</span> <span class="attr">addresses:</span>  <span class="comment"># 处于“就绪”状态的端点地址对象列表</span>  <span class="bullet">-</span> <span class="string">hostname</span>  <span class="string">&lt;string&gt;</span>  <span class="comment"># 端点主机名</span>    <span class="string">ip</span> <span class="string">&lt;string&gt;</span>          <span class="comment"># 端点的IP地址，必选字段</span>    <span class="string">nodeName</span> <span class="string">&lt;string&gt;</span>   <span class="comment"># 节点主机名</span>    <span class="string">targetRef：</span>              <span class="comment"># 提供了该端点的对象引用</span>      <span class="string">apiVersion</span> <span class="string">&lt;string&gt;</span>  <span class="comment"># 被引用对象所属的API群组及版本</span>      <span class="string">kind</span> <span class="string">&lt;string&gt;</span>  <span class="comment"># 被引用对象的资源类型，多为Pod</span>      <span class="string">name</span> <span class="string">&lt;string&gt;</span>  <span class="comment"># 对象名称</span>      <span class="string">namespace</span> <span class="string">&lt;string&gt;</span>  <span class="comment"># 对象所属的名称空间</span>      <span class="string">fieldPath</span> <span class="string">&lt;string&gt;</span>  <span class="comment"># 被引用的对象的字段，在未引用整个对象时使用，常用于仅引用</span><span class="comment"># 指定Pod对象中的单容器，例如spec.containers[1]</span>      <span class="string">uid</span> <span class="string">&lt;string&gt;</span>     <span class="comment"># 对象的标识符；</span>  <span class="attr">notReadyAddresses:</span>  <span class="comment"># 处于“未就绪”状态的端点地址对象列表，格式与address相同</span>  <span class="attr">ports:</span>                <span class="comment"># 端口对象列表</span>  <span class="bullet">-</span> <span class="string">name</span> <span class="string">&lt;string&gt;</span>  <span class="comment"># 端口名称；</span>    <span class="string">port</span> <span class="string">&lt;integer&gt;</span>  <span class="comment"># 端口号，必选字段；</span>    <span class="string">protocol</span> <span class="string">&lt;string&gt;</span>     <span class="comment"># 协议类型，仅支持UDP、TCP和SCTP，默认为TCP；</span>    <span class="string">appProtocol</span> <span class="string">&lt;string&gt;</span>  <span class="comment"># 应用层协议；</span></code></pre><ul><li><code>endpoint.metadata.name</code> ： 代表着 service name</li><li><code>endpoint.subsets[].addresses[].ip</code> 代表 状态为 ready pod 的ip</li><li><code>endpoint.subsets[].targetRef</code>： 代表来自该 ip 的 pod 详情</li><li><code>endpoint. subsets[].ports[]</code>:  数据来源于 service.spec.ports ,当 pods 内的 port 并不满足 targetPort ，则会在 endpoint.subsets[].addresses[] 中剔除该pod ip</li><li><code>endpoint. subsets[].notReadyAddresses</code> :未就绪 pod 列表</li></ul><h1 id="五、Service-设置-publishNotReadyAddresses"><a href="#五、Service-设置-publishNotReadyAddresses" class="headerlink" title="五、Service 设置 publishNotReadyAddresses"></a>五、Service 设置 publishNotReadyAddresses</h1><p>在 Kubernetes 中，默认情况下 Service 只将通过了就绪探针的 Pod 的 IP 和端口添加到其 Endpoints 对象中。这确保客户端只访问到健康且可用的 Pod。如果需要将未通过就绪探测的 Pod 也添加到 Endpoints 对象中，可通过 Service 访问。那么就需要设置 Service 的 publishNotReadyAddresses 属性。</p><p>例如如下情况，Pod未能通过就绪探测，无法通过 Service 访问 Pod</p><h2 id="1-案例一：未设置-publishNotReadyAddresses"><a href="#1-案例一：未设置-publishNotReadyAddresses" class="headerlink" title="1. 案例一：未设置 publishNotReadyAddresses"></a>1. 案例一：未设置 publishNotReadyAddresses</h2><p><strong>资源清单：</strong> <code>007-publishNotReadyAddresses-01.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">myapp-deployment-demo</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 标签选择器，管理具有包含以下标签的Pod</span>      <span class="attr">app:</span> <span class="string">nginx-pod</span>      <span class="attr">release:</span> <span class="string">stable</span>      <span class="attr">svc:</span> <span class="string">clusterip</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span> <span class="comment"># Pod模板定义标签，需完全包含 spec.selector.matchLabels 定义的标签</span>        <span class="attr">app:</span> <span class="string">nginx-pod</span>        <span class="attr">release:</span> <span class="string">stable</span>        <span class="attr">svc:</span> <span class="string">clusterip</span>        <span class="attr">env:</span> <span class="string">test</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>              <span class="attr">containerPort:</span> <span class="number">80</span>          <span class="attr">readinessProbe:</span> <span class="comment"># 定义就绪探测</span>            <span class="attr">httpGet:</span>              <span class="attr">port:</span> <span class="number">80</span>              <span class="attr">path:</span> <span class="string">/index1.html</span>            <span class="attr">initialDelaySeconds:</span> <span class="number">1</span>            <span class="attr">periodSeconds:</span> <span class="number">3</span>            <span class="meta">---</span><span class="meta"></span><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Service</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">myapp-clusterip-service</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">clusterIP:</span> <span class="number">10.96</span><span class="number">.120</span><span class="number">.10</span> <span class="comment"># 手动指定Service的Ip地址，不指定默认自动生成</span>  <span class="attr">type:</span> <span class="string">ClusterIP</span> <span class="comment"># Service类型，默认为 ClusterIp，集群内部访问</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">nginx-pod</span>    <span class="attr">release:</span> <span class="string">stable</span>    <span class="attr">svc:</span> <span class="string">clusterip</span>  <span class="attr">ports:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># Service对外暴露的端口</span>      <span class="attr">targetPort:</span> <span class="number">80</span> <span class="comment"># 转发到Pod的端口</span></code></pre><p><strong>部署后查看Pod、Service、Endpoints</strong></p><pre><code class="highlight bash"><span class="comment"># 部署资源</span>$ kubectl apply -f 007-publishNotReadyAddresses-01.yaml<span class="comment"># 查看 Pod</span>$ kubectl get podsNAME                                     READY   STATUS    RESTARTS   AGEmyapp-deployment-demo-54c7c7df5f-z7j57   0/1     Running   0          9s<span class="comment"># 查看 Service</span>$ kubectl get svc myapp-clusterip-serviceNAME                      TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGEmyapp-clusterip-service   ClusterIP   10.96.120.10   &lt;none&gt;        80/TCP    2m27s<span class="comment"># 查看 Endpoints</span>$ kubectl get EndpointsNAME                      ENDPOINTS            AGEkubernetes                192.168.6.139:6443   30hmyapp-clusterip-service                        2m49s<span class="comment"># 访问 Service</span>$ curl 10.96.120.10curl: (7) Failed to connect to 10.96.120.10 port 80: Connection refused</code></pre><p>由于部署的Deployment 没有 &#x2F;index1.html 这个资源，导致 Pod 无法通过就绪探测。因此 Pod 不能添加到 Endpoints 中，Service无法访问 Pod.</p><h2 id="2-案例二：设置了-publishNotReadyAddresses"><a href="#2-案例二：设置了-publishNotReadyAddresses" class="headerlink" title="2. 案例二：设置了 publishNotReadyAddresses"></a>2. 案例二：设置了 publishNotReadyAddresses</h2><p>为了让未通过就绪探测的 Pod 也能添加 Endpoints中，暴露给 Service 访问，可以通过设置 <code>publishNotReadyAddresses</code> 实现。</p><p><strong>方式一：通过命令行动态设置</strong></p><pre><code class="highlight bash">$ kubectl patch service myapp-clusterip-service -p <span class="string">&#x27;&#123;&quot;spec&quot;:&#123;&quot;publishNotReadyAddresses&quot;: true&#125;&#125;&#x27;</span></code></pre><p><strong>方式二：配置资源清单文件</strong></p><p><code>007-publishNotReadyAddresses-02.yaml</code></p><pre><code class="highlight bash">apiVersion: apps/v1kind: Deploymentmetadata:  name: myapp-deployment-demo  namespace: defaultspec:  replicas: 1  selector:    matchLabels: <span class="comment"># 标签选择器，管理具有包含以下标签的Pod</span>      app: nginx-pod      release: stable      svc: clusterip  template:    metadata:      labels: <span class="comment"># Pod模板定义标签，需完全包含 spec.selector.matchLabels 定义的标签</span>        app: nginx-pod        release: stable        svc: clusterip        <span class="built_in">env</span>: <span class="built_in">test</span>    spec:      containers:        - name: myapp-container          image: wangyanglinux/myapp:v1.0          imagePullPolicy: IfNotPresent          ports:            - name: http              containerPort: 80          readinessProbe: <span class="comment"># 定义就绪探测</span>            httpGet:              port: 80              path: /index1.html            initialDelaySeconds: 1            periodSeconds: 3---apiVersion: v1kind: Servicemetadata:  name: myapp-clusterip-service  namespace: defaultspec:  clusterIP: 10.96.120.10 <span class="comment"># 手动指定Service的Ip地址，不指定默认自动生成</span>  <span class="built_in">type</span>: ClusterIP <span class="comment"># Service类型，默认为 ClusterIp，集群内部访问</span>  selector:    app: nginx-pod    release: stable    svc: clusterip  ports:    - name: http      port: 80 <span class="comment"># Service对外暴露的端口</span>      targetPort: 80 <span class="comment"># 转发到Pod的端口</span>  publishNotReadyAddresses: <span class="literal">true</span> <span class="comment"># 允许未就绪的 Pod 添加到 Endpoints 中</span></code></pre><p>添加了 <code>publishNotReadyAddresses: true</code> ， 允许未就绪的 Pod 添加到 Endpoints 中</p><p>重新部署资源清单</p><pre><code class="highlight bash">$ kubectl apply -f 007-publishNotReadyAddresses-02.yaml<span class="comment"># 查看 Endpoints </span>$ kubectl get endpoints NAME                      ENDPOINTS            AGEmyapp-clusterip-service   172.16.58.211:80     18s<span class="comment"># 测试 Service 访问</span>$ curl 172.16.58.211:80www.xinxianghf.com | hello MyAPP | version v1.0</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、Service-工作原理&quot;&gt;&lt;a href=&quot;#一、Service-工作原理&quot; class=&quot;headerlink&quot; title=&quot;一、Service 工作原理&quot;&gt;&lt;/a&gt;一、Service 工作原理&lt;/h1&gt;&lt;h2 id=&quot;1-Service-简介&quot;&gt;&lt;a </summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>005-Kubernetes控制器</title>
    <link href="https://georgechan95.github.io/blog/c790096a.html"/>
    <id>https://georgechan95.github.io/blog/c790096a.html</id>
    <published>2025-04-02T12:12:00.000Z</published>
    <updated>2025-04-18T02:18:45.728Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、控制器概述"><a href="#一、控制器概述" class="headerlink" title="一、控制器概述"></a>一、控制器概述</h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>在 Kubernetes 中运行了一系列控制器来确保集群的当前状态与期望状态保持一致，它们就是 Kubernetes 集群内部的管理控制中心或者说是”中心大脑”。例如，ReplicaSet 控制器负责维护集群中运行的 Pod 数量；Node 控制器负责监控节点的状态，并在节点出现故障时，执行自动化修复流程，确保集群始终处于预期的工作状态。</p><p><strong>控制器-控制循环</strong></p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/02/20250402-201433.png" alt="控制器-控制循环"></p><h2 id="2-控制器分类"><a href="#2-控制器分类" class="headerlink" title="2. 控制器分类"></a>2. 控制器分类</h2><p>Pod控制器有如下几类：</p><ul><li>ReplicationController 和 ReplicaSet<ul><li><strong>功能</strong>：确保指定数量的 Pod 副本始终运行。<ul><li><strong>ReplicationController</strong>（旧版）：通过标签选择器管理 Pod 副本数，但功能较基础。</li><li><strong>ReplicaSet</strong>（推荐）：新一代控制器，支持更灵活的<strong>集合型标签选择器</strong>（如 <code>matchLabels</code> 和 <code>matchExpressions</code>），通常被 Deployment 间接使用。</li></ul></li><li><strong>典型场景</strong>：无状态应用的副本维护（如 Web 服务）。</li></ul></li><li>Deployment<ul><li><strong>功能</strong>：管理 ReplicaSet 并提供声明式更新（如滚动升级、回滚）。<ul><li>通过控制 ReplicaSet 实现 Pod 的副本管理。</li><li>支持版本控制和更新策略（如 <code>RollingUpdate</code> 或 <code>Recreate</code>）。</li></ul></li><li><strong>典型场景</strong>：需要滚动更新或回滚的无状态应用（如微服务）。</li></ul></li><li>DaemonSet<ul><li><strong>功能</strong>：确保每个节点（或指定节点）运行一个指定的 Pod。<ul><li>Pod 通常与节点绑定（如日志收集、网络插件）。</li><li>节点加入集群时自动创建 Pod，节点移除时删除。</li></ul></li><li><strong>典型场景</strong>：集群级守护进程（如 <code>kube-proxy</code>、<code>fluentd</code>）。</li></ul></li><li>StateFulSet<ul><li><strong>功能</strong>：管理有状态应用的 Pod，提供稳定的标识和持久化存储。<ul><li>每个 Pod 有唯一名称（如 <code>web-0</code>、<code>web-1</code>）和持久化存储（PVC）。</li><li>支持有序部署&#x2F;扩展（按序号顺序操作）。</li></ul></li><li><strong>典型场景</strong>：数据库、分布式存储（如 MySQL、ZooKeeper）。</li></ul></li><li>Job&#x2F;CronJob<ul><li><strong>Job</strong>：<ul><li>创建一次性 Pod 并确保其成功完成。</li><li>支持并行执行和重试机制。</li><li><strong>场景</strong>：批处理任务（如数据处理）。</li></ul></li><li><strong>CronJob</strong>：<ul><li>基于时间表（Cron 表达式）周期性运行 Job。</li><li><strong>场景</strong>：定时任务（如每日备份）。</li></ul></li></ul></li><li>Horizontal Pod Autoscaling<ul><li><strong>功能</strong>：根据 CPU 使用率或其他自定义指标自动调整 Pod 副本数。<ul><li>与 ReplicaSet&#x2F;Deployment 配合使用。</li><li>支持动态扩缩容（如流量高峰时扩容）。</li></ul></li><li><strong>典型场景</strong>：应对负载波动的服务（如电商大促）。</li></ul></li></ul><h1 id="二、ReplicationController-和-ReplicaSet"><a href="#二、ReplicationController-和-ReplicaSet" class="headerlink" title="二、ReplicationController 和 ReplicaSet"></a>二、ReplicationController 和 ReplicaSet</h1><p>ReplicationController（RC）用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的 Pod 来替代；而如果异常多出来的容器也会自动回收；</p><p>在新版本的 Kubernetes 中建议使用 ReplicaSet 来取代 ReplicationController 。ReplicaSet 跟 ReplicationController 没有本质的不同，只是名字不一样，并且 ReplicaSet 支持集合式的 selector；</p><h2 id="1-案例：ReplicationController"><a href="#1-案例：ReplicationController" class="headerlink" title="1. 案例：ReplicationController"></a>1. 案例：ReplicationController</h2><p><code>001-replication-controller.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">ReplicationController</span> <span class="comment"># 资源类型为 ReplicationController（旧版副本控制器）</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">rc-demo</span> <span class="comment"># RC 的名称，在命名空间中唯一</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># 确保始终有 3 个 Pod 副本在运行</span>  <span class="attr">selector:</span>    <span class="attr">app:</span> <span class="string">rc-demo</span>  <span class="comment"># 选择标签为 `app: rc-demo` 的 Pod 进行管理</span>  <span class="attr">template:</span> <span class="comment"># Pod 模板</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">rc-demo</span> <span class="comment"># 给 Pod 打上标签，与 selector 对应</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">rc-demo-container</span> <span class="comment"># 容器名称</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">env:</span> <span class="comment"># 定义环境变量</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GET_HOSTS_FROM</span> <span class="comment"># 环境变量1 key</span>              <span class="attr">value:</span> <span class="string">dns</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">zhangsan</span> <span class="comment"># 环境变量2 key</span>              <span class="attr">value:</span> <span class="string">&quot;123&quot;</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 容器暴露的端口</span></code></pre><p><strong>运行 ReplicationController</strong></p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f 001-replication-controller.yaml</span></code></pre><p><strong>查看Pod的运行情况</strong></p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod -o wide -w</span>NAME            READY   STATUS    RESTARTS         AGE   IP              NODE         NOMINATED NODE   READINESS GATESrc-demo-47nqt   1/1     Running   0                36s   172.16.85.199   k8s-node01   &lt;none&gt;           &lt;none&gt;rc-demo-74hbx   1/1     Running   0                36s   172.16.58.198   k8s-node02   &lt;none&gt;           &lt;none&gt;rc-demo-zp8ck   1/1     Running   0                36s   172.16.85.200   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>在两个node子节点上，运行了三个 Pod</p><p><strong>测试Pod自动恢复</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">新起一个shell终端，杀死一个pod</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl delete pod rc-demo-74hbx</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">观察Pod运行情况</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod -o wide -w</span>NAME            READY   STATUS    RESTARTS         AGE   IP              NODE         NOMINATED NODE   READINESS GATESrc-demo-47nqt   1/1     Running   0                36s   172.16.85.199   k8s-node01   &lt;none&gt;           &lt;none&gt;rc-demo-74hbx   1/1     Running   0                36s   172.16.58.198   k8s-node02   &lt;none&gt;           &lt;none&gt;rc-demo-zp8ck   1/1     Running   0                36s   172.16.85.200   k8s-node01   &lt;none&gt;           &lt;none&gt;rc-demo-74hbx   1/1     Terminating   0                63s   172.16.58.198   k8s-node02   &lt;none&gt;           &lt;none&gt;rc-demo-fgfmr   0/1     Pending       0                1s    &lt;none&gt;          &lt;none&gt;       &lt;none&gt;           &lt;none&gt;rc-demo-fgfmr   0/1     Pending       0                1s    &lt;none&gt;          k8s-node02   &lt;none&gt;           &lt;none&gt;rc-demo-fgfmr   0/1     ContainerCreating   0                2s    &lt;none&gt;          k8s-node02   &lt;none&gt;           &lt;none&gt;rc-demo-74hbx   1/1     Terminating         0                65s   172.16.58.198   k8s-node02   &lt;none&gt;           &lt;none&gt;rc-demo-74hbx   0/1     Terminating         0                71s   172.16.58.198   k8s-node02   &lt;none&gt;           &lt;none&gt;rc-demo-74hbx   0/1     Terminating         0                75s   &lt;none&gt;          k8s-node02   &lt;none&gt;           &lt;none&gt;rc-demo-74hbx   0/1     Terminating         0                75s   &lt;none&gt;          k8s-node02   &lt;none&gt;           &lt;none&gt;rc-demo-74hbx   0/1     Terminating         0                75s   &lt;none&gt;          k8s-node02   &lt;none&gt;           &lt;none&gt;rc-demo-fgfmr   0/1     ContainerCreating   0                13s   &lt;none&gt;          k8s-node02   &lt;none&gt;           &lt;none&gt;rc-demo-fgfmr   1/1     Running             0                20s   172.16.58.199   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>杀死了 Pod <code>rc-demo-74hbx</code>， k8s又自动创建了Pod <code>rc-demo-fgfmr</code>。</p><h2 id="2-案例：ReplicaSet"><a href="#2-案例：ReplicaSet" class="headerlink" title="2. 案例：ReplicaSet"></a>2. 案例：ReplicaSet</h2><h3 id="2-1-RS-yaml-文件"><a href="#2-1-RS-yaml-文件" class="headerlink" title="2.1 RS yaml 文件"></a>2.1 RS yaml 文件</h3><p><code>002-ReplicaSet.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">ReplicaSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">replica-set-demo</span> <span class="comment"># rs的名字，全局唯一，生成的Pod的名字：replica-set-demo-xxxx</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">3</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 基于标签匹配</span>      <span class="attr">app:</span> <span class="string">rs-ml-demo</span> <span class="comment"># ReplicaSet 将管理带有标签 app=rs-ml-demo 的 Pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">namespace:</span> <span class="string">default</span>      <span class="attr">labels:</span> <span class="comment"># 为 Pod 设置标签</span>        <span class="attr">app:</span> <span class="string">rs-ml-demo</span> <span class="comment"># 给 Pod 打上标签 app=rs-ml-demo，与 selector 中的 matchLabels 对应</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">rs-ml-container</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">env:</span> <span class="comment"># 定义容器的环境变量</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GET_HOSTS_FROM</span>              <span class="attr">value:</span> <span class="string">dns</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">George</span>              <span class="attr">value:</span> <span class="string">&quot;30&quot;</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></code></pre><h3 id="2-2-启动RS"><a href="#2-2-启动RS" class="headerlink" title="2.2 启动RS"></a>2.2 启动RS</h3><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f 002-ReplicaSet.yaml</span></code></pre><h3 id="2-3-查看RS启动详情"><a href="#2-3-查看RS启动详情" class="headerlink" title="2.3 查看RS启动详情"></a>2.3 查看RS启动详情</h3><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl describe replicaset replica-set-demo</span>Name:         replica-set-demoNamespace:    defaultSelector:     app=rs-ml-demoLabels:       &lt;none&gt;Annotations:  &lt;none&gt;Replicas:     3 current / 3 desiredPods Status:  3 Running / 0 Waiting / 0 Succeeded / 0 FailedPod Template:  Labels:  app=rs-ml-demo  Containers:   rs-ml-container:    Image:      wangyanglinux/myapp:v1.0    Port:       80/TCP    Host Port:  0/TCP    Environment:      GET_HOSTS_FROM:  dns      George:          30    Mounts:            &lt;none&gt;  Volumes:             &lt;none&gt;Events:  Type    Reason            Age   From                   Message  ----    ------            ----  ----                   -------  Normal  SuccessfulCreate  67s   replicaset-controller  Created pod: replica-set-demo-p4tpb  Normal  SuccessfulCreate  67s   replicaset-controller  Created pod: replica-set-demo-hnddq  Normal  SuccessfulCreate  67s   replicaset-controller  Created pod: replica-set-demo-89pz7</code></pre><p>RS 创建了3个 Pod 副本，均已启动成功。</p><h3 id="2-4-查看-RS-启动的-Pod"><a href="#2-4-查看-RS-启动的-Pod" class="headerlink" title="2.4  查看 RS 启动的 Pod"></a>2.4  查看 RS 启动的 Pod</h3><p>根据 Pod 的标签过滤</p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pods -l app=rs-ml-demo -o wide</span>NAME                     READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESreplica-set-demo-89pz7   1/1     Running   0          2m58s   172.16.58.203   k8s-node02   &lt;none&gt;           &lt;none&gt;replica-set-demo-hnddq   1/1     Running   0          2m58s   172.16.85.202   k8s-node01   &lt;none&gt;           &lt;none&gt;replica-set-demo-p4tpb   1/1     Running   0          2m58s   172.16.58.202   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><h3 id="2-5-查看Pod的日志"><a href="#2-5-查看Pod的日志" class="headerlink" title="2.5 查看Pod的日志"></a>2.5 查看Pod的日志</h3><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">查看最近1000行日志</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl logs -f --<span class="built_in">tail</span>=1000 replica-set-demo-89pz7</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看最近1小时的日志</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl logs -f --<span class="built_in">tail</span>=1000 replica-set-demo-89pz7 --since=1h</span></code></pre><h3 id="2-6-验证Pod设置的环境变量是否有效"><a href="#2-6-验证Pod设置的环境变量是否有效" class="headerlink" title="2.6 验证Pod设置的环境变量是否有效"></a>2.6 验证Pod设置的环境变量是否有效</h3><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">进入Pod容器</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">exec</span> -it replica-set-demo-89pz7 /bin/bash</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">打印环境变量</span>replica-set-demo-89pz7:/# echo $GET_HOSTS_FROMdnsreplica-set-demo-89pz7:/# echo $George30</code></pre><h3 id="2-7-验证RS对于Pod副本数量的自动恢复"><a href="#2-7-验证RS对于Pod副本数量的自动恢复" class="headerlink" title="2.7 验证RS对于Pod副本数量的自动恢复"></a>2.7 验证RS对于Pod副本数量的自动恢复</h3><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">在一个shell中监控RS</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl get replicaset replica-set-demo -o wide -w</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">在另一个shell中，杀死这个RS管理的其中一个Pod</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl delete pod replica-set-demo-89pz7</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">可以看到RS管理的Pod从最开始3个，变成2个，又迅速恢复成3个</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl get replicaset replica-set-demo -o wide -w</span>NAME               DESIRED   CURRENT   READY   AGE   CONTAINERS        IMAGES                     SELECTORreplica-set-demo   3         3         3       10m   rs-ml-container   wangyanglinux/myapp:v1.0   app=rs-ml-demoreplica-set-demo   3         2         2       11m   rs-ml-container   wangyanglinux/myapp:v1.0   app=rs-ml-demoreplica-set-demo   3         3         2       11m   rs-ml-container   wangyanglinux/myapp:v1.0   app=rs-ml-demoreplica-set-demo   3         3         3       11m   rs-ml-container   wangyanglinux/myapp:v1.0   app=rs-ml-demo</code></pre><h3 id="2-8-验证-yaml-文件中定义的Pod的标签与RS标签选择器不一致时，是否可以启动"><a href="#2-8-验证-yaml-文件中定义的Pod的标签与RS标签选择器不一致时，是否可以启动" class="headerlink" title="2.8 验证 yaml 文件中定义的Pod的标签与RS标签选择器不一致时，是否可以启动"></a>2.8 验证 yaml 文件中定义的Pod的标签与RS标签选择器不一致时，是否可以启动</h3><p><strong>yaml文件如下：</strong></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">ReplicaSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">replica-set-demo</span> <span class="comment"># rs命名，全局唯一</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">3</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span> <span class="comment"># 基于标签匹配</span>      <span class="attr">app:</span> <span class="string">rs-ml-demo</span> <span class="comment"># ReplicaSet 将管理带有标签 app=rs-ml-demo 的 Pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">namespace:</span> <span class="string">default</span>      <span class="attr">labels:</span> <span class="comment"># 为 Pod 设置标签</span>        <span class="attr">app:</span> <span class="string">rs-ml-demo-123</span> <span class="comment"># 给 Pod 打上标签 app=rs-ml-demo，与 selector 中的 matchLabels 对应</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">rs-ml-container</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">env:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GET_HOSTS_FROM</span>              <span class="attr">value:</span> <span class="string">dns</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">George</span>              <span class="attr">value:</span> <span class="string">&quot;30&quot;</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></code></pre><p>RS 标签选择器管理的标签是 rs-ml-demo ， 而 Pod模板定义的标签是 rs-ml-demo-123 ，这样 RS 将无法管理此 Pod。</p><p><strong>启动RS</strong></p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f 002-ReplicaSet.yaml</span> The ReplicaSet &quot;replica-set-demo&quot; is invalid: spec.template.metadata.labels: Invalid value: map[string]string&#123;&quot;app&quot;:&quot;rs-ml-demo-123&quot;&#125;: `selector` does not match template `labels`</code></pre><p>启动报错，K8S不允许定义定Pod标签与RS标签选择器无法匹配的情况。</p><h2 id="3-标签选择器"><a href="#3-标签选择器" class="headerlink" title="3. 标签选择器"></a>3. 标签选择器</h2><p>在 Kubernetes 的 ReplicaSet（或其他资源如 Deployment、Service 等）中，matchLabels 是 selector 的一部分，用于指定如何选择要管理的 Pod。它基于<strong>标签（labels）</strong>进行匹配。matchLabels 本身只支持一种匹配模式：<strong>精确匹配（exact match）</strong>，即键值对必须完全相等。但 Kubernetes 提供了更灵活的标签选择器机制，比如 matchExpressions，可以实现更复杂的匹配模式。</p><h3 id="3-1-matchLabels-的匹配模式"><a href="#3-1-matchLabels-的匹配模式" class="headerlink" title="3.1 matchLabels 的匹配模式"></a>3.1 matchLabels 的匹配模式</h3><ul><li><p><strong>定义</strong>：matchLabels 是一个键值对映射，要求被选中的 Pod 的标签与 matchLabels 中定义的键值对完全一致。</p></li><li><p><strong>模式</strong>：仅支持<strong>精确匹配</strong>。</p></li><li><p><strong>语法</strong>：</p><pre><code class="highlight yaml"><span class="attr">selector:</span>  <span class="attr">matchLabels:</span>    <span class="attr">key1:</span> <span class="string">value1</span>    <span class="attr">key2:</span> <span class="string">value2</span></code></pre></li><li><p><strong>行为</strong>：Pod 必须同时具备所有指定的标签键值对才能被选中。（Pod定的标签可以比 matchLabels 定义的标签多，但是不能比 matchLabels 定义的标签少，否则无法被 RS 管理）</p></li><li><p><strong>示例</strong>： 在你的 ReplicaSet 配置中：</p><pre><code class="highlight yaml"><span class="attr">selector:</span>  <span class="attr">matchLabels:</span>    <span class="attr">app:</span> <span class="string">rs-ml-demo</span>    <span class="attr">key2:</span> <span class="string">value2</span></code></pre><ul><li>这表示 ReplicaSet 只管理带有标签 <code>app=rs-ml-demo</code> 和 <code>key2=value2</code> 的 Pod。</li><li>Pod 的标签必须完全匹配 <code>app: rs-ml-demo</code> 和 <code>key2: value2</code> ，多余的标签不会影响匹配，但缺少这个标签的 Pod 不会被选中。</li></ul></li></ul><h3 id="3-2-matchExpressions-的匹配模式"><a href="#3-2-matchExpressions-的匹配模式" class="headerlink" title="3.2 matchExpressions 的匹配模式"></a>3.2 matchExpressions 的匹配模式</h3><p> Kubernetes 的 selector 还支持 matchExpressions，它提供了更丰富的匹配模式。matchExpressions 是一个可选字段，与 matchLabels 可以一起使用，允许基于逻辑运算进行标签选择。</p><p>它提供了更丰富的匹配模式。matchExpressions 是一个可选字段，与 matchLabels 可以一起使用，允许基于逻辑运算进行标签选择。</p><ul><li><p><strong>语法</strong>：</p><pre><code class="highlight yaml"><span class="attr">selector:</span>  <span class="attr">matchLabels:</span>    <span class="attr">app:</span> <span class="string">rs-ml-demo</span>  <span class="attr">matchExpressions:</span>    <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">environment</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">prod</span>, <span class="string">staging</span>]&#125;</code></pre></li><li><p><strong>支持的运算符（Operator）</strong>：</p><ol><li><strong>In</strong>：<ul><li>标签的值必须在指定值列表中。</li><li>示例：environment 的值必须是 prod 或 staging。</li></ul></li><li><strong>NotIn</strong>：<ul><li>标签的值不能在指定值列表中。</li><li>示例：environment 的值不能是 dev 或 test。</li></ul></li><li><strong>Exists</strong>：<ul><li>标签键必须存在，值无要求。</li><li>示例：Pod 必须有 environment 标签，具体值不限。</li></ul></li><li><strong>DoesNotExist</strong>：<ul><li>标签键不能存在。</li><li>示例：Pod 不能有 environment 标签。</li></ul></li></ol></li><li><p><strong>示例</strong>：</p><pre><code class="highlight yaml"><span class="attr">selector:</span>  <span class="attr">matchExpressions:</span>    <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">tier</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">frontend</span>, <span class="string">backend</span>]&#125;    <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">deprecated</span>, <span class="attr">operator:</span> <span class="string">DoesNotExist</span>&#125;</code></pre><ul><li>匹配条件：Pod 必须有 tier&#x3D;frontend 或 tier&#x3D;backend，且不能有 deprecated 标签。</li></ul></li></ul><h3 id="3-3-matchLabels-和-matchExpressions-的关系"><a href="#3-3-matchLabels-和-matchExpressions-的关系" class="headerlink" title="3.3 matchLabels 和 matchExpressions 的关系"></a>3.3 matchLabels 和 matchExpressions 的关系</h3><ul><li><p>matchLabels 是简化的写法：它会被 Kubernetes 内部转换为等价的 matchExpressions，每个键值对对应一个 In 运算符。</p><ul><li><p>例如：</p><pre><code class="highlight yaml"><span class="attr">matchLabels:</span>  <span class="attr">app:</span> <span class="string">rs-ml-demo</span></code></pre><p>等价于：</p><pre><code class="highlight yaml"><span class="attr">matchExpressions:</span>  <span class="bullet">-</span> &#123;<span class="attr">key:</span> <span class="string">app</span>, <span class="attr">operator:</span> <span class="string">In</span>, <span class="attr">values:</span> [<span class="string">rs-ml-demo</span>]&#125;</code></pre></li></ul></li><li><p><strong>组合使用</strong>：如果同时指定 matchLabels 和 matchExpressions，Pod 必须满足两者的条件（逻辑“与”关系）。</p></li></ul><h3 id="3-4-注意事项"><a href="#3-4-注意事项" class="headerlink" title="3.4 注意事项"></a>3.4 注意事项</h3><ul><li><strong>一致性</strong>：selector.matchLabels（或 matchExpressions）必须与 template.metadata.labels 中的标签匹配，否则 ReplicaSet 无法正确管理 Pod。</li><li><strong>大小写敏感</strong>：标签键和值是大小写敏感的，例如 app: Rs-ml-demo 和 app: rs-ml-demo 不匹配。</li><li><strong>Service 的选择器</strong>：虽然问题聚焦于 ReplicaSet，但值得一提的是 Service 的 selector 只支持 matchLabels 风格的精确匹配，不支持 matchExpressions。</li></ul><h3 id="3-5-实际案例"><a href="#3-5-实际案例" class="headerlink" title="3.5 实际案例"></a>3.5 实际案例</h3><p><code>003-matchExpressions.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">ReplicaSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">rs-me-exists-demo</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">3</span>  <span class="attr">selector:</span>    <span class="attr">matchExpressions:</span>      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span> <span class="comment"># Pod 必须有 app 标签</span>        <span class="attr">operator:</span> <span class="string">Exists</span>      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">version</span> <span class="comment"># Pod 必须有 version=v1 或 version=v2</span>        <span class="attr">operator:</span> <span class="string">In</span>        <span class="attr">values:</span>          <span class="bullet">-</span> <span class="string">v1</span>          <span class="bullet">-</span> <span class="string">v2</span>      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">souce</span> <span class="comment"># Pod不能有 souce 标签</span>        <span class="attr">operator:</span> <span class="string">DoesNotExist</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">namespace:</span> <span class="string">default</span>      <span class="attr">labels:</span> <span class="comment"># 为 Pod 设置标签</span>        <span class="attr">app:</span> <span class="string">rs-ml-demo</span> <span class="comment"># 给 Pod 打上标签 app=rs-ml-demo，与 selector 中的 matchLabels 对应</span>        <span class="attr">version:</span> <span class="string">v1</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">rs-ml-container</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="attr">env:</span> <span class="comment"># 定义容器的环境变量</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GET_HOSTS_FROM</span>              <span class="attr">value:</span> <span class="string">dns</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">George</span>              <span class="attr">value:</span> <span class="string">&quot;30&quot;</span>          <span class="attr">ports:</span>            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></code></pre><h3 id="3-6-总结"><a href="#3-6-总结" class="headerlink" title="3.6 总结"></a>3.6 总结</h3><ul><li><strong>matchLabels</strong>：只支持<strong>精确匹配</strong>，键值对必须完全相等。</li><li><strong>matchExpressions</strong>（扩展功能）：支持 In、NotIn、Exists、DoesNotExist 四种模式，提供更灵活的匹配。</li></ul><h1 id="三、Deployment-控制器"><a href="#三、Deployment-控制器" class="headerlink" title="三、Deployment 控制器"></a>三、Deployment 控制器</h1><h2 id="1-Deployment-基本概念"><a href="#1-Deployment-基本概念" class="headerlink" title="1. Deployment - 基本概念"></a>1. Deployment - 基本概念</h2><p>Deployment 为 Pod 和 ReplicaSet 提供了一个声明式定义 ( declarative ) 方法，用来替代以前的 ReplicationController 来方便的管理应用。典型的应用场景包括：</p><ul><li>定义 Deployment 来创建 Pod 和 ReplicaSet</li><li>滚动升级和回滚应用</li><li>扩容和缩容</li><li>暂停和继续 Deployment</li></ul><h2 id="2-Deployment-与-RS-的关联"><a href="#2-Deployment-与-RS-的关联" class="headerlink" title="2. Deployment - 与 RS 的关联"></a>2. Deployment - 与 RS 的关联</h2><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/07/20250407-083305.png" alt="Deployment - 与 RS 的关联"></p><p>Deployment 是通过创建 ReplicaSet 来间接的管理 Pod。</p><h2 id="3-Deployment-常用命令"><a href="#3-Deployment-常用命令" class="headerlink" title="3. Deployment - 常用命令"></a>3. Deployment - 常用命令</h2><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">根据资源清单创建 deployment</span> <span class="meta prompt_"># </span><span class="language-bash">--record 参数可以记录命令，我们可以很方便的查看每次 revision 的变化</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl create -f deployment.yaml --record</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">修改 Deployment 类型的 Pod 的数量</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl scale deployment nginx-deployment --replicas 10</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">设置 Pod 自动扩缩容，最大15个，最小 10个，扩缩依据：CPU利用率是否超过 80%</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">更新 deployment 类型的Pod nginx-deployment 下的容器 nginx-deployment-container 的镜像为：wangyanglinux/myapp:v2.0</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">set</span> image deployment/nginx-deployment nginx-deployment-container=wangyanglinux/myapp:v2.0</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">回滚Pod变更 (只能回滚到前一次变更操作，如：1 -&gt; 2 -&gt; 3, 第一次回滚回到2，第二次回滚则回到3，无法回滚到)</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl rollout undo deployment/nginx-deployment</span></code></pre><h2 id="4-apply-、create、replace-区别"><a href="#4-apply-、create、replace-区别" class="headerlink" title="4. apply 、create、replace 区别"></a>4. apply 、create、replace 区别</h2><p><code>kubectl create -f deployment.yaml</code> 和 <code>kubectl apply -f deployment.yaml</code> 都是用于创建或更新 Kubernetes 资源的命令，但它们在行为上有<strong>关键区别</strong>，主要涉及 <strong>声明式管理</strong> 和 <strong>命令式管理</strong> 的不同逻辑。</p><h3 id="4-1-命令式命令"><a href="#4-1-命令式命令" class="headerlink" title="4.1  命令式命令"></a>4.1  命令式命令</h3><pre><code class="highlight shell">kubectl create -f deployment.yaml</code></pre><ul><li><strong>作用</strong>：<strong>严格创建新资源</strong>。</li><li><strong>行为</strong>：<ul><li>如果资源（如 Deployment）<strong>已存在</strong>，会报错并拒绝执行（报 <code>AlreadyExists</code> 错误）。</li><li>仅适用于<strong>首次创建</strong>，不能用于更新。</li></ul></li><li><strong>适用场景</strong>：<ul><li>你明确知道资源不存在，且只需要一次性创建。</li><li>脚本中需要严格避免覆盖现有配置时。</li></ul></li></ul><p><strong>示例输出（资源已存在时）：</strong></p><pre><code class="highlight sh">Error from server (AlreadyExists): deployments.apps <span class="string">&quot;deployment-demo-1&quot;</span> already exists</code></pre><h3 id="4-2-声明式命令"><a href="#4-2-声明式命令" class="headerlink" title="4.2 声明式命令"></a>4.2 声明式命令</h3><ul><li><strong>作用</strong>：<strong>创建或更新资源</strong>，智能合并变更。</li><li><strong>行为</strong>：<ul><li>如果资源<strong>不存在</strong>，则创建它（等同于 <code>create</code>）。</li><li>如果资源<strong>已存在</strong>，则对比当前配置和 YAML 文件的差异，<strong>增量更新</strong>（保留未修改的字段）。</li><li>依赖 <code>metadata.annotations</code> 中的 <code>kubectl.kubernetes.io/last-applied-configuration</code> 记录上次配置，用于计算变更。</li></ul></li><li><strong>适用场景</strong>：<ul><li>日常维护（例如更新镜像版本、调整副本数）。</li><li>GitOps 或 CI&#x2F;CD 流程中（推荐使用 <code>apply</code> 而非 <code>create</code>）。</li></ul></li></ul><p><strong>示例输出（更新时）</strong>：</p><pre><code class="highlight shell">deployment.apps/deployment-demo-1 configured</code></pre><h3 id="4-3-关键区别总结"><a href="#4-3-关键区别总结" class="headerlink" title="4.3 关键区别总结"></a>4.3 关键区别总结</h3><table><thead><tr><th align="left">特性</th><th align="left"><code>kubectl create</code></th><th align="left"><code>kubectl apply</code></th></tr></thead><tbody><tr><td align="left"><strong>资源已存在</strong></td><td align="left">报错，拒绝执行</td><td align="left">合并更新</td></tr><tr><td align="left"><strong>资源不存在</strong></td><td align="left">创建资源</td><td align="left">创建资源</td></tr><tr><td align="left"><strong>管理方式</strong></td><td align="left">命令式（直接执行）</td><td align="left">声明式（对比差异后更新）</td></tr><tr><td align="left"><strong>记录变更</strong></td><td align="left">无</td><td align="left">记录到 <code>last-applied-configuration</code></td></tr><tr><td align="left"><strong>适用场景</strong></td><td align="left">一次性创建</td><td align="left">持续维护（创建 + 更新）</td></tr></tbody></table><h3 id="4-4-kubectl-replace-f"><a href="#4-4-kubectl-replace-f" class="headerlink" title="4.4 kubectl replace -f"></a>4.4 kubectl replace -f</h3><ul><li>类似 <code>create</code>，但会<strong>强制替换</strong>现有资源（需资源已存在）。</li><li>与 <code>apply</code> 不同：<strong>不合并字段</strong>，直接覆盖整个配置（可能丢失未指定的字段）。</li><li>慎用，通常仅在需要完全重置配置时使用。</li></ul><p><strong>建议</strong>：</p><ul><li>**优先使用 <code>apply</code>**（声明式操作更符合 Kubernetes 设计理念）。</li><li>仅在需要严格控制创建时使用 <code>create</code>。</li><li><strong>自动化流程</strong>：推荐始终使用 <code>apply</code>（避免因资源存在导致失败）。</li></ul><h2 id="5-Deployment-案例实操"><a href="#5-Deployment-案例实操" class="headerlink" title="5. Deployment - 案例实操"></a>5. Deployment - 案例实操</h2><h3 id="5-1-编写资源清单"><a href="#5-1-编写资源清单" class="headerlink" title="5.1 编写资源清单"></a>5.1 编写资源清单</h3><p><code>004-deployment-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># 版本号</span><span class="attr">kind:</span> <span class="string">Deployment</span> <span class="comment"># 控制器类型为：Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">deployment-demo</span> <span class="comment"># 控制器标签</span>  <span class="attr">name:</span> <span class="string">deployment-demo-1</span> <span class="comment"># 控制器名称</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span> <span class="comment"># 初始Pod副本数</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">deployment-demo</span> <span class="comment"># Pod标签选择器，管理 标签为 app: deployment-demo 的Pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">deployment-demo</span> <span class="comment"># Pod的标签，与 selector 标签选择器对应</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span> <span class="comment"># 容器使用的镜像</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取策略</span>          <span class="attr">name:</span> <span class="string">deployment-demo-container</span> <span class="comment"># 镜像</span></code></pre><h3 id="5-2-创建-Deployment"><a href="#5-2-创建-Deployment" class="headerlink" title="5.2 创建 Deployment"></a>5.2 创建 Deployment</h3><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">根据资源清单创建 Deployment 和对应的 Pod</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f 004-deployment-demo.yaml</span></code></pre><h3 id="5-3-查看-Deployment-和-Pod"><a href="#5-3-查看-Deployment-和-Pod" class="headerlink" title="5.3 查看 Deployment  和 Pod"></a>5.3 查看 Deployment  和 Pod</h3><p><strong>查看 Deployment 信息</strong></p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get deployment -o wide</span> NAME                READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS                  IMAGES                     SELECTORdeployment-demo-1   1/1     1            1           2m21s   deployment-demo-container   wangyanglinux/myapp:v1.0   app=deployment-demo</code></pre><p>可以看到创建一个 Deployment 类型的控制器，名称为：deployment-demo-1， 标签为：app&#x3D;deployment-demo，控制器内 Pod的副本数为 1。</p><p><strong>查看 Deployment 详细信息</strong></p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get deployment deployment-demo-1 -o yaml</span></code></pre><p><em>内容如下：</em></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">Deployment</span><span class="attr">metadata:</span>  <span class="attr">annotations:</span>    <span class="attr">deployment.kubernetes.io/revision:</span> <span class="string">&quot;1&quot;</span> <span class="comment"># 当前修订版本号（用于回滚）</span>    <span class="attr">kubectl.kubernetes.io/last-applied-configuration:</span> <span class="string">|</span> <span class="comment"># 上次 kubectl apply 使用的完整配置（用于对比变更）</span>      &#123;<span class="string">&quot;apiVersion&quot;</span><span class="string">:&quot;apps/v1&quot;</span>,<span class="string">&quot;kind&quot;</span><span class="string">:&quot;Deployment&quot;</span>,<span class="string">&quot;metadata&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;annotations&quot;</span><span class="string">:</span>&#123;&#125;,<span class="string">&quot;labels&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;app&quot;</span><span class="string">:&quot;deployment-demo&quot;</span>&#125;,<span class="string">&quot;name&quot;</span><span class="string">:&quot;deployment-demo-1&quot;</span>,<span class="string">&quot;namespace&quot;</span><span class="string">:&quot;default&quot;</span>&#125;,<span class="string">&quot;spec&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;replicas&quot;</span><span class="string">:1</span>,<span class="string">&quot;selector&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;matchLabels&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;app&quot;</span><span class="string">:&quot;deployment-demo&quot;</span>&#125;&#125;,<span class="string">&quot;template&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;metadata&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;labels&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;app&quot;</span><span class="string">:&quot;deployment-demo&quot;</span>&#125;&#125;,<span class="string">&quot;spec&quot;</span><span class="string">:</span>&#123;<span class="string">&quot;containers&quot;</span><span class="string">:</span>[&#123;<span class="string">&quot;image&quot;</span><span class="string">:&quot;wangyanglinux/myapp:v1.0&quot;</span>,<span class="string">&quot;imagePullPolicy&quot;</span><span class="string">:&quot;IfNotPresent&quot;</span>,<span class="string">&quot;name&quot;</span><span class="string">:&quot;deployment-demo-container&quot;</span>&#125;]&#125;&#125;&#125;&#125;  <span class="attr">creationTimestamp:</span> <span class="string">&quot;2025-04-09T01:59:05Z&quot;</span>  <span class="attr">generation:</span> <span class="number">1</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">deployment-demo</span>  <span class="attr">name:</span> <span class="string">deployment-demo-1</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">resourceVersion:</span> <span class="string">&quot;1484447&quot;</span>  <span class="attr">uid:</span> <span class="string">8cec6671-c1e9-4292-921c-dbe8bae8c357</span><span class="attr">spec:</span>  <span class="attr">progressDeadlineSeconds:</span> <span class="number">600</span>  <span class="attr">replicas:</span> <span class="number">1</span>  <span class="attr">revisionHistoryLimit:</span> <span class="number">10</span> <span class="comment"># 保留最近 10 个历史版本（用于回滚），超出部分会被自动清理</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">deployment-demo</span>  <span class="attr">strategy:</span>    <span class="attr">rollingUpdate:</span> <span class="comment"># 滚动更新策略 (strategy)</span>      <span class="attr">maxSurge:</span> <span class="number">25</span><span class="string">%</span> <span class="comment"># 允许临时超出期望副本数的比例（例如 1.25 个 Pod）</span>      <span class="attr">maxUnavailable:</span> <span class="number">25</span><span class="string">%</span> <span class="comment"># 更新时允许不可用的 Pod 比例（例如最多 0.75 个 Pod 不可用）</span>    <span class="attr">type:</span> <span class="string">RollingUpdate</span> <span class="comment"># 更新策略类型: 滚动更新,逐步替换旧 Pod，确保服务不中断。</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">creationTimestamp:</span> <span class="literal">null</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">deployment-demo</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>        <span class="attr">name:</span> <span class="string">deployment-demo-container</span>        <span class="attr">resources:</span> &#123;&#125;        <span class="attr">terminationMessagePath:</span> <span class="string">/dev/termination-log</span>        <span class="attr">terminationMessagePolicy:</span> <span class="string">File</span>      <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirst</span>      <span class="attr">restartPolicy:</span> <span class="string">Always</span>      <span class="attr">schedulerName:</span> <span class="string">default-scheduler</span>      <span class="attr">securityContext:</span> &#123;&#125;      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span> <span class="comment"># 终止前等待 30 秒（优雅退出）</span><span class="attr">status:</span>  <span class="attr">availableReplicas:</span> <span class="number">1</span> <span class="comment"># 当前可用的 Pod 数量</span>  <span class="attr">conditions:</span>  <span class="bullet">-</span> <span class="attr">lastTransitionTime:</span> <span class="string">&quot;2025-04-09T01:59:07Z&quot;</span>    <span class="attr">lastUpdateTime:</span> <span class="string">&quot;2025-04-09T01:59:07Z&quot;</span>    <span class="attr">message:</span> <span class="string">Deployment</span> <span class="string">has</span> <span class="string">minimum</span> <span class="string">availability.</span>    <span class="attr">reason:</span> <span class="string">MinimumReplicasAvailable</span>    <span class="attr">status:</span> <span class="string">&quot;True&quot;</span>    <span class="attr">type:</span> <span class="string">Available</span>  <span class="bullet">-</span> <span class="attr">lastTransitionTime:</span> <span class="string">&quot;2025-04-09T01:59:05Z&quot;</span>    <span class="attr">lastUpdateTime:</span> <span class="string">&quot;2025-04-09T01:59:07Z&quot;</span>    <span class="attr">message:</span> <span class="string">ReplicaSet</span> <span class="string">&quot;deployment-demo-1-6995c75668&quot;</span> <span class="string">has</span> <span class="string">successfully</span> <span class="string">progressed.</span>    <span class="attr">reason:</span> <span class="string">NewReplicaSetAvailable</span>    <span class="attr">status:</span> <span class="string">&quot;True&quot;</span>    <span class="attr">type:</span> <span class="string">Progressing</span>  <span class="attr">observedGeneration:</span> <span class="number">1</span>  <span class="attr">readyReplicas:</span> <span class="number">1</span> <span class="comment"># 已就绪的 Pod 数量</span>  <span class="attr">replicas:</span> <span class="number">1</span> <span class="comment"># 实际运行的 Pod 数量</span>  <span class="attr">updatedReplicas:</span> <span class="number">1</span> <span class="comment"># 已更新到最新版本的 Pod 数量</span></code></pre><p><strong>查看Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod -o wide</span>NAME                                 READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESdeployment-demo-1-6995c75668-klh7h   1/1     Running   0          33m   172.16.58.208   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>注意看 Pod 的名字是 <code>deployment-demo-1-6995c75668-klh7h</code> ，这是由 Deployment 创建时，自动创建了 对应的 ReplicaSet 的名字(<code>deployment-demo-1-6995c75668</code>) 再拼接上 随机字符串：<code>klh7h</code> 生成的，可以查看是否有 ReplicaSet 验证：</p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get rs</span>NAME                           DESIRED   CURRENT   READY   AGEdeployment-demo-1-6995c75668   1         1         1       33m</code></pre><h3 id="5-4-Pod-副本扩缩容"><a href="#5-4-Pod-副本扩缩容" class="headerlink" title="5.4 Pod 副本扩缩容"></a>5.4 Pod 副本扩缩容</h3><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">查看当前Pod副本数</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pods</span>NAME                                 READY   STATUS    RESTARTS   AGEdeployment-demo-1-6995c75668-klh7h   1/1     Running   0          29h<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">扩展 Pod 数量</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl scale deployment deployment-demo-1 --replicas 10</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">再次查看 Pod 数量</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod</span> NAME                                 READY   STATUS    RESTARTS   AGEdeployment-demo-1-6995c75668-44fnz   1/1     Running   0          10sdeployment-demo-1-6995c75668-64zdm   1/1     Running   0          10sdeployment-demo-1-6995c75668-9xxbc   1/1     Running   0          10sdeployment-demo-1-6995c75668-klh7h   1/1     Running   0          29hdeployment-demo-1-6995c75668-kqqhj   1/1     Running   0          10sdeployment-demo-1-6995c75668-mmdrx   1/1     Running   0          10sdeployment-demo-1-6995c75668-twr24   1/1     Running   0          10sdeployment-demo-1-6995c75668-vq67h   1/1     Running   0          10sdeployment-demo-1-6995c75668-wpq6x   1/1     Running   0          10sdeployment-demo-1-6995c75668-zxvwc   1/1     Running   0          10s<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">缩小 Pod 副本数</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl scale deployment deployment-demo-1 --replicas 1</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">再次查看Pod</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod</span> NAME                                 READY   STATUS    RESTARTS   AGEdeployment-demo-1-6995c75668-klh7h   1/1     Running   0          29h</code></pre><h3 id="5-5-动态更新-Deployment-的-Pod-容器镜像"><a href="#5-5-动态更新-Deployment-的-Pod-容器镜像" class="headerlink" title="5.5 动态更新 Deployment 的 Pod 容器镜像"></a>5.5 动态更新 Deployment 的 Pod 容器镜像</h3><p>当前资源清单中使用的镜像是：<code>wangyanglinux/myapp:v1.0</code> ，现在测试在不停止Pod运行的情况下，将镜像升级到  <code>wangyanglinux/myapp:v2.0</code></p><p><strong>查看当前运行中的Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">创建 Pod</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl create -f 004-deployment-demo.yaml --record</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pods -o wide</span>NAME                                 READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESdeployment-demo-1-6995c75668-4rljk   1/1     Running   0          28m   172.16.58.213   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">访问Pod，确认当前版本是 1.0</span><span class="meta prompt_">$ </span><span class="language-bash">curl 172.16.58.213</span>www.xinxianghf.com | hello MyAPP | version v1.0</code></pre><p><em>命令后面添加  <code>--record</code> 目的是为了让 kubectl 记住Pod操作历史，以便于后期回滚操作。</em></p><p><strong>升级容器镜像版本</strong></p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">set</span> image deployment/deployment-demo-1 deployment-demo-container=wangyanglinux/myapp:v2.0 --record</span><span class="meta prompt_"></span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pods -o wide</span>NAME                                 READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESdeployment-demo-1-6465d4c5c9-b5dsn   1/1     Running   0          89s   172.16.58.214   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">访问Pod，镜像版本已更新到 2.0</span><span class="meta prompt_">$ </span><span class="language-bash">curl 172.16.58.214</span>www.xinxianghf.com | hello MyAPP | version v2.0</code></pre><p><strong>查看Pod更新的历史记录</strong></p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl rollout <span class="built_in">history</span> deployment/deployment-demo-1</span>deployment.apps/deployment-demo-1 REVISION  CHANGE-CAUSE1         kubectl apply --filename=004-deployment-demo.yaml --record=true2         kubectl set image deployment/deployment-demo-1 deployment-demo-container=wangyanglinux/myapp:v2.0 --record=true</code></pre><h2 id="6-Deployment-滚动升级"><a href="#6-Deployment-滚动升级" class="headerlink" title="6. Deployment 滚动升级"></a>6. Deployment 滚动升级</h2><p>在 Kubernetes 中，<strong>Deployment</strong> 是管理 Pod 副本和实现无缝升级的核心资源。<strong>滚动升级（Rolling Update）</strong> 是默认的更新策略，它允许逐步替换旧版本的 Pod，确保应用在升级过程中<strong>不中断服务</strong>。</p><h3 id="6-1-滚动升级的核心机制"><a href="#6-1-滚动升级的核心机制" class="headerlink" title="6.1 滚动升级的核心机制"></a>6.1 滚动升级的核心机制</h3><h3 id="（1）更新流程"><a href="#（1）更新流程" class="headerlink" title="（1）更新流程"></a>（1）更新流程</h3><ol><li><strong>创建新版本的 ReplicaSet</strong><ul><li>当修改 Deployment 的 Pod 模板（如镜像版本）时，Kubernetes 会创建一个新的 ReplicaSet。</li><li>新 ReplicaSet 逐步启动新 Pod，旧 ReplicaSet 逐步缩减旧 Pod。</li></ul></li><li><strong>逐步替换 Pod</strong><ul><li>通过 <code>maxSurge</code> 和 <code>maxUnavailable</code> 控制替换速度：<ul><li>**<code>maxSurge</code>**：允许临时超出 <code>replicas</code> 的 Pod 数量（默认 25%）。</li><li>**<code>maxUnavailable</code>**：升级过程中允许不可用的 Pod 比例（默认 25%）。</li></ul></li></ul></li><li><strong>完成升级</strong><ul><li>所有旧 Pod 被替换后，旧 ReplicaSet 保留（便于回滚），但 Pod 数为 0。</li></ul></li></ol><h3 id="（2）关键配置参数"><a href="#（2）关键配置参数" class="headerlink" title="（2）关键配置参数"></a>（2）关键配置参数</h3><p>在 Deployment 的 <code>spec.strategy</code> 中定义：</p><pre><code class="highlight yaml"><span class="attr">spec:</span>  <span class="attr">strategy:</span>    <span class="attr">type:</span> <span class="string">RollingUpdate</span>    <span class="attr">rollingUpdate:</span>      <span class="attr">maxSurge:</span> <span class="number">25</span><span class="string">%</span>     <span class="comment"># 允许临时多启动 25% 的 Pod（例如 replicas=4 时，最多 5 个 Pod）</span>      <span class="attr">maxUnavailable:</span> <span class="number">25</span><span class="string">%</span>  <span class="comment"># 允许最多 25% 的 Pod 不可用（例如 replicas=4 时，至少 3 个 Pod 可用）</span></code></pre><h3 id="6-2-触发滚动升级的方式"><a href="#6-2-触发滚动升级的方式" class="headerlink" title="6.2 触发滚动升级的方式"></a>6.2 触发滚动升级的方式</h3><h3 id="（1）直接修改-YAML-并应用"><a href="#（1）直接修改-YAML-并应用" class="headerlink" title="（1）直接修改 YAML 并应用"></a>（1）直接修改 YAML 并应用</h3><pre><code class="highlight shell">kubectl apply -f deployment.yaml</code></pre><p>适用于通过版本控制的 YAML 文件管理部署。</p><h3 id="（2）命令式更新镜像版本"><a href="#（2）命令式更新镜像版本" class="headerlink" title="（2）命令式更新镜像版本"></a>（2）命令式更新镜像版本</h3><pre><code class="highlight shell">kubectl set image deployment/&lt;deployment-name&gt; &lt;container-name&gt;=&lt;new-image&gt;:&lt;tag&gt;</code></pre><p>例如：</p><pre><code class="highlight shell">kubectl set image deployment/deployment-demo-1 deployment-demo-container=wangyanglinux/myapp:v2.0</code></pre><h3 id="（3）其他可触发升级的操作"><a href="#（3）其他可触发升级的操作" class="headerlink" title="（3）其他可触发升级的操作"></a>（3）其他可触发升级的操作</h3><ul><li>修改环境变量、资源限制（CPU&#x2F;内存）、标签等 Pod 模板内容。</li><li><strong>调整副本数（<code>kubectl scale</code>）不会触发滚动升级。</strong></li></ul><h3 id="6-3-查看升级状态"><a href="#6-3-查看升级状态" class="headerlink" title="6.3 查看升级状态"></a>6.3 查看升级状态</h3><h3 id="（1）检查升级进度"><a href="#（1）检查升级进度" class="headerlink" title="（1）检查升级进度"></a>（1）检查升级进度</h3><pre><code class="highlight bash">kubectl rollout status deployment/&lt;deployment-name&gt;</code></pre><p>输出示例：</p><pre><code class="highlight bash">Waiting <span class="keyword">for</span> rollout to finish: 2 out of 3 new replicas have been updated...</code></pre><h3 id="（2）查看历史版本"><a href="#（2）查看历史版本" class="headerlink" title="（2）查看历史版本"></a>（2）查看历史版本</h3><pre><code class="highlight bash">kubectl rollout <span class="built_in">history</span> deployment/&lt;deployment-name&gt;</code></pre><p>输出示例：</p><pre><code class="highlight bash">REVISION  CHANGE-CAUSE1         kubectl apply --filename=deployment.yaml2         kubectl <span class="built_in">set</span> image deployment/deployment-demo-1 deployment-demo-container=myapp:v2.0</code></pre><h3 id="（3）查看具体版本的配置"><a href="#（3）查看具体版本的配置" class="headerlink" title="（3）查看具体版本的配置"></a>（3）查看具体版本的配置</h3><pre><code class="highlight bash">kubectl rollout <span class="built_in">history</span> deployment/&lt;deployment-name&gt; --revision=&lt;revision-number&gt;</code></pre><p>例如：</p><pre><code class="highlight plaintext">kubectl rollout history deployment/deployment-demo-1 --revision=2</code></pre><h3 id="6-4-回滚升级"><a href="#6-4-回滚升级" class="headerlink" title="6.4 回滚升级"></a>6.4 回滚升级</h3><p>如果新版本出现问题，可快速回滚到之前的版本：</p><h3 id="（1）回滚到上一个版本"><a href="#（1）回滚到上一个版本" class="headerlink" title="（1）回滚到上一个版本"></a>（1）回滚到上一个版本</h3><pre><code class="highlight bash">kubectl rollout undo deployment/&lt;deployment-name&gt;</code></pre><h3 id="（2）回滚到指定版本"><a href="#（2）回滚到指定版本" class="headerlink" title="（2）回滚到指定版本"></a>（2）回滚到指定版本</h3><pre><code class="highlight bash">kubectl rollout undo deployment/&lt;deployment-name&gt; --to-revision=&lt;revision-number&gt;</code></pre><p>例如：</p><pre><code class="highlight bash">kubectl rollout undo deployment/deployment-demo-1 --to-revision=1</code></pre><h3 id="6-5-高级控制技巧"><a href="#6-5-高级控制技巧" class="headerlink" title="6.5 高级控制技巧"></a>6.5 高级控制技巧</h3><h3 id="（1）暂停-恢复升级"><a href="#（1）暂停-恢复升级" class="headerlink" title="（1）暂停&#x2F;恢复升级"></a>（1）暂停&#x2F;恢复升级</h3><ul><li><p><strong>暂停升级</strong>（手动分阶段发布）：</p><pre><code class="highlight bash">kubectl rollout pause deployment/&lt;deployment-name&gt;</code></pre></li><li><p><strong>恢复升级</strong>：</p><pre><code class="highlight bash">kubectl rollout resume deployment/&lt;deployment-name&gt;</code></pre></li></ul><h3 id="（2）强制重建-Pod（非滚动更新）"><a href="#（2）强制重建-Pod（非滚动更新）" class="headerlink" title="（2）强制重建 Pod（非滚动更新）"></a>（2）强制重建 Pod（非滚动更新）</h3><p>删除所有 Pod 触发重建（慎用）：</p><pre><code class="highlight bash">kubectl delete pods -l app=&lt;deployment-label&gt;</code></pre><h3 id="（3）修改默认滚动策略"><a href="#（3）修改默认滚动策略" class="headerlink" title="（3）修改默认滚动策略"></a>（3）修改默认滚动策略</h3><p>默认滚动策略如下：</p><pre><code class="highlight yaml"><span class="attr">spec:</span>  <span class="attr">strategy:</span>    <span class="attr">type:</span> <span class="string">RollingUpdate</span>    <span class="attr">rollingUpdate:</span>      <span class="attr">maxSurge:</span> <span class="number">25</span><span class="string">%</span>     <span class="comment"># 允许临时多启动 25% 的 Pod（例如 replicas=4 时，最多 5 个 Pod）</span>      <span class="attr">maxUnavailable:</span> <span class="number">25</span><span class="string">%</span>  <span class="comment"># 允许最多 25% 的 Pod 不可用（例如 replicas=4 时，至少 3 个 Pod 可用）</span></code></pre><p>查看当前 Deployment 滚动策略：</p><pre><code class="highlight bash"><span class="variable">$kubectl</span> get deployment my-deployment-demo -o jsonpath=<span class="string">&#x27;&#123;.spec.strategy&#125;&#x27;</span>&#123;<span class="string">&quot;rollingUpdate&quot;</span>:&#123;<span class="string">&quot;maxSurge&quot;</span>:<span class="string">&quot;25%&quot;</span>,<span class="string">&quot;maxUnavailable&quot;</span>:<span class="string">&quot;25%&quot;</span>&#125;,<span class="string">&quot;type&quot;</span>:<span class="string">&quot;RollingUpdate&quot;</span>&#125;</code></pre><p>修改滚动策略，</p><pre><code class="highlight bash"><span class="variable">$kubectl</span> edit deployment my-deployment-demo --record</code></pre><p>修改完成后保存，会自动生效。</p><h3 id="6-6-故障排查"><a href="#6-6-故障排查" class="headerlink" title="6.6 故障排查"></a>6.6 故障排查</h3><h3 id="（1）升级卡住怎么办？"><a href="#（1）升级卡住怎么办？" class="headerlink" title="（1）升级卡住怎么办？"></a>（1）升级卡住怎么办？</h3><ul><li><p>检查事件：</p><pre><code class="highlight bash">kubectl describe deployment/&lt;deployment-name&gt;</code></pre></li><li><p>查看 Pod 状态：</p><pre><code class="highlight bash">kubectl get pods</code></pre></li></ul><h3 id="（2）常见原因"><a href="#（2）常见原因" class="headerlink" title="（2）常见原因"></a>（2）常见原因</h3><ul><li><strong>镜像拉取失败</strong>：检查镜像名称或权限。</li><li><strong>资源不足</strong>：节点 CPU&#x2F;内存不足。</li><li><strong>就绪探针失败</strong>：新版本 Pod 未通过健康检查。</li></ul><h2 id="7-滚动升级案例实操"><a href="#7-滚动升级案例实操" class="headerlink" title="7. 滚动升级案例实操"></a>7. 滚动升级案例实操</h2><p>演示一个 Deployment 下有多个 Pod 副本（10个），升级镜像版本，以及回退版本相关操作。</p><h3 id="7-1-资源清单"><a href="#7-1-资源清单" class="headerlink" title="7.1 资源清单"></a>7.1 资源清单</h3><p> <code>005-deployment-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># 版本号</span><span class="attr">kind:</span> <span class="string">Deployment</span> <span class="comment"># 控制器类型为：Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">deployment-demo</span> <span class="comment"># 控制器标签</span>  <span class="attr">name:</span> <span class="string">my-deployment-demo</span> <span class="comment"># 控制器名称</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span> <span class="comment"># 初始Pod副本数</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">deployment-demo</span> <span class="comment"># Pod标签选择器，管理 标签为 app: deployment-demo 的Pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">deployment-demo</span> <span class="comment"># Pod的标签，与 selector 标签选择器对应</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">deployment-demo-container</span> <span class="comment"># 容器名称</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span> <span class="comment"># 容器使用的镜像</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取策略</span></code></pre><h3 id="7-2-创建-Service"><a href="#7-2-创建-Service" class="headerlink" title="7.2 创建 Service"></a>7.2 创建 Service</h3><p>创建Service的目的是为了通过访问 service，查看 Pod 滚动升级的过程。</p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">创建 Service</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl create svc clusterip deployment-demo --tcp=80:80</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看 Service</span> <span class="meta prompt_">$ </span><span class="language-bash">kubectl get svc</span>NAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGEdeployment-demo   ClusterIP   10.103.97.136   &lt;none&gt;        80/TCP    5m53skubernetes        ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   13d<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">while</span> 命令循环访问 service</span><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span> curl 10.103.97.136; <span class="keyword">done</span></span></code></pre><h3 id="7-3-创建Deloyment"><a href="#7-3-创建Deloyment" class="headerlink" title="7.3 创建Deloyment"></a>7.3 创建Deloyment</h3><pre><code class="highlight bash"><span class="comment"># 创建 Deployment ，添加了 --record 会记录操作的命令详情</span>$ kubectl create -f 005-deployment-demo.yaml --recordFlag --record has been deprecated, --record will be removed <span class="keyword">in</span> the futuredeployment.apps/my-deployment-demo created<span class="comment"># 查看 Deployment</span>$ kubectl get deployment -o wide NAME                 READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS                  IMAGES                     SELECTORmy-deployment-demo   1/1     1            1           3s    deployment-demo-container   wangyanglinux/myapp:v1.0   app=deployment-demo</code></pre><h3 id="7-4-Pod副本扩容"><a href="#7-4-Pod副本扩容" class="headerlink" title="7.4 Pod副本扩容"></a>7.4 Pod副本扩容</h3><pre><code class="highlight bash"><span class="comment"># 将当前Pod数量从1个，扩容到10个</span>$ kubectl scale deployment my-deployment-demo --replicas 10deployment.apps/my-deployment-demo scaled<span class="comment"># 查看Deployment</span>$ kubectl get deployment -o wide NAME                 READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS                  IMAGES                     SELECTORmy-deployment-demo   10/10   10           10          2m49s   deployment-demo-container   wangyanglinux/myapp:v1.0   app=deployment-demo<span class="comment"># 查看Pod</span>$ kubectl get pod -l app=deployment-demo -o wideNAME                                  READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESmy-deployment-demo-6995c75668-5fxrj   1/1     Running   0          2m31s   172.16.85.211   k8s-node01   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-977kq   1/1     Running   0          2m31s   172.16.58.223   k8s-node02   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-lq4kj   1/1     Running   0          2m31s   172.16.58.221   k8s-node02   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-mvdsm   1/1     Running   0          2m31s   172.16.58.220   k8s-node02   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-rt2wp   1/1     Running   0          2m31s   172.16.85.208   k8s-node01   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-ssx86   1/1     Running   0          2m31s   172.16.58.222   k8s-node02   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-v69wv   1/1     Running   0          2m31s   172.16.85.210   k8s-node01   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-vvjg2   1/1     Running   0          2m31s   172.16.85.212   k8s-node01   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-whc7z   1/1     Running   0          5m3s    172.16.58.219   k8s-node02   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-zsgg9   1/1     Running   0          2m31s   172.16.85.209   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h3 id="7-5-查看当前Pod的镜像版本"><a href="#7-5-查看当前Pod的镜像版本" class="headerlink" title="7.5 查看当前Pod的镜像版本"></a>7.5 查看当前Pod的镜像版本</h3><pre><code class="highlight bash">$ <span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span> curl 10.103.97.136; <span class="keyword">done</span>www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0</code></pre><p>当前访问的所有Pod 镜像版本都是 1.0</p><h3 id="7-6-升级-Pod-镜像版本"><a href="#7-6-升级-Pod-镜像版本" class="headerlink" title="7.6 升级 Pod 镜像版本"></a>7.6 升级 Pod 镜像版本</h3><p>新开一个shell终端，执行命令升级镜像版本，前一个shell终端循环访问pod，打印Pod镜像版本信息</p><pre><code class="highlight bash"><span class="comment"># 升级镜像版本，并打印当前pod详细信息</span>$ kubectl <span class="built_in">set</span> image deployment/my-deployment-demo deployment-demo-container=wangyanglinux/myapp:v2.0 --record &amp;&amp; kubectl get pod -l app=deployment-demo -o widedeployment.apps/my-deployment-demo image updatedNAME                                  READY   STATUS              RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESmy-deployment-demo-6465d4c5c9-crrcz   0/1     Pending             0          0s    &lt;none&gt;          k8s-node02   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6465d4c5c9-fckht   0/1     ContainerCreating   0          0s    &lt;none&gt;          k8s-node02   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6465d4c5c9-tkjst   0/1     ContainerCreating   0          0s    &lt;none&gt;          k8s-node01   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-2fg6c   1/1     Running             0          12m   172.16.58.229   k8s-node02   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-bhs4q   1/1     Running             0          11m   172.16.85.221   k8s-node01   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-fj7hf   1/1     Running             0          11m   172.16.85.220   k8s-node01   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-p7bhr   1/1     Running             0          11m   172.16.85.218   k8s-node01   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-qbdmg   1/1     Running             0          11m   172.16.58.230   k8s-node02   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-qprl6   1/1     Running             0          11m   172.16.85.222   k8s-node01   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-qtdbb   1/1     Terminating         0          11m   172.16.58.232   k8s-node02   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-r2xvv   1/1     Running             0          11m   172.16.85.219   k8s-node01   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-sg7vt   1/1     Terminating         0          11m   172.16.58.233   k8s-node02   &lt;none&gt;           &lt;none&gt;my-deployment-demo-6995c75668-wbqn2   1/1     Running             0          11m   172.16.58.231   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>此时Pod正在升级滚动升级中，当前看到共有13个Pod，这是因为Pod在滚动升级的过程中，默认允许新增不超过原设定副本数 25% 副本数量（<code>maxSurge: 25%</code>）。（上面的打印结果有2个Pod的状态是 Terminating，运行中和加载中的Pod数没有超过原设备Pod数的 125%）</p><p>查看前一个shell终端的打印结果如下：</p><pre><code class="highlight bash">w.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v2.0www.xinxianghf.com | hello MyAPP | version v2.0www.xinxianghf.com | hello MyAPP | version v2.0www.xinxianghf.com | hello MyAPP | version v1.0curl: (7) Failed to connect to 10.103.97.136 port 80: Connection refusedwww.xinxianghf.com | hello MyAPP | version v1.0curl: (7) Failed to connect to 10.103.97.136 port 80: Connection refusedwww.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v2.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v2.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0curl: (7) Failed to connect to 10.103.97.136 port 80: Connection refusedcurl: (7) Failed to connect to 10.103.97.136 port 80: Connection refusedwww.xinxianghf.com | hello MyAPP | version v2.0curl: (7) Failed to connect to 10.103.97.136 port 80: Connection refusedwww.xinxianghf.com | hello MyAPP | version v1.0curl: (7) Failed to connect to 10.103.97.136 port 80: Connection refusedwww.xinxianghf.com | hello MyAPP | version v1.0www.xinxianghf.com | hello MyAPP | version v1.0</code></pre><p><strong>可以得出如下结论：</strong></p><ul><li>通过访问 Service 会轮询访问 lable 名称与 Service 名称一样的 Pod</li><li>Pod 正处于滚动升级的过程中，打印的镜像版本有的是 1.0，有的是 2.0，有的处于 Terminating 状态，不可访问</li></ul><h2 id="8-Deloyment-回滚案例实操"><a href="#8-Deloyment-回滚案例实操" class="headerlink" title="8. Deloyment 回滚案例实操"></a>8. Deloyment 回滚案例实操</h2><h3 id="8-1-资源清单"><a href="#8-1-资源清单" class="headerlink" title="8.1 资源清单"></a>8.1 资源清单</h3><p><code>006-deployment-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># 版本号</span><span class="attr">kind:</span> <span class="string">Deployment</span> <span class="comment"># 控制器类型为：Deployment</span><span class="attr">metadata:</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">deployment-demo</span> <span class="comment"># 控制器标签</span>  <span class="attr">name:</span> <span class="string">my-deployment-demo</span> <span class="comment"># 控制器名称</span><span class="attr">spec:</span>  <span class="attr">replicas:</span> <span class="number">1</span> <span class="comment"># 初始Pod副本数</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">app:</span> <span class="string">deployment-demo</span> <span class="comment"># Pod标签选择器，管理 标签为 app: deployment-demo 的Pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">deployment-demo</span> <span class="comment"># Pod的标签，与 selector 标签选择器对应</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">deployment-demo-container</span> <span class="comment"># 容器名称</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span> <span class="comment"># 容器使用的镜像</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取策略</span></code></pre><h3 id="8-2-创建Deployment"><a href="#8-2-创建Deployment" class="headerlink" title="8.2 创建Deployment"></a>8.2 创建Deployment</h3><pre><code class="highlight bash"><span class="comment"># 1.创建 Service</span>$ kubectl create svc clusterip deployment-demo --tcp=80:80<span class="comment"># 查看 Service </span>$ kubectl get svcNAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGEdeployment-demo   ClusterIP   10.103.97.136   &lt;none&gt;        80/TCP    5m53skubernetes        ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   13d<span class="comment"># 2.创建 Deployment ，添加了 --record 会记录操作的命令详情</span>$ kubectl create -f 006-deployment-demo.yaml --record<span class="comment"># 3. 将当前Pod数量从1个，扩容到10个</span>$ kubectl scale deployment my-deployment-demo --replicas 10<span class="comment"># 查看Deployment</span>$ kubectl get deployment -o wide NAME                 READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS                  IMAGES                     SELECTORmy-deployment-demo   10/10   10           10          2m49s   deployment-demo-container   wangyanglinux/myapp:v1.0   app=deployment-demo<span class="comment"># 查看当前 Pod 镜像版本</span>$ curl 10.103.97.136www.xinxianghf.com | hello MyAPP | version v1.0</code></pre><h3 id="8-3-升级镜像"><a href="#8-3-升级镜像" class="headerlink" title="8.3 升级镜像"></a>8.3 升级镜像</h3><pre><code class="highlight bash"><span class="comment"># 1. 将镜像版本升级到 2.0</span>$ kubectl <span class="built_in">set</span> image deployment/my-deployment-demo deployment-demo-container=wangyanglinux/myapp:v2.0 --record<span class="comment"># 测试访问镜像</span>$ curl 10.103.97.136www.xinxianghf.com | hello MyAPP | version v2.0<span class="comment"># 2. 将镜像版本升级到 3.0</span>$ kubectl <span class="built_in">set</span> image deployment/my-deployment-demo deployment-demo-container=wangyanglinux/myapp:v3.0 --record<span class="comment"># 测试访问镜像</span>$ curl 10.103.97.136www.xinxianghf.com | hello MyAPP | version v3.0<span class="comment"># 3. 查看 Deployment 历史版本（创建Deployment、升级镜像命令都添加了 --record 参数，所以CHANGE-CAUSE才有操作记录）</span>$ kubectl rollout <span class="built_in">history</span> deployment/my-deployment-demodeployment.apps/my-deployment-demo REVISION  CHANGE-CAUSE1         kubectl apply --filename=006-deployment-demo.yaml --record=<span class="literal">true</span>2         kubectl <span class="built_in">set</span> image deployment/my-deployment-demo deployment-demo-container=wangyanglinux/myapp:v2.0 --record=<span class="literal">true</span>3         kubectl <span class="built_in">set</span> image deployment/my-deployment-demo deployment-demo-container=wangyanglinux/myapp:v3.0 --record=<span class="literal">true</span></code></pre><h3 id="8-4-回滚镜像版本"><a href="#8-4-回滚镜像版本" class="headerlink" title="8.4 回滚镜像版本"></a>8.4 回滚镜像版本</h3><h4 id="6-4-1-回滚到上一个版本"><a href="#6-4-1-回滚到上一个版本" class="headerlink" title="6.4.1 回滚到上一个版本"></a>6.4.1 回滚到上一个版本</h4><pre><code class="highlight bash"><span class="comment"># 1.回滚到上一个版本（从3.0 -&gt; 2.0）</span>$ kubectl rollout undo deployment/my-deployment-demo<span class="comment"># 测试访问镜像（此时已回滚到 2.0版本）</span>$ curl 10.103.97.136www.xinxianghf.com | hello MyAPP | version v2.0<span class="comment"># 2.再次执行版本回滚</span>$ kubectl rollout undo deployment/my-deployment-demo<span class="comment"># 测试访问镜像（此时又回滚到 3.0版本）</span>$ curl 10.103.97.136www.xinxianghf.com | hello MyAPP | version v3.0</code></pre><p><code>kubectl rollout undo deployment/&lt;deployment-demo&gt;</code> 命令只能回滚到前一次操作，但无法回滚到前前上操作，例如升级操作如下：<br>v1 -&gt; v2 -&gt; v3<br>升级到v3版本后开始回滚：v1 -&gt; v2 -&gt; v3 -&gt; v2 -&gt; v3 -&gt; v2 -&gt; v3 ，<br>这样无法从 v3 -&gt; v1</p><h4 id="8-4-2-回滚到指定版本"><a href="#8-4-2-回滚到指定版本" class="headerlink" title="8.4.2 回滚到指定版本"></a>8.4.2 回滚到指定版本</h4><p>前面的每次升级操作命令，都携带了参数 <code>--record</code> ，此参数会让 kubectl 记录操作命令，通过查看 deployment 历史版本，方便版本回滚。</p><pre><code class="highlight bash"><span class="comment"># 1.查看 Deployment 历史版本（REVISION 就是每次操作后的版本号）</span>$ kubectl rollout <span class="built_in">history</span> deployment/my-deployment-demodeployment.apps/my-deployment-demo REVISION  CHANGE-CAUSE1         kubectl apply --filename=006-deployment-demo.yaml --record=<span class="literal">true</span>4         kubectl <span class="built_in">set</span> image deployment/my-deployment-demo deployment-demo-container=wangyanglinux/myapp:v2.0 --record=<span class="literal">true</span>5         kubectl <span class="built_in">set</span> image deployment/my-deployment-demo deployment-demo-container=wangyanglinux/myapp:v3.0 --record=<span class="literal">true</span><span class="comment"># 2.回滚到 v1.0 版本（通过指定版本号）</span>$ kubectl rollout undo deployment my-deployment-demo --to-revision=1<span class="comment"># 测试访问镜像（此时回滚到 1.0版本）</span>$ curl 10.103.97.136www.xinxianghf.com | hello MyAPP | version v1.0</code></pre><h2 id="9-Deployment-清理策略"><a href="#9-Deployment-清理策略" class="headerlink" title="9. Deployment 清理策略"></a>9. Deployment 清理策略</h2><p>过设置 <code>.spec.revisionHistoryLimit</code> 项来指定 deployment 最多保留多少 revision 历史记录。默认的会保留所有的 revision；如果将该项设置为0，Deployment 就不允许回退了</p><h1 id="四、DaemonSet-控制器"><a href="#四、DaemonSet-控制器" class="headerlink" title="四、DaemonSet 控制器"></a>四、DaemonSet 控制器</h1><h2 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h2><p>在 Kubernetes 中，<strong>DaemonSet</strong> 控制器用于确保集群中的每个节点（或指定节点子集）都运行一个 Pod 副本。通常用于部署系统级别的服务，例如日志收集代理（如 Fluentd、Logstash）、监控代理（如 Prometheus Node Exporter）或网络代理（如 kube-proxy）。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod</p><p>使用 DaemonSet  的一些典型用法：</p><ul><li>运行集群存储 daemon，例如在每个 Node 上运行 <code>glusterd</code>、<code>ceph</code></li><li>在每个 Node 上运行日志收集 daemon，例如<code>fluentd</code>、<code>logstash</code></li><li>在每个 Node 上运行监控 daemon，例如 Prometheus Node Exporter、<code>collectd</code>、Datadog 代理、New Relic 代理，或 Ganglia <code>gmond</code></li></ul><h2 id="2-DaemonSet-的核心特性"><a href="#2-DaemonSet-的核心特性" class="headerlink" title="2. DaemonSet 的核心特性"></a>2. DaemonSet 的核心特性</h2><ul><li><strong>自动调度</strong>：DaemonSet 确保每个符合条件的节点上运行一个 Pod。如果节点被添加或移除，DaemonSet 会自动调整。</li><li><strong>Pod 一致性</strong>：所有 Pod 通常使用相同的 Pod 模板运行。</li><li><strong>节点选择</strong>：可以通过 nodeSelector 或 taints&#x2F;tolerations 控制 DaemonSet 在哪些节点上运行。</li><li><strong>更新策略</strong>：支持 RollingUpdate 和 OnDelete 两种更新策略，默认是 RollingUpdate。</li></ul><h2 id="3-案例演示"><a href="#3-案例演示" class="headerlink" title="3. 案例演示"></a>3. 案例演示</h2><h3 id="3-1-资源清单"><a href="#3-1-资源清单" class="headerlink" title="3.1 资源清单"></a>3.1 资源清单</h3><p><code>007-DaemonSet-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">DaemonSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-daemonset-demo</span> <span class="comment"># DaemonSet 控制器的名字</span>  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment"># 命名空间</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">daemonset-demo</span> <span class="comment"># DaemonSet 控制的标签</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">name:</span> <span class="string">daemonset-demo</span> <span class="comment"># 匹配标签为 name: daemonset-demo 的Pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span> <span class="comment"># Pod模板标签，与 spec.selector.matchLabels 对应</span>        <span class="attr">name:</span> <span class="string">daemonset-demo</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span> <span class="comment"># 主容器</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">daemonset-demo-container</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></code></pre><h3 id="3-1-创建-DaemonSet"><a href="#3-1-创建-DaemonSet" class="headerlink" title="3.1 创建 DaemonSet"></a>3.1 创建 DaemonSet</h3><pre><code class="highlight bash"><span class="comment"># 创建 DaemonSet 控制器</span>$ kubectl apply -f 007-DaemonSet-demo.yaml</code></pre><h3 id="3-2-查看-DeamonSet"><a href="#3-2-查看-DeamonSet" class="headerlink" title="3.2 查看 DeamonSet"></a>3.2 查看 DeamonSet</h3><pre><code class="highlight yaml"><span class="comment"># 查看 DaemonSet (指定了 名称空间、标签)</span><span class="string">$</span> <span class="string">kubectl</span> <span class="string">get</span> <span class="string">ds</span> <span class="string">-n</span> <span class="string">default</span> <span class="string">-l</span> <span class="string">app=daemonset-demo</span> <span class="string">-o</span> <span class="string">wide</span><span class="string">NAME</span>                <span class="string">DESIRED</span>   <span class="string">CURRENT</span>   <span class="string">READY</span>   <span class="string">UP-TO-DATE</span>   <span class="string">AVAILABLE</span>   <span class="string">NODE</span> <span class="string">SELECTOR</span>   <span class="string">AGE</span>    <span class="string">CONTAINERS</span>                 <span class="string">IMAGES</span>                     <span class="string">SELECTOR</span><span class="string">my-daemonset-demo</span>   <span class="number">2</span>         <span class="number">2</span>         <span class="number">2</span>       <span class="number">2</span>            <span class="number">2</span>           <span class="string">&lt;none&gt;</span>          <span class="string">4m5s</span>   <span class="string">daemonset-demo-container</span>   <span class="string">wangyanglinux/myapp:v1.0</span>   <span class="string">name=daemonset-demo</span></code></pre><h3 id="3-3-查看-Pod"><a href="#3-3-查看-Pod" class="headerlink" title="3.3 查看 Pod"></a>3.3 查看 Pod</h3><pre><code class="highlight bash">$ kubectl get pod -n default -o wideNAME                      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESmy-daemonset-demo-kltsf   1/1     Running   0          36s   172.16.58.215   k8s-node02   &lt;none&gt;           &lt;none&gt;my-daemonset-demo-tn554   1/1     Running   0          36s   172.16.85.211   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>DanmonSet 控制器自动创建了两个 Pod，分别运行到两个子节点上（k8s-node01、k8s-node02），而没有运行到 master 节点，这是为什么呢？</p><h3 id="3-4-为什么-DeamonSet-没有运行在主节点上"><a href="#3-4-为什么-DeamonSet-没有运行在主节点上" class="headerlink" title="3.4 为什么 DeamonSet 没有运行在主节点上"></a>3.4 为什么 DeamonSet 没有运行在主节点上</h3><p>在 Kubernetes 中，<strong>DaemonSet 创建的 Pod 默认不会运行到主节点（master 或 control-plane 节点）</strong>，主要是因为主节点通常被配置了<strong>污点（Taints）</strong>，而 DaemonSet 创建的 Pod 没有默认的<strong>容忍（Tolerations）</strong>来匹配这些污点。以下是详细原因及机制：</p><h4 id="3-4-1-主节点的污点（Taints）"><a href="#3-4-1-主节点的污点（Taints）" class="headerlink" title="3.4.1 主节点的污点（Taints）"></a>3.4.1 主节点的污点（Taints）</h4><p>Kubernetes 主节点通常被配置了一个或多个污点，以防止普通的工作负载（包括 DaemonSet 的 Pod）调度到这些节点上。常见的污点是：</p><ul><li><strong>node-role.kubernetes.io&#x2F;master:NoSchedule</strong>（Kubernetes 1.24 及更早版本）</li><li><strong>node-role.kubernetes.io&#x2F;control-plane:NoSchedule</strong>（Kubernetes 1.25 及更新版本）</li></ul><p>这些污点的效果是 NoSchedule，表示除非 Pod 明确声明可以容忍该污点，否则不会被调度到主节点。</p><p>查看主节点污点：</p><pre><code class="highlight bash">kubectl describe node &lt;master-node-name&gt; | grep -i taint</code></pre><p>示例输出：</p><pre><code class="highlight bash">Taints:             node-role.kubernetes.io/control-plane:NoSchedule</code></pre><h3 id="3-4-2-DaemonSet-Pod-的容忍（Tolerations）"><a href="#3-4-2-DaemonSet-Pod-的容忍（Tolerations）" class="headerlink" title="3.4.2 DaemonSet Pod 的容忍（Tolerations）"></a>3.4.2 DaemonSet Pod 的容忍（Tolerations）</h3><p>DaemonSet 的 Pod 模板（spec.template.spec）默认不包含任何 tolerations。这意味着它们无法绕过主节点的 NoSchedule 污点，因此不会被调度到主节点。</p><p>例如资源清单 <code>007-DaemonSet-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">DaemonSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-daemonset-demo</span> <span class="comment"># DaemonSet 控制器的名字</span>  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment"># 命名空间</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">daemonset-demo</span> <span class="comment"># DaemonSet 控制的标签</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">name:</span> <span class="string">daemonset-demo</span> <span class="comment"># 匹配标签为 name: daemonset-demo 的Pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span> <span class="comment"># Pod模板标签，与 spec.selector.matchLabels 对应</span>        <span class="attr">name:</span> <span class="string">daemonset-demo</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span> <span class="comment"># 主容器</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">daemonset-demo-container</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></code></pre><p>在这个配置中，spec.template.spec 没有定义 tolerations，因此 Pod 不会调度到带有 NoSchedule 污点的主节点。</p><h4 id="3-4-3-为什么主节点需要污点？"><a href="#3-4-3-为什么主节点需要污点？" class="headerlink" title="3.4.3 为什么主节点需要污点？"></a>3.4.3 为什么主节点需要污点？</h4><p>主节点运行控制平面组件（如 kube-apiserver、kube-scheduler、kube-controller-manager），这些组件对集群的稳定性至关重要。允许普通工作负载（如 DaemonSet 的 Pod）运行在主节点可能会导致以下问题：</p><ul><li><strong>资源竞争</strong>：DaemonSet Pod 可能消耗 CPU、内存等资源，影响控制平面组件的性能。</li><li><strong>稳定性风险</strong>：某些 DaemonSet Pod（例如日志收集或监控代理）可能出现异常，干扰主节点的运行。</li><li><strong>安全隔离</strong>：主节点通常需要更高的隔离级别，避免不受信任的工作负载运行。</li></ul><p>因此，Kubernetes 默认通过污点机制保护主节点，只允许特定的、必要的 Pod（如控制平面组件或特定的系统 DaemonSet）运行。</p><h4 id="3-4-4-例外情况：系统-DaemonSet"><a href="#3-4-4-例外情况：系统-DaemonSet" class="headerlink" title="3.4.4 例外情况：系统 DaemonSet"></a>3.4.4 例外情况：系统 DaemonSet</h4><p>某些系统级的 DaemonSet（如 kube-proxy、CNI 插件）确实需要运行在所有节点上，包括主节点。这些 DaemonSet 的 YAML 通常会显式配置 tolerations 来容忍主节点的污点。例如：</p><pre><code class="highlight yaml"><span class="attr">spec:</span>  <span class="attr">template:</span>    <span class="attr">spec:</span>      <span class="attr">tolerations:</span>      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/control-plane</span>        <span class="attr">operator:</span> <span class="string">Exists</span>        <span class="attr">effect:</span> <span class="string">NoSchedule</span>      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span>        <span class="attr">operator:</span> <span class="string">Exists</span>        <span class="attr">effect:</span> <span class="string">NoSchedule</span></code></pre><p>这种配置允许 Pod 忽略主节点的污点，从而调度到主节点。</p><h4 id="3-4-5-如何让-DaemonSet-Pod-运行在主节点？"><a href="#3-4-5-如何让-DaemonSet-Pod-运行在主节点？" class="headerlink" title="3.4.5 如何让 DaemonSet Pod 运行在主节点？"></a>3.4.5 如何让 DaemonSet Pod 运行在主节点？</h4><p>如果你希望 DaemonSet 的 Pod 运行在主节点上，可以在 DaemonSet 的 Pod 模板中添加相应的 tolerations。</p><p><strong>查看节点列表</strong></p><pre><code class="highlight bash">$ kubectl get nodes --show-labelsNAME         STATUS   ROLES           AGE   VERSION    LABELSk8s-node01   Ready    &lt;none&gt;          14d   v1.29.15   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node01,kubernetes.io/os=linuxk8s-node02   Ready    &lt;none&gt;          14d   v1.29.15   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node02,kubernetes.io/os=linuxnode         Ready    control-plane   14d   v1.29.15   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node.kubernetes.io/exclude-from-external-load-balancers=</code></pre><p>可以看到有三个节点，其中 name为 node 的就是 master 节点，因为该节点的标签中包含：<code>node-role.kubernetes.io/control-plane</code></p><p><strong>查看 master 节点详情</strong></p><pre><code class="highlight bash">$ kubectl describe nodes nodeName:               nodeRoles:              control-planeLabels:             beta.kubernetes.io/arch=amd64                    beta.kubernetes.io/os=linux                    kubernetes.io/arch=amd64                    kubernetes.io/hostname=node                    kubernetes.io/os=linux                    node-role.kubernetes.io/control-plane=                    node.kubernetes.io/exclude-from-external-load-balancers=Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock                    node.alpha.kubernetes.io/ttl: 0                    projectcalico.org/IPv4Address: 192.168.6.139/24                    projectcalico.org/IPv4IPIPTunnelAddr: 172.16.167.128                    volumes.kubernetes.io/controller-managed-attach-detach: <span class="literal">true</span>CreationTimestamp:  Fri, 28 Mar 2025 17:24:27 +0800<span class="comment"># Node自身设置的污点，key为node-role.kubernetes.io/control-plane，影响效果：:NoSchedule(不是key的值)</span>Taints:             node-role.kubernetes.io/control-plane:NoScheduleUnschedulable:      <span class="literal">false</span>Lease:  HolderIdentity:  node  AcquireTime:     &lt;<span class="built_in">unset</span>&gt;  RenewTime:       Sat, 12 Apr 2025 14:07:56 +0800...</code></pre><p><strong>资源清单内容如下：</strong><br><code>008-DaemonSet-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span><span class="attr">kind:</span> <span class="string">DaemonSet</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">my-daemonset-demo</span> <span class="comment"># DaemonSet 控制器的名字</span>  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment"># 命名空间</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">daemonset-demo</span> <span class="comment"># DaemonSet 控制的标签</span><span class="attr">spec:</span>  <span class="attr">selector:</span>    <span class="attr">matchLabels:</span>      <span class="attr">name:</span> <span class="string">daemonset-demo</span> <span class="comment"># 匹配标签为 name: daemonset-demo 的Pod</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">labels:</span> <span class="comment"># Pod模板标签，与 spec.selector.matchLabels 对应</span>        <span class="attr">name:</span> <span class="string">daemonset-demo</span>    <span class="attr">spec:</span>      <span class="attr">tolerations:</span> <span class="comment"># 定义了 Pod 的容忍度，允许 Pod 被调度到带有特定污点的节点上</span>        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/control-plane</span> <span class="comment"># 这里允许 Pod 被调度到控制平面节点（通常有 node-role.kubernetes.io/control-plane:NoSchedule 污点）</span>          <span class="attr">operator:</span> <span class="string">Exists</span> <span class="comment"># 表示只要存在指定的 key 就容忍(Exists：只要节点上有这个键的污点就匹配（不需要检查值）, 如果是Equal：要求键和值都匹配（此时需要指定 value 字段）)</span>          <span class="attr">effect:</span> <span class="string">NoSchedule</span> <span class="comment"># 指定要容忍污点的影响效果</span>      <span class="attr">containers:</span> <span class="comment"># 主容器</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">daemonset-demo-container</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></code></pre><p><strong>创建 DaemonSet</strong></p><pre><code class="highlight bash"><span class="comment"># 创建DS</span>$ kubectl apply -f 008-DaemonSet-demo.yaml --record<span class="comment"># 查看DS，可以看到DS运行了三个 Pod</span>$ kubectl get ds -o wideNAME                DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE     CONTAINERS                 IMAGES                     SELECTORmy-daemonset-demo   3         3         3       3            3           &lt;none&gt;          2m33s   daemonset-demo-container   wangyanglinux/myapp:v1.0   name=daemonset-demo<span class="comment"># 查看Pod（master节点也运行了一个Pod）</span>$ kubectl get pods -o wideNAME                      READY   STATUS    RESTARTS   AGE   IP                NODE         NOMINATED NODE   READINESS GATESmy-daemonset-demo-gsjlk   1/1     Running   0          11s   192.168.167.141   node         &lt;none&gt;           &lt;none&gt;my-daemonset-demo-j5nls   1/1     Running   0          11s   192.168.58.200    k8s-node02   &lt;none&gt;           &lt;none&gt;my-daemonset-demo-vv9cf   1/1     Running   0          11s   192.168.85.204    k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p><strong>查看Pod</strong></p><pre><code class="highlight bash"><span class="comment"># 查看 DaemonSet，此时 DeamonSet 控制器有了三个Pod</span>$ kubectl get ds -o wideNAME                DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE    CONTAINERS                 IMAGES                     SELECTORmy-daemonset-demo   3         3         3       3            3           &lt;none&gt;          135m   daemonset-demo-container   wangyanglinux/myapp:v1.0   name=daemonset-demo<span class="comment"># 查看 Pod</span>$ kubectl get pods -o wideNAME                      READY   STATUS    RESTARTS       AGE    IP                NODE         NOMINATED NODE   READINESS GATESmy-daemonset-demo-gsjlk   1/1     Running   1 (129m ago)   137m   192.168.167.142   node         &lt;none&gt;           &lt;none&gt;my-daemonset-demo-j5nls   1/1     Running   1 (129m ago)   137m   192.168.58.201    k8s-node02   &lt;none&gt;           &lt;none&gt;my-daemonset-demo-vv9cf   1/1     Running   1 (129m ago)   137m   192.168.85.205    k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>master 节点上也运行了一个 Pod，资源清单配置生效。</p><h1 id="五、Job-控制器"><a href="#五、Job-控制器" class="headerlink" title="五、Job 控制器"></a>五、Job 控制器</h1><h2 id="1-Job-控制器特性"><a href="#1-Job-控制器特性" class="headerlink" title="1. Job 控制器特性"></a>1. Job 控制器特性</h2><p>Job 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束</p><p><strong>特殊说明</strong></p><ul><li>spec.template 格式同 Pod</li><li>RestartPolicy 仅支持 Never 或 OnFailure</li><li>单个 Pod 时，默认 Pod 成功运行后 Job 即结束</li><li><code>.spec.completions</code> 标志 Job 结束需要成功运行的 Pod 个数，默认为 1</li><li><code>.spec.parallelism</code> 标志并行运行的 Pod 的个数，默认为 1</li><li><code>spec.activeDeadlineSeconds</code> 设置了 Job 的最长活动时间（单位：秒）。这个计时器从 Job 被创建时开始计时：<ul><li><strong>超时强制终止</strong>：如果 Job 运行时间超过 10 秒（包括 Pod 创建、执行、重试等所有时间），整个 Job 会被 Kubernetes 强制终止。</li><li><strong>状态标记</strong>：超时后 Job 的状态会变为 <code>Failed</code>，并显示原因 <code>Reason: DeadlineExceeded</code>。</li></ul></li></ul><h2 id="2-案例演示"><a href="#2-案例演示" class="headerlink" title="2. 案例演示"></a>2. 案例演示</h2><p>求 π 值，算法：马青公式</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/04/13/20250413-211253.png" alt="马青公式"></p><p>这个公式由英国天文学教授 约翰·马青 于 1706 年发现。他利用这个公式计算到了 100 位的圆周率。马青公式每计算一项可以得到 1.4 位的 十进制精度。因为它的计算过程中被乘数和被除数都不大于长整数，所以可以很容易地在计算机上编程实现</p><h3 id="2-1-Python代码"><a href="#2-1-Python代码" class="headerlink" title="2.1 Python代码"></a>2.1 Python代码</h3><p><code>main.py</code></p><pre><code class="highlight python"><span class="comment"># -*- coding: utf-8 -*-</span><span class="keyword">from</span> __future__ <span class="keyword">import</span> division<span class="comment"># 导入时间模块</span><span class="keyword">import</span> time<span class="comment"># 计算当前时间</span>time1=time.time()<span class="comment"># 算法根据马青公式计算圆周率 #</span>number = <span class="number">1000</span><span class="comment"># 多计算10位，防止尾数取舍的影响</span>number1 = number+<span class="number">10</span><span class="comment"># 算到小数点后number1位</span>b = <span class="number">10</span>**number1<span class="comment"># 求含4/5的首项</span>x1 = b*<span class="number">4</span>//<span class="number">5</span><span class="comment"># 求含1/239的首项</span>x2 = b // -<span class="number">239</span><span class="comment"># 求第一大项</span>he = x1+x2<span class="comment">#设置下面循环的终点，即共计算n项</span>number *= <span class="number">2</span><span class="comment">#循环初值=3，末值2n,步长=2</span><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">3</span>,number,<span class="number">2</span>):  <span class="comment"># 求每个含1/5的项及符号</span>  x1 //= -<span class="number">25</span>  <span class="comment"># 求每个含1/239的项及符号</span>  x2 //= -<span class="number">57121</span>  <span class="comment"># 求两项之和</span>  x = (x1+x2) // i  <span class="comment"># 求总和</span>  he += x<span class="comment"># 求出π</span>pai = he*<span class="number">4</span><span class="comment">#舍掉后十位</span>pai //= <span class="number">10</span>**<span class="number">10</span><span class="comment"># 输出圆周率π的值</span>paistring=<span class="built_in">str</span>(pai)result=paistring[<span class="number">0</span>]+<span class="built_in">str</span>(<span class="string">&#x27;.&#x27;</span>)+paistring[<span class="number">1</span>:<span class="built_in">len</span>(paistring)]<span class="built_in">print</span> resulttime2=time.time()<span class="built_in">print</span> <span class="string">u&#x27;Total time:&#x27;</span> + <span class="built_in">str</span>(time2 - time1) + <span class="string">&#x27;s&#x27;</span></code></pre><h3 id="2-2-Dockerfile"><a href="#2-2-Dockerfile" class="headerlink" title="2.2 Dockerfile"></a>2.2 Dockerfile</h3><pre><code class="highlight dockerfile"><span class="keyword">FROM</span> python:<span class="number">2.7</span><span class="keyword">ADD</span><span class="language-bash"> ./main.py /root</span><span class="keyword">CMD</span><span class="language-bash"> /usr/bin/python /root/main.py</span></code></pre><h3 id="2-3-构建镜像"><a href="#2-3-构建镜像" class="headerlink" title="2.3 构建镜像"></a>2.3 构建镜像</h3><pre><code class="highlight bash"><span class="comment"># 将 main.py 放到 Dockerfile 同级目录下，并在此目录执行下面的命令构建镜像</span>docker build -t tools:maqingpythonv1 .</code></pre><h3 id="2-4-资源清单"><a href="#2-4-资源清单" class="headerlink" title="2.4 资源清单"></a>2.4 资源清单</h3><p><code>009-job-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span><span class="attr">kind:</span> <span class="string">Job</span> <span class="comment"># Job控制器资源类型</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">job-demo</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">my-job</span><span class="attr">spec:</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">name:</span> <span class="string">my-job-pod</span>      <span class="attr">labels:</span>        <span class="attr">app:</span> <span class="string">my-job</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">job-demo-container</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/tools:maqingpythonv1</span>      <span class="attr">restartPolicy:</span> <span class="string">Never</span> <span class="comment"># 对于 Job 控制器，容器重启策略仅支持 Never 和 OnFailure</span></code></pre><p>查看日志，可以显示出打印的 2000 位  π 值</p><h3 id="2-5-运行Pod，查看日志"><a href="#2-5-运行Pod，查看日志" class="headerlink" title="2.5 运行Pod，查看日志"></a>2.5 运行Pod，查看日志</h3><p><strong>运行Pod</strong></p><pre><code class="highlight bash"><span class="comment"># 运行job控制器</span>$ kubectl apply -f 009-job-demo.yaml</code></pre><p><strong>查看Job运行状态</strong></p><pre><code class="highlight bash"><span class="comment"># 查看job列表</span>$ kubectl get jobNAME       COMPLETIONS   DURATION   AGEjob-demo   1/1           3s         6m48s<span class="comment"># 查看Job详情</span>$ kubectl describe job job-demoName:             job-demoNamespace:        defaultSelector:         batch.kubernetes.io/controller-uid=ea1dec0d-b8d4-4942-8b72-2d3ac0abde91Labels:           app=my-jobAnnotations:      &lt;none&gt;Parallelism:      1Completions:      1Completion Mode:  NonIndexedStart Time:       Thu, 17 Apr 2025 21:32:13 +0800Completed At:     Thu, 17 Apr 2025 21:32:16 +0800Duration:         3sPods Statuses:    0 Active (0 Ready) / 1 Succeeded / 0 FailedPod Template:  Labels:  app=my-job           batch.kubernetes.io/controller-uid=ea1dec0d-b8d4-4942-8b72-2d3ac0abde91           batch.kubernetes.io/job-name=job-demo           controller-uid=ea1dec0d-b8d4-4942-8b72-2d3ac0abde91           job-name=job-demo  Containers:   job-demo-container:    Image:        wangyanglinux/tools:maqingpythonv1    Port:         &lt;none&gt;    Host Port:    &lt;none&gt;    Environment:  &lt;none&gt;    Mounts:       &lt;none&gt;  Volumes:        &lt;none&gt;Events:  Type    Reason            Age    From            Message  ----    ------            ----   ----            -------  Normal  SuccessfulCreate  6m25s  job-controller  Created pod: job-demo-6q4sh  Normal  Completed         6m22s  job-controller  Job completed</code></pre><p>通过查看Job详情，观察到 Job 已运行完成</p><p><strong>查看Pod列表</strong></p><pre><code class="highlight bash">$ kubectl get pods -o wideNAME             READY   STATUS      RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESjob-demo-6q4sh   0/1     Completed   0          7m58s   172.16.58.217   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p><strong>查看Pod运行日志</strong></p><pre><code class="highlight bash">$ kubectl logs job-demo-6q4sh -f --<span class="built_in">tail</span>=10003.141592653589793238462643383279502884197169399375105820974944592307816406286208998628034825342117067982148086513282306647093844609550582231725359408128481117450284102701938521105559644622948954930381964428810975665933446128475648233786783165271201909145648566923460348610454326648213393607260249141273724587006606315588174881520920962829254091715364367892590360011330530548820466521384146951941511609433057270365759591953092186117381932611793105118548074462379962749567351885752724891227938183011949129833673362440656643086021394946395224737190702179860943702770539217176293176752384674818467669405132000568127145263560827785771342757789609173637178721468440901224953430146549585371050792279689258923542019956112129021960864034418159813629774771309960518707211349999998372978049951059731732816096318595024459455346908302642522308253344685035261931188171010003137838752886587533208381420617177669147303598253490428755468731159562863882353787593751957781857780532171226806613001927876611195909216420198</code></pre><p>打印出了圆周率！！！</p><h2 id="3-Job-正常退出完成"><a href="#3-Job-正常退出完成" class="headerlink" title="3. Job - 正常退出完成"></a>3. Job - 正常退出完成</h2><p>Job 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束</p><h3 id="3-1-案例一：让容器返回码为1"><a href="#3-1-案例一：让容器返回码为1" class="headerlink" title="3.1 案例一：让容器返回码为1"></a>3.1 案例一：让容器返回码为1</h3><p>目的：指定容器退出的返回码为1，验证当返回码不为0时，Job会异常退出。</p><p><code>010-job-rand-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span><span class="attr">kind:</span> <span class="string">Job</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">rand</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">completions:</span> <span class="number">1</span> <span class="comment"># 标志Job结束需要成功运行的 Pod 个数，默认为1</span>  <span class="attr">parallelism:</span> <span class="number">5</span> <span class="comment"># 标志并行运行的Pod的个数，默认为1</span>  <span class="comment"># activeDeadlineSeconds: 10 # 标志失败Pod 的重试最大时间，由于Pod重启策略为Never，因此超过 10秒，整个Pod强制中止</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">name:</span> <span class="string">rand</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">rand</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/tools:randexitv1</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>          <span class="comment"># 指定退出码</span>          <span class="attr">args:</span> [<span class="string">&quot;--exitcode=1&quot;</span>]      <span class="attr">restartPolicy:</span> <span class="string">Never</span></code></pre><p><strong>运行Pod，查看结果</strong></p><pre><code class="highlight bash">$ kubectl apply -f 010-job-rand-demo.yaml</code></pre><p><strong>监控Pod运行结果</strong></p><pre><code class="highlight bash">$ kubectl get pod -o wide -wNAME         READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESrand-4ftcj   0/1     Error     0          27s   172.16.58.225   k8s-node02   &lt;none&gt;           &lt;none&gt;rand-76fkv   1/1     Running   0          2s    172.16.58.224   k8s-node02   &lt;none&gt;           &lt;none&gt;rand-zd9bp   0/1     Error     0          42s   172.16.58.228   k8s-node02   &lt;none&gt;           &lt;none&gt;rand-76fkv   0/1     Error     0          6s    172.16.58.224   k8s-node02   &lt;none&gt;           &lt;none&gt;rand-76fkv   0/1     Error     0          7s    172.16.58.224   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>上面的Pod监控列表，一个Pod处于运行中，两个返回都是失败（运行中的Pod也会返回失败，因为在资源清单中制定了返回码为 1）。</p><p>由于在资源清单中指定了容器退出返回码为1，所以此清单创建的所有Pod都会返回失败。</p><p><strong>查看Pod日志</strong></p><pre><code class="highlight bash">$ kubectl logs rand-4ftcj -f --<span class="built_in">tail</span>=100休眠 4 秒，返回码为 1！$ kubectl logs rand-76fkv -f --<span class="built_in">tail</span>=100休眠 4 秒，返回码为 1！</code></pre><p>结论：只有当Pod容器返回码不为0为，Pod异常退出。</p><h3 id="3-2-案例二：随机生成返回码"><a href="#3-2-案例二：随机生成返回码" class="headerlink" title="3.2 案例二：随机生成返回码"></a>3.2 案例二：随机生成返回码</h3><p>目的：当Pod容器返回码为1是，Pod成功退出。</p><p><code>011-job-rand-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span><span class="attr">kind:</span> <span class="string">Job</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">rand</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">completions:</span> <span class="number">3</span> <span class="comment"># 标志Job结束需要成功运行的 Pod 个数，默认为1</span>  <span class="attr">parallelism:</span> <span class="number">5</span> <span class="comment"># 标志并行运行的Pod的个数，默认为1</span>  <span class="attr">template:</span>    <span class="attr">metadata:</span>      <span class="attr">name:</span> <span class="string">rand</span>    <span class="attr">spec:</span>      <span class="attr">containers:</span>        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">rand</span>          <span class="attr">image:</span> <span class="string">wangyanglinux/tools:randexitv1</span>          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">restartPolicy:</span> <span class="string">Never</span></code></pre><p><strong>运行Pod，查看结果</strong></p><pre><code class="highlight bash"><span class="comment"># 运行Pod</span>$ kubectl apply -f 011-job-rand-demo.yaml</code></pre><p><strong>查看Pod运行列表</strong></p><pre><code class="highlight bash">$ kubectl get podsNAME         READY   STATUS    RESTARTS   AGErand-4jcmh   1/1     Running   0          5srand-dfnf9   1/1     Running   0          5srand-sh9vp   1/1     Running   0          5s</code></pre><p>有3个Pod 并行运行，符合资源清单设置内容 <code>spec.parallelism: 5</code></p><p><strong>等待Job运行结束后，再次查看Pod列表</strong></p><pre><code class="highlight bash">$ kubectl get pod -o wideNAME         READY   STATUS      RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATESrand-4jcmh   0/1     Error       0          4m43s   172.16.58.238   k8s-node02   &lt;none&gt;           &lt;none&gt;rand-8kwhc   0/1     Completed   0          4m25s   172.16.58.242   k8s-node02   &lt;none&gt;           &lt;none&gt;rand-dfnf9   0/1     Completed   0          4m43s   172.16.58.229   k8s-node02   &lt;none&gt;           &lt;none&gt;rand-hk9lw   0/1     Completed   0          4m25s   172.16.58.239   k8s-node02   &lt;none&gt;           &lt;none&gt;rand-sh9vp   0/1     Error       0          4m43s   172.16.85.215   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>一共运行了5个Pod，其中3个运行完成，2个返回失败</p><p><strong>查看Job</strong></p><pre><code class="highlight bash">$ kubectl get job -o wideNAME   COMPLETIONS   DURATION   AGE   CONTAINERS   IMAGES                           SELECTORrand   3/3           26s        48s   rand         wangyanglinux/tools:randexitv1   batch.kubernetes.io/controller-uid=76957688-7f47-4694-a451-9adfb4f9c9cd</code></pre><p>Job 有3个Pod 运行完成，成功退出，满足资源清单设置要求：<code>spec.completions: 3</code></p><h1 id="六、CronJob-控制器"><a href="#六、CronJob-控制器" class="headerlink" title="六、CronJob 控制器"></a>六、CronJob 控制器</h1><h2 id="1-CronJob-控制器特性"><a href="#1-CronJob-控制器特性" class="headerlink" title="1. CronJob 控制器特性"></a>1. CronJob 控制器特性</h2><p>Cron Job  管理基于时间的 Job，即： </p><ul><li><p>在给定时间点只运行一次</p></li><li><p>周期性地在给定时间点运行</p></li></ul><p><strong>使用条件：当前使用的 Kubernetes 集群，版本 &gt;&#x3D; 1.8（对 CronJob）</strong></p><p>典型的用法如下所示：</p><ul><li>在给定的时间点调度 Job 运行</li><li>创建周期性运行的 Job，例如：数据库备份、发送邮件</li></ul><h2 id="2-CroneJob-资源清单"><a href="#2-CroneJob-资源清单" class="headerlink" title="2. CroneJob 资源清单"></a>2. CroneJob 资源清单</h2><ul><li><p><code>.spec.schedule</code>：调度，必需字段，指定任务运行周期，格式同 Cron</p></li><li><p><code>.spec.jobTemplate</code>：Job 模板，必需字段，指定需要运行的任务，格式同 Job</p></li><li><p><code>.spec.startingDeadlineSeconds</code> ：启动 Job 的期限（秒级别），该字段是可选的。如果因为任何原因而错过了被调度的时间，那么错过执行时间的 Job 将被认为是失败的。如果没有指定，则没有期限</p></li><li><p><code>.spec.concurrencyPolicy</code>：并发策略，该字段也是可选的。它指定了如何处理被 Cron Job 创建的 Job 的并发执行。只允许指定下面策略中的一种：</p><ul><li><code>Allow</code>（默认）：允许并发运行 Job</li><li><code>Forbid</code>：禁止并发运行，如果前一个还没有完成，则直接跳过下一个</li><li><code>Replace</code>：取消当前正在运行的 Job，用一个新的来替换</li><li>注意，当前策略只能应用于同一个 Cron Job 创建的 Job。如果存在多个 Cron Job，     它们创建的 Job 之间总是允许并发运行。</li></ul></li><li><p><code>.spec.suspend</code> ：挂起，该字段也是可选的。如果设置为 <code>true</code>，后续所有执行都会被挂起。它对已经开始执行的 Job 不起作用。默认值为 <code>false</code></p></li><li><p><code>.spec.successfulJobsHistoryLimit</code> 和 <code>.spec.failedJobsHistoryLimit</code> ：历史限制，是可选的字段。它们指定了可以保留多少完成和失败的 Job。默认情况下，它们分别设置为 <code>3</code> 和 <code>1</code>。设置限制的值为 <code>0</code>，相关类型的 Job 完成后将不会被保留</p></li></ul><h2 id="3-案例演示-1"><a href="#3-案例演示-1" class="headerlink" title="3. 案例演示"></a>3. 案例演示</h2><h3 id="3-1-资源清单-1"><a href="#3-1-资源清单-1" class="headerlink" title="3.1 资源清单"></a>3.1 资源清单</h3><p><code>012-cronjob-demo.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span><span class="attr">kind:</span> <span class="string">CronJob</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">cronjob-demo</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="comment"># 调度，必需字段，指定任务运行周期，格式同 Cron</span>  <span class="attr">schedule:</span> <span class="string">&quot;*/1 * * * *&quot;</span> <span class="comment"># 每分钟执行一次</span>  <span class="attr">startingDeadlineSeconds:</span> <span class="number">30</span> <span class="comment"># 启动 Job 的期限（秒级别），该字段是可选的。如果因为任何原因而错过了被调度的时间，那么错过执行时间的 Job 将被认为是失败的。如果没有指定，则没有期限</span>  <span class="attr">concurrencyPolicy:</span> <span class="string">Allow</span> <span class="comment"># 并发策略，该字段也是可选的。（默认）允许并发运行 Job</span>  <span class="attr">successfulJobsHistoryLimit:</span> <span class="number">10</span> <span class="comment"># 保留运行成功的job数，默认：3</span>  <span class="attr">failedJobsHistoryLimit:</span> <span class="number">3</span> <span class="comment">#保留云心告失败的Job数，默认：1</span>  <span class="comment"># Job 模板，必需字段，指定需要运行的任务，格式同 Job</span>  <span class="attr">jobTemplate:</span>    <span class="attr">spec:</span>      <span class="attr">completions:</span> <span class="number">3</span> <span class="comment"># 标志Job结束需要成功运行的 Pod 个数，默认为1</span>      <span class="attr">parallelism:</span> <span class="number">3</span> <span class="comment"># 标志并行运行的Pod的个数，默认为1</span>      <span class="attr">template:</span>        <span class="attr">spec:</span>          <span class="attr">containers:</span>            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cronjob-demo-container</span>              <span class="attr">image:</span> <span class="string">busybox</span>              <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>              <span class="attr">args:</span>                <span class="bullet">-</span> <span class="string">/bin/sh</span>                <span class="bullet">-</span> <span class="string">-c</span>                <span class="bullet">-</span> <span class="string">date;</span> <span class="string">echo</span> <span class="string">Hello</span> <span class="string">from</span> <span class="string">the</span> <span class="string">Kubernetes</span> <span class="string">cluster</span>          <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span> <span class="comment">#  重启策略：失败重启</span></code></pre><h3 id="启动-CronJob"><a href="#启动-CronJob" class="headerlink" title="启动 CronJob"></a>启动 CronJob</h3><pre><code class="highlight bash">$ kubectl apply -f 012-cronjob-demo.yaml</code></pre><p><strong>查看结果</strong></p><pre><code class="highlight bash"><span class="comment"># 查看Pod运行列表，完成了3个Pod</span>$ kubectl get pods -o wideNAME                          READY   STATUS      RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATEScronjob-demo-29082370-8zl5f   0/1     Completed   0          15s   172.16.58.244   k8s-node02   &lt;none&gt;           &lt;none&gt;cronjob-demo-29082370-ht2mk   0/1     Completed   0          15s   172.16.85.217   k8s-node01   &lt;none&gt;           &lt;none&gt;cronjob-demo-29082370-mm7kc   0/1     Completed   0          15s   172.16.58.247   k8s-node02   &lt;none&gt;           &lt;none&gt;<span class="comment"># 查看 cronjob 控制器（cronjob 每分钟都会执行一次）</span>$ kubectl get cronjob -o wideNAME           SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE     CONTAINERS               IMAGES    SELECTORcronjob-demo   */1 * * * *   False     0        52s             2m14s   cronjob-demo-container   busybox   &lt;none&gt;<span class="comment"># 过一会再次查看Pod列表，又多了三个Pod，因为 cronjob 设置每次完成需要 3个pod，spec.completions: 3</span>$ kubectl get pods -o wideNAME                          READY   STATUS      RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATEScronjob-demo-29082370-8zl5f   0/1     Completed   0          114s   172.16.58.244   k8s-node02   &lt;none&gt;           &lt;none&gt;cronjob-demo-29082370-ht2mk   0/1     Completed   0          114s   172.16.85.217   k8s-node01   &lt;none&gt;           &lt;none&gt;cronjob-demo-29082370-mm7kc   0/1     Completed   0          114s   172.16.58.247   k8s-node02   &lt;none&gt;           &lt;none&gt;cronjob-demo-29082371-68kdz   0/1     Completed   0          54s    172.16.58.243   k8s-node02   &lt;none&gt;           &lt;none&gt;cronjob-demo-29082371-9b5j6   0/1     Completed   0          54s    172.16.58.251   k8s-node02   &lt;none&gt;           &lt;none&gt;cronjob-demo-29082371-cf2dg   0/1     Completed   0          54s    172.16.85.216   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h2 id="4-CronJob-限制"><a href="#4-CronJob-限制" class="headerlink" title="4. CronJob - 限制"></a>4. CronJob - 限制</h2><p><strong>创建 Job 操作应该是幂等的</strong></p><h1 id="七、StatefulSet-控制器"><a href="#七、StatefulSet-控制器" class="headerlink" title="七、StatefulSet 控制器"></a>七、StatefulSet 控制器</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、控制器概述&quot;&gt;&lt;a href=&quot;#一、控制器概述&quot; class=&quot;headerlink&quot; title=&quot;一、控制器概述&quot;&gt;&lt;/a&gt;一、控制器概述&lt;/h1&gt;&lt;h2 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; titl</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
  <entry>
    <title>004-Pod的生命周期</title>
    <link href="https://georgechan95.github.io/blog/79e06aab.html"/>
    <id>https://georgechan95.github.io/blog/79e06aab.html</id>
    <published>2025-03-22T01:05:00.000Z</published>
    <updated>2025-04-02T03:28:05.700Z</updated>
    
    <content type="html"><![CDATA[<p><strong>系统环境</strong></p><blockquote><p>RockyLinux：9.3</p><p>K8s版本：1.29</p><p>Docker版本：27.4.1</p></blockquote><h1 id="1、Pod生命周期概述"><a href="#1、Pod生命周期概述" class="headerlink" title="1、Pod生命周期概述"></a>1、Pod生命周期概述</h1><p>Pod 的生命周期如下图：</p><p><img src="https://raw.githubusercontent.com/GeorgeChan95/blogimg/master/img/2025/03/22/20250322-103306.png" alt="Pod 的生命周期"></p><h1 id="2、initC"><a href="#2、initC" class="headerlink" title="2、initC"></a>2、initC</h1><h2 id="2-1-initC概述"><a href="#2-1-initC概述" class="headerlink" title="2.1 initC概述"></a>2.1 initC概述</h2><p>init 容器与普通的容器非常像，除了如下三点：</p><ul><li>init 容器总是运行到成功完成为止</li><li>每个 init 容器都必须在下一个 init 容器启动之前成功完成</li><li>initC 无法定义 readinessProbe，其它以外同应用容器定义无异</li></ul><p>如果 Pod 的 Init 容器失败，Kubernetes 会不断地重启该 Pod，直到 Init 容器成功为止。然而，如果 Pod 对应的 restartPolicy 为 Never，它不会重新启动</p><p>在主容器 [mainC] 启动前,可以定义 initC 作为前置容器，用于检测主容器所需要的环境是否已准备完成(当然initC的定义不是必须的)。当在配置中定义了 initC ，则必须所有的initC都启动完成后，mainC 才能启动，否则 mainC 会一直处于阻塞中。</p><p>另外 initC 会按照 yaml文件中定义的顺序启动，只有当第一个 initC 容器启动完成后，第二个 initC 才能启动，否则第二个 initC 也会处于阻塞中。</p><p>下面是 initC 阻塞性检测的示例：</p><h2 id="2-2-pod-yaml文件"><a href="#2-2-pod-yaml文件" class="headerlink" title="2.2 pod yaml文件"></a>2.2 pod yaml文件</h2><h3 id="2-2-1-yaml文件内容"><a href="#2-2-1-yaml文件内容" class="headerlink" title="2.2.1 yaml文件内容"></a>2.2.1 yaml文件内容</h3><p><code>001-initC.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span> <span class="comment"># API版本</span><span class="attr">kind:</span> <span class="string">Pod</span> <span class="comment"># 资源类型</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">init-1</span> <span class="comment"># Pod名称</span>  <span class="attr">labels:</span> <span class="comment"># 标签</span>    <span class="attr">app:</span> <span class="string">initc</span><span class="attr">spec:</span> <span class="comment"># Pod 期望</span>  <span class="attr">containers:</span> <span class="comment"># 容器定义</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span> <span class="comment"># 容器名</span>      <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span> <span class="comment"># 该容器使用的镜像</span>      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;echo The app is running! &amp;&amp; sleep 3600&#x27;</span>]  <span class="attr">initContainers:</span> <span class="comment"># 初始化容器全部成功后，myapp-container容器才能启动成功</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-myservice</span> <span class="comment"># 第一个初始化容器，等待 myservice 的 DNS 解析成功。</span>      <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span>      <span class="attr">command:</span>        <span class="bullet">-</span> <span class="string">&#x27;sh&#x27;</span>        <span class="bullet">-</span> <span class="string">&#x27;-c&#x27;</span>        <span class="bullet">-</span> <span class="string">&#x27;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#x27;</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-mydb</span> <span class="comment"># 第二个初始化容器，等待 mydb 的 DNS 解析成功。 然后才会启动主容器 myapp-container。</span>      <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span>      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#x27;</span>]</code></pre><h3 id="2-2-2-pod-yaml文件解析"><a href="#2-2-2-pod-yaml文件解析" class="headerlink" title="2.2.2 pod yaml文件解析"></a>2.2.2 pod yaml文件解析</h3><pre><code class="highlight yaml"><span class="attr">containers:</span> <span class="comment"># 容器定义</span>  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span> <span class="comment"># 容器名</span>    <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span> <span class="comment"># 该容器使用的镜像</span>    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;echo The app is running! &amp;&amp; sleep 3600&#x27;</span>]</code></pre><p>主容器 <code>myapp-container</code> 启动成功后会打印内容：<code>The app is running!</code> ，并且 sleep 3600 秒</p><pre><code class="highlight yaml"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-myservice</span> <span class="comment"># 第一个初始化容器，等待 myservice 的 DNS 解析成功。</span>  <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span>  <span class="attr">command:</span>    <span class="bullet">-</span> <span class="string">&#x27;sh&#x27;</span>    <span class="bullet">-</span> <span class="string">&#x27;-c&#x27;</span>    <span class="bullet">-</span> <span class="string">&#x27;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#x27;</span></code></pre><p>第一个初始化容器：<code>init-myservice</code> 启动时会解析 DNS 域名：<code>myservice</code>， 解析成功则该初始化容器成功启动，解析失败则打印日志：<code>waiting for myservice</code>， 然后 sleep 2秒后，继续解析，直到成功为止。</p><pre><code class="highlight yaml"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-mydb</span> <span class="comment"># 第二个初始化容器，等待 mydb 的 DNS 解析成功。 然后才会启动主容器 myapp-container。</span>  <span class="attr">image:</span> <span class="string">gcr.io/google-containers/busybox:1.27</span>  <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#x27;</span>]</code></pre><p>第一个初始化容器：<code>init-mydb</code> 启动时会解析 DNS 域名：<code>mydb</code>， 解析成功则该初始化容器成功启动，解析失败则打印日志：<code>waiting for mydb</code>， 然后 sleep 2秒后，继续解析，直到成功为止。</p><h2 id="2-3-启动Pod测试"><a href="#2-3-启动Pod测试" class="headerlink" title="2.3 启动Pod测试"></a>2.3 启动Pod测试</h2><h3 id="2-3-1-启动pod"><a href="#2-3-1-启动pod" class="headerlink" title="2.3.1 启动pod"></a>2.3.1 启动pod</h3><pre><code class="highlight shell">kubectl apply -f /opt/k8s/04/001-initC.yaml</code></pre><p>此时观察Pod 启动情况</p><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl get podsNAME     READY   STATUS     RESTARTS   AGEinit-1   0/1     Init:0/2   0          2m42s<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">或者动态监控</span>[root@k8s-master01 ~]$ kubectl get pods -o wide -wNAME     READY   STATUS     RESTARTS   AGE    IP               NODE         NOMINATED NODE   READINESS GATESinit-1   0/1     Init:0/2   0          3m6s   192.168.85.193   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>此时可以看到 主容器未启动，且初始化容器未启动。</p><h3 id="2-3-2-查看初始化容器日志"><a href="#2-3-2-查看初始化容器日志" class="headerlink" title="2.3.2 查看初始化容器日志"></a>2.3.2 查看初始化容器日志</h3><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl logs -f --tail=100 init-1 -c init-myservicenslookup: can&#x27;t resolve &#x27;myservice&#x27;Server:    10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.localwaiting for myservicenslookup: can&#x27;t resolve &#x27;myservice&#x27;Server:    10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</code></pre><p><code>init-myservice</code> DNS未能解析名为 <code>myservice</code> 的服务，而此时初始化容器 <code>init-mydb</code> 还未启动。</p><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl logs -f --tail=100 init-1 -c init-mydbError from server (BadRequest): container &quot;init-mydb&quot; in pod &quot;init-1&quot; is waiting to start: PodInitializing</code></pre><h3 id="2-3-3-创建Service：myservice"><a href="#2-3-3-创建Service：myservice" class="headerlink" title="2.3.3 创建Service：myservice"></a>2.3.3 创建Service：myservice</h3><pre><code class="highlight shell">kubectl create svc clusterip myservice --tcp=80:80</code></pre><p>创建Service，名为 <code>myservice</code>，在k8s中默认名称即为域名，这样在集群中就有了一个域名为：myservice 的服务了。</p><p>此时再观察 Pod 的启动情况：</p><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl get podsNAME     READY   STATUS     RESTARTS   AGEinit-1   0/1     Init:1/2   0          13m</code></pre><p>初始化容器1已启动。</p><h3 id="2-3-4-观察初始化容器2：init-mydb"><a href="#2-3-4-观察初始化容器2：init-mydb" class="headerlink" title="2.3.4 观察初始化容器2：init-mydb"></a>2.3.4 观察初始化容器2：<code>init-mydb</code></h3><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl logs -f --tail=100 init-1 -c init-mydbServer:    10.96.0.10nslookup: can&#x27;t resolve &#x27;mydb&#x27;Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.localwaiting for mydbServer:    10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</code></pre><p><code>init-mydb</code> 容器未启动，因为无法解析域名：<code>mydb</code>，此时主容器 <code>myapp-container</code> 未启动，需要等待初始化容器都启动成功后才能启动主容器。</p><h3 id="2-3-5-创建Service：mydb"><a href="#2-3-5-创建Service：mydb" class="headerlink" title="2.3.5 创建Service：mydb"></a>2.3.5 创建Service：mydb</h3><pre><code class="highlight shell">kubectl create svc clusterip mydb --tcp=80:80</code></pre><p>此时再观察Pod启动情况</p><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl get pods -o wide -wNAME     READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESinit-1   1/1     Running   0          18m   192.168.85.193   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>初始化容器启动完成，主容器启动完成。</p><h3 id="2-3-6-查看容器启动日志"><a href="#2-3-6-查看容器启动日志" class="headerlink" title="2.3.6 查看容器启动日志"></a>2.3.6 查看容器启动日志</h3><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl logs -f --tail=100 init-1 -c myapp-containerThe app is running!</code></pre><p><strong>结论：</strong></p><ul><li>初始化容器必须全部启动完成后，主容器才能启动</li><li>初始化容器启动是有顺序的</li></ul><h1 id="3、探针"><a href="#3、探针" class="headerlink" title="3、探针"></a>3、探针</h1><h2 id="3-1-探针概述"><a href="#3-1-探针概述" class="headerlink" title="3.1 探针概述"></a>3.1 探针概述</h2><p>探针是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 调用由容器实现的 Handler。有三种类型的处理程序：</p><ul><li><code>ExecAction</code>：在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功</li><li><code>TCPSocketAction</code>：对指定端口上的容器的 IP 地址进行 TCP 检查。如果端口打开，则诊断被认为是成功的</li><li><code>HTTPGetAction</code>：对指定的端口和路径上的容器的 IP 地址执行 HTTP Get 请求。如果响应的状态码大于等于200 且小于 400，则诊断被认为是成功的</li></ul><p>每次探测都将获得以下三种结果之一：</p><ul><li>成功：容器通过了诊断。</li><li>失败：容器未通过诊断。</li><li>未知：诊断失败，因此不会采取任何行动</li></ul><h2 id="3-2-探针分类"><a href="#3-2-探针分类" class="headerlink" title="3.2 探针分类"></a>3.2 探针分类</h2><ul><li><code>startupProbe</code>：启动探测，用于检测容器是否已启动</li><li><code>livenessProbe</code>：存活探测，用于检测容器是否还存活</li><li><code>readinessProbe</code>：就绪探测，检查容器是否已就绪，可以对外提供服务了。</li></ul><h1 id="4、readinessProbe-就绪探针"><a href="#4、readinessProbe-就绪探针" class="headerlink" title="4、readinessProbe 就绪探针"></a>4、readinessProbe 就绪探针</h1><p>介绍：k8s 通过添加就绪探针，解决尤其是在扩容时保证提供给用户的服务都是可用的。</p><h2 id="4-1-选项说明"><a href="#4-1-选项说明" class="headerlink" title="4.1 选项说明"></a>4.1 选项说明</h2><ul><li><code>initialDelaySeconds</code>：容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</li><li><code>periodSeconds</code>：执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</li><li><code>timeoutSeconds</code>：探针执行检测请求后，等待响应的超时时间，默认为 1s，单位“秒”，最小值是 1</li><li><code>successThreshold</code>：探针检测失败后认为成功的最小连接成功次数，默认值为 1。必须为 1 才能激活和启动。最小值为1</li><li><code>failureThreshold</code>：探测失败的重试次数，重试一定次数后将认为失败，默认值为 3 ，最小值为 1。</li></ul><h2 id="4-2-案例：基于HTTP-Get-方式"><a href="#4-2-案例：基于HTTP-Get-方式" class="headerlink" title="4.2 案例：基于HTTP Get 方式"></a>4.2 案例：基于HTTP Get 方式</h2><p><code>002-readiness-http.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">readiness-httpget-pod</span> <span class="comment"># pod 名</span>  <span class="attr">namespace:</span> <span class="string">default</span> <span class="comment"># 名称空间</span>  <span class="attr">labels:</span> <span class="comment"># 定义多个标签</span>    <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">env:</span> <span class="string">test</span><span class="attr">spec:</span>  <span class="attr">containers:</span> <span class="comment"># 定义主容器</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-httpget-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取策略，如果存在则不拉取</span>      <span class="attr">readinessProbe:</span> <span class="comment"># 定义就绪探测</span>        <span class="attr">httpGet:</span> <span class="comment"># http请求</span>          <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># 请求端口</span>          <span class="attr">path:</span> <span class="string">/index1.html</span> <span class="comment"># 访问资源地址</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">1</span> <span class="comment"># 容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</span>        <span class="attr">periodSeconds:</span> <span class="number">30</span> <span class="comment"># 执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</span>        <span class="attr">timeoutSeconds:</span> <span class="number">1</span> <span class="comment"># 探针执行检测请求后，等待响应的超时时间，默认为 1s，单位“秒”，最小值是 1</span>        <span class="attr">successThreshold:</span> <span class="number">1</span> <span class="comment"># 探针检测失败后认为成功的最小连接成功次数，默认值为 1。必须为 1 才能激活和启动。最小值为1</span>        <span class="attr">failureThreshold:</span> <span class="number">10</span> <span class="comment"># 探测失败的重试次数，重试一定次数后将认为失败，默认值为 3 ，最小值为 1</span></code></pre><p><strong>创建Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">创建Pod</span>kubectl apply -f /opt/k8s/04/002-readiness-http.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行情况</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get podsNAME                    READY   STATUS    RESTARTS   AGEreadiness-httpget-pod   0/1     Running   0          8s</code></pre><p>Pod已启动，但是未就绪，下面查看日志，直到Pod未就绪的原因</p><p><strong>查看Pod日志</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">查看Pod日志</span>kubectl logs -f readiness-httpget-pod<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">日志内容如下</span>192.168.142.202 - - [22/Mar/2025:23:59:58 +0800] &quot;GET /index1.html HTTP/1.1&quot; 404 153 &quot;-&quot; &quot;kube-probe/1.29&quot;2025/03/22 23:59:58 [error] 7#7: *1 open() &quot;/usr/local/nginx/html/index1.html&quot; failed (2: No such file or directory), client: 192.168.142.202, server: localhost, request: &quot;GET /index1.html HTTP/1.1&quot;, host: &quot;192.168.58.196:80&quot;</code></pre><p>可以发现Pod在做就绪检测，访问 <a href="http://192.168.58.196/index1.html">http://192.168.58.196:80/index1.html</a> 结果404，就绪检测未通过，因此Pod处于未就绪状态。</p><p><strong>进入Pod内容，创建资源文件，让Pod就绪检测通过</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">进入Pod容器内部</span>[root@k8s-master01 /opt/k8s/04]$ kubectl exec -it readiness-httpget-pod /bin/bash<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">创建资源文件</span>readiness-httpget-pod:/# cd /usr/local/nginx/html/readiness-httpget-pod:/usr/local/nginx/html# ls50x.html       hostname.html  index.htmlreadiness-httpget-pod:/usr/local/nginx/html# cp index.html index1.html readiness-httpget-pod:/usr/local/nginx/html# exitexit<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">再次查看Pod运行状态，Pod已处于就绪状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get podsNAME                    READY   STATUS    RESTARTS   AGEreadiness-httpget-pod   1/1     Running   0          95s</code></pre><h2 id="4-3-案例：基于EXEC方式"><a href="#4-3-案例：基于EXEC方式" class="headerlink" title="4.3 案例：基于EXEC方式"></a>4.3 案例：基于EXEC方式</h2><p>就绪检测在容器从启动到关闭的整个周期内都是有效的，例如容器刚启动时，就绪检测通过了，</p><p><code>003-readiness-exec.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">readiness-exec-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">env:</span> <span class="string">test</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取策略，如果存在则不拉取</span>      <span class="comment"># 主容器启动成功后自动创建目录 /tmp/live, 60秒后删除该目录，</span>      <span class="attr">command:</span> [<span class="string">&#x27;/bin/sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;touch /tmp/live; sleep 60; rm -rf /tmp/live; sleep 3600&#x27;</span>]      <span class="attr">readinessProbe:</span>        <span class="attr">exec:</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&#x27;test&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;-e&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;/tmp/live&#x27;</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">2</span> <span class="comment"># 容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span> <span class="comment"># 执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</span></code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 003-readiness-exec.yaml <span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get podsNAME                 READY   STATUS    RESTARTS   AGEreadiness-exec-pod   1/1     Running   0          5s</code></pre><p>由于主容器 <code>readiness-exec-container</code> 在启动成功后创建目录 <code>/tmp/live</code> ，因此 exec 就绪检测在容器刚启动时会通过。但在容器启动60秒后会删除目录 <code>/tmp/live</code>，由于就绪检测会持续不断的进行，因此此时就绪检测会失败。</p><p><strong>再次查看Pod运行状态</strong></p><pre><code class="highlight shell">[root@k8s-master01 /opt/k8s/04]$ kubectl get podsNAME                 READY   STATUS    RESTARTS   AGEreadiness-exec-pod   0/1     Running   0          15m</code></pre><p>Pod此时处于未就绪状态</p><h2 id="4-4-案例：基于-TCP-Check-方式"><a href="#4-4-案例：基于-TCP-Check-方式" class="headerlink" title="4.4 案例：基于 TCP Check 方式"></a>4.4 案例：基于 TCP Check 方式</h2><p><code>004-readiness-tcp.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">readiness-tcp-pod</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">readinessProbe:</span> <span class="comment"># 定义就绪检测</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">3</span>        <span class="attr">timeoutSeconds:</span> <span class="number">1</span>        <span class="attr">tcpSocket:</span> <span class="comment"># 探测 tcp 端口</span>          <span class="attr">port:</span> <span class="number">80</span></code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 004-readiness-tcp.yaml <span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get podsNAME                READY   STATUS    RESTARTS   AGEreadiness-tcp-pod   1/1     Running   0          10s</code></pre><h1 id="5、livenessProbe-存活探针"><a href="#5、livenessProbe-存活探针" class="headerlink" title="5、livenessProbe 存活探针"></a>5、livenessProbe 存活探针</h1><p>介绍：k8s 通过添加存活探针，解决虽然活着但是已经死了的问题。</p><h2 id="5-1-选项说明："><a href="#5-1-选项说明：" class="headerlink" title="5.1 选项说明："></a>5.1 选项说明：</h2><ul><li><code>initialDelaySeconds</code>：容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</li><li><code>periodSeconds</code>：执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</li><li><code>timeoutSeconds</code>：探针执行检测请求后，等待响应的超时时间，默认为 1s，单位“秒”，最小值是 1</li><li><code>successThreshold</code>：探针检测失败后认为成功的最小连接成功次数，默认值为 1。必须为 1 才能激活和启动。最小值为1</li><li><code>failureThreshold</code>：探测失败的重试次数，重试一定次数后将认为失败，默认值为 3 ，最小值为 1。</li></ul><h2 id="5-2-案例：基于-HTTP-Get-方式"><a href="#5-2-案例：基于-HTTP-Get-方式" class="headerlink" title="5.2 案例：基于 HTTP Get 方式"></a>5.2 案例：基于 HTTP Get 方式</h2><p><code>005-liveness-httpget.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">liveness-httpget-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness-httpget-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span> <span class="comment"># 指定容器暴露的端口，这里是 80 端口（通常用于 HTTP 服务）</span>          <span class="attr">name:</span> <span class="string">http</span> <span class="comment"># 为这个端口命名，方便引用（例如在 Service 中）。</span>      <span class="attr">livenessProbe:</span> <span class="comment"># 定义存活探针（Liveness Probe），用于检查容器是否健康。如果探针失败，Kubernetes 会重启容器。</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">2</span> <span class="comment"># 容器启动后，探针延迟 2 秒开始首次检查。这给应用留出启动时间。</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span> <span class="comment"># 探针检查的频率，每 3 秒执行一次。</span>        <span class="attr">successThreshold:</span> <span class="number">1</span> <span class="comment"># 探针成功的次数阈值，设置为 1 表示一次成功即认为容器健康。</span>        <span class="attr">failureThreshold:</span> <span class="number">3</span> <span class="comment"># 探针失败的次数阈值，设置为 3 表示连续 3 次失败后，Kubernetes 会重启容器。</span>        <span class="attr">httpGet:</span> <span class="comment"># 定义探针类型为 HTTP GET 请求。</span>          <span class="attr">port:</span> <span class="number">80</span> <span class="comment"># 请求的目标端口，这里是容器的 80 端口。</span>          <span class="attr">path:</span> <span class="string">/index1.html</span> <span class="comment"># 请求的路径，探针会访问 http://&lt;容器IP&gt;:80/index1.html。如果返回状态码 200-399，则认为容器健康。</span></code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 005-liveness-httpget.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get pods -o wide -wNAME                   READY   STATUS    RESTARTS      AGE    IP               NODE         NOMINATED NODE   READINESS GATESliveness-httpget-pod   1/1     Running   5 (65s ago)   100s   192.168.85.198   k8s-node01   &lt;none&gt;           &lt;none&gt;liveness-httpget-pod   0/1     CrashLoopBackOff   5 (23s ago)   109s   192.168.85.198   k8s-node01   &lt;none&gt;           &lt;none&gt;liveness-httpget-pod   1/1     Running            6 (113s ago)   3m19s   192.168.85.198   k8s-node01   &lt;none&gt;           &lt;none&gt;liveness-httpget-pod   0/1     CrashLoopBackOff   6 (23s ago)    3m28s   192.168.85.198   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>Pod由最开始的 Running 状态，然后容器启动2秒后存活探针开始工作，检测 http:&#x2F;&#x2F;&lt;容器IP&gt;:80&#x2F;index1.html 资源不存在，于是间隔 periodSeconds 时长再次检测，连续失败 failureThreshold 次，容器重启。循环这个操作。</p><h2 id="5-3-案例：基于-Exec-方式"><a href="#5-3-案例：基于-Exec-方式" class="headerlink" title="5.3 案例：基于 Exec 方式"></a>5.3 案例：基于 Exec 方式</h2><p><code>006-liveness-exec.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">readiness-exec-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">env:</span> <span class="string">test</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取策略，如果存在则不拉取</span>      <span class="comment"># 主容器启动成功后自动创建目录 /tmp/live, 60秒后删除该目录，</span>      <span class="attr">command:</span> [<span class="string">&#x27;/bin/sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;touch /tmp/live; sleep 30; rm -rf /tmp/live; sleep 3600&#x27;</span>]      <span class="attr">livenessProbe:</span>        <span class="attr">exec:</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&#x27;test&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;-e&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;/tmp/live&#x27;</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">2</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span></code></pre><p><strong>启动Pod，查看运行状态</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 006-liveness-exec.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">监控Pod运行状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get pods -o wide -wNAME                 READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESreadiness-exec-pod   1/1     Running   0          12s   192.168.85.199   k8s-node01   &lt;none&gt;           &lt;none&gt;readiness-exec-pod   1/1     Running   1 (23s ago)   71s   192.168.85.199   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>Pod刚启动时，会自动创建目录 <code>/tmp/live</code>, <code>initialDelaySeconds</code> 秒后开始存活探测，此时Pod的存活探测是通过的。30秒后容器把目录  <code>/tmp/live</code> 删掉了，由于存活探测是持续轮询执行的，这时的存活探测就是失败的，当连续3次（默认failureThreshold是3）的探测失败后，容器会重启。</p><h2 id="5-4-案例：基于-TCP-Check-方式"><a href="#5-4-案例：基于-TCP-Check-方式" class="headerlink" title="5.4 案例：基于 TCP Check 方式"></a>5.4 案例：基于 TCP Check 方式</h2><p><code>007-liveness-tcp.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">readiness-tcp-pod</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>          <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">livenessProbe:</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">2</span>        <span class="attr">timeoutSeconds:</span> <span class="number">1</span>        <span class="attr">tcpSocket:</span>          <span class="attr">port:</span> <span class="number">80</span></code></pre><p><strong>启动Pod，查看状态</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 007-liveness-tcp.yaml <span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod的运行状态</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get pods -o wide -wNAME                READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESreadiness-tcp-pod   1/1     Running   0          14s   192.168.85.200   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><h1 id="6、startupProbe-启动探针"><a href="#6、startupProbe-启动探针" class="headerlink" title="6、startupProbe 启动探针"></a>6、startupProbe 启动探针</h1><p>介绍：k8s 在 1.16 版本后增加 startupProbe 探针，主要解决在复杂的程序中 readinessProbe、livenessProbe 探针无法更好的判断程序是否启动、是否存活。</p><h2 id="6-1-选项说明"><a href="#6-1-选项说明" class="headerlink" title="6.1 选项说明"></a>6.1 选项说明</h2><ul><li>initialDelaySeconds：容器启动后要等待多少秒后就探针开始工作，单位“秒”，默认是 0 秒，最小值是 0</li><li>periodSeconds：执行探测的时间间隔（单位是秒），默认为 10s，单位“秒”，最小值是 1</li><li>timeoutSeconds：探针执行检测请求后，等待响应的超时时间，默认为 1s，单位“秒”，最小值是 1</li><li>successThreshold：探针检测失败后认为成功的最小连接成功次数，默认值为 1。必须为 1 才能激活和启动。最小值为1</li><li>failureThreshold：探测失败的重试次数，重试一定次数后将认为失败，默认值为 3 ，最小值为 1。</li></ul><h2 id="6-2-案例：基于-HTTP-Get-方式"><a href="#6-2-案例：基于-HTTP-Get-方式" class="headerlink" title="6.2 案例：基于 HTTP Get 方式"></a>6.2 案例：基于 HTTP Get 方式</h2><p><code>008-startup-probe.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">startup-probe-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">startup-probe-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>          <span class="attr">name:</span> <span class="string">http</span>      <span class="attr">startupProbe:</span> <span class="comment"># 定义启动探针</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">0</span>        <span class="attr">successThreshold:</span> <span class="number">1</span>        <span class="attr">failureThreshold:</span> <span class="number">30</span>        <span class="attr">periodSeconds:</span> <span class="number">10</span>        <span class="attr">httpGet:</span>          <span class="attr">port:</span> <span class="number">80</span>          <span class="attr">path:</span> <span class="string">/index1.html</span></code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 008-startup-probe.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">监控Pod运行状态</span>[root@k8s-master01 ~]$ kubectl get pods -o wide -wNAME                READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESstartup-probe-pod   0/1     Running   0          97s   192.168.85.201   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>由于容器内没有 index1.html 资源，启动探测失败，因此Pod处于未就绪状态。</p><p><strong>进入容器，创建 index1.html</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">进入容器</span>[root@k8s-master01 /opt/k8s/04]$ kubectl exec -it startup-probe-pod /bin/bashstartup-probe-pod:/# cd /usr/local/nginx/html/startup-probe-pod:/usr/local/nginx/html# ls50x.html       hostname.html  index.html<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">创建 index1.html</span>startup-probe-pod:/usr/local/nginx/html# cp index.html index1.html</code></pre><p><strong>再次查看Pod运行状态</strong></p><pre><code class="highlight shell">[root@k8s-master01 ~]$ kubectl get pods -o wide -wNAME                READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESstartup-probe-pod   0/1     Running   0          97s   192.168.85.201   k8s-node01   &lt;none&gt;           &lt;none&gt;startup-probe-pod   1/1     Running   0          111s   192.168.85.201   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>此时Pod变成已就绪状态。由于 <code>008-startup-probe.yaml</code> 文件中没有定义就绪检测，因此启动探测成功后，默认就绪检测成功。</p><p><strong>注意：应用程序将会有最多 5 分钟 failureThreshold * periodSeconds（30 * 10 &#x3D; 300s）的时间来完成其启动过程。</strong></p><h2 id="6-3-案例：基于EXEC方式"><a href="#6-3-案例：基于EXEC方式" class="headerlink" title="6.3 案例：基于EXEC方式"></a>6.3 案例：基于EXEC方式</h2><p><code>009-startup-exec.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">startup-exec-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span>    <span class="attr">env:</span> <span class="string">test</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">startup-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span> <span class="comment"># 镜像拉取策略，如果存在则不拉取</span>      <span class="comment"># 主容器启动成功后自动创建目录 /tmp/live, 3秒后删除该目录，</span>      <span class="attr">command:</span> [<span class="string">&#x27;/bin/sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;touch /tmp/live; sleep 3; rm -rf /tmp/live; sleep 3600&#x27;</span>]      <span class="attr">startupProbe:</span>        <span class="attr">exec:</span>          <span class="attr">command:</span>            <span class="bullet">-</span> <span class="string">&#x27;test&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;-e&#x27;</span>            <span class="bullet">-</span> <span class="string">&#x27;/tmp/live&#x27;</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">4</span> <span class="comment"># 延迟4秒后启动探测，此时 /tmp/live 文件夹已被删除</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span></code></pre><p><strong>启动Pod，查看状态</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 009-startup-exec.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行状态</span>[root@k8s-master01 ~]$ kubectl get pods -o wide -wNAME               READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATESstartup-exec-pod   0/1     Running   0          6s    192.168.85.203   k8s-node01   &lt;none&gt;           &lt;none&gt;startup-exec-pod   0/1     Running   1 (22s ago)   43s   192.168.85.203   k8s-node01   &lt;none&gt;           &lt;none&gt;</code></pre><p>启动探测失败，Pod未就绪。</p><h1 id="7、钩子"><a href="#7、钩子" class="headerlink" title="7、钩子"></a>7、钩子</h1><h2 id="7-1-钩子概述"><a href="#7-1-钩子概述" class="headerlink" title="7.1 钩子概述"></a>7.1 钩子概述</h2><p>Pod hook（钩子）是由 Kubernetes 管理的 kubelet 发起的，当容器中的**进程启动前(其实是启动后，对应：postStart)<strong>或者容器中的</strong>进程终止之前(对应：preStop)*<em>运行，这是包含在容器的生命周期之中。</em>可以同时为 Pod 中的所有容器都配置 hook*</p><p>Hook 的类型包括两种：</p><ul><li><code>exec</code>：执行一段命令</li><li><code>HTTP</code>：发送 HTTP 请求</li></ul><h2 id="7-2-案例：基于-Exec-方式"><a href="#7-2-案例：基于-Exec-方式" class="headerlink" title="7.2 案例：基于 Exec 方式"></a>7.2 案例：基于 Exec 方式</h2><p><code>010-hook-exec.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">lifecycle-exec-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lifecycle-exec-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1</span>      <span class="attr">lifecycle:</span>        <span class="attr">postStart:</span> <span class="comment"># 启动后钩子</span>          <span class="attr">exec:</span>            <span class="attr">command:</span>              <span class="bullet">-</span> <span class="string">&#x27;/bin/sh&#x27;</span>              <span class="bullet">-</span> <span class="string">&#x27;-c&#x27;</span>              <span class="bullet">-</span> <span class="string">&#x27;echo postStart &gt; /usr/share/message&#x27;</span>        <span class="attr">preStop:</span> <span class="comment"># 关闭前钩子</span>          <span class="attr">exec:</span>            <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;echo preStop &gt; /usr/share/message&quot;</span>]</code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 010-hook-exec.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod运行情况</span>[root@k8s-master01 /opt/k8s/04]$ kubectl get pods -o wide -wNAME                 READY   STATUS              RESTARTS   AGE   IP       NODE         NOMINATED NODE   READINESS GATESlifecycle-exec-pod   0/1     ContainerCreating   0          4s    &lt;none&gt;   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-exec-pod   0/1     ContainerCreating   0          9s    &lt;none&gt;   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-exec-pod   1/1     Running             0          16s   172.16.58.195   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre><p>Pod已成功启动，并就绪</p><p><strong>测试启动后钩子是否生效</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">进入Pod</span>kubectl exec -it lifecycle-exec-pod /bin/bash<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">在容器内查看启动后钩子执行的脚本是否生效</span>lifecycle-exec-pod:/# cat /usr/share/messagepostStart</code></pre><p>可以发现 “postStart” 已被写入文件中</p><p><strong>测试关闭前钩子是否生效</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">1.进入Pod容器中</span>kubectl exec -it lifecycle-exec-pod /bin/bash<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">2.在容器内写一段脚本持续读取输出 /usr/share/message</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">脚本内容如下：</span><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">无限循环执行 <span class="built_in">cat</span> /usr/share/message</span>while true; do    cat /usr/share/messagedone<span class="meta prompt_"></span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">3.给脚本授权（容器内操作）</span>chmod +x 123.sh<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">4.执行脚本（容器内操作）</span>sh 123.sh<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">5.新起一个shell终端，执行关闭Pod操作</span>kubectl delete -f 010-hook-exec.yaml<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">6.查看脚本打印内容</span>......preStoppreStoppreStop......</code></pre><p>可以看到关闭前钩子在容器被杀死前，执行了 <code>echo preStop &gt; /usr/share/message</code> </p><h2 id="7-3-案例：基于HTTP-Get请求"><a href="#7-3-案例：基于HTTP-Get请求" class="headerlink" title="7.3 案例：基于HTTP Get请求"></a>7.3 案例：基于HTTP Get请求</h2><p><strong>测试容器</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">开启一个测试 webServer</span><span class="meta prompt_">$ </span><span class="language-bash">docker run -itd --<span class="built_in">rm</span> -p 1234:80 --name=<span class="built_in">test</span> wangyanglinux/myapp:v1.0</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">监控测试容器的日志打印情况</span><span class="meta prompt_">$ </span><span class="language-bash">docker logs -f --<span class="built_in">tail</span> 1000 <span class="built_in">test</span></span></code></pre><p><code>011-hook-http.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">lifecycle-http-pod</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myApp</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lifecycle-httpget-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">lifecycle:</span>        <span class="attr">postStart:</span> <span class="comment"># 启动后钩子</span>          <span class="attr">httpGet:</span> <span class="comment"># 基于Http Get 请求方式</span>            <span class="attr">port:</span> <span class="number">1234</span> <span class="comment"># http 访问端口</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span> <span class="comment"># http访问Host地址</span>            <span class="attr">path:</span> <span class="string">index.html</span> <span class="comment"># http访问资源路径</span>        <span class="attr">preStop:</span>          <span class="attr">httpGet:</span>            <span class="attr">port:</span> <span class="number">1234</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span>            <span class="attr">path:</span> <span class="string">hostname.html</span></code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f 011-hook-http.yaml</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看测试容器的日志</span>[root@k8s-master01 /opt/k8s/04]$ docker logs -f --tail 1000 test192.168.6.141 - - [02/Apr/2025:10:26:16 +0800] &quot;GET /index.html HTTP/1.1&quot; 200 48 &quot;-&quot; &quot;kube-lifecycle/1.29&quot;</code></pre><p>pod启动成功，并执行了 postStart 定义的Http Get请求，访问了 <a href="http://192.168.6.139:1234/index.html">http://192.168.6.139:1234/index.html</a> </p><p><strong>停止Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">删除Pod</span><span class="meta prompt_">$ </span><span class="language-bash">kubectl delete -f 011-hook-http.yaml</span><span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看测试容器的日志</span>[root@k8s-master01 /opt/k8s/04]$ docker logs -f --tail 1000 test192.168.6.141 - - [02/Apr/2025:10:26:16 +0800] &quot;GET /index.html HTTP/1.1&quot; 200 48 &quot;-&quot; &quot;kube-lifecycle/1.29&quot;192.168.6.141 - - [02/Apr/2025:10:28:44 +0800] &quot;GET /hostname.html HTTP/1.1&quot; 200 13 &quot;-&quot; &quot;kube-lifecycle/1.29&quot;</code></pre><p>Pod在关闭前，执行了 preStop 定义的Http Get 请求，访问了 <a href="http://192.168.6.139:1234/hostname.html">http://192.168.6.139:1234/hostname.html</a> </p><h2 id="7-4-关于-preStop-的延伸"><a href="#7-4-关于-preStop-的延伸" class="headerlink" title="7.4 关于 preStop 的延伸"></a>7.4 关于 preStop 的延伸</h2><p>在 k8s 中，理想的状态是 pod 优雅释放，但是并不是每一个 Pod 都会这么顺利</p><ul><li>Pod 卡死，处理不了优雅退出的命令或者操作</li><li>优雅退出的逻辑有 BUG，陷入死循环</li><li>代码问题，导致执行的命令没有效果</li></ul><p>对于以上问题，k8s 的 Pod 终止流程中还有一个 “最多可以容忍的时间”，即 grace period ( 在 <code>pod.spec.terminationGracePeriodSeconds</code> 字段定义)，这个值默认是 30 秒，当我们执行 <code>kubectl delete</code>  的时候也可以通过 <code>--grace-period</code> 参数显示指定一个优雅退出时间来覆盖 Pod 中的配置，如果我们配置的 grace period 超过时间之后，k8s 就只能选择强制 kill Pod。值得注意的是，这与preStop Hook和 SIGTERM 信号并行发生。k8s 不会等待 preStop Hook 完成。如果你的应用程序完成关闭并在terminationGracePeriod 完成之前退出，k8s  会立即进入下一步</p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">name:</span> <span class="string">lifecycle-http-pod</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myApp</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lifecycle-httpget-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">ports:</span>        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span>      <span class="attr">lifecycle:</span>        <span class="attr">postStart:</span> <span class="comment"># 启动后钩子</span>          <span class="attr">httpGet:</span> <span class="comment"># 基于Http Get 请求方式</span>            <span class="attr">port:</span> <span class="number">1234</span> <span class="comment"># http 访问端口</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span> <span class="comment"># http访问Host地址</span>            <span class="attr">path:</span> <span class="string">index.html</span> <span class="comment"># http访问资源路径</span>        <span class="attr">preStop:</span>          <span class="attr">httpGet:</span>            <span class="attr">port:</span> <span class="number">1234</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span>            <span class="attr">path:</span> <span class="string">hostname.html</span>  <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span> <span class="comment"># 如果执行 kubectl delete 不能顺利将pod关闭，最长30秒强制杀死pod</span></code></pre><h1 id="8、Pod生命周期完整演示"><a href="#8、Pod生命周期完整演示" class="headerlink" title="8、Pod生命周期完整演示"></a>8、Pod生命周期完整演示</h1><p><code>012-lifecycle-all.yaml</code></p><pre><code class="highlight yaml"><span class="attr">apiVersion:</span> <span class="string">v1</span><span class="attr">kind:</span> <span class="string">Pod</span><span class="attr">metadata:</span>  <span class="attr">name:</span> <span class="string">lifecycle-pod</span>  <span class="attr">namespace:</span> <span class="string">default</span>  <span class="attr">labels:</span>    <span class="attr">app:</span> <span class="string">myapp</span><span class="attr">spec:</span>  <span class="attr">containers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox-container</span> <span class="comment"># 主容器1</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/tools:busybox</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;touch /tmp/live ; sleep 600; rm -rf /tmp/live; sleep 3600&quot;</span>]      <span class="attr">livenessProbe:</span> <span class="comment"># 主容器1存活探针</span>        <span class="attr">exec:</span> <span class="comment"># 基于 exec执行命令，探测主容器内文件是否存在</span>          <span class="attr">command:</span> [<span class="string">&quot;test&quot;</span>,<span class="string">&quot;-e&quot;</span>,<span class="string">&quot;/tmp/live&quot;</span>]        <span class="attr">initialDelaySeconds:</span> <span class="number">1</span> <span class="comment"># 容器启动1秒后探测</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span> <span class="comment"># 循环3秒</span>      <span class="attr">lifecycle:</span>        <span class="attr">postStart:</span>          <span class="attr">httpGet:</span>            <span class="attr">port:</span> <span class="number">1234</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span>            <span class="attr">path:</span> <span class="string">index.html</span>        <span class="attr">preStop:</span>          <span class="attr">httpGet:</span>            <span class="attr">port:</span> <span class="number">1234</span>            <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.139</span>            <span class="attr">path:</span> <span class="string">hostname.html</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1.0</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">livenessProbe:</span>        <span class="attr">httpGet:</span>          <span class="attr">port:</span> <span class="number">80</span>          <span class="attr">path:</span> <span class="string">/index.html</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">1</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span>        <span class="attr">timeoutSeconds:</span> <span class="number">3</span> <span class="comment"># http Get 请求超时时间(秒)</span>      <span class="attr">readinessProbe:</span>        <span class="attr">httpGet:</span>          <span class="attr">port:</span> <span class="number">80</span>          <span class="attr">path:</span> <span class="string">/index1.html</span>        <span class="attr">initialDelaySeconds:</span> <span class="number">1</span>        <span class="attr">periodSeconds:</span> <span class="number">3</span>        <span class="attr">timeoutSeconds:</span> <span class="number">3</span>  <span class="attr">initContainers:</span>    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-myservice</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/tools:busybox</span>      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span>      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#x27;</span>]    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-mydb</span>      <span class="attr">image:</span> <span class="string">wangyanglinux/tools:busybox</span>      <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#x27;</span>]</code></pre><p><strong>启动Pod</strong></p><pre><code class="highlight shell"><span class="meta prompt_"># </span><span class="language-bash">启动Pod</span>kubectl apply -f 012-lifecycle-all.yaml <span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看Pod日志</span>kubectl logs -f --tail=100 lifecycle-pod<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">查看initC日志</span>kubectl logs -f --tail=100 lifecycle-pod -c init-myservicekubectl logs -f --tail=100 lifecycle-pod -c init-mydb<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">创建initC需要的service</span>kubectl create svc clusterip myservice --tcp=80:80kubectl logs -f --tail=100 lifecycle-pod -c init-myservicekubectl logs -f --tail=100 lifecycle-pod -c init-mydbkubectl create svc clusterip mydb --tcp=80:80<span class="meta prompt_"></span><span class="meta prompt_"># </span><span class="language-bash">进入主容器</span>kubectl exec -it lifecycle-pod -c myapp-container /bin/bash<span class="meta prompt_"># </span><span class="language-bash">创建主容器就绪检测所需资源</span>cd /usr/local/nginx/html/cp index.html index1.html</code></pre><p>完成以上操作后，此Pod才能真正完整运行起来。</p><p><strong>Pod运行监控</strong></p><pre><code class="highlight shell"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod -o wide -w</span>NAME            READY   STATUS     RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATESlifecycle-pod   0/2     Init:0/2   0          43s   172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-pod   0/2     Init:1/2   0          3m21s   172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-pod   0/2     Init:1/2   0          3m26s   172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-pod   0/2     PodInitializing   0          4m7s    172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-pod   1/2     Running           0          4m17s   172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;lifecycle-pod   2/2     Running           0          5m45s   172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;系统环境&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;RockyLinux：9.3&lt;/p&gt;
&lt;p&gt;K8s版本：1.29&lt;/p&gt;
&lt;p&gt;Docker版本：27.4.1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;1、Pod生命周期概述&quot;&gt;</summary>
      
    
    
    
    <category term="k8s" scheme="https://georgechan95.github.io/categories/k8s/"/>
    
    
    <category term="linux" scheme="https://georgechan95.github.io/tags/linux/"/>
    
    <category term="Docker" scheme="https://georgechan95.github.io/tags/Docker/"/>
    
    <category term="Rocky" scheme="https://georgechan95.github.io/tags/Rocky/"/>
    
  </entry>
  
</feed>
